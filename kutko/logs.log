2025-03-24 14:53:38,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 14:53:38,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 14:53:38,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 14:53:38,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 14:53:53,427:INFO:PyCaret RegressionExperiment
2025-03-24 14:53:53,427:INFO:Logging name: reg-default-name
2025-03-24 14:53:53,428:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-24 14:53:53,428:INFO:version 3.3.2
2025-03-24 14:53:53,428:INFO:Initializing setup()
2025-03-24 14:53:53,428:INFO:self.USI: 7067
2025-03-24 14:53:53,428:INFO:self._variable_keys: {'_ml_usecase', 'html_param', 'fold_shuffle_param', 'transform_target_param', 'exp_id', 'X_test', 'X_train', 'memory', 'y_test', 'exp_name_log', 'gpu_param', 'USI', 'y', 'seed', 'fold_generator', 'X', 'idx', 'pipeline', 'target_param', 'gpu_n_jobs_param', 'n_jobs_param', 'fold_groups_param', 'logging_param', 'log_plots_param', '_available_plots', 'y_train', 'data'}
2025-03-24 14:53:53,428:INFO:Checking environment
2025-03-24 14:53:53,428:INFO:python_version: 3.10.16
2025-03-24 14:53:53,428:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-24 14:53:53,428:INFO:machine: AMD64
2025-03-24 14:53:53,428:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-24 14:53:53,431:INFO:Memory: svmem(total=33411727360, available=15402250240, percent=53.9, used=18009477120, free=15402250240)
2025-03-24 14:53:53,432:INFO:Physical Core: 6
2025-03-24 14:53:53,432:INFO:Logical Core: 12
2025-03-24 14:53:53,432:INFO:Checking libraries
2025-03-24 14:53:53,432:INFO:System:
2025-03-24 14:53:53,432:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-24 14:53:53,432:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-24 14:53:53,432:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-24 14:53:53,432:INFO:PyCaret required dependencies:
2025-03-24 14:53:53,433:INFO:                 pip: 25.0.1
2025-03-24 14:53:53,433:INFO:          setuptools: 75.8.2
2025-03-24 14:53:53,433:INFO:             pycaret: 3.3.2
2025-03-24 14:53:53,433:INFO:             IPython: 8.34.0
2025-03-24 14:53:53,433:INFO:          ipywidgets: 8.1.5
2025-03-24 14:53:53,433:INFO:                tqdm: 4.67.1
2025-03-24 14:53:53,433:INFO:               numpy: 1.26.4
2025-03-24 14:53:53,433:INFO:              pandas: 2.1.4
2025-03-24 14:53:53,433:INFO:              jinja2: 3.1.6
2025-03-24 14:53:53,433:INFO:               scipy: 1.11.4
2025-03-24 14:53:53,433:INFO:              joblib: 1.3.2
2025-03-24 14:53:53,433:INFO:             sklearn: 1.4.2
2025-03-24 14:53:53,433:INFO:                pyod: 2.0.2
2025-03-24 14:53:53,433:INFO:            imblearn: 0.13.0
2025-03-24 14:53:53,433:INFO:   category_encoders: 2.7.0
2025-03-24 14:53:53,433:INFO:            lightgbm: 4.6.0
2025-03-24 14:53:53,433:INFO:               numba: 0.61.0
2025-03-24 14:53:53,433:INFO:            requests: 2.32.3
2025-03-24 14:53:53,433:INFO:          matplotlib: 3.10.1
2025-03-24 14:53:53,433:INFO:          scikitplot: 0.3.7
2025-03-24 14:53:53,433:INFO:         yellowbrick: 1.5
2025-03-24 14:53:53,433:INFO:              plotly: 6.0.1
2025-03-24 14:53:53,433:INFO:    plotly-resampler: Not installed
2025-03-24 14:53:53,433:INFO:             kaleido: 0.2.1
2025-03-24 14:53:53,433:INFO:           schemdraw: 0.15
2025-03-24 14:53:53,433:INFO:         statsmodels: 0.14.4
2025-03-24 14:53:53,433:INFO:              sktime: 0.26.0
2025-03-24 14:53:53,433:INFO:               tbats: 1.1.3
2025-03-24 14:53:53,433:INFO:            pmdarima: 2.0.4
2025-03-24 14:53:53,433:INFO:              psutil: 7.0.0
2025-03-24 14:53:53,433:INFO:          markupsafe: 3.0.2
2025-03-24 14:53:53,433:INFO:             pickle5: Not installed
2025-03-24 14:53:53,433:INFO:         cloudpickle: 3.1.1
2025-03-24 14:53:53,433:INFO:         deprecation: 2.1.0
2025-03-24 14:53:53,433:INFO:              xxhash: 3.5.0
2025-03-24 14:53:53,433:INFO:           wurlitzer: 3.1.1
2025-03-24 14:53:53,433:INFO:PyCaret optional dependencies:
2025-03-24 14:53:53,441:INFO:                shap: Not installed
2025-03-24 14:53:53,442:INFO:           interpret: Not installed
2025-03-24 14:53:53,442:INFO:                umap: 0.5.7
2025-03-24 14:53:53,442:INFO:     ydata_profiling: Not installed
2025-03-24 14:53:53,442:INFO:  explainerdashboard: Not installed
2025-03-24 14:53:53,442:INFO:             autoviz: Not installed
2025-03-24 14:53:53,443:INFO:           fairlearn: Not installed
2025-03-24 14:53:53,443:INFO:          deepchecks: Not installed
2025-03-24 14:53:53,443:INFO:             xgboost: Not installed
2025-03-24 14:53:53,443:INFO:            catboost: Not installed
2025-03-24 14:53:53,443:INFO:              kmodes: Not installed
2025-03-24 14:53:53,443:INFO:             mlxtend: Not installed
2025-03-24 14:53:53,443:INFO:       statsforecast: Not installed
2025-03-24 14:53:53,443:INFO:        tune_sklearn: Not installed
2025-03-24 14:53:53,443:INFO:                 ray: Not installed
2025-03-24 14:53:53,443:INFO:            hyperopt: Not installed
2025-03-24 14:53:53,443:INFO:              optuna: Not installed
2025-03-24 14:53:53,443:INFO:               skopt: Not installed
2025-03-24 14:53:53,443:INFO:              mlflow: Not installed
2025-03-24 14:53:53,443:INFO:              gradio: Not installed
2025-03-24 14:53:53,443:INFO:             fastapi: Not installed
2025-03-24 14:53:53,443:INFO:             uvicorn: Not installed
2025-03-24 14:53:53,443:INFO:              m2cgen: Not installed
2025-03-24 14:53:53,443:INFO:           evidently: Not installed
2025-03-24 14:53:53,443:INFO:               fugue: Not installed
2025-03-24 14:53:53,443:INFO:           streamlit: Not installed
2025-03-24 14:53:53,443:INFO:             prophet: Not installed
2025-03-24 14:53:53,443:INFO:None
2025-03-24 14:53:53,443:INFO:Set up data.
2025-03-24 14:53:53,453:INFO:Set up folding strategy.
2025-03-24 14:53:53,453:INFO:Set up train/test split.
2025-03-24 14:53:53,460:INFO:Set up index.
2025-03-24 14:53:53,460:INFO:Assigning column types.
2025-03-24 14:53:53,465:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-24 14:53:53,465:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,468:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,470:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,509:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,551:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,554:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,557:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,619:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,620:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,620:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-24 14:53:53,622:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,626:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,663:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,697:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,769:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-24 14:53:53,775:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,810:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,835:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,841:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,904:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,905:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-24 14:53:53,944:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,007:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:54,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:54,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,033:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-24 14:53:54,073:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:54,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,137:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:54,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,163:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-24 14:53:54,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,303:INFO:Preparing preprocessing pipeline...
2025-03-24 14:53:54,303:INFO:Set up simple imputation.
2025-03-24 14:53:54,308:INFO:Set up encoding of categorical features.
2025-03-24 14:53:54,309:INFO:Set up column name cleaning.
2025-03-24 14:53:54,405:INFO:Finished creating preprocessing pipeline.
2025-03-24 14:53:54,410:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-24 14:53:54,410:INFO:Creating final display dataframe.
2025-03-24 14:53:54,625:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              7067
2025-03-24 14:53:54,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,766:INFO:setup() successfully completed in 1.34s...............
2025-03-24 14:53:54,766:INFO:Initializing compare_models()
2025-03-24 14:53:54,766:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-24 14:53:54,766:INFO:Checking exceptions
2025-03-24 14:53:54,768:INFO:Preparing display monitor
2025-03-24 14:53:54,783:INFO:Initializing Linear Regression
2025-03-24 14:53:54,783:INFO:Total runtime is 0.0 minutes
2025-03-24 14:53:54,785:INFO:SubProcess create_model() called ==================================
2025-03-24 14:53:54,785:INFO:Initializing create_model()
2025-03-24 14:53:54,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:53:54,785:INFO:Checking exceptions
2025-03-24 14:53:54,786:INFO:Importing libraries
2025-03-24 14:53:54,786:INFO:Copying training dataset
2025-03-24 14:53:54,795:INFO:Defining folds
2025-03-24 14:53:54,795:INFO:Declaring metric variables
2025-03-24 14:53:54,798:INFO:Importing untrained model
2025-03-24 14:53:54,800:INFO:Linear Regression Imported successfully
2025-03-24 14:53:54,805:INFO:Starting cross validation
2025-03-24 14:53:54,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:53:57,807:INFO:Calculating mean and std
2025-03-24 14:53:57,808:INFO:Creating metrics dataframe
2025-03-24 14:53:57,811:INFO:Uploading results into container
2025-03-24 14:53:57,812:INFO:Uploading model into container now
2025-03-24 14:53:57,813:INFO:_master_model_container: 1
2025-03-24 14:53:57,813:INFO:_display_container: 2
2025-03-24 14:53:57,813:INFO:LinearRegression(n_jobs=-1)
2025-03-24 14:53:57,813:INFO:create_model() successfully completed......................................
2025-03-24 14:53:57,902:INFO:SubProcess create_model() end ==================================
2025-03-24 14:53:57,902:INFO:Creating metrics dataframe
2025-03-24 14:53:57,906:INFO:Initializing Lasso Regression
2025-03-24 14:53:57,906:INFO:Total runtime is 0.052065594991048174 minutes
2025-03-24 14:53:57,909:INFO:SubProcess create_model() called ==================================
2025-03-24 14:53:57,909:INFO:Initializing create_model()
2025-03-24 14:53:57,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:53:57,910:INFO:Checking exceptions
2025-03-24 14:53:57,910:INFO:Importing libraries
2025-03-24 14:53:57,910:INFO:Copying training dataset
2025-03-24 14:53:57,916:INFO:Defining folds
2025-03-24 14:53:57,916:INFO:Declaring metric variables
2025-03-24 14:53:57,919:INFO:Importing untrained model
2025-03-24 14:53:57,920:INFO:Lasso Regression Imported successfully
2025-03-24 14:53:57,925:INFO:Starting cross validation
2025-03-24 14:53:57,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:53:59,668:INFO:Calculating mean and std
2025-03-24 14:53:59,669:INFO:Creating metrics dataframe
2025-03-24 14:53:59,671:INFO:Uploading results into container
2025-03-24 14:53:59,672:INFO:Uploading model into container now
2025-03-24 14:53:59,673:INFO:_master_model_container: 2
2025-03-24 14:53:59,673:INFO:_display_container: 2
2025-03-24 14:53:59,673:INFO:Lasso(random_state=123)
2025-03-24 14:53:59,673:INFO:create_model() successfully completed......................................
2025-03-24 14:53:59,738:INFO:SubProcess create_model() end ==================================
2025-03-24 14:53:59,738:INFO:Creating metrics dataframe
2025-03-24 14:53:59,742:INFO:Initializing Ridge Regression
2025-03-24 14:53:59,742:INFO:Total runtime is 0.08266065915425619 minutes
2025-03-24 14:53:59,744:INFO:SubProcess create_model() called ==================================
2025-03-24 14:53:59,744:INFO:Initializing create_model()
2025-03-24 14:53:59,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:53:59,744:INFO:Checking exceptions
2025-03-24 14:53:59,744:INFO:Importing libraries
2025-03-24 14:53:59,745:INFO:Copying training dataset
2025-03-24 14:53:59,751:INFO:Defining folds
2025-03-24 14:53:59,751:INFO:Declaring metric variables
2025-03-24 14:53:59,753:INFO:Importing untrained model
2025-03-24 14:53:59,755:INFO:Ridge Regression Imported successfully
2025-03-24 14:53:59,761:INFO:Starting cross validation
2025-03-24 14:53:59,762:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:00,024:INFO:Calculating mean and std
2025-03-24 14:54:00,025:INFO:Creating metrics dataframe
2025-03-24 14:54:00,026:INFO:Uploading results into container
2025-03-24 14:54:00,027:INFO:Uploading model into container now
2025-03-24 14:54:00,027:INFO:_master_model_container: 3
2025-03-24 14:54:00,027:INFO:_display_container: 2
2025-03-24 14:54:00,027:INFO:Ridge(random_state=123)
2025-03-24 14:54:00,027:INFO:create_model() successfully completed......................................
2025-03-24 14:54:00,095:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:00,095:INFO:Creating metrics dataframe
2025-03-24 14:54:00,100:INFO:Initializing Elastic Net
2025-03-24 14:54:00,100:INFO:Total runtime is 0.0886220137278239 minutes
2025-03-24 14:54:00,101:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:00,102:INFO:Initializing create_model()
2025-03-24 14:54:00,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:00,102:INFO:Checking exceptions
2025-03-24 14:54:00,102:INFO:Importing libraries
2025-03-24 14:54:00,102:INFO:Copying training dataset
2025-03-24 14:54:00,110:INFO:Defining folds
2025-03-24 14:54:00,110:INFO:Declaring metric variables
2025-03-24 14:54:00,112:INFO:Importing untrained model
2025-03-24 14:54:00,115:INFO:Elastic Net Imported successfully
2025-03-24 14:54:00,120:INFO:Starting cross validation
2025-03-24 14:54:00,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:00,369:INFO:Calculating mean and std
2025-03-24 14:54:00,370:INFO:Creating metrics dataframe
2025-03-24 14:54:00,371:INFO:Uploading results into container
2025-03-24 14:54:00,372:INFO:Uploading model into container now
2025-03-24 14:54:00,372:INFO:_master_model_container: 4
2025-03-24 14:54:00,372:INFO:_display_container: 2
2025-03-24 14:54:00,372:INFO:ElasticNet(random_state=123)
2025-03-24 14:54:00,372:INFO:create_model() successfully completed......................................
2025-03-24 14:54:00,440:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:00,440:INFO:Creating metrics dataframe
2025-03-24 14:54:00,446:INFO:Initializing Least Angle Regression
2025-03-24 14:54:00,446:INFO:Total runtime is 0.09439135392506917 minutes
2025-03-24 14:54:00,448:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:00,448:INFO:Initializing create_model()
2025-03-24 14:54:00,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:00,448:INFO:Checking exceptions
2025-03-24 14:54:00,448:INFO:Importing libraries
2025-03-24 14:54:00,448:INFO:Copying training dataset
2025-03-24 14:54:00,455:INFO:Defining folds
2025-03-24 14:54:00,455:INFO:Declaring metric variables
2025-03-24 14:54:00,457:INFO:Importing untrained model
2025-03-24 14:54:00,459:INFO:Least Angle Regression Imported successfully
2025-03-24 14:54:00,463:INFO:Starting cross validation
2025-03-24 14:54:00,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:00,710:INFO:Calculating mean and std
2025-03-24 14:54:00,711:INFO:Creating metrics dataframe
2025-03-24 14:54:00,712:INFO:Uploading results into container
2025-03-24 14:54:00,712:INFO:Uploading model into container now
2025-03-24 14:54:00,712:INFO:_master_model_container: 5
2025-03-24 14:54:00,712:INFO:_display_container: 2
2025-03-24 14:54:00,712:INFO:Lars(random_state=123)
2025-03-24 14:54:00,712:INFO:create_model() successfully completed......................................
2025-03-24 14:54:00,781:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:00,782:INFO:Creating metrics dataframe
2025-03-24 14:54:00,786:INFO:Initializing Lasso Least Angle Regression
2025-03-24 14:54:00,786:INFO:Total runtime is 0.10006282726923625 minutes
2025-03-24 14:54:00,788:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:00,788:INFO:Initializing create_model()
2025-03-24 14:54:00,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:00,788:INFO:Checking exceptions
2025-03-24 14:54:00,788:INFO:Importing libraries
2025-03-24 14:54:00,788:INFO:Copying training dataset
2025-03-24 14:54:00,795:INFO:Defining folds
2025-03-24 14:54:00,795:INFO:Declaring metric variables
2025-03-24 14:54:00,797:INFO:Importing untrained model
2025-03-24 14:54:00,799:INFO:Lasso Least Angle Regression Imported successfully
2025-03-24 14:54:00,802:INFO:Starting cross validation
2025-03-24 14:54:00,803:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:01,052:INFO:Calculating mean and std
2025-03-24 14:54:01,052:INFO:Creating metrics dataframe
2025-03-24 14:54:01,054:INFO:Uploading results into container
2025-03-24 14:54:01,055:INFO:Uploading model into container now
2025-03-24 14:54:01,055:INFO:_master_model_container: 6
2025-03-24 14:54:01,056:INFO:_display_container: 2
2025-03-24 14:54:01,056:INFO:LassoLars(random_state=123)
2025-03-24 14:54:01,056:INFO:create_model() successfully completed......................................
2025-03-24 14:54:01,120:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:01,120:INFO:Creating metrics dataframe
2025-03-24 14:54:01,125:INFO:Initializing Orthogonal Matching Pursuit
2025-03-24 14:54:01,125:INFO:Total runtime is 0.10571455558141073 minutes
2025-03-24 14:54:01,127:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:01,127:INFO:Initializing create_model()
2025-03-24 14:54:01,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:01,127:INFO:Checking exceptions
2025-03-24 14:54:01,127:INFO:Importing libraries
2025-03-24 14:54:01,127:INFO:Copying training dataset
2025-03-24 14:54:01,135:INFO:Defining folds
2025-03-24 14:54:01,135:INFO:Declaring metric variables
2025-03-24 14:54:01,136:INFO:Importing untrained model
2025-03-24 14:54:01,138:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-24 14:54:01,143:INFO:Starting cross validation
2025-03-24 14:54:01,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:01,402:INFO:Calculating mean and std
2025-03-24 14:54:01,403:INFO:Creating metrics dataframe
2025-03-24 14:54:01,404:INFO:Uploading results into container
2025-03-24 14:54:01,404:INFO:Uploading model into container now
2025-03-24 14:54:01,405:INFO:_master_model_container: 7
2025-03-24 14:54:01,405:INFO:_display_container: 2
2025-03-24 14:54:01,405:INFO:OrthogonalMatchingPursuit()
2025-03-24 14:54:01,405:INFO:create_model() successfully completed......................................
2025-03-24 14:54:01,473:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:01,474:INFO:Creating metrics dataframe
2025-03-24 14:54:01,479:INFO:Initializing Bayesian Ridge
2025-03-24 14:54:01,479:INFO:Total runtime is 0.11160955826441447 minutes
2025-03-24 14:54:01,480:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:01,480:INFO:Initializing create_model()
2025-03-24 14:54:01,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:01,480:INFO:Checking exceptions
2025-03-24 14:54:01,480:INFO:Importing libraries
2025-03-24 14:54:01,480:INFO:Copying training dataset
2025-03-24 14:54:01,488:INFO:Defining folds
2025-03-24 14:54:01,488:INFO:Declaring metric variables
2025-03-24 14:54:01,489:INFO:Importing untrained model
2025-03-24 14:54:01,492:INFO:Bayesian Ridge Imported successfully
2025-03-24 14:54:01,496:INFO:Starting cross validation
2025-03-24 14:54:01,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:01,781:INFO:Calculating mean and std
2025-03-24 14:54:01,781:INFO:Creating metrics dataframe
2025-03-24 14:54:01,783:INFO:Uploading results into container
2025-03-24 14:54:01,783:INFO:Uploading model into container now
2025-03-24 14:54:01,783:INFO:_master_model_container: 8
2025-03-24 14:54:01,784:INFO:_display_container: 2
2025-03-24 14:54:01,784:INFO:BayesianRidge()
2025-03-24 14:54:01,784:INFO:create_model() successfully completed......................................
2025-03-24 14:54:01,853:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:01,853:INFO:Creating metrics dataframe
2025-03-24 14:54:01,859:INFO:Initializing Passive Aggressive Regressor
2025-03-24 14:54:01,859:INFO:Total runtime is 0.11794429222742717 minutes
2025-03-24 14:54:01,862:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:01,862:INFO:Initializing create_model()
2025-03-24 14:54:01,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:01,862:INFO:Checking exceptions
2025-03-24 14:54:01,862:INFO:Importing libraries
2025-03-24 14:54:01,862:INFO:Copying training dataset
2025-03-24 14:54:01,870:INFO:Defining folds
2025-03-24 14:54:01,870:INFO:Declaring metric variables
2025-03-24 14:54:01,872:INFO:Importing untrained model
2025-03-24 14:54:01,875:INFO:Passive Aggressive Regressor Imported successfully
2025-03-24 14:54:01,879:INFO:Starting cross validation
2025-03-24 14:54:01,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:02,306:INFO:Calculating mean and std
2025-03-24 14:54:02,307:INFO:Creating metrics dataframe
2025-03-24 14:54:02,309:INFO:Uploading results into container
2025-03-24 14:54:02,309:INFO:Uploading model into container now
2025-03-24 14:54:02,309:INFO:_master_model_container: 9
2025-03-24 14:54:02,309:INFO:_display_container: 2
2025-03-24 14:54:02,309:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-24 14:54:02,310:INFO:create_model() successfully completed......................................
2025-03-24 14:54:02,373:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:02,374:INFO:Creating metrics dataframe
2025-03-24 14:54:02,379:INFO:Initializing Huber Regressor
2025-03-24 14:54:02,379:INFO:Total runtime is 0.1266133189201355 minutes
2025-03-24 14:54:02,381:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:02,381:INFO:Initializing create_model()
2025-03-24 14:54:02,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:02,381:INFO:Checking exceptions
2025-03-24 14:54:02,381:INFO:Importing libraries
2025-03-24 14:54:02,382:INFO:Copying training dataset
2025-03-24 14:54:02,389:INFO:Defining folds
2025-03-24 14:54:02,389:INFO:Declaring metric variables
2025-03-24 14:54:02,390:INFO:Importing untrained model
2025-03-24 14:54:02,393:INFO:Huber Regressor Imported successfully
2025-03-24 14:54:02,396:INFO:Starting cross validation
2025-03-24 14:54:02,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:04,133:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,156:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,173:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,184:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,191:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,200:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,213:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,233:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,294:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,310:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,338:INFO:Calculating mean and std
2025-03-24 14:54:04,339:INFO:Creating metrics dataframe
2025-03-24 14:54:04,341:INFO:Uploading results into container
2025-03-24 14:54:04,341:INFO:Uploading model into container now
2025-03-24 14:54:04,342:INFO:_master_model_container: 10
2025-03-24 14:54:04,342:INFO:_display_container: 2
2025-03-24 14:54:04,342:INFO:HuberRegressor()
2025-03-24 14:54:04,342:INFO:create_model() successfully completed......................................
2025-03-24 14:54:04,419:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:04,419:INFO:Creating metrics dataframe
2025-03-24 14:54:04,426:INFO:Initializing K Neighbors Regressor
2025-03-24 14:54:04,426:INFO:Total runtime is 0.1607317090034485 minutes
2025-03-24 14:54:04,429:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:04,430:INFO:Initializing create_model()
2025-03-24 14:54:04,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:04,430:INFO:Checking exceptions
2025-03-24 14:54:04,430:INFO:Importing libraries
2025-03-24 14:54:04,430:INFO:Copying training dataset
2025-03-24 14:54:04,436:INFO:Defining folds
2025-03-24 14:54:04,436:INFO:Declaring metric variables
2025-03-24 14:54:04,438:INFO:Importing untrained model
2025-03-24 14:54:04,441:INFO:K Neighbors Regressor Imported successfully
2025-03-24 14:54:04,446:INFO:Starting cross validation
2025-03-24 14:54:04,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:05,314:INFO:Calculating mean and std
2025-03-24 14:54:05,314:INFO:Creating metrics dataframe
2025-03-24 14:54:05,316:INFO:Uploading results into container
2025-03-24 14:54:05,317:INFO:Uploading model into container now
2025-03-24 14:54:05,317:INFO:_master_model_container: 11
2025-03-24 14:54:05,317:INFO:_display_container: 2
2025-03-24 14:54:05,318:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-24 14:54:05,318:INFO:create_model() successfully completed......................................
2025-03-24 14:54:05,386:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:05,386:INFO:Creating metrics dataframe
2025-03-24 14:54:05,391:INFO:Initializing Decision Tree Regressor
2025-03-24 14:54:05,392:INFO:Total runtime is 0.1768297791481018 minutes
2025-03-24 14:54:05,395:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:05,395:INFO:Initializing create_model()
2025-03-24 14:54:05,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:05,395:INFO:Checking exceptions
2025-03-24 14:54:05,395:INFO:Importing libraries
2025-03-24 14:54:05,395:INFO:Copying training dataset
2025-03-24 14:54:05,403:INFO:Defining folds
2025-03-24 14:54:05,403:INFO:Declaring metric variables
2025-03-24 14:54:05,405:INFO:Importing untrained model
2025-03-24 14:54:05,408:INFO:Decision Tree Regressor Imported successfully
2025-03-24 14:54:05,414:INFO:Starting cross validation
2025-03-24 14:54:05,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:05,769:INFO:Calculating mean and std
2025-03-24 14:54:05,770:INFO:Creating metrics dataframe
2025-03-24 14:54:05,771:INFO:Uploading results into container
2025-03-24 14:54:05,771:INFO:Uploading model into container now
2025-03-24 14:54:05,773:INFO:_master_model_container: 12
2025-03-24 14:54:05,773:INFO:_display_container: 2
2025-03-24 14:54:05,773:INFO:DecisionTreeRegressor(random_state=123)
2025-03-24 14:54:05,773:INFO:create_model() successfully completed......................................
2025-03-24 14:54:05,844:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:05,844:INFO:Creating metrics dataframe
2025-03-24 14:54:05,852:INFO:Initializing Random Forest Regressor
2025-03-24 14:54:05,852:INFO:Total runtime is 0.18449822664260865 minutes
2025-03-24 14:54:05,854:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:05,854:INFO:Initializing create_model()
2025-03-24 14:54:05,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:05,854:INFO:Checking exceptions
2025-03-24 14:54:05,854:INFO:Importing libraries
2025-03-24 14:54:05,854:INFO:Copying training dataset
2025-03-24 14:54:05,863:INFO:Defining folds
2025-03-24 14:54:05,863:INFO:Declaring metric variables
2025-03-24 14:54:05,864:INFO:Importing untrained model
2025-03-24 14:54:05,866:INFO:Random Forest Regressor Imported successfully
2025-03-24 14:54:05,872:INFO:Starting cross validation
2025-03-24 14:54:05,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:12,127:INFO:Calculating mean and std
2025-03-24 14:54:12,127:INFO:Creating metrics dataframe
2025-03-24 14:54:12,129:INFO:Uploading results into container
2025-03-24 14:54:12,129:INFO:Uploading model into container now
2025-03-24 14:54:12,129:INFO:_master_model_container: 13
2025-03-24 14:54:12,129:INFO:_display_container: 2
2025-03-24 14:54:12,130:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:12,130:INFO:create_model() successfully completed......................................
2025-03-24 14:54:12,205:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:12,205:INFO:Creating metrics dataframe
2025-03-24 14:54:12,213:INFO:Initializing Extra Trees Regressor
2025-03-24 14:54:12,213:INFO:Total runtime is 0.29050584634145105 minutes
2025-03-24 14:54:12,215:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:12,215:INFO:Initializing create_model()
2025-03-24 14:54:12,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:12,215:INFO:Checking exceptions
2025-03-24 14:54:12,215:INFO:Importing libraries
2025-03-24 14:54:12,215:INFO:Copying training dataset
2025-03-24 14:54:12,223:INFO:Defining folds
2025-03-24 14:54:12,223:INFO:Declaring metric variables
2025-03-24 14:54:12,226:INFO:Importing untrained model
2025-03-24 14:54:12,228:INFO:Extra Trees Regressor Imported successfully
2025-03-24 14:54:12,233:INFO:Starting cross validation
2025-03-24 14:54:12,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:16,439:INFO:Calculating mean and std
2025-03-24 14:54:16,439:INFO:Creating metrics dataframe
2025-03-24 14:54:16,443:INFO:Uploading results into container
2025-03-24 14:54:16,443:INFO:Uploading model into container now
2025-03-24 14:54:16,444:INFO:_master_model_container: 14
2025-03-24 14:54:16,444:INFO:_display_container: 2
2025-03-24 14:54:16,444:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:16,444:INFO:create_model() successfully completed......................................
2025-03-24 14:54:16,562:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:16,562:INFO:Creating metrics dataframe
2025-03-24 14:54:16,571:INFO:Initializing AdaBoost Regressor
2025-03-24 14:54:16,571:INFO:Total runtime is 0.36314464012781783 minutes
2025-03-24 14:54:16,575:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:16,575:INFO:Initializing create_model()
2025-03-24 14:54:16,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:16,575:INFO:Checking exceptions
2025-03-24 14:54:16,575:INFO:Importing libraries
2025-03-24 14:54:16,575:INFO:Copying training dataset
2025-03-24 14:54:16,588:INFO:Defining folds
2025-03-24 14:54:16,588:INFO:Declaring metric variables
2025-03-24 14:54:16,592:INFO:Importing untrained model
2025-03-24 14:54:16,596:INFO:AdaBoost Regressor Imported successfully
2025-03-24 14:54:16,603:INFO:Starting cross validation
2025-03-24 14:54:16,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:17,798:INFO:Calculating mean and std
2025-03-24 14:54:17,799:INFO:Creating metrics dataframe
2025-03-24 14:54:17,801:INFO:Uploading results into container
2025-03-24 14:54:17,801:INFO:Uploading model into container now
2025-03-24 14:54:17,802:INFO:_master_model_container: 15
2025-03-24 14:54:17,802:INFO:_display_container: 2
2025-03-24 14:54:17,802:INFO:AdaBoostRegressor(random_state=123)
2025-03-24 14:54:17,802:INFO:create_model() successfully completed......................................
2025-03-24 14:54:17,898:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:17,898:INFO:Creating metrics dataframe
2025-03-24 14:54:17,908:INFO:Initializing Gradient Boosting Regressor
2025-03-24 14:54:17,908:INFO:Total runtime is 0.3854273438453675 minutes
2025-03-24 14:54:17,912:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:17,912:INFO:Initializing create_model()
2025-03-24 14:54:17,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:17,912:INFO:Checking exceptions
2025-03-24 14:54:17,912:INFO:Importing libraries
2025-03-24 14:54:17,912:INFO:Copying training dataset
2025-03-24 14:54:17,925:INFO:Defining folds
2025-03-24 14:54:17,925:INFO:Declaring metric variables
2025-03-24 14:54:17,928:INFO:Importing untrained model
2025-03-24 14:54:17,931:INFO:Gradient Boosting Regressor Imported successfully
2025-03-24 14:54:17,936:INFO:Starting cross validation
2025-03-24 14:54:17,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:20,357:INFO:Calculating mean and std
2025-03-24 14:54:20,358:INFO:Creating metrics dataframe
2025-03-24 14:54:20,360:INFO:Uploading results into container
2025-03-24 14:54:20,360:INFO:Uploading model into container now
2025-03-24 14:54:20,360:INFO:_master_model_container: 16
2025-03-24 14:54:20,360:INFO:_display_container: 2
2025-03-24 14:54:20,360:INFO:GradientBoostingRegressor(random_state=123)
2025-03-24 14:54:20,360:INFO:create_model() successfully completed......................................
2025-03-24 14:54:20,430:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:20,430:INFO:Creating metrics dataframe
2025-03-24 14:54:20,437:INFO:Initializing Light Gradient Boosting Machine
2025-03-24 14:54:20,437:INFO:Total runtime is 0.42757436434427903 minutes
2025-03-24 14:54:20,439:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:20,439:INFO:Initializing create_model()
2025-03-24 14:54:20,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:20,439:INFO:Checking exceptions
2025-03-24 14:54:20,439:INFO:Importing libraries
2025-03-24 14:54:20,439:INFO:Copying training dataset
2025-03-24 14:54:20,447:INFO:Defining folds
2025-03-24 14:54:20,448:INFO:Declaring metric variables
2025-03-24 14:54:20,450:INFO:Importing untrained model
2025-03-24 14:54:20,451:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 14:54:20,456:INFO:Starting cross validation
2025-03-24 14:54:20,457:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:21,456:INFO:Calculating mean and std
2025-03-24 14:54:21,457:INFO:Creating metrics dataframe
2025-03-24 14:54:21,459:INFO:Uploading results into container
2025-03-24 14:54:21,459:INFO:Uploading model into container now
2025-03-24 14:54:21,460:INFO:_master_model_container: 17
2025-03-24 14:54:21,460:INFO:_display_container: 2
2025-03-24 14:54:21,460:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:21,460:INFO:create_model() successfully completed......................................
2025-03-24 14:54:21,547:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:21,548:INFO:Creating metrics dataframe
2025-03-24 14:54:21,554:INFO:Initializing Dummy Regressor
2025-03-24 14:54:21,554:INFO:Total runtime is 0.4461960474650066 minutes
2025-03-24 14:54:21,556:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:21,557:INFO:Initializing create_model()
2025-03-24 14:54:21,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:21,557:INFO:Checking exceptions
2025-03-24 14:54:21,557:INFO:Importing libraries
2025-03-24 14:54:21,557:INFO:Copying training dataset
2025-03-24 14:54:21,565:INFO:Defining folds
2025-03-24 14:54:21,565:INFO:Declaring metric variables
2025-03-24 14:54:21,568:INFO:Importing untrained model
2025-03-24 14:54:21,570:INFO:Dummy Regressor Imported successfully
2025-03-24 14:54:21,575:INFO:Starting cross validation
2025-03-24 14:54:21,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:21,827:INFO:Calculating mean and std
2025-03-24 14:54:21,828:INFO:Creating metrics dataframe
2025-03-24 14:54:21,830:INFO:Uploading results into container
2025-03-24 14:54:21,830:INFO:Uploading model into container now
2025-03-24 14:54:21,830:INFO:_master_model_container: 18
2025-03-24 14:54:21,830:INFO:_display_container: 2
2025-03-24 14:54:21,831:INFO:DummyRegressor()
2025-03-24 14:54:21,831:INFO:create_model() successfully completed......................................
2025-03-24 14:54:21,907:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:21,907:INFO:Creating metrics dataframe
2025-03-24 14:54:21,914:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-24 14:54:21,919:INFO:Initializing create_model()
2025-03-24 14:54:21,919:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:21,919:INFO:Checking exceptions
2025-03-24 14:54:21,920:INFO:Importing libraries
2025-03-24 14:54:21,920:INFO:Copying training dataset
2025-03-24 14:54:21,926:INFO:Defining folds
2025-03-24 14:54:21,927:INFO:Declaring metric variables
2025-03-24 14:54:21,927:INFO:Importing untrained model
2025-03-24 14:54:21,927:INFO:Declaring custom model
2025-03-24 14:54:21,927:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 14:54:21,928:INFO:Cross validation set to False
2025-03-24 14:54:21,928:INFO:Fitting Model
2025-03-24 14:54:22,018:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 14:54:22,020:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.
2025-03-24 14:54:22,020:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 14:54:22,020:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 14:54:22,020:INFO:[LightGBM] [Info] Total Bins 562
2025-03-24 14:54:22,020:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-24 14:54:22,020:INFO:[LightGBM] [Info] Start training from score 3248.074833
2025-03-24 14:54:22,092:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:22,092:INFO:create_model() successfully completed......................................
2025-03-24 14:54:22,187:INFO:_master_model_container: 18
2025-03-24 14:54:22,187:INFO:_display_container: 2
2025-03-24 14:54:22,188:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:22,189:INFO:compare_models() successfully completed......................................
2025-03-24 14:54:22,192:INFO:Initializing evaluate_model()
2025-03-24 14:54:22,192:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 14:54:22,204:INFO:Initializing plot_model()
2025-03-24 14:54:22,204:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, system=True)
2025-03-24 14:54:22,204:INFO:Checking exceptions
2025-03-24 14:54:22,207:INFO:Preloading libraries
2025-03-24 14:54:22,210:INFO:Copying training dataset
2025-03-24 14:54:22,210:INFO:Plot type: pipeline
2025-03-24 14:54:22,353:INFO:Visual Rendered Successfully
2025-03-24 14:54:22,422:INFO:plot_model() successfully completed......................................
2025-03-24 14:54:22,425:INFO:Initializing predict_model()
2025-03-24 14:54:22,425:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C94EDCBEB0>)
2025-03-24 14:54:22,425:INFO:Checking exceptions
2025-03-24 14:54:22,425:INFO:Preloading libraries
2025-03-24 14:54:22,542:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-24 14:54:22,630:INFO:Initializing finalize_model()
2025-03-24 14:54:22,630:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-24 14:54:22,630:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:22,635:INFO:Initializing create_model()
2025-03-24 14:54:22,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:22,635:INFO:Checking exceptions
2025-03-24 14:54:22,636:INFO:Importing libraries
2025-03-24 14:54:22,636:INFO:Copying training dataset
2025-03-24 14:54:22,636:INFO:Defining folds
2025-03-24 14:54:22,636:INFO:Declaring metric variables
2025-03-24 14:54:22,637:INFO:Importing untrained model
2025-03-24 14:54:22,637:INFO:Declaring custom model
2025-03-24 14:54:22,637:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 14:54:22,638:INFO:Cross validation set to False
2025-03-24 14:54:22,638:INFO:Fitting Model
2025-03-24 14:54:22,744:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 14:54:22,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.
2025-03-24 14:54:22,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 14:54:22,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 14:54:22,747:INFO:[LightGBM] [Info] Total Bins 572
2025-03-24 14:54:22,747:INFO:[LightGBM] [Info] Number of data points in the train set: 48204, number of used features: 16
2025-03-24 14:54:22,747:INFO:[LightGBM] [Info] Start training from score 3259.818355
2025-03-24 14:54:22,807:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-03-24 14:54:22,807:INFO:create_model() successfully completed......................................
2025-03-24 14:54:22,884:INFO:_master_model_container: 18
2025-03-24 14:54:22,885:INFO:_display_container: 3
2025-03-24 14:54:22,893:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-03-24 14:54:22,893:INFO:finalize_model() successfully completed......................................
2025-03-24 14:54:22,972:INFO:Initializing save_model()
2025-03-24 14:54:22,972:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=traffic_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-24 14:54:22,973:INFO:Adding model into prep_pipe
2025-03-24 14:54:22,973:WARNING:Only Model saved as it was a pipeline.
2025-03-24 14:54:22,979:INFO:traffic_model.pkl saved in current working directory
2025-03-24 14:54:22,986:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-03-24 14:54:22,986:INFO:save_model() successfully completed......................................
2025-03-24 21:18:23,308:INFO:PyCaret RegressionExperiment
2025-03-24 21:18:23,308:INFO:Logging name: reg-default-name
2025-03-24 21:18:23,309:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-24 21:18:23,309:INFO:version 3.3.2
2025-03-24 21:18:23,309:INFO:Initializing setup()
2025-03-24 21:18:23,309:INFO:self.USI: fb62
2025-03-24 21:18:23,309:INFO:self._variable_keys: {'_ml_usecase', 'html_param', 'fold_shuffle_param', 'transform_target_param', 'exp_id', 'X_test', 'X_train', 'memory', 'y_test', 'exp_name_log', 'gpu_param', 'USI', 'y', 'seed', 'fold_generator', 'X', 'idx', 'pipeline', 'target_param', 'gpu_n_jobs_param', 'n_jobs_param', 'fold_groups_param', 'logging_param', 'log_plots_param', '_available_plots', 'y_train', 'data'}
2025-03-24 21:18:23,310:INFO:Checking environment
2025-03-24 21:18:23,310:INFO:python_version: 3.10.16
2025-03-24 21:18:23,310:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-24 21:18:23,310:INFO:machine: AMD64
2025-03-24 21:18:23,310:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-24 21:18:23,316:INFO:Memory: svmem(total=33411727360, available=15628259328, percent=53.2, used=17783468032, free=15628259328)
2025-03-24 21:18:23,316:INFO:Physical Core: 6
2025-03-24 21:18:23,316:INFO:Logical Core: 12
2025-03-24 21:18:23,316:INFO:Checking libraries
2025-03-24 21:18:23,317:INFO:System:
2025-03-24 21:18:23,317:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-24 21:18:23,317:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-24 21:18:23,317:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-24 21:18:23,317:INFO:PyCaret required dependencies:
2025-03-24 21:18:23,317:INFO:                 pip: 25.0.1
2025-03-24 21:18:23,317:INFO:          setuptools: 75.8.2
2025-03-24 21:18:23,317:INFO:             pycaret: 3.3.2
2025-03-24 21:18:23,317:INFO:             IPython: 8.34.0
2025-03-24 21:18:23,317:INFO:          ipywidgets: 8.1.5
2025-03-24 21:18:23,317:INFO:                tqdm: 4.67.1
2025-03-24 21:18:23,317:INFO:               numpy: 1.26.4
2025-03-24 21:18:23,317:INFO:              pandas: 2.1.4
2025-03-24 21:18:23,317:INFO:              jinja2: 3.1.6
2025-03-24 21:18:23,317:INFO:               scipy: 1.11.4
2025-03-24 21:18:23,317:INFO:              joblib: 1.3.2
2025-03-24 21:18:23,317:INFO:             sklearn: 1.4.2
2025-03-24 21:18:23,317:INFO:                pyod: 2.0.2
2025-03-24 21:18:23,318:INFO:            imblearn: 0.13.0
2025-03-24 21:18:23,318:INFO:   category_encoders: 2.7.0
2025-03-24 21:18:23,318:INFO:            lightgbm: 4.6.0
2025-03-24 21:18:23,318:INFO:               numba: 0.61.0
2025-03-24 21:18:23,318:INFO:            requests: 2.32.3
2025-03-24 21:18:23,318:INFO:          matplotlib: 3.10.1
2025-03-24 21:18:23,318:INFO:          scikitplot: 0.3.7
2025-03-24 21:18:23,318:INFO:         yellowbrick: 1.5
2025-03-24 21:18:23,318:INFO:              plotly: 6.0.1
2025-03-24 21:18:23,318:INFO:    plotly-resampler: Not installed
2025-03-24 21:18:23,318:INFO:             kaleido: 0.2.1
2025-03-24 21:18:23,318:INFO:           schemdraw: 0.15
2025-03-24 21:18:23,318:INFO:         statsmodels: 0.14.4
2025-03-24 21:18:23,318:INFO:              sktime: 0.26.0
2025-03-24 21:18:23,318:INFO:               tbats: 1.1.3
2025-03-24 21:18:23,318:INFO:            pmdarima: 2.0.4
2025-03-24 21:18:23,318:INFO:              psutil: 7.0.0
2025-03-24 21:18:23,318:INFO:          markupsafe: 3.0.2
2025-03-24 21:18:23,318:INFO:             pickle5: Not installed
2025-03-24 21:18:23,318:INFO:         cloudpickle: 3.1.1
2025-03-24 21:18:23,318:INFO:         deprecation: 2.1.0
2025-03-24 21:18:23,318:INFO:              xxhash: 3.5.0
2025-03-24 21:18:23,318:INFO:           wurlitzer: 3.1.1
2025-03-24 21:18:23,318:INFO:PyCaret optional dependencies:
2025-03-24 21:18:23,318:INFO:                shap: Not installed
2025-03-24 21:18:23,318:INFO:           interpret: Not installed
2025-03-24 21:18:23,318:INFO:                umap: 0.5.7
2025-03-24 21:18:23,318:INFO:     ydata_profiling: Not installed
2025-03-24 21:18:23,318:INFO:  explainerdashboard: Not installed
2025-03-24 21:18:23,318:INFO:             autoviz: Not installed
2025-03-24 21:18:23,318:INFO:           fairlearn: Not installed
2025-03-24 21:18:23,318:INFO:          deepchecks: Not installed
2025-03-24 21:18:23,318:INFO:             xgboost: Not installed
2025-03-24 21:18:23,318:INFO:            catboost: Not installed
2025-03-24 21:18:23,318:INFO:              kmodes: Not installed
2025-03-24 21:18:23,318:INFO:             mlxtend: Not installed
2025-03-24 21:18:23,318:INFO:       statsforecast: Not installed
2025-03-24 21:18:23,318:INFO:        tune_sklearn: Not installed
2025-03-24 21:18:23,318:INFO:                 ray: Not installed
2025-03-24 21:18:23,318:INFO:            hyperopt: Not installed
2025-03-24 21:18:23,318:INFO:              optuna: Not installed
2025-03-24 21:18:23,318:INFO:               skopt: Not installed
2025-03-24 21:18:23,318:INFO:              mlflow: Not installed
2025-03-24 21:18:23,318:INFO:              gradio: Not installed
2025-03-24 21:18:23,318:INFO:             fastapi: Not installed
2025-03-24 21:18:23,318:INFO:             uvicorn: Not installed
2025-03-24 21:18:23,318:INFO:              m2cgen: Not installed
2025-03-24 21:18:23,318:INFO:           evidently: Not installed
2025-03-24 21:18:23,318:INFO:               fugue: Not installed
2025-03-24 21:18:23,319:INFO:           streamlit: Not installed
2025-03-24 21:18:23,319:INFO:             prophet: Not installed
2025-03-24 21:18:23,319:INFO:None
2025-03-24 21:18:23,319:INFO:Set up data.
2025-03-24 21:18:23,329:INFO:Set up folding strategy.
2025-03-24 21:18:23,329:INFO:Set up train/test split.
2025-03-24 21:18:23,336:INFO:Set up index.
2025-03-24 21:18:23,336:INFO:Assigning column types.
2025-03-24 21:18:23,342:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-24 21:18:23,342:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,345:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,347:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,415:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,416:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,419:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,422:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,489:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-24 21:18:23,492:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,565:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,568:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,608:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,634:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,635:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-24 21:18:23,640:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,708:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,716:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,752:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,778:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,778:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-24 21:18:23,820:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,888:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,913:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,913:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-24 21:18:23,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:24,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,047:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-24 21:18:24,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,181:INFO:Preparing preprocessing pipeline...
2025-03-24 21:18:24,181:INFO:Set up simple imputation.
2025-03-24 21:18:24,184:INFO:Set up encoding of categorical features.
2025-03-24 21:18:24,185:INFO:Set up column name cleaning.
2025-03-24 21:18:24,289:INFO:Finished creating preprocessing pipeline.
2025-03-24 21:18:24,293:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-24 21:18:24,293:INFO:Creating final display dataframe.
2025-03-24 21:18:24,526:INFO:Setup _display_container:                     Description             Value
0                    Session id              1741
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              fb62
2025-03-24 21:18:24,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,668:INFO:setup() successfully completed in 1.36s...............
2025-03-24 21:19:01,835:INFO:Initializing compare_models()
2025-03-24 21:19:01,835:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-24 21:19:01,836:INFO:Checking exceptions
2025-03-24 21:19:01,839:INFO:Preparing display monitor
2025-03-24 21:19:01,855:INFO:Initializing Linear Regression
2025-03-24 21:19:01,855:INFO:Total runtime is 0.0 minutes
2025-03-24 21:19:01,857:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:01,858:INFO:Initializing create_model()
2025-03-24 21:19:01,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:01,858:INFO:Checking exceptions
2025-03-24 21:19:01,858:INFO:Importing libraries
2025-03-24 21:19:01,858:INFO:Copying training dataset
2025-03-24 21:19:01,866:INFO:Defining folds
2025-03-24 21:19:01,866:INFO:Declaring metric variables
2025-03-24 21:19:01,868:INFO:Importing untrained model
2025-03-24 21:19:01,870:INFO:Linear Regression Imported successfully
2025-03-24 21:19:01,873:INFO:Starting cross validation
2025-03-24 21:19:01,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:04,940:INFO:Calculating mean and std
2025-03-24 21:19:04,942:INFO:Creating metrics dataframe
2025-03-24 21:19:04,944:INFO:Uploading results into container
2025-03-24 21:19:04,944:INFO:Uploading model into container now
2025-03-24 21:19:04,945:INFO:_master_model_container: 1
2025-03-24 21:19:04,945:INFO:_display_container: 2
2025-03-24 21:19:04,946:INFO:LinearRegression(n_jobs=-1)
2025-03-24 21:19:04,946:INFO:create_model() successfully completed......................................
2025-03-24 21:19:05,097:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:05,097:INFO:Creating metrics dataframe
2025-03-24 21:19:05,103:INFO:Initializing Lasso Regression
2025-03-24 21:19:05,103:INFO:Total runtime is 0.054133248329162595 minutes
2025-03-24 21:19:05,105:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:05,105:INFO:Initializing create_model()
2025-03-24 21:19:05,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:05,105:INFO:Checking exceptions
2025-03-24 21:19:05,105:INFO:Importing libraries
2025-03-24 21:19:05,106:INFO:Copying training dataset
2025-03-24 21:19:05,114:INFO:Defining folds
2025-03-24 21:19:05,114:INFO:Declaring metric variables
2025-03-24 21:19:05,117:INFO:Importing untrained model
2025-03-24 21:19:05,120:INFO:Lasso Regression Imported successfully
2025-03-24 21:19:05,123:INFO:Starting cross validation
2025-03-24 21:19:05,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:06,880:INFO:Calculating mean and std
2025-03-24 21:19:06,880:INFO:Creating metrics dataframe
2025-03-24 21:19:06,883:INFO:Uploading results into container
2025-03-24 21:19:06,883:INFO:Uploading model into container now
2025-03-24 21:19:06,883:INFO:_master_model_container: 2
2025-03-24 21:19:06,883:INFO:_display_container: 2
2025-03-24 21:19:06,884:INFO:Lasso(random_state=1741)
2025-03-24 21:19:06,884:INFO:create_model() successfully completed......................................
2025-03-24 21:19:06,956:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:06,956:INFO:Creating metrics dataframe
2025-03-24 21:19:06,960:INFO:Initializing Ridge Regression
2025-03-24 21:19:06,960:INFO:Total runtime is 0.08509182135264079 minutes
2025-03-24 21:19:06,963:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:06,963:INFO:Initializing create_model()
2025-03-24 21:19:06,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:06,963:INFO:Checking exceptions
2025-03-24 21:19:06,963:INFO:Importing libraries
2025-03-24 21:19:06,964:INFO:Copying training dataset
2025-03-24 21:19:06,970:INFO:Defining folds
2025-03-24 21:19:06,970:INFO:Declaring metric variables
2025-03-24 21:19:06,972:INFO:Importing untrained model
2025-03-24 21:19:06,973:INFO:Ridge Regression Imported successfully
2025-03-24 21:19:06,977:INFO:Starting cross validation
2025-03-24 21:19:06,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:07,224:INFO:Calculating mean and std
2025-03-24 21:19:07,225:INFO:Creating metrics dataframe
2025-03-24 21:19:07,227:INFO:Uploading results into container
2025-03-24 21:19:07,227:INFO:Uploading model into container now
2025-03-24 21:19:07,227:INFO:_master_model_container: 3
2025-03-24 21:19:07,228:INFO:_display_container: 2
2025-03-24 21:19:07,228:INFO:Ridge(random_state=1741)
2025-03-24 21:19:07,228:INFO:create_model() successfully completed......................................
2025-03-24 21:19:07,302:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:07,303:INFO:Creating metrics dataframe
2025-03-24 21:19:07,306:INFO:Initializing Elastic Net
2025-03-24 21:19:07,307:INFO:Total runtime is 0.09087685743967693 minutes
2025-03-24 21:19:07,309:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:07,309:INFO:Initializing create_model()
2025-03-24 21:19:07,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:07,310:INFO:Checking exceptions
2025-03-24 21:19:07,310:INFO:Importing libraries
2025-03-24 21:19:07,310:INFO:Copying training dataset
2025-03-24 21:19:07,317:INFO:Defining folds
2025-03-24 21:19:07,317:INFO:Declaring metric variables
2025-03-24 21:19:07,319:INFO:Importing untrained model
2025-03-24 21:19:07,321:INFO:Elastic Net Imported successfully
2025-03-24 21:19:07,325:INFO:Starting cross validation
2025-03-24 21:19:07,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:07,582:INFO:Calculating mean and std
2025-03-24 21:19:07,583:INFO:Creating metrics dataframe
2025-03-24 21:19:07,584:INFO:Uploading results into container
2025-03-24 21:19:07,584:INFO:Uploading model into container now
2025-03-24 21:19:07,585:INFO:_master_model_container: 4
2025-03-24 21:19:07,585:INFO:_display_container: 2
2025-03-24 21:19:07,585:INFO:ElasticNet(random_state=1741)
2025-03-24 21:19:07,585:INFO:create_model() successfully completed......................................
2025-03-24 21:19:07,657:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:07,657:INFO:Creating metrics dataframe
2025-03-24 21:19:07,663:INFO:Initializing Least Angle Regression
2025-03-24 21:19:07,663:INFO:Total runtime is 0.09681055148442587 minutes
2025-03-24 21:19:07,665:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:07,666:INFO:Initializing create_model()
2025-03-24 21:19:07,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:07,666:INFO:Checking exceptions
2025-03-24 21:19:07,666:INFO:Importing libraries
2025-03-24 21:19:07,666:INFO:Copying training dataset
2025-03-24 21:19:07,673:INFO:Defining folds
2025-03-24 21:19:07,673:INFO:Declaring metric variables
2025-03-24 21:19:07,675:INFO:Importing untrained model
2025-03-24 21:19:07,677:INFO:Least Angle Regression Imported successfully
2025-03-24 21:19:07,681:INFO:Starting cross validation
2025-03-24 21:19:07,683:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:07,938:INFO:Calculating mean and std
2025-03-24 21:19:07,939:INFO:Creating metrics dataframe
2025-03-24 21:19:07,940:INFO:Uploading results into container
2025-03-24 21:19:07,940:INFO:Uploading model into container now
2025-03-24 21:19:07,940:INFO:_master_model_container: 5
2025-03-24 21:19:07,942:INFO:_display_container: 2
2025-03-24 21:19:07,942:INFO:Lars(random_state=1741)
2025-03-24 21:19:07,942:INFO:create_model() successfully completed......................................
2025-03-24 21:19:08,008:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:08,008:INFO:Creating metrics dataframe
2025-03-24 21:19:08,013:INFO:Initializing Lasso Least Angle Regression
2025-03-24 21:19:08,013:INFO:Total runtime is 0.10263184706370036 minutes
2025-03-24 21:19:08,015:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:08,015:INFO:Initializing create_model()
2025-03-24 21:19:08,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:08,015:INFO:Checking exceptions
2025-03-24 21:19:08,015:INFO:Importing libraries
2025-03-24 21:19:08,015:INFO:Copying training dataset
2025-03-24 21:19:08,022:INFO:Defining folds
2025-03-24 21:19:08,022:INFO:Declaring metric variables
2025-03-24 21:19:08,023:INFO:Importing untrained model
2025-03-24 21:19:08,026:INFO:Lasso Least Angle Regression Imported successfully
2025-03-24 21:19:08,029:INFO:Starting cross validation
2025-03-24 21:19:08,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:08,267:INFO:Calculating mean and std
2025-03-24 21:19:08,268:INFO:Creating metrics dataframe
2025-03-24 21:19:08,269:INFO:Uploading results into container
2025-03-24 21:19:08,269:INFO:Uploading model into container now
2025-03-24 21:19:08,270:INFO:_master_model_container: 6
2025-03-24 21:19:08,270:INFO:_display_container: 2
2025-03-24 21:19:08,270:INFO:LassoLars(random_state=1741)
2025-03-24 21:19:08,270:INFO:create_model() successfully completed......................................
2025-03-24 21:19:08,343:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:08,343:INFO:Creating metrics dataframe
2025-03-24 21:19:08,348:INFO:Initializing Orthogonal Matching Pursuit
2025-03-24 21:19:08,348:INFO:Total runtime is 0.10822073221206666 minutes
2025-03-24 21:19:08,351:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:08,351:INFO:Initializing create_model()
2025-03-24 21:19:08,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:08,351:INFO:Checking exceptions
2025-03-24 21:19:08,351:INFO:Importing libraries
2025-03-24 21:19:08,351:INFO:Copying training dataset
2025-03-24 21:19:08,358:INFO:Defining folds
2025-03-24 21:19:08,358:INFO:Declaring metric variables
2025-03-24 21:19:08,360:INFO:Importing untrained model
2025-03-24 21:19:08,362:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-24 21:19:08,366:INFO:Starting cross validation
2025-03-24 21:19:08,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:08,608:INFO:Calculating mean and std
2025-03-24 21:19:08,609:INFO:Creating metrics dataframe
2025-03-24 21:19:08,610:INFO:Uploading results into container
2025-03-24 21:19:08,611:INFO:Uploading model into container now
2025-03-24 21:19:08,611:INFO:_master_model_container: 7
2025-03-24 21:19:08,611:INFO:_display_container: 2
2025-03-24 21:19:08,611:INFO:OrthogonalMatchingPursuit()
2025-03-24 21:19:08,611:INFO:create_model() successfully completed......................................
2025-03-24 21:19:08,684:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:08,684:INFO:Creating metrics dataframe
2025-03-24 21:19:08,690:INFO:Initializing Bayesian Ridge
2025-03-24 21:19:08,690:INFO:Total runtime is 0.1139179031054179 minutes
2025-03-24 21:19:08,692:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:08,693:INFO:Initializing create_model()
2025-03-24 21:19:08,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:08,693:INFO:Checking exceptions
2025-03-24 21:19:08,693:INFO:Importing libraries
2025-03-24 21:19:08,693:INFO:Copying training dataset
2025-03-24 21:19:08,701:INFO:Defining folds
2025-03-24 21:19:08,701:INFO:Declaring metric variables
2025-03-24 21:19:08,703:INFO:Importing untrained model
2025-03-24 21:19:08,705:INFO:Bayesian Ridge Imported successfully
2025-03-24 21:19:08,710:INFO:Starting cross validation
2025-03-24 21:19:08,711:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:08,982:INFO:Calculating mean and std
2025-03-24 21:19:08,983:INFO:Creating metrics dataframe
2025-03-24 21:19:08,984:INFO:Uploading results into container
2025-03-24 21:19:08,985:INFO:Uploading model into container now
2025-03-24 21:19:08,985:INFO:_master_model_container: 8
2025-03-24 21:19:08,985:INFO:_display_container: 2
2025-03-24 21:19:08,985:INFO:BayesianRidge()
2025-03-24 21:19:08,985:INFO:create_model() successfully completed......................................
2025-03-24 21:19:09,054:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:09,054:INFO:Creating metrics dataframe
2025-03-24 21:19:09,060:INFO:Initializing Passive Aggressive Regressor
2025-03-24 21:19:09,060:INFO:Total runtime is 0.12008246978123983 minutes
2025-03-24 21:19:09,062:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:09,062:INFO:Initializing create_model()
2025-03-24 21:19:09,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:09,062:INFO:Checking exceptions
2025-03-24 21:19:09,062:INFO:Importing libraries
2025-03-24 21:19:09,062:INFO:Copying training dataset
2025-03-24 21:19:09,069:INFO:Defining folds
2025-03-24 21:19:09,069:INFO:Declaring metric variables
2025-03-24 21:19:09,070:INFO:Importing untrained model
2025-03-24 21:19:09,072:INFO:Passive Aggressive Regressor Imported successfully
2025-03-24 21:19:09,076:INFO:Starting cross validation
2025-03-24 21:19:09,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:09,447:INFO:Calculating mean and std
2025-03-24 21:19:09,448:INFO:Creating metrics dataframe
2025-03-24 21:19:09,449:INFO:Uploading results into container
2025-03-24 21:19:09,449:INFO:Uploading model into container now
2025-03-24 21:19:09,450:INFO:_master_model_container: 9
2025-03-24 21:19:09,450:INFO:_display_container: 2
2025-03-24 21:19:09,450:INFO:PassiveAggressiveRegressor(random_state=1741)
2025-03-24 21:19:09,450:INFO:create_model() successfully completed......................................
2025-03-24 21:19:09,521:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:09,521:INFO:Creating metrics dataframe
2025-03-24 21:19:09,527:INFO:Initializing Huber Regressor
2025-03-24 21:19:09,527:INFO:Total runtime is 0.12787710825602214 minutes
2025-03-24 21:19:09,529:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:09,529:INFO:Initializing create_model()
2025-03-24 21:19:09,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:09,530:INFO:Checking exceptions
2025-03-24 21:19:09,530:INFO:Importing libraries
2025-03-24 21:19:09,530:INFO:Copying training dataset
2025-03-24 21:19:09,537:INFO:Defining folds
2025-03-24 21:19:09,537:INFO:Declaring metric variables
2025-03-24 21:19:09,539:INFO:Importing untrained model
2025-03-24 21:19:09,541:INFO:Huber Regressor Imported successfully
2025-03-24 21:19:09,546:INFO:Starting cross validation
2025-03-24 21:19:09,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:11,039:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,084:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,088:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,103:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,113:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,121:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,134:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,136:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,215:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,222:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,254:INFO:Calculating mean and std
2025-03-24 21:19:11,255:INFO:Creating metrics dataframe
2025-03-24 21:19:11,256:INFO:Uploading results into container
2025-03-24 21:19:11,256:INFO:Uploading model into container now
2025-03-24 21:19:11,256:INFO:_master_model_container: 10
2025-03-24 21:19:11,256:INFO:_display_container: 2
2025-03-24 21:19:11,257:INFO:HuberRegressor()
2025-03-24 21:19:11,257:INFO:create_model() successfully completed......................................
2025-03-24 21:19:11,322:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:11,323:INFO:Creating metrics dataframe
2025-03-24 21:19:11,329:INFO:Initializing K Neighbors Regressor
2025-03-24 21:19:11,329:INFO:Total runtime is 0.1578987995783488 minutes
2025-03-24 21:19:11,331:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:11,332:INFO:Initializing create_model()
2025-03-24 21:19:11,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:11,332:INFO:Checking exceptions
2025-03-24 21:19:11,332:INFO:Importing libraries
2025-03-24 21:19:11,332:INFO:Copying training dataset
2025-03-24 21:19:11,339:INFO:Defining folds
2025-03-24 21:19:11,339:INFO:Declaring metric variables
2025-03-24 21:19:11,341:INFO:Importing untrained model
2025-03-24 21:19:11,343:INFO:K Neighbors Regressor Imported successfully
2025-03-24 21:19:11,347:INFO:Starting cross validation
2025-03-24 21:19:11,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:12,146:INFO:Calculating mean and std
2025-03-24 21:19:12,147:INFO:Creating metrics dataframe
2025-03-24 21:19:12,148:INFO:Uploading results into container
2025-03-24 21:19:12,148:INFO:Uploading model into container now
2025-03-24 21:19:12,149:INFO:_master_model_container: 11
2025-03-24 21:19:12,149:INFO:_display_container: 2
2025-03-24 21:19:12,149:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-24 21:19:12,149:INFO:create_model() successfully completed......................................
2025-03-24 21:19:12,216:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:12,216:INFO:Creating metrics dataframe
2025-03-24 21:19:12,221:INFO:Initializing Decision Tree Regressor
2025-03-24 21:19:12,222:INFO:Total runtime is 0.17278945446014404 minutes
2025-03-24 21:19:12,224:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:12,225:INFO:Initializing create_model()
2025-03-24 21:19:12,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:12,225:INFO:Checking exceptions
2025-03-24 21:19:12,225:INFO:Importing libraries
2025-03-24 21:19:12,225:INFO:Copying training dataset
2025-03-24 21:19:12,231:INFO:Defining folds
2025-03-24 21:19:12,231:INFO:Declaring metric variables
2025-03-24 21:19:12,233:INFO:Importing untrained model
2025-03-24 21:19:12,235:INFO:Decision Tree Regressor Imported successfully
2025-03-24 21:19:12,239:INFO:Starting cross validation
2025-03-24 21:19:12,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:12,549:INFO:Calculating mean and std
2025-03-24 21:19:12,550:INFO:Creating metrics dataframe
2025-03-24 21:19:12,550:INFO:Uploading results into container
2025-03-24 21:19:12,552:INFO:Uploading model into container now
2025-03-24 21:19:12,552:INFO:_master_model_container: 12
2025-03-24 21:19:12,552:INFO:_display_container: 2
2025-03-24 21:19:12,552:INFO:DecisionTreeRegressor(random_state=1741)
2025-03-24 21:19:12,552:INFO:create_model() successfully completed......................................
2025-03-24 21:19:12,618:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:12,618:INFO:Creating metrics dataframe
2025-03-24 21:19:12,623:INFO:Initializing Random Forest Regressor
2025-03-24 21:19:12,623:INFO:Total runtime is 0.1794646700223287 minutes
2025-03-24 21:19:12,625:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:12,626:INFO:Initializing create_model()
2025-03-24 21:19:12,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:12,626:INFO:Checking exceptions
2025-03-24 21:19:12,626:INFO:Importing libraries
2025-03-24 21:19:12,626:INFO:Copying training dataset
2025-03-24 21:19:12,632:INFO:Defining folds
2025-03-24 21:19:12,632:INFO:Declaring metric variables
2025-03-24 21:19:12,633:INFO:Importing untrained model
2025-03-24 21:19:12,635:INFO:Random Forest Regressor Imported successfully
2025-03-24 21:19:12,640:INFO:Starting cross validation
2025-03-24 21:19:12,642:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:18,893:INFO:Calculating mean and std
2025-03-24 21:19:18,894:INFO:Creating metrics dataframe
2025-03-24 21:19:18,896:INFO:Uploading results into container
2025-03-24 21:19:18,896:INFO:Uploading model into container now
2025-03-24 21:19:18,896:INFO:_master_model_container: 13
2025-03-24 21:19:18,896:INFO:_display_container: 2
2025-03-24 21:19:18,897:INFO:RandomForestRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:19:18,897:INFO:create_model() successfully completed......................................
2025-03-24 21:19:18,977:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:18,977:INFO:Creating metrics dataframe
2025-03-24 21:19:18,983:INFO:Initializing Extra Trees Regressor
2025-03-24 21:19:18,983:INFO:Total runtime is 0.2854660908381144 minutes
2025-03-24 21:19:18,986:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:18,986:INFO:Initializing create_model()
2025-03-24 21:19:18,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:18,986:INFO:Checking exceptions
2025-03-24 21:19:18,986:INFO:Importing libraries
2025-03-24 21:19:18,986:INFO:Copying training dataset
2025-03-24 21:19:18,995:INFO:Defining folds
2025-03-24 21:19:18,995:INFO:Declaring metric variables
2025-03-24 21:19:18,998:INFO:Importing untrained model
2025-03-24 21:19:19,002:INFO:Extra Trees Regressor Imported successfully
2025-03-24 21:19:19,005:INFO:Starting cross validation
2025-03-24 21:19:19,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:23,176:INFO:Calculating mean and std
2025-03-24 21:19:23,177:INFO:Creating metrics dataframe
2025-03-24 21:19:23,179:INFO:Uploading results into container
2025-03-24 21:19:23,179:INFO:Uploading model into container now
2025-03-24 21:19:23,179:INFO:_master_model_container: 14
2025-03-24 21:19:23,179:INFO:_display_container: 2
2025-03-24 21:19:23,180:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:19:23,180:INFO:create_model() successfully completed......................................
2025-03-24 21:19:23,262:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:23,262:INFO:Creating metrics dataframe
2025-03-24 21:19:23,269:INFO:Initializing AdaBoost Regressor
2025-03-24 21:19:23,269:INFO:Total runtime is 0.3569036285082499 minutes
2025-03-24 21:19:23,271:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:23,272:INFO:Initializing create_model()
2025-03-24 21:19:23,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:23,272:INFO:Checking exceptions
2025-03-24 21:19:23,272:INFO:Importing libraries
2025-03-24 21:19:23,272:INFO:Copying training dataset
2025-03-24 21:19:23,282:INFO:Defining folds
2025-03-24 21:19:23,282:INFO:Declaring metric variables
2025-03-24 21:19:23,285:INFO:Importing untrained model
2025-03-24 21:19:23,287:INFO:AdaBoost Regressor Imported successfully
2025-03-24 21:19:23,291:INFO:Starting cross validation
2025-03-24 21:19:23,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:24,385:INFO:Calculating mean and std
2025-03-24 21:19:24,386:INFO:Creating metrics dataframe
2025-03-24 21:19:24,387:INFO:Uploading results into container
2025-03-24 21:19:24,388:INFO:Uploading model into container now
2025-03-24 21:19:24,388:INFO:_master_model_container: 15
2025-03-24 21:19:24,388:INFO:_display_container: 2
2025-03-24 21:19:24,388:INFO:AdaBoostRegressor(random_state=1741)
2025-03-24 21:19:24,388:INFO:create_model() successfully completed......................................
2025-03-24 21:19:24,468:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:24,468:INFO:Creating metrics dataframe
2025-03-24 21:19:24,477:INFO:Initializing Gradient Boosting Regressor
2025-03-24 21:19:24,477:INFO:Total runtime is 0.37704548438390095 minutes
2025-03-24 21:19:24,480:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:24,482:INFO:Initializing create_model()
2025-03-24 21:19:24,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:24,482:INFO:Checking exceptions
2025-03-24 21:19:24,482:INFO:Importing libraries
2025-03-24 21:19:24,482:INFO:Copying training dataset
2025-03-24 21:19:24,494:INFO:Defining folds
2025-03-24 21:19:24,495:INFO:Declaring metric variables
2025-03-24 21:19:24,504:INFO:Importing untrained model
2025-03-24 21:19:24,508:INFO:Gradient Boosting Regressor Imported successfully
2025-03-24 21:19:24,518:INFO:Starting cross validation
2025-03-24 21:19:24,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:26,632:INFO:Calculating mean and std
2025-03-24 21:19:26,633:INFO:Creating metrics dataframe
2025-03-24 21:19:26,634:INFO:Uploading results into container
2025-03-24 21:19:26,634:INFO:Uploading model into container now
2025-03-24 21:19:26,635:INFO:_master_model_container: 16
2025-03-24 21:19:26,635:INFO:_display_container: 2
2025-03-24 21:19:26,635:INFO:GradientBoostingRegressor(random_state=1741)
2025-03-24 21:19:26,635:INFO:create_model() successfully completed......................................
2025-03-24 21:19:26,700:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:26,700:INFO:Creating metrics dataframe
2025-03-24 21:19:26,705:INFO:Initializing Light Gradient Boosting Machine
2025-03-24 21:19:26,705:INFO:Total runtime is 0.41417887608210247 minutes
2025-03-24 21:19:26,707:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:26,708:INFO:Initializing create_model()
2025-03-24 21:19:26,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:26,708:INFO:Checking exceptions
2025-03-24 21:19:26,708:INFO:Importing libraries
2025-03-24 21:19:26,708:INFO:Copying training dataset
2025-03-24 21:19:26,714:INFO:Defining folds
2025-03-24 21:19:26,715:INFO:Declaring metric variables
2025-03-24 21:19:26,717:INFO:Importing untrained model
2025-03-24 21:19:26,719:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:19:26,722:INFO:Starting cross validation
2025-03-24 21:19:26,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:27,529:INFO:Calculating mean and std
2025-03-24 21:19:27,530:INFO:Creating metrics dataframe
2025-03-24 21:19:27,532:INFO:Uploading results into container
2025-03-24 21:19:27,532:INFO:Uploading model into container now
2025-03-24 21:19:27,533:INFO:_master_model_container: 17
2025-03-24 21:19:27,533:INFO:_display_container: 2
2025-03-24 21:19:27,533:INFO:LGBMRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:19:27,533:INFO:create_model() successfully completed......................................
2025-03-24 21:19:27,619:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:27,619:INFO:Creating metrics dataframe
2025-03-24 21:19:27,626:INFO:Initializing Dummy Regressor
2025-03-24 21:19:27,626:INFO:Total runtime is 0.42952747742335 minutes
2025-03-24 21:19:27,628:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:27,628:INFO:Initializing create_model()
2025-03-24 21:19:27,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:27,628:INFO:Checking exceptions
2025-03-24 21:19:27,628:INFO:Importing libraries
2025-03-24 21:19:27,628:INFO:Copying training dataset
2025-03-24 21:19:27,635:INFO:Defining folds
2025-03-24 21:19:27,635:INFO:Declaring metric variables
2025-03-24 21:19:27,638:INFO:Importing untrained model
2025-03-24 21:19:27,640:INFO:Dummy Regressor Imported successfully
2025-03-24 21:19:27,645:INFO:Starting cross validation
2025-03-24 21:19:27,646:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:27,837:INFO:Calculating mean and std
2025-03-24 21:19:27,838:INFO:Creating metrics dataframe
2025-03-24 21:19:27,839:INFO:Uploading results into container
2025-03-24 21:19:27,839:INFO:Uploading model into container now
2025-03-24 21:19:27,840:INFO:_master_model_container: 18
2025-03-24 21:19:27,840:INFO:_display_container: 2
2025-03-24 21:19:27,840:INFO:DummyRegressor()
2025-03-24 21:19:27,840:INFO:create_model() successfully completed......................................
2025-03-24 21:19:27,905:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:27,905:INFO:Creating metrics dataframe
2025-03-24 21:19:27,911:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-24 21:19:27,916:INFO:Initializing create_model()
2025-03-24 21:19:27,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:27,916:INFO:Checking exceptions
2025-03-24 21:19:27,917:INFO:Importing libraries
2025-03-24 21:19:27,917:INFO:Copying training dataset
2025-03-24 21:19:27,924:INFO:Defining folds
2025-03-24 21:19:27,924:INFO:Declaring metric variables
2025-03-24 21:19:27,924:INFO:Importing untrained model
2025-03-24 21:19:27,924:INFO:Declaring custom model
2025-03-24 21:19:27,924:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:19:27,926:INFO:Cross validation set to False
2025-03-24 21:19:27,926:INFO:Fitting Model
2025-03-24 21:19:28,005:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:19:28,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000591 seconds.
2025-03-24 21:19:28,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:19:28,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:19:28,006:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:19:28,007:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-24 21:19:28,007:INFO:[LightGBM] [Info] Start training from score 3253.240353
2025-03-24 21:19:28,049:INFO:LGBMRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:19:28,049:INFO:create_model() successfully completed......................................
2025-03-24 21:19:28,144:INFO:_master_model_container: 18
2025-03-24 21:19:28,144:INFO:_display_container: 2
2025-03-24 21:19:28,144:INFO:LGBMRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:19:28,144:INFO:compare_models() successfully completed......................................
2025-03-24 21:20:16,413:INFO:Initializing evaluate_model()
2025-03-24 21:20:16,413:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:20:16,424:INFO:Initializing plot_model()
2025-03-24 21:20:16,424:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:16,425:INFO:Checking exceptions
2025-03-24 21:20:16,428:INFO:Preloading libraries
2025-03-24 21:20:16,431:INFO:Copying training dataset
2025-03-24 21:20:16,431:INFO:Plot type: pipeline
2025-03-24 21:20:16,517:INFO:Visual Rendered Successfully
2025-03-24 21:20:16,585:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:23,982:INFO:Initializing plot_model()
2025-03-24 21:20:23,982:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:23,982:INFO:Checking exceptions
2025-03-24 21:20:23,986:INFO:Preloading libraries
2025-03-24 21:20:23,988:INFO:Copying training dataset
2025-03-24 21:20:23,988:INFO:Plot type: parameter
2025-03-24 21:20:23,991:INFO:Visual Rendered Successfully
2025-03-24 21:20:24,064:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:24,707:INFO:Initializing plot_model()
2025-03-24 21:20:24,707:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:24,707:INFO:Checking exceptions
2025-03-24 21:20:24,712:INFO:Preloading libraries
2025-03-24 21:20:24,715:INFO:Copying training dataset
2025-03-24 21:20:24,715:INFO:Plot type: residuals
2025-03-24 21:20:24,966:INFO:Fitting Model
2025-03-24 21:20:25,024:INFO:Scoring test/hold-out set
2025-03-24 21:20:25,448:INFO:Visual Rendered Successfully
2025-03-24 21:20:25,525:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:25,558:INFO:Initializing plot_model()
2025-03-24 21:20:25,558:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:25,558:INFO:Checking exceptions
2025-03-24 21:20:25,563:INFO:Preloading libraries
2025-03-24 21:20:25,578:INFO:Copying training dataset
2025-03-24 21:20:25,578:INFO:Plot type: parameter
2025-03-24 21:20:25,582:INFO:Visual Rendered Successfully
2025-03-24 21:20:25,664:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:25,789:INFO:Initializing plot_model()
2025-03-24 21:20:25,789:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:25,789:INFO:Checking exceptions
2025-03-24 21:20:25,793:INFO:Preloading libraries
2025-03-24 21:20:25,795:INFO:Copying training dataset
2025-03-24 21:20:25,795:INFO:Plot type: pipeline
2025-03-24 21:20:25,873:INFO:Visual Rendered Successfully
2025-03-24 21:20:25,944:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:31,735:INFO:Initializing plot_model()
2025-03-24 21:20:31,735:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:31,735:INFO:Checking exceptions
2025-03-24 21:20:31,738:INFO:Preloading libraries
2025-03-24 21:20:31,740:INFO:Copying training dataset
2025-03-24 21:20:31,741:INFO:Plot type: parameter
2025-03-24 21:20:31,744:INFO:Visual Rendered Successfully
2025-03-24 21:20:31,814:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:33,835:INFO:Initializing plot_model()
2025-03-24 21:20:33,836:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:33,836:INFO:Checking exceptions
2025-03-24 21:20:33,839:INFO:Preloading libraries
2025-03-24 21:20:33,841:INFO:Copying training dataset
2025-03-24 21:20:33,841:INFO:Plot type: residuals
2025-03-24 21:20:34,075:INFO:Fitting Model
2025-03-24 21:20:34,125:INFO:Scoring test/hold-out set
2025-03-24 21:20:34,466:INFO:Visual Rendered Successfully
2025-03-24 21:20:34,548:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:34,667:INFO:Initializing plot_model()
2025-03-24 21:20:34,667:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:34,667:INFO:Checking exceptions
2025-03-24 21:20:34,671:INFO:Preloading libraries
2025-03-24 21:20:34,673:INFO:Copying training dataset
2025-03-24 21:20:34,674:INFO:Plot type: error
2025-03-24 21:20:34,898:INFO:Fitting Model
2025-03-24 21:20:34,898:INFO:Scoring test/hold-out set
2025-03-24 21:20:35,108:INFO:Visual Rendered Successfully
2025-03-24 21:20:35,171:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:35,776:INFO:Initializing plot_model()
2025-03-24 21:20:35,777:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:35,777:INFO:Checking exceptions
2025-03-24 21:20:35,782:INFO:Preloading libraries
2025-03-24 21:20:35,787:INFO:Copying training dataset
2025-03-24 21:20:35,787:INFO:Plot type: cooks
2025-03-24 21:20:36,007:INFO:Fitting Model
2025-03-24 21:20:41,141:INFO:Initializing plot_model()
2025-03-24 21:20:41,141:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:41,142:INFO:Checking exceptions
2025-03-24 21:20:41,146:INFO:Preloading libraries
2025-03-24 21:20:41,148:INFO:Copying training dataset
2025-03-24 21:20:41,148:INFO:Plot type: rfe
2025-03-24 21:20:41,371:INFO:Fitting Model
2025-03-24 21:20:41,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000616 seconds.
2025-03-24 21:20:41,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,393:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,393:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,393:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.
2025-03-24 21:20:41,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,474:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,474:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,474:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,550:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.
2025-03-24 21:20:41,550:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,550:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,550:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,550:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,550:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,623:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.
2025-03-24 21:20:41,623:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,623:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,623:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,623:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,623:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.
2025-03-24 21:20:41,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,676:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,677:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,677:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,731:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-03-24 21:20:41,731:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,731:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,731:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,731:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,731:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2025-03-24 21:20:41,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,782:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,782:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,782:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.
2025-03-24 21:20:41,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,832:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,832:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,834:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,886:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-24 21:20:41,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,886:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,886:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,886:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.
2025-03-24 21:20:41,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,940:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,940:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,940:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-03-24 21:20:41,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,994:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,994:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,994:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.
2025-03-24 21:20:42,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,048:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:42,049:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,049:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,101:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-24 21:20:42,101:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,101:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,101:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:42,101:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,101:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-24 21:20:42,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,155:INFO:[LightGBM] [Info] Total Bins 553
2025-03-24 21:20:42,155:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-24 21:20:42,155:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-24 21:20:42,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,204:INFO:[LightGBM] [Info] Total Bins 551
2025-03-24 21:20:42,204:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-24 21:20:42,204:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-24 21:20:42,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,251:INFO:[LightGBM] [Info] Total Bins 549
2025-03-24 21:20:42,251:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-24 21:20:42,251:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,299:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-03-24 21:20:42,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,299:INFO:[LightGBM] [Info] Total Bins 547
2025-03-24 21:20:42,300:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-24 21:20:42,300:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-03-24 21:20:42,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,347:INFO:[LightGBM] [Info] Total Bins 545
2025-03-24 21:20:42,347:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-24 21:20:42,347:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,391:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-24 21:20:42,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,393:INFO:[LightGBM] [Info] Total Bins 543
2025-03-24 21:20:42,393:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-24 21:20:42,393:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-24 21:20:42,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,439:INFO:[LightGBM] [Info] Total Bins 541
2025-03-24 21:20:42,439:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-24 21:20:42,440:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-24 21:20:42,484:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,485:INFO:[LightGBM] [Info] Total Bins 539
2025-03-24 21:20:42,485:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-24 21:20:42,485:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-24 21:20:42,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,531:INFO:[LightGBM] [Info] Total Bins 537
2025-03-24 21:20:42,531:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-24 21:20:42,532:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,576:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.
2025-03-24 21:20:42,576:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,576:INFO:[LightGBM] [Info] Total Bins 535
2025-03-24 21:20:42,576:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-24 21:20:42,576:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000270 seconds.
2025-03-24 21:20:42,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,626:INFO:[LightGBM] [Info] Total Bins 533
2025-03-24 21:20:42,626:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-24 21:20:42,627:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,669:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.
2025-03-24 21:20:42,669:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,669:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,669:INFO:[LightGBM] [Info] Total Bins 531
2025-03-24 21:20:42,670:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-24 21:20:42,670:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,716:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.
2025-03-24 21:20:42,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,716:INFO:[LightGBM] [Info] Total Bins 488
2025-03-24 21:20:42,716:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-24 21:20:42,716:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.
2025-03-24 21:20:42,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,756:INFO:[LightGBM] [Info] Total Bins 255
2025-03-24 21:20:42,756:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 1
2025-03-24 21:20:42,756:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.
2025-03-24 21:20:42,813:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,813:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,813:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:42,813:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,813:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:42,865:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.
2025-03-24 21:20:42,865:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,865:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,865:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:42,865:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,866:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:42,917:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.
2025-03-24 21:20:42,917:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,917:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,918:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:42,918:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,918:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:42,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-03-24 21:20:42,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,981:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:42,981:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,981:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,036:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.
2025-03-24 21:20:43,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,037:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,037:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,037:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,090:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-24 21:20:43,090:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,090:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,090:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,090:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,090:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.
2025-03-24 21:20:43,144:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,144:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,144:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,144:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,197:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.
2025-03-24 21:20:43,197:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,197:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,197:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,197:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,197:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.
2025-03-24 21:20:43,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,250:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,250:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,250:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.
2025-03-24 21:20:43,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,301:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,301:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,301:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,353:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000541 seconds.
2025-03-24 21:20:43,353:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,353:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,353:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,353:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,353:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,403:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.
2025-03-24 21:20:43,403:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,403:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,403:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,403:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,403:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.
2025-03-24 21:20:43,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,454:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,454:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,454:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.
2025-03-24 21:20:43,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,505:INFO:[LightGBM] [Info] Total Bins 547
2025-03-24 21:20:43,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-24 21:20:43,505:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,556:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-24 21:20:43,556:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,556:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,557:INFO:[LightGBM] [Info] Total Bins 545
2025-03-24 21:20:43,557:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-24 21:20:43,557:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.
2025-03-24 21:20:43,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,610:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,610:INFO:[LightGBM] [Info] Total Bins 543
2025-03-24 21:20:43,610:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-24 21:20:43,610:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-24 21:20:43,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,664:INFO:[LightGBM] [Info] Total Bins 541
2025-03-24 21:20:43,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-24 21:20:43,664:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-24 21:20:43,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,714:INFO:[LightGBM] [Info] Total Bins 539
2025-03-24 21:20:43,714:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-24 21:20:43,714:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-03-24 21:20:43,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,760:INFO:[LightGBM] [Info] Total Bins 537
2025-03-24 21:20:43,760:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-24 21:20:43,760:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,810:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-24 21:20:43,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,810:INFO:[LightGBM] [Info] Total Bins 535
2025-03-24 21:20:43,810:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-24 21:20:43,810:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,859:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-24 21:20:43,859:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,859:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,859:INFO:[LightGBM] [Info] Total Bins 533
2025-03-24 21:20:43,859:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-24 21:20:43,859:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,907:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.
2025-03-24 21:20:43,907:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,907:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,907:INFO:[LightGBM] [Info] Total Bins 531
2025-03-24 21:20:43,907:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-24 21:20:43,907:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.
2025-03-24 21:20:43,954:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,954:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,954:INFO:[LightGBM] [Info] Total Bins 529
2025-03-24 21:20:43,954:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-24 21:20:43,954:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,999:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.
2025-03-24 21:20:43,999:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,999:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,999:INFO:[LightGBM] [Info] Total Bins 527
2025-03-24 21:20:43,999:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-24 21:20:44,000:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:44,045:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.
2025-03-24 21:20:44,045:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,045:INFO:[LightGBM] [Info] Total Bins 525
2025-03-24 21:20:44,045:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-24 21:20:44,045:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:44,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.
2025-03-24 21:20:44,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,089:INFO:[LightGBM] [Info] Total Bins 300
2025-03-24 21:20:44,089:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-24 21:20:44,089:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:44,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.
2025-03-24 21:20:44,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,131:INFO:[LightGBM] [Info] Total Bins 255
2025-03-24 21:20:44,131:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 1
2025-03-24 21:20:44,131:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:44,185:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-24 21:20:44,185:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,185:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,185:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,185:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,185:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.
2025-03-24 21:20:44,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,240:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,240:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,240:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.
2025-03-24 21:20:44,298:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,298:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,298:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,298:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,298:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-24 21:20:44,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,351:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,351:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,351:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,404:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-03-24 21:20:44,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,405:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,405:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,405:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,463:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000971 seconds.
2025-03-24 21:20:44,463:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,463:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,463:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,463:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,463:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,516:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000578 seconds.
2025-03-24 21:20:44,516:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,516:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,516:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,516:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,517:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,577:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000681 seconds.
2025-03-24 21:20:44,577:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,577:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,577:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,577:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,578:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-03-24 21:20:44,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,645:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,645:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,645:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.
2025-03-24 21:20:44,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,708:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,708:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,708:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,765:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-03-24 21:20:44,765:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,765:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,765:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,765:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,765:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,818:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.
2025-03-24 21:20:44,818:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,818:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,818:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,818:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,818:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-03-24 21:20:44,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,873:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,873:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,873:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-24 21:20:44,926:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,926:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,927:INFO:[LightGBM] [Info] Total Bins 552
2025-03-24 21:20:44,927:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-24 21:20:44,927:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-24 21:20:44,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,979:INFO:[LightGBM] [Info] Total Bins 550
2025-03-24 21:20:44,979:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-24 21:20:44,979:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-24 21:20:45,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,033:INFO:[LightGBM] [Info] Total Bins 548
2025-03-24 21:20:45,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-24 21:20:45,033:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,081:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-24 21:20:45,081:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,081:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,083:INFO:[LightGBM] [Info] Total Bins 546
2025-03-24 21:20:45,083:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-24 21:20:45,083:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-24 21:20:45,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,131:INFO:[LightGBM] [Info] Total Bins 544
2025-03-24 21:20:45,131:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-24 21:20:45,131:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,180:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000555 seconds.
2025-03-24 21:20:45,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,180:INFO:[LightGBM] [Info] Total Bins 542
2025-03-24 21:20:45,180:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-24 21:20:45,180:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,230:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.
2025-03-24 21:20:45,230:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,230:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,230:INFO:[LightGBM] [Info] Total Bins 540
2025-03-24 21:20:45,230:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-24 21:20:45,230:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,279:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000977 seconds.
2025-03-24 21:20:45,279:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,279:INFO:[LightGBM] [Info] Total Bins 538
2025-03-24 21:20:45,279:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-24 21:20:45,279:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,327:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-24 21:20:45,327:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,327:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,327:INFO:[LightGBM] [Info] Total Bins 536
2025-03-24 21:20:45,327:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-24 21:20:45,327:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-24 21:20:45,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,377:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,377:INFO:[LightGBM] [Info] Total Bins 534
2025-03-24 21:20:45,377:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-24 21:20:45,377:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,423:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.
2025-03-24 21:20:45,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,424:INFO:[LightGBM] [Info] Total Bins 532
2025-03-24 21:20:45,424:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-24 21:20:45,424:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,468:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.
2025-03-24 21:20:45,468:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,468:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,468:INFO:[LightGBM] [Info] Total Bins 530
2025-03-24 21:20:45,468:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-24 21:20:45,469:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000061 seconds.
2025-03-24 21:20:45,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,513:INFO:[LightGBM] [Info] Total Bins 301
2025-03-24 21:20:45,513:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-24 21:20:45,513:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,556:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.
2025-03-24 21:20:45,556:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,556:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,556:INFO:[LightGBM] [Info] Total Bins 255
2025-03-24 21:20:45,556:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-24 21:20:45,556:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,609:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-03-24 21:20:45,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,609:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,609:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,609:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,661:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000597 seconds.
2025-03-24 21:20:45,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,661:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,661:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,661:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000746 seconds.
2025-03-24 21:20:45,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,729:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,729:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,729:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,781:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.
2025-03-24 21:20:45,781:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,781:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,781:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,781:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,781:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-24 21:20:45,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,832:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,832:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,833:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-03-24 21:20:45,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,883:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,883:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-03-24 21:20:45,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,933:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,933:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,933:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,984:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.
2025-03-24 21:20:45,984:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,984:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,984:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,984:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,984:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,037:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-03-24 21:20:46,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,037:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:46,037:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,037:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-03-24 21:20:46,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,089:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:46,089:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,089:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-03-24 21:20:46,143:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,143:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,143:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:46,143:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,143:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-24 21:20:46,194:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,194:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,194:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:46,195:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,195:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,244:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.
2025-03-24 21:20:46,245:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,245:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,245:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:46,245:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,245:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.
2025-03-24 21:20:46,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,295:INFO:[LightGBM] [Info] Total Bins 550
2025-03-24 21:20:46,295:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-24 21:20:46,295:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.
2025-03-24 21:20:46,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,346:INFO:[LightGBM] [Info] Total Bins 548
2025-03-24 21:20:46,346:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-24 21:20:46,346:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,396:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-24 21:20:46,396:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,396:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,396:INFO:[LightGBM] [Info] Total Bins 546
2025-03-24 21:20:46,396:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-24 21:20:46,397:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.
2025-03-24 21:20:46,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,447:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,447:INFO:[LightGBM] [Info] Total Bins 544
2025-03-24 21:20:46,447:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-24 21:20:46,447:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-24 21:20:46,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,497:INFO:[LightGBM] [Info] Total Bins 542
2025-03-24 21:20:46,497:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-24 21:20:46,497:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,546:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-03-24 21:20:46,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,546:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,546:INFO:[LightGBM] [Info] Total Bins 540
2025-03-24 21:20:46,546:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-24 21:20:46,546:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000740 seconds.
2025-03-24 21:20:46,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,596:INFO:[LightGBM] [Info] Total Bins 538
2025-03-24 21:20:46,596:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-24 21:20:46,596:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.
2025-03-24 21:20:46,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,644:INFO:[LightGBM] [Info] Total Bins 536
2025-03-24 21:20:46,644:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-24 21:20:46,644:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.
2025-03-24 21:20:46,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-24 21:20:46,711:INFO:[LightGBM] [Info] Total Bins 534
2025-03-24 21:20:46,711:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-24 21:20:46,711:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.
2025-03-24 21:20:46,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,766:INFO:[LightGBM] [Info] Total Bins 532
2025-03-24 21:20:46,766:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-24 21:20:46,766:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.
2025-03-24 21:20:46,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,814:INFO:[LightGBM] [Info] Total Bins 530
2025-03-24 21:20:46,814:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-24 21:20:46,814:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.
2025-03-24 21:20:46,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,858:INFO:[LightGBM] [Info] Total Bins 528
2025-03-24 21:20:46,858:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-24 21:20:46,859:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.
2025-03-24 21:20:46,899:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,899:INFO:[LightGBM] [Info] Total Bins 301
2025-03-24 21:20:46,899:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-24 21:20:46,899:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000034 seconds.
2025-03-24 21:20:46,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,939:INFO:[LightGBM] [Info] Total Bins 255
2025-03-24 21:20:46,939:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-24 21:20:46,939:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,991:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.
2025-03-24 21:20:46,991:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,991:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,991:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:46,993:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,993:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.
2025-03-24 21:20:47,049:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,049:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,049:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,049:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,049:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.
2025-03-24 21:20:47,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,104:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,104:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,104:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,156:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-03-24 21:20:47,156:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,156:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,156:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,156:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,156:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.
2025-03-24 21:20:47,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,207:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,207:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,207:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,266:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2025-03-24 21:20:47,266:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,266:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,266:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,266:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,266:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.
2025-03-24 21:20:47,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,319:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,319:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,319:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,319:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,375:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.
2025-03-24 21:20:47,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,375:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,375:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,375:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,433:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000490 seconds.
2025-03-24 21:20:47,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,433:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,433:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,433:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,433:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-03-24 21:20:47,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,488:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,488:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,488:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,541:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-03-24 21:20:47,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,541:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,541:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,541:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000711 seconds.
2025-03-24 21:20:47,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,596:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,597:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,597:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.
2025-03-24 21:20:47,651:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,651:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,651:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,651:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.
2025-03-24 21:20:47,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,703:INFO:[LightGBM] [Info] Total Bins 552
2025-03-24 21:20:47,703:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-24 21:20:47,703:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,755:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.
2025-03-24 21:20:47,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,755:INFO:[LightGBM] [Info] Total Bins 550
2025-03-24 21:20:47,755:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-24 21:20:47,755:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-24 21:20:47,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,806:INFO:[LightGBM] [Info] Total Bins 548
2025-03-24 21:20:47,806:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-24 21:20:47,806:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,857:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.
2025-03-24 21:20:47,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,857:INFO:[LightGBM] [Info] Total Bins 546
2025-03-24 21:20:47,857:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-24 21:20:47,857:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.
2025-03-24 21:20:47,905:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,905:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,905:INFO:[LightGBM] [Info] Total Bins 544
2025-03-24 21:20:47,905:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-24 21:20:47,905:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-24 21:20:47,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,955:INFO:[LightGBM] [Info] Total Bins 542
2025-03-24 21:20:47,955:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-24 21:20:47,955:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-24 21:20:48,004:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,004:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,004:INFO:[LightGBM] [Info] Total Bins 540
2025-03-24 21:20:48,004:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-24 21:20:48,005:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-24 21:20:48,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,054:INFO:[LightGBM] [Info] Total Bins 538
2025-03-24 21:20:48,054:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-24 21:20:48,054:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-03-24 21:20:48,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,103:INFO:[LightGBM] [Info] Total Bins 536
2025-03-24 21:20:48,103:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-24 21:20:48,103:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-24 21:20:48,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,154:INFO:[LightGBM] [Info] Total Bins 534
2025-03-24 21:20:48,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-24 21:20:48,154:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.
2025-03-24 21:20:48,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,201:INFO:[LightGBM] [Info] Total Bins 532
2025-03-24 21:20:48,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-24 21:20:48,201:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.
2025-03-24 21:20:48,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,252:INFO:[LightGBM] [Info] Total Bins 530
2025-03-24 21:20:48,252:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-24 21:20:48,252:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.
2025-03-24 21:20:48,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,297:INFO:[LightGBM] [Info] Total Bins 484
2025-03-24 21:20:48,297:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-24 21:20:48,297:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,341:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.
2025-03-24 21:20:48,341:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,341:INFO:[LightGBM] [Info] Total Bins 255
2025-03-24 21:20:48,341:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-24 21:20:48,341:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.
2025-03-24 21:20:48,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,398:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:20:48,398:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:48,398:INFO:[LightGBM] [Info] Start training from score 3259.166063
2025-03-24 21:20:48,449:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-03-24 21:20:48,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,450:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,450:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:20:48,450:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:48,450:INFO:[LightGBM] [Info] Start training from score 3259.166063
2025-03-24 21:20:48,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-24 21:20:48,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,501:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:20:48,501:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:48,501:INFO:[LightGBM] [Info] Start training from score 3259.166063
2025-03-24 21:20:48,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-03-24 21:20:48,555:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,555:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,555:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:20:48,555:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:48,555:INFO:[LightGBM] [Info] Start training from score 3259.166063
2025-03-24 21:20:48,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.
2025-03-24 21:20:48,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,608:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:20:48,608:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:48,608:INFO:[LightGBM] [Info] Start training from score 3259.166063
2025-03-24 21:20:49,536:INFO:Initializing evaluate_model()
2025-03-24 21:20:49,536:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:20:49,543:INFO:Initializing plot_model()
2025-03-24 21:20:49,543:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:49,543:INFO:Checking exceptions
2025-03-24 21:20:49,546:INFO:Preloading libraries
2025-03-24 21:20:49,549:INFO:Copying training dataset
2025-03-24 21:20:49,549:INFO:Plot type: pipeline
2025-03-24 21:20:49,626:INFO:Visual Rendered Successfully
2025-03-24 21:20:49,726:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:49,733:INFO:Initializing plot_model()
2025-03-24 21:20:49,733:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:49,734:INFO:Checking exceptions
2025-03-24 21:20:49,737:INFO:Preloading libraries
2025-03-24 21:20:49,744:INFO:Copying training dataset
2025-03-24 21:20:49,744:INFO:Plot type: pipeline
2025-03-24 21:20:49,828:INFO:Visual Rendered Successfully
2025-03-24 21:20:49,922:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:53,957:INFO:Initializing evaluate_model()
2025-03-24 21:20:53,957:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:20:53,964:INFO:Initializing plot_model()
2025-03-24 21:20:53,965:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:53,965:INFO:Checking exceptions
2025-03-24 21:20:53,968:INFO:Preloading libraries
2025-03-24 21:20:53,970:INFO:Copying training dataset
2025-03-24 21:20:53,971:INFO:Plot type: pipeline
2025-03-24 21:20:54,057:INFO:Visual Rendered Successfully
2025-03-24 21:20:54,155:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:55,558:INFO:Initializing plot_model()
2025-03-24 21:20:55,558:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:55,558:INFO:Checking exceptions
2025-03-24 21:20:55,561:INFO:Preloading libraries
2025-03-24 21:20:55,564:INFO:Copying training dataset
2025-03-24 21:20:55,564:INFO:Plot type: parameter
2025-03-24 21:20:55,567:INFO:Visual Rendered Successfully
2025-03-24 21:20:55,675:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:56,373:INFO:Initializing plot_model()
2025-03-24 21:20:56,373:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:56,374:INFO:Checking exceptions
2025-03-24 21:20:56,377:INFO:Preloading libraries
2025-03-24 21:20:56,379:INFO:Copying training dataset
2025-03-24 21:20:56,379:INFO:Plot type: vc
2025-03-24 21:20:56,380:INFO:Determining param_name
2025-03-24 21:20:56,380:INFO:param_name: max_depth
2025-03-24 21:20:56,616:INFO:Fitting Model
2025-03-24 21:21:02,051:INFO:Visual Rendered Successfully
2025-03-24 21:21:02,152:INFO:plot_model() successfully completed......................................
2025-03-24 21:21:02,157:INFO:Initializing evaluate_model()
2025-03-24 21:21:02,157:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:21:02,166:INFO:Initializing plot_model()
2025-03-24 21:21:02,166:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:21:02,166:INFO:Checking exceptions
2025-03-24 21:21:02,169:INFO:Preloading libraries
2025-03-24 21:21:02,173:INFO:Copying training dataset
2025-03-24 21:21:02,173:INFO:Plot type: pipeline
2025-03-24 21:21:02,251:INFO:Visual Rendered Successfully
2025-03-24 21:21:02,348:INFO:plot_model() successfully completed......................................
2025-03-24 21:21:04,939:INFO:Initializing plot_model()
2025-03-24 21:21:04,940:INFO:plot_model(plot=manifold, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:21:04,940:INFO:Checking exceptions
2025-03-24 21:21:04,943:INFO:Preloading libraries
2025-03-24 21:21:04,945:INFO:Copying training dataset
2025-03-24 21:21:04,945:INFO:Plot type: manifold
2025-03-24 21:21:05,187:INFO:Fitting & Transforming Model
2025-03-24 21:21:05,195:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] The system cannot find the file specified
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-03-24 21:21:05,196:WARNING:  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\joblib\externals\loky\backend\context.py", line 257, in _count_physical_cores
2025-03-24 21:21:05,196:WARNING:    cpu_info = subprocess.run(
2025-03-24 21:21:05,196:WARNING:  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\subprocess.py", line 503, in run
2025-03-24 21:21:05,196:WARNING:    with Popen(*popenargs, **kwargs) as process:
2025-03-24 21:21:05,196:WARNING:  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\subprocess.py", line 971, in __init__
2025-03-24 21:21:05,196:WARNING:    self._execute_child(args, executable, preexec_fn, close_fds,
2025-03-24 21:21:05,196:WARNING:  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\subprocess.py", line 1456, in _execute_child
2025-03-24 21:21:05,196:WARNING:    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
2025-03-24 21:21:39,369:INFO:Initializing evaluate_model()
2025-03-24 21:21:39,369:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:21:39,377:INFO:Initializing plot_model()
2025-03-24 21:21:39,377:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:21:39,377:INFO:Checking exceptions
2025-03-24 21:21:39,380:INFO:Preloading libraries
2025-03-24 21:21:39,383:INFO:Copying training dataset
2025-03-24 21:21:39,383:INFO:Plot type: pipeline
2025-03-24 21:21:39,459:INFO:Visual Rendered Successfully
2025-03-24 21:21:39,561:INFO:plot_model() successfully completed......................................
2025-03-24 21:21:39,575:INFO:Initializing plot_model()
2025-03-24 21:21:39,576:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:21:39,576:INFO:Checking exceptions
2025-03-24 21:21:39,578:INFO:Preloading libraries
2025-03-24 21:21:39,581:INFO:Copying training dataset
2025-03-24 21:21:39,581:INFO:Plot type: pipeline
2025-03-24 21:21:39,667:INFO:Visual Rendered Successfully
2025-03-24 21:21:39,763:INFO:plot_model() successfully completed......................................
2025-03-24 21:21:45,464:INFO:Initializing evaluate_model()
2025-03-24 21:21:45,464:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:21:45,473:INFO:Initializing plot_model()
2025-03-24 21:21:45,473:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:21:45,473:INFO:Checking exceptions
2025-03-24 21:21:45,477:INFO:Preloading libraries
2025-03-24 21:21:45,479:INFO:Copying training dataset
2025-03-24 21:21:45,479:INFO:Plot type: pipeline
2025-03-24 21:21:45,566:INFO:Visual Rendered Successfully
2025-03-24 21:21:45,668:INFO:plot_model() successfully completed......................................
2025-03-24 21:21:51,436:INFO:Initializing tune_model()
2025-03-24 21:21:51,436:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>)
2025-03-24 21:21:51,436:INFO:Checking exceptions
2025-03-24 21:21:51,448:INFO:Copying training dataset
2025-03-24 21:21:51,453:INFO:Checking base model
2025-03-24 21:21:51,453:INFO:Base model : Light Gradient Boosting Machine
2025-03-24 21:21:51,456:INFO:Declaring metric variables
2025-03-24 21:21:51,458:INFO:Defining Hyperparameters
2025-03-24 21:21:51,564:INFO:Tuning with n_jobs=-1
2025-03-24 21:21:51,564:INFO:Initializing RandomizedSearchCV
2025-03-24 21:22:12,945:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 60, 'actual_estimator__n_estimators': 210, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.7}
2025-03-24 21:22:12,946:INFO:Hyperparameter search completed
2025-03-24 21:22:12,946:INFO:SubProcess create_model() called ==================================
2025-03-24 21:22:12,947:INFO:Initializing create_model()
2025-03-24 21:22:12,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C95D050280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.05, 'num_leaves': 60, 'n_estimators': 210, 'min_split_gain': 0.5, 'min_child_samples': 6, 'learning_rate': 0.05, 'feature_fraction': 0.6, 'bagging_freq': 5, 'bagging_fraction': 0.7})
2025-03-24 21:22:12,947:INFO:Checking exceptions
2025-03-24 21:22:12,947:INFO:Importing libraries
2025-03-24 21:22:12,947:INFO:Copying training dataset
2025-03-24 21:22:12,957:INFO:Defining folds
2025-03-24 21:22:12,957:INFO:Declaring metric variables
2025-03-24 21:22:12,960:INFO:Importing untrained model
2025-03-24 21:22:12,960:INFO:Declaring custom model
2025-03-24 21:22:12,964:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:22:12,968:INFO:Starting cross validation
2025-03-24 21:22:12,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:22:15,621:INFO:Calculating mean and std
2025-03-24 21:22:15,622:INFO:Creating metrics dataframe
2025-03-24 21:22:15,626:INFO:Finalizing model
2025-03-24 21:22:15,724:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-03-24 21:22:15,724:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-03-24 21:22:15,724:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-24 21:22:15,735:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:22:15,736:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-03-24 21:22:15,736:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-03-24 21:22:15,736:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-24 21:22:15,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.
2025-03-24 21:22:15,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:22:15,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:22:15,737:INFO:[LightGBM] [Info] Total Bins 568
2025-03-24 21:22:15,737:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 16
2025-03-24 21:22:15,738:INFO:[LightGBM] [Info] Start training from score 3253.240353
2025-03-24 21:22:15,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:15,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:15,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:15,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:15,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:15,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:16,050:INFO:Uploading results into container
2025-03-24 21:22:16,051:INFO:Uploading model into container now
2025-03-24 21:22:16,052:INFO:_master_model_container: 19
2025-03-24 21:22:16,052:INFO:_display_container: 3
2025-03-24 21:22:16,052:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, feature_fraction=0.6,
              learning_rate=0.05, min_child_samples=6, min_split_gain=0.5,
              n_estimators=210, n_jobs=-1, num_leaves=60, random_state=1741,
              reg_alpha=0.05, reg_lambda=0.0005)
2025-03-24 21:22:16,053:INFO:create_model() successfully completed......................................
2025-03-24 21:22:16,176:INFO:SubProcess create_model() end ==================================
2025-03-24 21:22:16,176:INFO:choose_better activated
2025-03-24 21:22:16,178:INFO:SubProcess create_model() called ==================================
2025-03-24 21:22:16,180:INFO:Initializing create_model()
2025-03-24 21:22:16,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:22:16,180:INFO:Checking exceptions
2025-03-24 21:22:16,181:INFO:Importing libraries
2025-03-24 21:22:16,181:INFO:Copying training dataset
2025-03-24 21:22:16,190:INFO:Defining folds
2025-03-24 21:22:16,190:INFO:Declaring metric variables
2025-03-24 21:22:16,190:INFO:Importing untrained model
2025-03-24 21:22:16,190:INFO:Declaring custom model
2025-03-24 21:22:16,191:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:22:16,191:INFO:Starting cross validation
2025-03-24 21:22:16,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:22:17,124:INFO:Calculating mean and std
2025-03-24 21:22:17,124:INFO:Creating metrics dataframe
2025-03-24 21:22:17,126:INFO:Finalizing model
2025-03-24 21:22:17,235:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:22:17,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.
2025-03-24 21:22:17,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:22:17,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:22:17,237:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:22:17,237:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-24 21:22:17,237:INFO:[LightGBM] [Info] Start training from score 3253.240353
2025-03-24 21:22:17,304:INFO:Uploading results into container
2025-03-24 21:22:17,305:INFO:Uploading model into container now
2025-03-24 21:22:17,305:INFO:_master_model_container: 20
2025-03-24 21:22:17,305:INFO:_display_container: 4
2025-03-24 21:22:17,305:INFO:LGBMRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:22:17,305:INFO:create_model() successfully completed......................................
2025-03-24 21:22:17,428:INFO:SubProcess create_model() end ==================================
2025-03-24 21:22:17,429:INFO:LGBMRegressor(n_jobs=-1, random_state=1741) result for R2 is 0.2166
2025-03-24 21:22:17,430:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, feature_fraction=0.6,
              learning_rate=0.05, min_child_samples=6, min_split_gain=0.5,
              n_estimators=210, n_jobs=-1, num_leaves=60, random_state=1741,
              reg_alpha=0.05, reg_lambda=0.0005) result for R2 is 0.2198
2025-03-24 21:22:17,430:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, feature_fraction=0.6,
              learning_rate=0.05, min_child_samples=6, min_split_gain=0.5,
              n_estimators=210, n_jobs=-1, num_leaves=60, random_state=1741,
              reg_alpha=0.05, reg_lambda=0.0005) is best model
2025-03-24 21:22:17,430:INFO:choose_better completed
2025-03-24 21:22:17,437:INFO:_master_model_container: 20
2025-03-24 21:22:17,437:INFO:_display_container: 3
2025-03-24 21:22:17,437:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, feature_fraction=0.6,
              learning_rate=0.05, min_child_samples=6, min_split_gain=0.5,
              n_estimators=210, n_jobs=-1, num_leaves=60, random_state=1741,
              reg_alpha=0.05, reg_lambda=0.0005)
2025-03-24 21:22:17,437:INFO:tune_model() successfully completed......................................
2025-03-24 21:22:17,586:INFO:Initializing save_model()
2025-03-24 21:22:17,586:INFO:save_model(model=LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, feature_fraction=0.6,
              learning_rate=0.05, min_child_samples=6, min_split_gain=0.5,
              n_estimators=210, n_jobs=-1, num_leaves=60, random_state=1741,
              reg_alpha=0.05, reg_lambda=0.0005), model_name=tuned_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-24 21:22:17,586:INFO:Adding model into prep_pipe
2025-03-24 21:22:17,607:INFO:tuned_model.pkl saved in current working directory
2025-03-24 21:22:17,617:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(inclu...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model',
                 LGBMRegressor(bagging_fraction=0.7, bagging_freq=5,
                               feature_fraction=0.6, learning_rate=0.05,
                               min_child_samples=6, min_split_gain=0.5,
                               n_estimators=210, n_jobs=-1, num_leaves=60,
                               random_state=1741, reg_alpha=0.05,
                               reg_lambda=0.0005))])
2025-03-24 21:22:17,617:INFO:save_model() successfully completed......................................
2025-03-24 21:29:58,511:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:29:58,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:29:58,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:29:58,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:30:00,611:INFO:Initializing load_model()
2025-03-24 21:30:00,611:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 21:30:38,315:INFO:Initializing load_model()
2025-03-24 21:30:38,315:INFO:load_model(model_name=tuned_model, platform=None, authentication=None, verbose=True)
2025-03-24 21:30:38,385:INFO:Initializing predict_model()
2025-03-24 21:30:38,385:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BE154C0DF0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(inclu...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model',
                 LGBMRegressor(bagging_fraction=0.7, bagging_freq=5,
                               feature_fraction=0.6, learning_rate=0.05,
                               min_child_samples=6, min_split_gain=0.5,
                               n_estimators=210, n_jobs=-1, num_leaves=60,
                               random_state=1741, reg_alpha=0.05,
                               reg_lambda=0.0005))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BE158ADAB0>)
2025-03-24 21:30:38,385:INFO:Checking exceptions
2025-03-24 21:30:38,385:INFO:Preloading libraries
2025-03-24 21:30:38,386:INFO:Set up data.
2025-03-24 21:30:38,397:INFO:Set up index.
2025-03-24 21:47:55,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:47:55,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:47:55,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:47:55,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:48:37,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:48:37,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:48:37,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:48:37,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:48:37,761:INFO:PyCaret RegressionExperiment
2025-03-24 21:48:37,761:INFO:Logging name: reg-default-name
2025-03-24 21:48:37,761:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-24 21:48:37,761:INFO:version 3.3.2
2025-03-24 21:48:37,762:INFO:Initializing setup()
2025-03-24 21:48:37,762:INFO:self.USI: 71b0
2025-03-24 21:48:37,762:INFO:self._variable_keys: {'_ml_usecase', '_available_plots', 'fold_shuffle_param', 'idx', 'fold_generator', 'html_param', 'pipeline', 'exp_name_log', 'logging_param', 'gpu_n_jobs_param', 'log_plots_param', 'memory', 'X_test', 'transform_target_param', 'seed', 'USI', 'exp_id', 'X_train', 'X', 'y', 'gpu_param', 'data', 'y_train', 'y_test', 'n_jobs_param', 'target_param', 'fold_groups_param'}
2025-03-24 21:48:37,762:INFO:Checking environment
2025-03-24 21:48:37,762:INFO:python_version: 3.10.16
2025-03-24 21:48:37,762:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-24 21:48:37,762:INFO:machine: AMD64
2025-03-24 21:48:37,762:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-24 21:48:37,766:INFO:Memory: svmem(total=33411727360, available=16526667776, percent=50.5, used=16885059584, free=16526667776)
2025-03-24 21:48:37,766:INFO:Physical Core: 6
2025-03-24 21:48:37,766:INFO:Logical Core: 12
2025-03-24 21:48:37,766:INFO:Checking libraries
2025-03-24 21:48:37,766:INFO:System:
2025-03-24 21:48:37,767:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-24 21:48:37,767:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-24 21:48:37,767:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-24 21:48:37,767:INFO:PyCaret required dependencies:
2025-03-24 21:48:37,767:INFO:                 pip: 25.0.1
2025-03-24 21:48:37,767:INFO:          setuptools: 75.8.2
2025-03-24 21:48:37,768:INFO:             pycaret: 3.3.2
2025-03-24 21:48:37,768:INFO:             IPython: 8.34.0
2025-03-24 21:48:37,768:INFO:          ipywidgets: 8.1.5
2025-03-24 21:48:37,768:INFO:                tqdm: 4.67.1
2025-03-24 21:48:37,768:INFO:               numpy: 1.26.4
2025-03-24 21:48:37,768:INFO:              pandas: 2.1.4
2025-03-24 21:48:37,768:INFO:              jinja2: 3.1.6
2025-03-24 21:48:37,768:INFO:               scipy: 1.11.4
2025-03-24 21:48:37,768:INFO:              joblib: 1.3.2
2025-03-24 21:48:37,768:INFO:             sklearn: 1.4.2
2025-03-24 21:48:37,768:INFO:                pyod: 2.0.2
2025-03-24 21:48:37,768:INFO:            imblearn: 0.13.0
2025-03-24 21:48:37,768:INFO:   category_encoders: 2.7.0
2025-03-24 21:48:37,768:INFO:            lightgbm: 4.6.0
2025-03-24 21:48:37,768:INFO:               numba: 0.61.0
2025-03-24 21:48:37,768:INFO:            requests: 2.32.3
2025-03-24 21:48:37,768:INFO:          matplotlib: 3.10.1
2025-03-24 21:48:37,768:INFO:          scikitplot: 0.3.7
2025-03-24 21:48:37,768:INFO:         yellowbrick: 1.5
2025-03-24 21:48:37,768:INFO:              plotly: 6.0.1
2025-03-24 21:48:37,768:INFO:    plotly-resampler: Not installed
2025-03-24 21:48:37,768:INFO:             kaleido: 0.2.1
2025-03-24 21:48:37,768:INFO:           schemdraw: 0.15
2025-03-24 21:48:37,768:INFO:         statsmodels: 0.14.4
2025-03-24 21:48:37,768:INFO:              sktime: 0.26.0
2025-03-24 21:48:37,768:INFO:               tbats: 1.1.3
2025-03-24 21:48:37,768:INFO:            pmdarima: 2.0.4
2025-03-24 21:48:37,768:INFO:              psutil: 7.0.0
2025-03-24 21:48:37,768:INFO:          markupsafe: 3.0.2
2025-03-24 21:48:37,768:INFO:             pickle5: Not installed
2025-03-24 21:48:37,768:INFO:         cloudpickle: 3.1.1
2025-03-24 21:48:37,768:INFO:         deprecation: 2.1.0
2025-03-24 21:48:37,768:INFO:              xxhash: 3.5.0
2025-03-24 21:48:37,768:INFO:           wurlitzer: 3.1.1
2025-03-24 21:48:37,768:INFO:PyCaret optional dependencies:
2025-03-24 21:48:37,776:INFO:                shap: Not installed
2025-03-24 21:48:37,776:INFO:           interpret: Not installed
2025-03-24 21:48:37,776:INFO:                umap: 0.5.7
2025-03-24 21:48:37,776:INFO:     ydata_profiling: Not installed
2025-03-24 21:48:37,776:INFO:  explainerdashboard: Not installed
2025-03-24 21:48:37,776:INFO:             autoviz: Not installed
2025-03-24 21:48:37,776:INFO:           fairlearn: Not installed
2025-03-24 21:48:37,776:INFO:          deepchecks: Not installed
2025-03-24 21:48:37,776:INFO:             xgboost: Not installed
2025-03-24 21:48:37,776:INFO:            catboost: Not installed
2025-03-24 21:48:37,776:INFO:              kmodes: Not installed
2025-03-24 21:48:37,776:INFO:             mlxtend: Not installed
2025-03-24 21:48:37,776:INFO:       statsforecast: Not installed
2025-03-24 21:48:37,776:INFO:        tune_sklearn: Not installed
2025-03-24 21:48:37,776:INFO:                 ray: Not installed
2025-03-24 21:48:37,776:INFO:            hyperopt: Not installed
2025-03-24 21:48:37,776:INFO:              optuna: Not installed
2025-03-24 21:48:37,776:INFO:               skopt: Not installed
2025-03-24 21:48:37,777:INFO:              mlflow: Not installed
2025-03-24 21:48:37,777:INFO:              gradio: Not installed
2025-03-24 21:48:37,777:INFO:             fastapi: Not installed
2025-03-24 21:48:37,777:INFO:             uvicorn: Not installed
2025-03-24 21:48:37,777:INFO:              m2cgen: Not installed
2025-03-24 21:48:37,777:INFO:           evidently: Not installed
2025-03-24 21:48:37,777:INFO:               fugue: Not installed
2025-03-24 21:48:37,777:INFO:           streamlit: 1.43.2
2025-03-24 21:48:37,777:INFO:             prophet: Not installed
2025-03-24 21:48:37,777:INFO:None
2025-03-24 21:48:37,777:INFO:Set up data.
2025-03-24 21:48:37,787:INFO:Set up folding strategy.
2025-03-24 21:48:37,787:INFO:Set up train/test split.
2025-03-24 21:48:37,793:INFO:Set up index.
2025-03-24 21:48:37,794:INFO:Assigning column types.
2025-03-24 21:48:37,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-24 21:48:37,800:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,802:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,804:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:37,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:37,912:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,915:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,918:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,952:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,977:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:37,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:37,978:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-24 21:48:37,981:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,983:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,019:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,046:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,109:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-24 21:48:38,114:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,178:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,237:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,238:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-24 21:48:38,276:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,340:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,364:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,365:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,365:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-24 21:48:38,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,471:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,496:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-24 21:48:38,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,624:INFO:Preparing preprocessing pipeline...
2025-03-24 21:48:38,624:INFO:Set up simple imputation.
2025-03-24 21:48:38,627:INFO:Set up encoding of categorical features.
2025-03-24 21:48:38,628:INFO:Set up column name cleaning.
2025-03-24 21:48:38,737:INFO:Finished creating preprocessing pipeline.
2025-03-24 21:48:38,741:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-24 21:48:38,741:INFO:Creating final display dataframe.
2025-03-24 21:48:38,959:INFO:Setup _display_container:                     Description             Value
0                    Session id              5755
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              71b0
2025-03-24 21:48:39,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:39,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:39,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:39,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:39,096:INFO:setup() successfully completed in 1.34s...............
2025-03-24 21:48:39,105:INFO:Initializing compare_models()
2025-03-24 21:48:39,105:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-24 21:48:39,106:INFO:Checking exceptions
2025-03-24 21:48:39,109:INFO:Preparing display monitor
2025-03-24 21:48:39,123:INFO:Initializing Linear Regression
2025-03-24 21:48:39,123:INFO:Total runtime is 0.0 minutes
2025-03-24 21:48:39,125:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:39,126:INFO:Initializing create_model()
2025-03-24 21:48:39,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:39,126:INFO:Checking exceptions
2025-03-24 21:48:39,126:INFO:Importing libraries
2025-03-24 21:48:39,126:INFO:Copying training dataset
2025-03-24 21:48:39,133:INFO:Defining folds
2025-03-24 21:48:39,133:INFO:Declaring metric variables
2025-03-24 21:48:39,135:INFO:Importing untrained model
2025-03-24 21:48:39,137:INFO:Linear Regression Imported successfully
2025-03-24 21:48:39,141:INFO:Starting cross validation
2025-03-24 21:48:39,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:42,143:INFO:Calculating mean and std
2025-03-24 21:48:42,144:INFO:Creating metrics dataframe
2025-03-24 21:48:42,146:INFO:Uploading results into container
2025-03-24 21:48:42,147:INFO:Uploading model into container now
2025-03-24 21:48:42,148:INFO:_master_model_container: 1
2025-03-24 21:48:42,148:INFO:_display_container: 2
2025-03-24 21:48:42,148:INFO:LinearRegression(n_jobs=-1)
2025-03-24 21:48:42,148:INFO:create_model() successfully completed......................................
2025-03-24 21:48:42,235:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:42,235:INFO:Creating metrics dataframe
2025-03-24 21:48:42,240:INFO:Initializing Lasso Regression
2025-03-24 21:48:42,240:INFO:Total runtime is 0.051948734124501544 minutes
2025-03-24 21:48:42,242:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:42,242:INFO:Initializing create_model()
2025-03-24 21:48:42,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:42,242:INFO:Checking exceptions
2025-03-24 21:48:42,242:INFO:Importing libraries
2025-03-24 21:48:42,242:INFO:Copying training dataset
2025-03-24 21:48:42,251:INFO:Defining folds
2025-03-24 21:48:42,251:INFO:Declaring metric variables
2025-03-24 21:48:42,254:INFO:Importing untrained model
2025-03-24 21:48:42,257:INFO:Lasso Regression Imported successfully
2025-03-24 21:48:42,266:INFO:Starting cross validation
2025-03-24 21:48:42,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:44,021:INFO:Calculating mean and std
2025-03-24 21:48:44,022:INFO:Creating metrics dataframe
2025-03-24 21:48:44,023:INFO:Uploading results into container
2025-03-24 21:48:44,024:INFO:Uploading model into container now
2025-03-24 21:48:44,024:INFO:_master_model_container: 2
2025-03-24 21:48:44,024:INFO:_display_container: 2
2025-03-24 21:48:44,025:INFO:Lasso(random_state=5755)
2025-03-24 21:48:44,025:INFO:create_model() successfully completed......................................
2025-03-24 21:48:44,098:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:44,099:INFO:Creating metrics dataframe
2025-03-24 21:48:44,104:INFO:Initializing Ridge Regression
2025-03-24 21:48:44,104:INFO:Total runtime is 0.08301487366358438 minutes
2025-03-24 21:48:44,107:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:44,107:INFO:Initializing create_model()
2025-03-24 21:48:44,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:44,107:INFO:Checking exceptions
2025-03-24 21:48:44,107:INFO:Importing libraries
2025-03-24 21:48:44,107:INFO:Copying training dataset
2025-03-24 21:48:44,115:INFO:Defining folds
2025-03-24 21:48:44,115:INFO:Declaring metric variables
2025-03-24 21:48:44,117:INFO:Importing untrained model
2025-03-24 21:48:44,119:INFO:Ridge Regression Imported successfully
2025-03-24 21:48:44,122:INFO:Starting cross validation
2025-03-24 21:48:44,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:44,347:INFO:Calculating mean and std
2025-03-24 21:48:44,347:INFO:Creating metrics dataframe
2025-03-24 21:48:44,349:INFO:Uploading results into container
2025-03-24 21:48:44,349:INFO:Uploading model into container now
2025-03-24 21:48:44,349:INFO:_master_model_container: 3
2025-03-24 21:48:44,350:INFO:_display_container: 2
2025-03-24 21:48:44,350:INFO:Ridge(random_state=5755)
2025-03-24 21:48:44,350:INFO:create_model() successfully completed......................................
2025-03-24 21:48:44,411:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:44,411:INFO:Creating metrics dataframe
2025-03-24 21:48:44,416:INFO:Initializing Elastic Net
2025-03-24 21:48:44,416:INFO:Total runtime is 0.08821722666422525 minutes
2025-03-24 21:48:44,418:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:44,418:INFO:Initializing create_model()
2025-03-24 21:48:44,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:44,418:INFO:Checking exceptions
2025-03-24 21:48:44,418:INFO:Importing libraries
2025-03-24 21:48:44,418:INFO:Copying training dataset
2025-03-24 21:48:44,426:INFO:Defining folds
2025-03-24 21:48:44,426:INFO:Declaring metric variables
2025-03-24 21:48:44,428:INFO:Importing untrained model
2025-03-24 21:48:44,430:INFO:Elastic Net Imported successfully
2025-03-24 21:48:44,434:INFO:Starting cross validation
2025-03-24 21:48:44,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:44,674:INFO:Calculating mean and std
2025-03-24 21:48:44,675:INFO:Creating metrics dataframe
2025-03-24 21:48:44,676:INFO:Uploading results into container
2025-03-24 21:48:44,677:INFO:Uploading model into container now
2025-03-24 21:48:44,677:INFO:_master_model_container: 4
2025-03-24 21:48:44,677:INFO:_display_container: 2
2025-03-24 21:48:44,677:INFO:ElasticNet(random_state=5755)
2025-03-24 21:48:44,677:INFO:create_model() successfully completed......................................
2025-03-24 21:48:44,740:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:44,740:INFO:Creating metrics dataframe
2025-03-24 21:48:44,745:INFO:Initializing Least Angle Regression
2025-03-24 21:48:44,745:INFO:Total runtime is 0.09369642337163289 minutes
2025-03-24 21:48:44,747:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:44,747:INFO:Initializing create_model()
2025-03-24 21:48:44,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:44,747:INFO:Checking exceptions
2025-03-24 21:48:44,747:INFO:Importing libraries
2025-03-24 21:48:44,748:INFO:Copying training dataset
2025-03-24 21:48:44,755:INFO:Defining folds
2025-03-24 21:48:44,755:INFO:Declaring metric variables
2025-03-24 21:48:44,756:INFO:Importing untrained model
2025-03-24 21:48:44,758:INFO:Least Angle Regression Imported successfully
2025-03-24 21:48:44,763:INFO:Starting cross validation
2025-03-24 21:48:44,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:44,985:INFO:Calculating mean and std
2025-03-24 21:48:44,986:INFO:Creating metrics dataframe
2025-03-24 21:48:44,987:INFO:Uploading results into container
2025-03-24 21:48:44,987:INFO:Uploading model into container now
2025-03-24 21:48:44,987:INFO:_master_model_container: 5
2025-03-24 21:48:44,987:INFO:_display_container: 2
2025-03-24 21:48:44,988:INFO:Lars(random_state=5755)
2025-03-24 21:48:44,988:INFO:create_model() successfully completed......................................
2025-03-24 21:48:45,052:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:45,053:INFO:Creating metrics dataframe
2025-03-24 21:48:45,057:INFO:Initializing Lasso Least Angle Regression
2025-03-24 21:48:45,057:INFO:Total runtime is 0.09889419873555501 minutes
2025-03-24 21:48:45,060:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:45,060:INFO:Initializing create_model()
2025-03-24 21:48:45,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:45,060:INFO:Checking exceptions
2025-03-24 21:48:45,060:INFO:Importing libraries
2025-03-24 21:48:45,060:INFO:Copying training dataset
2025-03-24 21:48:45,067:INFO:Defining folds
2025-03-24 21:48:45,067:INFO:Declaring metric variables
2025-03-24 21:48:45,069:INFO:Importing untrained model
2025-03-24 21:48:45,071:INFO:Lasso Least Angle Regression Imported successfully
2025-03-24 21:48:45,075:INFO:Starting cross validation
2025-03-24 21:48:45,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:45,294:INFO:Calculating mean and std
2025-03-24 21:48:45,295:INFO:Creating metrics dataframe
2025-03-24 21:48:45,297:INFO:Uploading results into container
2025-03-24 21:48:45,297:INFO:Uploading model into container now
2025-03-24 21:48:45,297:INFO:_master_model_container: 6
2025-03-24 21:48:45,297:INFO:_display_container: 2
2025-03-24 21:48:45,298:INFO:LassoLars(random_state=5755)
2025-03-24 21:48:45,298:INFO:create_model() successfully completed......................................
2025-03-24 21:48:45,358:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:45,358:INFO:Creating metrics dataframe
2025-03-24 21:48:45,363:INFO:Initializing Orthogonal Matching Pursuit
2025-03-24 21:48:45,363:INFO:Total runtime is 0.10400258302688598 minutes
2025-03-24 21:48:45,366:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:45,366:INFO:Initializing create_model()
2025-03-24 21:48:45,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:45,366:INFO:Checking exceptions
2025-03-24 21:48:45,366:INFO:Importing libraries
2025-03-24 21:48:45,366:INFO:Copying training dataset
2025-03-24 21:48:45,373:INFO:Defining folds
2025-03-24 21:48:45,373:INFO:Declaring metric variables
2025-03-24 21:48:45,376:INFO:Importing untrained model
2025-03-24 21:48:45,378:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-24 21:48:45,381:INFO:Starting cross validation
2025-03-24 21:48:45,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:45,606:INFO:Calculating mean and std
2025-03-24 21:48:45,607:INFO:Creating metrics dataframe
2025-03-24 21:48:45,608:INFO:Uploading results into container
2025-03-24 21:48:45,608:INFO:Uploading model into container now
2025-03-24 21:48:45,608:INFO:_master_model_container: 7
2025-03-24 21:48:45,609:INFO:_display_container: 2
2025-03-24 21:48:45,609:INFO:OrthogonalMatchingPursuit()
2025-03-24 21:48:45,609:INFO:create_model() successfully completed......................................
2025-03-24 21:48:45,670:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:45,670:INFO:Creating metrics dataframe
2025-03-24 21:48:45,676:INFO:Initializing Bayesian Ridge
2025-03-24 21:48:45,676:INFO:Total runtime is 0.10921567281087238 minutes
2025-03-24 21:48:45,678:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:45,678:INFO:Initializing create_model()
2025-03-24 21:48:45,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:45,678:INFO:Checking exceptions
2025-03-24 21:48:45,678:INFO:Importing libraries
2025-03-24 21:48:45,678:INFO:Copying training dataset
2025-03-24 21:48:45,686:INFO:Defining folds
2025-03-24 21:48:45,686:INFO:Declaring metric variables
2025-03-24 21:48:45,687:INFO:Importing untrained model
2025-03-24 21:48:45,689:INFO:Bayesian Ridge Imported successfully
2025-03-24 21:48:45,693:INFO:Starting cross validation
2025-03-24 21:48:45,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:45,947:INFO:Calculating mean and std
2025-03-24 21:48:45,948:INFO:Creating metrics dataframe
2025-03-24 21:48:45,949:INFO:Uploading results into container
2025-03-24 21:48:45,950:INFO:Uploading model into container now
2025-03-24 21:48:45,950:INFO:_master_model_container: 8
2025-03-24 21:48:45,950:INFO:_display_container: 2
2025-03-24 21:48:45,950:INFO:BayesianRidge()
2025-03-24 21:48:45,950:INFO:create_model() successfully completed......................................
2025-03-24 21:48:46,017:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:46,017:INFO:Creating metrics dataframe
2025-03-24 21:48:46,022:INFO:Initializing Passive Aggressive Regressor
2025-03-24 21:48:46,022:INFO:Total runtime is 0.11497770945231119 minutes
2025-03-24 21:48:46,024:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:46,024:INFO:Initializing create_model()
2025-03-24 21:48:46,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:46,025:INFO:Checking exceptions
2025-03-24 21:48:46,025:INFO:Importing libraries
2025-03-24 21:48:46,025:INFO:Copying training dataset
2025-03-24 21:48:46,031:INFO:Defining folds
2025-03-24 21:48:46,031:INFO:Declaring metric variables
2025-03-24 21:48:46,032:INFO:Importing untrained model
2025-03-24 21:48:46,036:INFO:Passive Aggressive Regressor Imported successfully
2025-03-24 21:48:46,040:INFO:Starting cross validation
2025-03-24 21:48:46,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:46,413:INFO:Calculating mean and std
2025-03-24 21:48:46,413:INFO:Creating metrics dataframe
2025-03-24 21:48:46,414:INFO:Uploading results into container
2025-03-24 21:48:46,415:INFO:Uploading model into container now
2025-03-24 21:48:46,415:INFO:_master_model_container: 9
2025-03-24 21:48:46,415:INFO:_display_container: 2
2025-03-24 21:48:46,415:INFO:PassiveAggressiveRegressor(random_state=5755)
2025-03-24 21:48:46,415:INFO:create_model() successfully completed......................................
2025-03-24 21:48:46,478:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:46,478:INFO:Creating metrics dataframe
2025-03-24 21:48:46,482:INFO:Initializing Huber Regressor
2025-03-24 21:48:46,484:INFO:Total runtime is 0.12268313964207966 minutes
2025-03-24 21:48:46,485:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:46,485:INFO:Initializing create_model()
2025-03-24 21:48:46,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:46,486:INFO:Checking exceptions
2025-03-24 21:48:46,486:INFO:Importing libraries
2025-03-24 21:48:46,486:INFO:Copying training dataset
2025-03-24 21:48:46,493:INFO:Defining folds
2025-03-24 21:48:46,493:INFO:Declaring metric variables
2025-03-24 21:48:46,494:INFO:Importing untrained model
2025-03-24 21:48:46,496:INFO:Huber Regressor Imported successfully
2025-03-24 21:48:46,500:INFO:Starting cross validation
2025-03-24 21:48:46,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:48,021:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,056:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,096:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,153:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,188:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,191:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,211:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,237:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,310:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,391:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,416:INFO:Calculating mean and std
2025-03-24 21:48:48,417:INFO:Creating metrics dataframe
2025-03-24 21:48:48,418:INFO:Uploading results into container
2025-03-24 21:48:48,418:INFO:Uploading model into container now
2025-03-24 21:48:48,418:INFO:_master_model_container: 10
2025-03-24 21:48:48,418:INFO:_display_container: 2
2025-03-24 21:48:48,419:INFO:HuberRegressor()
2025-03-24 21:48:48,419:INFO:create_model() successfully completed......................................
2025-03-24 21:48:48,494:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:48,494:INFO:Creating metrics dataframe
2025-03-24 21:48:48,501:INFO:Initializing K Neighbors Regressor
2025-03-24 21:48:48,502:INFO:Total runtime is 0.15631857713063557 minutes
2025-03-24 21:48:48,504:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:48,504:INFO:Initializing create_model()
2025-03-24 21:48:48,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:48,505:INFO:Checking exceptions
2025-03-24 21:48:48,505:INFO:Importing libraries
2025-03-24 21:48:48,505:INFO:Copying training dataset
2025-03-24 21:48:48,512:INFO:Defining folds
2025-03-24 21:48:48,512:INFO:Declaring metric variables
2025-03-24 21:48:48,514:INFO:Importing untrained model
2025-03-24 21:48:48,516:INFO:K Neighbors Regressor Imported successfully
2025-03-24 21:48:48,520:INFO:Starting cross validation
2025-03-24 21:48:48,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:49,309:INFO:Calculating mean and std
2025-03-24 21:48:49,309:INFO:Creating metrics dataframe
2025-03-24 21:48:49,311:INFO:Uploading results into container
2025-03-24 21:48:49,311:INFO:Uploading model into container now
2025-03-24 21:48:49,311:INFO:_master_model_container: 11
2025-03-24 21:48:49,312:INFO:_display_container: 2
2025-03-24 21:48:49,312:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-24 21:48:49,312:INFO:create_model() successfully completed......................................
2025-03-24 21:48:49,376:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:49,376:INFO:Creating metrics dataframe
2025-03-24 21:48:49,381:INFO:Initializing Decision Tree Regressor
2025-03-24 21:48:49,382:INFO:Total runtime is 0.17098120053609211 minutes
2025-03-24 21:48:49,383:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:49,384:INFO:Initializing create_model()
2025-03-24 21:48:49,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:49,384:INFO:Checking exceptions
2025-03-24 21:48:49,384:INFO:Importing libraries
2025-03-24 21:48:49,384:INFO:Copying training dataset
2025-03-24 21:48:49,391:INFO:Defining folds
2025-03-24 21:48:49,391:INFO:Declaring metric variables
2025-03-24 21:48:49,393:INFO:Importing untrained model
2025-03-24 21:48:49,395:INFO:Decision Tree Regressor Imported successfully
2025-03-24 21:48:49,398:INFO:Starting cross validation
2025-03-24 21:48:49,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:49,714:INFO:Calculating mean and std
2025-03-24 21:48:49,715:INFO:Creating metrics dataframe
2025-03-24 21:48:49,716:INFO:Uploading results into container
2025-03-24 21:48:49,716:INFO:Uploading model into container now
2025-03-24 21:48:49,716:INFO:_master_model_container: 12
2025-03-24 21:48:49,716:INFO:_display_container: 2
2025-03-24 21:48:49,717:INFO:DecisionTreeRegressor(random_state=5755)
2025-03-24 21:48:49,717:INFO:create_model() successfully completed......................................
2025-03-24 21:48:49,777:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:49,777:INFO:Creating metrics dataframe
2025-03-24 21:48:49,783:INFO:Initializing Random Forest Regressor
2025-03-24 21:48:49,783:INFO:Total runtime is 0.177664311726888 minutes
2025-03-24 21:48:49,786:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:49,786:INFO:Initializing create_model()
2025-03-24 21:48:49,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:49,786:INFO:Checking exceptions
2025-03-24 21:48:49,786:INFO:Importing libraries
2025-03-24 21:48:49,786:INFO:Copying training dataset
2025-03-24 21:48:49,793:INFO:Defining folds
2025-03-24 21:48:49,793:INFO:Declaring metric variables
2025-03-24 21:48:49,795:INFO:Importing untrained model
2025-03-24 21:48:49,797:INFO:Random Forest Regressor Imported successfully
2025-03-24 21:48:49,801:INFO:Starting cross validation
2025-03-24 21:48:49,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:55,985:INFO:Calculating mean and std
2025-03-24 21:48:55,986:INFO:Creating metrics dataframe
2025-03-24 21:48:55,988:INFO:Uploading results into container
2025-03-24 21:48:55,988:INFO:Uploading model into container now
2025-03-24 21:48:55,988:INFO:_master_model_container: 13
2025-03-24 21:48:55,988:INFO:_display_container: 2
2025-03-24 21:48:55,989:INFO:RandomForestRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:48:55,989:INFO:create_model() successfully completed......................................
2025-03-24 21:48:56,063:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:56,064:INFO:Creating metrics dataframe
2025-03-24 21:48:56,070:INFO:Initializing Extra Trees Regressor
2025-03-24 21:48:56,070:INFO:Total runtime is 0.28244372208913165 minutes
2025-03-24 21:48:56,072:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:56,073:INFO:Initializing create_model()
2025-03-24 21:48:56,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:56,073:INFO:Checking exceptions
2025-03-24 21:48:56,073:INFO:Importing libraries
2025-03-24 21:48:56,073:INFO:Copying training dataset
2025-03-24 21:48:56,081:INFO:Defining folds
2025-03-24 21:48:56,081:INFO:Declaring metric variables
2025-03-24 21:48:56,082:INFO:Importing untrained model
2025-03-24 21:48:56,084:INFO:Extra Trees Regressor Imported successfully
2025-03-24 21:48:56,088:INFO:Starting cross validation
2025-03-24 21:48:56,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:59,907:INFO:Calculating mean and std
2025-03-24 21:48:59,908:INFO:Creating metrics dataframe
2025-03-24 21:48:59,910:INFO:Uploading results into container
2025-03-24 21:48:59,910:INFO:Uploading model into container now
2025-03-24 21:48:59,910:INFO:_master_model_container: 14
2025-03-24 21:48:59,910:INFO:_display_container: 2
2025-03-24 21:48:59,911:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:48:59,911:INFO:create_model() successfully completed......................................
2025-03-24 21:49:00,016:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:00,016:INFO:Creating metrics dataframe
2025-03-24 21:49:00,023:INFO:Initializing AdaBoost Regressor
2025-03-24 21:49:00,023:INFO:Total runtime is 0.3483403205871582 minutes
2025-03-24 21:49:00,025:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:00,025:INFO:Initializing create_model()
2025-03-24 21:49:00,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:00,026:INFO:Checking exceptions
2025-03-24 21:49:00,026:INFO:Importing libraries
2025-03-24 21:49:00,026:INFO:Copying training dataset
2025-03-24 21:49:00,035:INFO:Defining folds
2025-03-24 21:49:00,035:INFO:Declaring metric variables
2025-03-24 21:49:00,038:INFO:Importing untrained model
2025-03-24 21:49:00,041:INFO:AdaBoost Regressor Imported successfully
2025-03-24 21:49:00,046:INFO:Starting cross validation
2025-03-24 21:49:00,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:00,992:INFO:Calculating mean and std
2025-03-24 21:49:00,993:INFO:Creating metrics dataframe
2025-03-24 21:49:00,995:INFO:Uploading results into container
2025-03-24 21:49:00,995:INFO:Uploading model into container now
2025-03-24 21:49:00,996:INFO:_master_model_container: 15
2025-03-24 21:49:00,996:INFO:_display_container: 2
2025-03-24 21:49:00,996:INFO:AdaBoostRegressor(random_state=5755)
2025-03-24 21:49:00,996:INFO:create_model() successfully completed......................................
2025-03-24 21:49:01,068:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:01,068:INFO:Creating metrics dataframe
2025-03-24 21:49:01,075:INFO:Initializing Gradient Boosting Regressor
2025-03-24 21:49:01,075:INFO:Total runtime is 0.36586999893188477 minutes
2025-03-24 21:49:01,076:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:01,076:INFO:Initializing create_model()
2025-03-24 21:49:01,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:01,076:INFO:Checking exceptions
2025-03-24 21:49:01,078:INFO:Importing libraries
2025-03-24 21:49:01,078:INFO:Copying training dataset
2025-03-24 21:49:01,084:INFO:Defining folds
2025-03-24 21:49:01,084:INFO:Declaring metric variables
2025-03-24 21:49:01,086:INFO:Importing untrained model
2025-03-24 21:49:01,089:INFO:Gradient Boosting Regressor Imported successfully
2025-03-24 21:49:01,093:INFO:Starting cross validation
2025-03-24 21:49:01,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:03,082:INFO:Calculating mean and std
2025-03-24 21:49:03,083:INFO:Creating metrics dataframe
2025-03-24 21:49:03,084:INFO:Uploading results into container
2025-03-24 21:49:03,084:INFO:Uploading model into container now
2025-03-24 21:49:03,084:INFO:_master_model_container: 16
2025-03-24 21:49:03,084:INFO:_display_container: 2
2025-03-24 21:49:03,085:INFO:GradientBoostingRegressor(random_state=5755)
2025-03-24 21:49:03,085:INFO:create_model() successfully completed......................................
2025-03-24 21:49:03,150:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:03,150:INFO:Creating metrics dataframe
2025-03-24 21:49:03,157:INFO:Initializing Light Gradient Boosting Machine
2025-03-24 21:49:03,157:INFO:Total runtime is 0.4005635976791382 minutes
2025-03-24 21:49:03,158:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:03,159:INFO:Initializing create_model()
2025-03-24 21:49:03,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:03,159:INFO:Checking exceptions
2025-03-24 21:49:03,159:INFO:Importing libraries
2025-03-24 21:49:03,159:INFO:Copying training dataset
2025-03-24 21:49:03,165:INFO:Defining folds
2025-03-24 21:49:03,165:INFO:Declaring metric variables
2025-03-24 21:49:03,169:INFO:Importing untrained model
2025-03-24 21:49:03,171:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:49:03,175:INFO:Starting cross validation
2025-03-24 21:49:03,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:03,968:INFO:Calculating mean and std
2025-03-24 21:49:03,969:INFO:Creating metrics dataframe
2025-03-24 21:49:03,970:INFO:Uploading results into container
2025-03-24 21:49:03,971:INFO:Uploading model into container now
2025-03-24 21:49:03,971:INFO:_master_model_container: 17
2025-03-24 21:49:03,971:INFO:_display_container: 2
2025-03-24 21:49:03,972:INFO:LGBMRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:49:03,972:INFO:create_model() successfully completed......................................
2025-03-24 21:49:04,048:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:04,048:INFO:Creating metrics dataframe
2025-03-24 21:49:04,057:INFO:Initializing Dummy Regressor
2025-03-24 21:49:04,057:INFO:Total runtime is 0.4155646642049154 minutes
2025-03-24 21:49:04,059:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:04,059:INFO:Initializing create_model()
2025-03-24 21:49:04,059:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:04,059:INFO:Checking exceptions
2025-03-24 21:49:04,059:INFO:Importing libraries
2025-03-24 21:49:04,060:INFO:Copying training dataset
2025-03-24 21:49:04,068:INFO:Defining folds
2025-03-24 21:49:04,068:INFO:Declaring metric variables
2025-03-24 21:49:04,069:INFO:Importing untrained model
2025-03-24 21:49:04,071:INFO:Dummy Regressor Imported successfully
2025-03-24 21:49:04,075:INFO:Starting cross validation
2025-03-24 21:49:04,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:04,279:INFO:Calculating mean and std
2025-03-24 21:49:04,279:INFO:Creating metrics dataframe
2025-03-24 21:49:04,281:INFO:Uploading results into container
2025-03-24 21:49:04,281:INFO:Uploading model into container now
2025-03-24 21:49:04,281:INFO:_master_model_container: 18
2025-03-24 21:49:04,281:INFO:_display_container: 2
2025-03-24 21:49:04,281:INFO:DummyRegressor()
2025-03-24 21:49:04,282:INFO:create_model() successfully completed......................................
2025-03-24 21:49:04,348:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:04,348:INFO:Creating metrics dataframe
2025-03-24 21:49:04,355:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-24 21:49:04,359:INFO:Initializing create_model()
2025-03-24 21:49:04,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:04,360:INFO:Checking exceptions
2025-03-24 21:49:04,360:INFO:Importing libraries
2025-03-24 21:49:04,361:INFO:Copying training dataset
2025-03-24 21:49:04,367:INFO:Defining folds
2025-03-24 21:49:04,367:INFO:Declaring metric variables
2025-03-24 21:49:04,369:INFO:Importing untrained model
2025-03-24 21:49:04,369:INFO:Declaring custom model
2025-03-24 21:49:04,369:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:49:04,370:INFO:Cross validation set to False
2025-03-24 21:49:04,370:INFO:Fitting Model
2025-03-24 21:49:04,454:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:49:04,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.
2025-03-24 21:49:04,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:49:04,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:49:04,457:INFO:[LightGBM] [Info] Total Bins 559
2025-03-24 21:49:04,457:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-24 21:49:04,457:INFO:[LightGBM] [Info] Start training from score 3266.233596
2025-03-24 21:49:04,509:INFO:LGBMRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:49:04,509:INFO:create_model() successfully completed......................................
2025-03-24 21:49:04,607:INFO:_master_model_container: 18
2025-03-24 21:49:04,607:INFO:_display_container: 2
2025-03-24 21:49:04,607:INFO:LGBMRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:49:04,607:INFO:compare_models() successfully completed......................................
2025-03-24 21:49:04,644:INFO:Initializing evaluate_model()
2025-03-24 21:49:04,644:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:49:04,655:INFO:Initializing plot_model()
2025-03-24 21:49:04,655:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, system=True)
2025-03-24 21:49:04,655:INFO:Checking exceptions
2025-03-24 21:49:04,659:INFO:Preloading libraries
2025-03-24 21:49:04,665:INFO:Copying training dataset
2025-03-24 21:49:04,665:INFO:Plot type: pipeline
2025-03-24 21:49:04,801:INFO:Visual Rendered Successfully
2025-03-24 21:49:04,868:INFO:plot_model() successfully completed......................................
2025-03-24 21:49:04,891:INFO:Initializing tune_model()
2025-03-24 21:49:04,891:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=5755), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>)
2025-03-24 21:49:04,891:INFO:Checking exceptions
2025-03-24 21:49:04,903:INFO:Copying training dataset
2025-03-24 21:49:04,909:INFO:Checking base model
2025-03-24 21:49:04,909:INFO:Base model : Light Gradient Boosting Machine
2025-03-24 21:49:04,912:INFO:Declaring metric variables
2025-03-24 21:49:04,914:INFO:Defining Hyperparameters
2025-03-24 21:49:04,991:INFO:Tuning with n_jobs=-1
2025-03-24 21:49:04,991:INFO:Initializing RandomizedSearchCV
2025-03-24 21:49:28,844:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 8, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2025-03-24 21:49:28,845:INFO:Hyperparameter search completed
2025-03-24 21:49:28,845:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:28,847:INFO:Initializing create_model()
2025-03-24 21:49:28,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA35BEE60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 10, 'reg_alpha': 0.0005, 'num_leaves': 8, 'n_estimators': 90, 'min_split_gain': 0.3, 'min_child_samples': 61, 'learning_rate': 0.15, 'feature_fraction': 0.9, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2025-03-24 21:49:28,847:INFO:Checking exceptions
2025-03-24 21:49:28,847:INFO:Importing libraries
2025-03-24 21:49:28,847:INFO:Copying training dataset
2025-03-24 21:49:28,858:INFO:Defining folds
2025-03-24 21:49:28,858:INFO:Declaring metric variables
2025-03-24 21:49:28,860:INFO:Importing untrained model
2025-03-24 21:49:28,860:INFO:Declaring custom model
2025-03-24 21:49:28,864:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:49:28,868:INFO:Starting cross validation
2025-03-24 21:49:28,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:29,387:INFO:Calculating mean and std
2025-03-24 21:49:29,388:INFO:Creating metrics dataframe
2025-03-24 21:49:29,393:INFO:Finalizing model
2025-03-24 21:49:29,503:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-03-24 21:49:29,503:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-03-24 21:49:29,503:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-03-24 21:49:29,518:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:49:29,518:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-03-24 21:49:29,518:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-03-24 21:49:29,518:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-03-24 21:49:29,519:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-24 21:49:29,519:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:49:29,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:49:29,519:INFO:[LightGBM] [Info] Total Bins 548
2025-03-24 21:49:29,520:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 13
2025-03-24 21:49:29,520:INFO:[LightGBM] [Info] Start training from score 3266.233596
2025-03-24 21:49:29,573:INFO:Uploading results into container
2025-03-24 21:49:29,574:INFO:Uploading model into container now
2025-03-24 21:49:29,575:INFO:_master_model_container: 19
2025-03-24 21:49:29,575:INFO:_display_container: 3
2025-03-24 21:49:29,577:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.9,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.3,
              n_estimators=90, n_jobs=-1, num_leaves=8, random_state=5755,
              reg_alpha=0.0005, reg_lambda=10)
2025-03-24 21:49:29,577:INFO:create_model() successfully completed......................................
2025-03-24 21:49:29,660:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:29,660:INFO:choose_better activated
2025-03-24 21:49:29,663:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:29,663:INFO:Initializing create_model()
2025-03-24 21:49:29,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:29,664:INFO:Checking exceptions
2025-03-24 21:49:29,665:INFO:Importing libraries
2025-03-24 21:49:29,665:INFO:Copying training dataset
2025-03-24 21:49:29,675:INFO:Defining folds
2025-03-24 21:49:29,675:INFO:Declaring metric variables
2025-03-24 21:49:29,675:INFO:Importing untrained model
2025-03-24 21:49:29,675:INFO:Declaring custom model
2025-03-24 21:49:29,676:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:49:29,676:INFO:Starting cross validation
2025-03-24 21:49:29,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:30,569:INFO:Calculating mean and std
2025-03-24 21:49:30,569:INFO:Creating metrics dataframe
2025-03-24 21:49:30,571:INFO:Finalizing model
2025-03-24 21:49:30,677:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:49:30,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-24 21:49:30,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:49:30,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:49:30,678:INFO:[LightGBM] [Info] Total Bins 559
2025-03-24 21:49:30,678:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-24 21:49:30,678:INFO:[LightGBM] [Info] Start training from score 3266.233596
2025-03-24 21:49:30,748:INFO:Uploading results into container
2025-03-24 21:49:30,748:INFO:Uploading model into container now
2025-03-24 21:49:30,749:INFO:_master_model_container: 20
2025-03-24 21:49:30,749:INFO:_display_container: 4
2025-03-24 21:49:30,749:INFO:LGBMRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:49:30,749:INFO:create_model() successfully completed......................................
2025-03-24 21:49:30,825:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:30,827:INFO:LGBMRegressor(n_jobs=-1, random_state=5755) result for R2 is 0.214
2025-03-24 21:49:30,828:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.9,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.3,
              n_estimators=90, n_jobs=-1, num_leaves=8, random_state=5755,
              reg_alpha=0.0005, reg_lambda=10) result for R2 is 0.2026
2025-03-24 21:49:30,828:INFO:LGBMRegressor(n_jobs=-1, random_state=5755) is best model
2025-03-24 21:49:30,828:INFO:choose_better completed
2025-03-24 21:49:30,828:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-24 21:49:30,835:INFO:_master_model_container: 20
2025-03-24 21:49:30,835:INFO:_display_container: 3
2025-03-24 21:49:30,837:INFO:LGBMRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:49:30,837:INFO:tune_model() successfully completed......................................
2025-03-24 21:49:30,957:INFO:Initializing save_model()
2025-03-24 21:49:30,957:INFO:save_model(model=LGBMRegressor(n_jobs=-1, random_state=5755), model_name=traffic_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-24 21:49:30,957:INFO:Adding model into prep_pipe
2025-03-24 21:49:30,967:INFO:traffic_model.pkl saved in current working directory
2025-03-24 21:49:30,975:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))])
2025-03-24 21:49:30,975:INFO:save_model() successfully completed......................................
2025-03-24 21:49:41,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:49:41,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:49:41,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:49:41,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:51:11,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:51:11,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:51:11,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:51:11,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:52:15,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:52:15,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:52:15,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:52:15,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:53:32,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:53:32,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:53:32,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:53:32,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:55:10,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:55:10,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:55:10,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:55:10,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:55:12,832:INFO:Initializing load_model()
2025-03-24 21:55:12,833:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 21:55:12,897:INFO:Initializing predict_model()
2025-03-24 21:55:12,897:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025D3EF523B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025D3EFB5EA0>)
2025-03-24 21:55:12,897:INFO:Checking exceptions
2025-03-24 21:55:12,897:INFO:Preloading libraries
2025-03-24 21:55:12,897:INFO:Set up data.
2025-03-24 21:55:12,908:INFO:Set up index.
2025-03-24 21:59:07,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:59:07,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:59:07,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:59:07,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:59:09,570:INFO:Initializing load_model()
2025-03-24 21:59:09,570:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 21:59:09,628:INFO:Initializing predict_model()
2025-03-24 21:59:09,628:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002623A3D0790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002623BC372E0>)
2025-03-24 21:59:09,628:INFO:Checking exceptions
2025-03-24 21:59:09,628:INFO:Preloading libraries
2025-03-24 21:59:09,628:INFO:Set up data.
2025-03-24 21:59:09,639:INFO:Set up index.
2025-03-24 22:00:05,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:05,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:05,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:05,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:07,617:INFO:Initializing load_model()
2025-03-24 22:00:07,618:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:00:07,676:INFO:Initializing predict_model()
2025-03-24 22:00:07,677:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A4DB241480>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A4DB1FACB0>)
2025-03-24 22:00:07,677:INFO:Checking exceptions
2025-03-24 22:00:07,677:INFO:Preloading libraries
2025-03-24 22:00:07,677:INFO:Set up data.
2025-03-24 22:00:07,687:INFO:Set up index.
2025-03-24 22:00:30,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:30,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:30,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:30,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:33,147:INFO:Initializing load_model()
2025-03-24 22:00:33,147:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:00:33,201:INFO:Initializing predict_model()
2025-03-24 22:00:33,201:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001274B0AA1D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001274B9EFE20>)
2025-03-24 22:00:33,201:INFO:Checking exceptions
2025-03-24 22:00:33,203:INFO:Preloading libraries
2025-03-24 22:00:33,203:INFO:Set up data.
2025-03-24 22:00:33,213:INFO:Set up index.
2025-03-24 22:01:11,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:11,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:11,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:11,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:13,348:INFO:Initializing load_model()
2025-03-24 22:01:13,348:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:01:13,405:INFO:Initializing predict_model()
2025-03-24 22:01:13,405:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C8426FD60>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C84207520>)
2025-03-24 22:01:13,405:INFO:Checking exceptions
2025-03-24 22:01:13,405:INFO:Preloading libraries
2025-03-24 22:01:13,405:INFO:Set up data.
2025-03-24 22:01:13,416:INFO:Set up index.
2025-03-24 22:01:31,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:31,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:31,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:31,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:32,982:INFO:Initializing load_model()
2025-03-24 22:01:32,983:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:01:33,040:INFO:Initializing predict_model()
2025-03-24 22:01:33,040:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F380EF06D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F380E37880>)
2025-03-24 22:01:33,041:INFO:Checking exceptions
2025-03-24 22:01:33,041:INFO:Preloading libraries
2025-03-24 22:01:33,041:INFO:Set up data.
2025-03-24 22:01:33,051:INFO:Set up index.
2025-03-24 22:01:52,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:52,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:52,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:52,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:54,811:INFO:Initializing load_model()
2025-03-24 22:01:54,811:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:01:54,869:INFO:Initializing predict_model()
2025-03-24 22:01:54,869:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BBE9CA8250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BBE9BFF490>)
2025-03-24 22:01:54,869:INFO:Checking exceptions
2025-03-24 22:01:54,869:INFO:Preloading libraries
2025-03-24 22:01:54,870:INFO:Set up data.
2025-03-24 22:01:54,880:INFO:Set up index.
2025-03-24 22:02:10,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:02:10,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:02:10,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:02:10,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:02:11,913:INFO:Initializing load_model()
2025-03-24 22:02:11,914:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:02:11,970:INFO:Initializing predict_model()
2025-03-24 22:02:11,970:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023600047E50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002360001F9A0>)
2025-03-24 22:02:11,970:INFO:Checking exceptions
2025-03-24 22:02:11,970:INFO:Preloading libraries
2025-03-24 22:02:11,971:INFO:Set up data.
2025-03-24 22:02:11,980:INFO:Set up index.
2025-03-24 22:03:15,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:03:15,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:03:15,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:03:15,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:03:17,859:INFO:Initializing load_model()
2025-03-24 22:03:17,860:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:03:17,913:INFO:Initializing predict_model()
2025-03-24 22:03:17,913:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F81DCAB1F0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F81DC77910>)
2025-03-24 22:03:17,914:INFO:Checking exceptions
2025-03-24 22:03:17,914:INFO:Preloading libraries
2025-03-24 22:03:17,914:INFO:Set up data.
2025-03-24 22:03:17,924:INFO:Set up index.
2025-03-24 22:05:33,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:05:33,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:05:33,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:05:33,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:05:36,192:INFO:Initializing load_model()
2025-03-24 22:05:36,192:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:05:36,247:INFO:Initializing predict_model()
2025-03-24 22:05:36,248:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A7AC76CD30>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A7AC72EB00>)
2025-03-24 22:05:36,248:INFO:Checking exceptions
2025-03-24 22:05:36,248:INFO:Preloading libraries
2025-03-24 22:05:36,248:INFO:Set up data.
2025-03-24 22:05:36,257:INFO:Set up index.
2025-03-24 22:07:46,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:07:46,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:07:46,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:07:46,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:07:47,970:INFO:Initializing load_model()
2025-03-24 22:07:47,971:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:07:48,027:INFO:Initializing predict_model()
2025-03-24 22:07:48,027:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C437D6C250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C437CCB6D0>)
2025-03-24 22:07:48,028:INFO:Checking exceptions
2025-03-24 22:07:48,028:INFO:Preloading libraries
2025-03-24 22:07:48,028:INFO:Set up data.
2025-03-24 22:07:48,037:INFO:Set up index.
2025-03-24 23:23:49,023:INFO:Initializing load_model()
2025-03-24 23:23:49,023:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 23:23:49,039:INFO:Initializing predict_model()
2025-03-24 23:23:49,039:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C439024A90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C43900F760>)
2025-03-24 23:23:49,039:INFO:Checking exceptions
2025-03-24 23:23:49,039:INFO:Preloading libraries
2025-03-24 23:23:49,039:INFO:Set up data.
2025-03-24 23:23:49,051:INFO:Set up index.
2025-03-25 08:47:28,493:INFO:PyCaret RegressionExperiment
2025-03-25 08:47:28,493:INFO:Logging name: reg-default-name
2025-03-25 08:47:28,494:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-25 08:47:28,494:INFO:version 3.3.2
2025-03-25 08:47:28,494:INFO:Initializing setup()
2025-03-25 08:47:28,494:INFO:self.USI: 830a
2025-03-25 08:47:28,495:INFO:self._variable_keys: {'_ml_usecase', '_available_plots', 'fold_shuffle_param', 'idx', 'fold_generator', 'html_param', 'pipeline', 'exp_name_log', 'logging_param', 'gpu_n_jobs_param', 'log_plots_param', 'memory', 'X_test', 'transform_target_param', 'seed', 'USI', 'exp_id', 'X_train', 'X', 'y', 'gpu_param', 'data', 'y_train', 'y_test', 'n_jobs_param', 'target_param', 'fold_groups_param'}
2025-03-25 08:47:28,495:INFO:Checking environment
2025-03-25 08:47:28,495:INFO:python_version: 3.10.16
2025-03-25 08:47:28,495:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-25 08:47:28,495:INFO:machine: AMD64
2025-03-25 08:47:28,496:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-25 08:47:28,500:INFO:Memory: svmem(total=33411727360, available=11881947136, percent=64.4, used=21529780224, free=11881947136)
2025-03-25 08:47:28,500:INFO:Physical Core: 6
2025-03-25 08:47:28,500:INFO:Logical Core: 12
2025-03-25 08:47:28,500:INFO:Checking libraries
2025-03-25 08:47:28,500:INFO:System:
2025-03-25 08:47:28,500:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-25 08:47:28,500:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-25 08:47:28,500:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-25 08:47:28,500:INFO:PyCaret required dependencies:
2025-03-25 08:47:28,500:INFO:                 pip: 25.0.1
2025-03-25 08:47:28,500:INFO:          setuptools: 75.8.2
2025-03-25 08:47:28,500:INFO:             pycaret: 3.3.2
2025-03-25 08:47:28,500:INFO:             IPython: 8.34.0
2025-03-25 08:47:28,500:INFO:          ipywidgets: 8.1.5
2025-03-25 08:47:28,502:INFO:                tqdm: 4.67.1
2025-03-25 08:47:28,502:INFO:               numpy: 1.26.4
2025-03-25 08:47:28,502:INFO:              pandas: 2.1.4
2025-03-25 08:47:28,502:INFO:              jinja2: 3.1.6
2025-03-25 08:47:28,502:INFO:               scipy: 1.11.4
2025-03-25 08:47:28,502:INFO:              joblib: 1.3.2
2025-03-25 08:47:28,502:INFO:             sklearn: 1.4.2
2025-03-25 08:47:28,502:INFO:                pyod: 2.0.2
2025-03-25 08:47:28,502:INFO:            imblearn: 0.13.0
2025-03-25 08:47:28,502:INFO:   category_encoders: 2.7.0
2025-03-25 08:47:28,502:INFO:            lightgbm: 4.6.0
2025-03-25 08:47:28,502:INFO:               numba: 0.61.0
2025-03-25 08:47:28,502:INFO:            requests: 2.32.3
2025-03-25 08:47:28,502:INFO:          matplotlib: 3.10.1
2025-03-25 08:47:28,502:INFO:          scikitplot: 0.3.7
2025-03-25 08:47:28,502:INFO:         yellowbrick: 1.5
2025-03-25 08:47:28,502:INFO:              plotly: 6.0.1
2025-03-25 08:47:28,502:INFO:    plotly-resampler: Not installed
2025-03-25 08:47:28,502:INFO:             kaleido: 0.2.1
2025-03-25 08:47:28,502:INFO:           schemdraw: 0.15
2025-03-25 08:47:28,502:INFO:         statsmodels: 0.14.4
2025-03-25 08:47:28,502:INFO:              sktime: 0.26.0
2025-03-25 08:47:28,502:INFO:               tbats: 1.1.3
2025-03-25 08:47:28,502:INFO:            pmdarima: 2.0.4
2025-03-25 08:47:28,502:INFO:              psutil: 7.0.0
2025-03-25 08:47:28,502:INFO:          markupsafe: 3.0.2
2025-03-25 08:47:28,502:INFO:             pickle5: Not installed
2025-03-25 08:47:28,502:INFO:         cloudpickle: 3.1.1
2025-03-25 08:47:28,502:INFO:         deprecation: 2.1.0
2025-03-25 08:47:28,502:INFO:              xxhash: 3.5.0
2025-03-25 08:47:28,502:INFO:           wurlitzer: 3.1.1
2025-03-25 08:47:28,502:INFO:PyCaret optional dependencies:
2025-03-25 08:47:28,502:INFO:                shap: Not installed
2025-03-25 08:47:28,502:INFO:           interpret: Not installed
2025-03-25 08:47:28,502:INFO:                umap: 0.5.7
2025-03-25 08:47:28,502:INFO:     ydata_profiling: Not installed
2025-03-25 08:47:28,502:INFO:  explainerdashboard: Not installed
2025-03-25 08:47:28,502:INFO:             autoviz: Not installed
2025-03-25 08:47:28,502:INFO:           fairlearn: Not installed
2025-03-25 08:47:28,502:INFO:          deepchecks: Not installed
2025-03-25 08:47:28,502:INFO:             xgboost: Not installed
2025-03-25 08:47:28,502:INFO:            catboost: Not installed
2025-03-25 08:47:28,502:INFO:              kmodes: Not installed
2025-03-25 08:47:28,502:INFO:             mlxtend: Not installed
2025-03-25 08:47:28,502:INFO:       statsforecast: Not installed
2025-03-25 08:47:28,502:INFO:        tune_sklearn: Not installed
2025-03-25 08:47:28,502:INFO:                 ray: Not installed
2025-03-25 08:47:28,502:INFO:            hyperopt: Not installed
2025-03-25 08:47:28,502:INFO:              optuna: Not installed
2025-03-25 08:47:28,502:INFO:               skopt: Not installed
2025-03-25 08:47:28,502:INFO:              mlflow: Not installed
2025-03-25 08:47:28,502:INFO:              gradio: Not installed
2025-03-25 08:47:28,503:INFO:             fastapi: Not installed
2025-03-25 08:47:28,503:INFO:             uvicorn: Not installed
2025-03-25 08:47:28,503:INFO:              m2cgen: Not installed
2025-03-25 08:47:28,503:INFO:           evidently: Not installed
2025-03-25 08:47:28,503:INFO:               fugue: Not installed
2025-03-25 08:47:28,503:INFO:           streamlit: 1.43.2
2025-03-25 08:47:28,503:INFO:             prophet: Not installed
2025-03-25 08:47:28,503:INFO:None
2025-03-25 08:47:28,503:INFO:Set up data.
2025-03-25 08:47:28,510:INFO:Set up folding strategy.
2025-03-25 08:47:28,510:INFO:Set up train/test split.
2025-03-25 08:47:28,516:INFO:Set up index.
2025-03-25 08:47:28,517:INFO:Assigning column types.
2025-03-25 08:47:28,520:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-25 08:47:28,520:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,523:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,526:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,564:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,593:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,595:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,598:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,664:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-25 08:47:28,666:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,669:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,706:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,736:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,776:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,802:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,803:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-25 08:47:28,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,845:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,878:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,946:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-25 08:47:28,989:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,062:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,090:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-25 08:47:29,132:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,228:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-25 08:47:29,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,371:INFO:Preparing preprocessing pipeline...
2025-03-25 08:47:29,372:INFO:Set up simple imputation.
2025-03-25 08:47:29,376:INFO:Set up encoding of categorical features.
2025-03-25 08:47:29,376:INFO:Set up column name cleaning.
2025-03-25 08:47:29,487:INFO:Finished creating preprocessing pipeline.
2025-03-25 08:47:29,491:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-25 08:47:29,491:INFO:Creating final display dataframe.
2025-03-25 08:47:29,710:INFO:Setup _display_container:                     Description             Value
0                    Session id              2242
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              830a
2025-03-25 08:47:29,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,860:INFO:setup() successfully completed in 1.37s...............
2025-03-25 08:47:31,097:INFO:Initializing compare_models()
2025-03-25 08:47:31,098:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-25 08:47:31,098:INFO:Checking exceptions
2025-03-25 08:47:31,102:INFO:Preparing display monitor
2025-03-25 08:47:31,118:INFO:Initializing Linear Regression
2025-03-25 08:47:31,118:INFO:Total runtime is 0.0 minutes
2025-03-25 08:47:31,120:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:31,120:INFO:Initializing create_model()
2025-03-25 08:47:31,120:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:31,120:INFO:Checking exceptions
2025-03-25 08:47:31,120:INFO:Importing libraries
2025-03-25 08:47:31,120:INFO:Copying training dataset
2025-03-25 08:47:31,128:INFO:Defining folds
2025-03-25 08:47:31,128:INFO:Declaring metric variables
2025-03-25 08:47:31,132:INFO:Importing untrained model
2025-03-25 08:47:31,134:INFO:Linear Regression Imported successfully
2025-03-25 08:47:31,138:INFO:Starting cross validation
2025-03-25 08:47:31,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:34,460:INFO:Calculating mean and std
2025-03-25 08:47:34,462:INFO:Creating metrics dataframe
2025-03-25 08:47:34,463:INFO:Uploading results into container
2025-03-25 08:47:34,464:INFO:Uploading model into container now
2025-03-25 08:47:34,465:INFO:_master_model_container: 1
2025-03-25 08:47:34,465:INFO:_display_container: 2
2025-03-25 08:47:34,466:INFO:LinearRegression(n_jobs=-1)
2025-03-25 08:47:34,466:INFO:create_model() successfully completed......................................
2025-03-25 08:47:34,600:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:34,600:INFO:Creating metrics dataframe
2025-03-25 08:47:34,604:INFO:Initializing Lasso Regression
2025-03-25 08:47:34,604:INFO:Total runtime is 0.058097438017527266 minutes
2025-03-25 08:47:34,607:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:34,607:INFO:Initializing create_model()
2025-03-25 08:47:34,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:34,607:INFO:Checking exceptions
2025-03-25 08:47:34,607:INFO:Importing libraries
2025-03-25 08:47:34,607:INFO:Copying training dataset
2025-03-25 08:47:34,615:INFO:Defining folds
2025-03-25 08:47:34,616:INFO:Declaring metric variables
2025-03-25 08:47:34,619:INFO:Importing untrained model
2025-03-25 08:47:34,621:INFO:Lasso Regression Imported successfully
2025-03-25 08:47:34,625:INFO:Starting cross validation
2025-03-25 08:47:34,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:36,531:INFO:Calculating mean and std
2025-03-25 08:47:36,532:INFO:Creating metrics dataframe
2025-03-25 08:47:36,533:INFO:Uploading results into container
2025-03-25 08:47:36,534:INFO:Uploading model into container now
2025-03-25 08:47:36,534:INFO:_master_model_container: 2
2025-03-25 08:47:36,534:INFO:_display_container: 2
2025-03-25 08:47:36,535:INFO:Lasso(random_state=2242)
2025-03-25 08:47:36,535:INFO:create_model() successfully completed......................................
2025-03-25 08:47:36,640:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:36,640:INFO:Creating metrics dataframe
2025-03-25 08:47:36,645:INFO:Initializing Ridge Regression
2025-03-25 08:47:36,645:INFO:Total runtime is 0.0921022375424703 minutes
2025-03-25 08:47:36,647:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:36,647:INFO:Initializing create_model()
2025-03-25 08:47:36,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:36,648:INFO:Checking exceptions
2025-03-25 08:47:36,648:INFO:Importing libraries
2025-03-25 08:47:36,648:INFO:Copying training dataset
2025-03-25 08:47:36,655:INFO:Defining folds
2025-03-25 08:47:36,655:INFO:Declaring metric variables
2025-03-25 08:47:36,658:INFO:Importing untrained model
2025-03-25 08:47:36,660:INFO:Ridge Regression Imported successfully
2025-03-25 08:47:36,664:INFO:Starting cross validation
2025-03-25 08:47:36,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:36,971:INFO:Calculating mean and std
2025-03-25 08:47:36,972:INFO:Creating metrics dataframe
2025-03-25 08:47:36,974:INFO:Uploading results into container
2025-03-25 08:47:36,974:INFO:Uploading model into container now
2025-03-25 08:47:36,974:INFO:_master_model_container: 3
2025-03-25 08:47:36,975:INFO:_display_container: 2
2025-03-25 08:47:36,975:INFO:Ridge(random_state=2242)
2025-03-25 08:47:36,975:INFO:create_model() successfully completed......................................
2025-03-25 08:47:37,078:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:37,078:INFO:Creating metrics dataframe
2025-03-25 08:47:37,083:INFO:Initializing Elastic Net
2025-03-25 08:47:37,083:INFO:Total runtime is 0.09940207799275716 minutes
2025-03-25 08:47:37,085:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:37,085:INFO:Initializing create_model()
2025-03-25 08:47:37,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:37,085:INFO:Checking exceptions
2025-03-25 08:47:37,085:INFO:Importing libraries
2025-03-25 08:47:37,085:INFO:Copying training dataset
2025-03-25 08:47:37,093:INFO:Defining folds
2025-03-25 08:47:37,093:INFO:Declaring metric variables
2025-03-25 08:47:37,096:INFO:Importing untrained model
2025-03-25 08:47:37,099:INFO:Elastic Net Imported successfully
2025-03-25 08:47:37,105:INFO:Starting cross validation
2025-03-25 08:47:37,106:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:37,404:INFO:Calculating mean and std
2025-03-25 08:47:37,405:INFO:Creating metrics dataframe
2025-03-25 08:47:37,407:INFO:Uploading results into container
2025-03-25 08:47:37,407:INFO:Uploading model into container now
2025-03-25 08:47:37,408:INFO:_master_model_container: 4
2025-03-25 08:47:37,408:INFO:_display_container: 2
2025-03-25 08:47:37,408:INFO:ElasticNet(random_state=2242)
2025-03-25 08:47:37,409:INFO:create_model() successfully completed......................................
2025-03-25 08:47:37,508:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:37,509:INFO:Creating metrics dataframe
2025-03-25 08:47:37,514:INFO:Initializing Least Angle Regression
2025-03-25 08:47:37,514:INFO:Total runtime is 0.10658913056055705 minutes
2025-03-25 08:47:37,516:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:37,517:INFO:Initializing create_model()
2025-03-25 08:47:37,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:37,517:INFO:Checking exceptions
2025-03-25 08:47:37,517:INFO:Importing libraries
2025-03-25 08:47:37,517:INFO:Copying training dataset
2025-03-25 08:47:37,528:INFO:Defining folds
2025-03-25 08:47:37,528:INFO:Declaring metric variables
2025-03-25 08:47:37,531:INFO:Importing untrained model
2025-03-25 08:47:37,534:INFO:Least Angle Regression Imported successfully
2025-03-25 08:47:37,539:INFO:Starting cross validation
2025-03-25 08:47:37,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:37,812:INFO:Calculating mean and std
2025-03-25 08:47:37,812:INFO:Creating metrics dataframe
2025-03-25 08:47:37,814:INFO:Uploading results into container
2025-03-25 08:47:37,814:INFO:Uploading model into container now
2025-03-25 08:47:37,814:INFO:_master_model_container: 5
2025-03-25 08:47:37,814:INFO:_display_container: 2
2025-03-25 08:47:37,815:INFO:Lars(random_state=2242)
2025-03-25 08:47:37,815:INFO:create_model() successfully completed......................................
2025-03-25 08:47:37,915:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:37,915:INFO:Creating metrics dataframe
2025-03-25 08:47:37,922:INFO:Initializing Lasso Least Angle Regression
2025-03-25 08:47:37,922:INFO:Total runtime is 0.11338719526926677 minutes
2025-03-25 08:47:37,924:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:37,924:INFO:Initializing create_model()
2025-03-25 08:47:37,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:37,924:INFO:Checking exceptions
2025-03-25 08:47:37,924:INFO:Importing libraries
2025-03-25 08:47:37,924:INFO:Copying training dataset
2025-03-25 08:47:37,932:INFO:Defining folds
2025-03-25 08:47:37,932:INFO:Declaring metric variables
2025-03-25 08:47:37,935:INFO:Importing untrained model
2025-03-25 08:47:37,938:INFO:Lasso Least Angle Regression Imported successfully
2025-03-25 08:47:37,943:INFO:Starting cross validation
2025-03-25 08:47:37,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:38,214:INFO:Calculating mean and std
2025-03-25 08:47:38,215:INFO:Creating metrics dataframe
2025-03-25 08:47:38,217:INFO:Uploading results into container
2025-03-25 08:47:38,218:INFO:Uploading model into container now
2025-03-25 08:47:38,218:INFO:_master_model_container: 6
2025-03-25 08:47:38,218:INFO:_display_container: 2
2025-03-25 08:47:38,218:INFO:LassoLars(random_state=2242)
2025-03-25 08:47:38,219:INFO:create_model() successfully completed......................................
2025-03-25 08:47:38,317:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:38,317:INFO:Creating metrics dataframe
2025-03-25 08:47:38,323:INFO:Initializing Orthogonal Matching Pursuit
2025-03-25 08:47:38,323:INFO:Total runtime is 0.12008169492085775 minutes
2025-03-25 08:47:38,325:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:38,325:INFO:Initializing create_model()
2025-03-25 08:47:38,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:38,326:INFO:Checking exceptions
2025-03-25 08:47:38,326:INFO:Importing libraries
2025-03-25 08:47:38,326:INFO:Copying training dataset
2025-03-25 08:47:38,334:INFO:Defining folds
2025-03-25 08:47:38,334:INFO:Declaring metric variables
2025-03-25 08:47:38,337:INFO:Importing untrained model
2025-03-25 08:47:38,340:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-25 08:47:38,343:INFO:Starting cross validation
2025-03-25 08:47:38,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:38,591:INFO:Calculating mean and std
2025-03-25 08:47:38,592:INFO:Creating metrics dataframe
2025-03-25 08:47:38,593:INFO:Uploading results into container
2025-03-25 08:47:38,593:INFO:Uploading model into container now
2025-03-25 08:47:38,594:INFO:_master_model_container: 7
2025-03-25 08:47:38,594:INFO:_display_container: 2
2025-03-25 08:47:38,594:INFO:OrthogonalMatchingPursuit()
2025-03-25 08:47:38,594:INFO:create_model() successfully completed......................................
2025-03-25 08:47:38,694:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:38,694:INFO:Creating metrics dataframe
2025-03-25 08:47:38,700:INFO:Initializing Bayesian Ridge
2025-03-25 08:47:38,700:INFO:Total runtime is 0.12635663350423176 minutes
2025-03-25 08:47:38,702:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:38,702:INFO:Initializing create_model()
2025-03-25 08:47:38,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:38,702:INFO:Checking exceptions
2025-03-25 08:47:38,703:INFO:Importing libraries
2025-03-25 08:47:38,703:INFO:Copying training dataset
2025-03-25 08:47:38,710:INFO:Defining folds
2025-03-25 08:47:38,710:INFO:Declaring metric variables
2025-03-25 08:47:38,713:INFO:Importing untrained model
2025-03-25 08:47:38,716:INFO:Bayesian Ridge Imported successfully
2025-03-25 08:47:38,723:INFO:Starting cross validation
2025-03-25 08:47:38,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:39,009:INFO:Calculating mean and std
2025-03-25 08:47:39,010:INFO:Creating metrics dataframe
2025-03-25 08:47:39,010:INFO:Uploading results into container
2025-03-25 08:47:39,012:INFO:Uploading model into container now
2025-03-25 08:47:39,012:INFO:_master_model_container: 8
2025-03-25 08:47:39,012:INFO:_display_container: 2
2025-03-25 08:47:39,013:INFO:BayesianRidge()
2025-03-25 08:47:39,013:INFO:create_model() successfully completed......................................
2025-03-25 08:47:39,104:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:39,104:INFO:Creating metrics dataframe
2025-03-25 08:47:39,109:INFO:Initializing Passive Aggressive Regressor
2025-03-25 08:47:39,109:INFO:Total runtime is 0.13317962090174357 minutes
2025-03-25 08:47:39,112:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:39,112:INFO:Initializing create_model()
2025-03-25 08:47:39,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:39,112:INFO:Checking exceptions
2025-03-25 08:47:39,112:INFO:Importing libraries
2025-03-25 08:47:39,112:INFO:Copying training dataset
2025-03-25 08:47:39,120:INFO:Defining folds
2025-03-25 08:47:39,120:INFO:Declaring metric variables
2025-03-25 08:47:39,123:INFO:Importing untrained model
2025-03-25 08:47:39,125:INFO:Passive Aggressive Regressor Imported successfully
2025-03-25 08:47:39,129:INFO:Starting cross validation
2025-03-25 08:47:39,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:39,576:INFO:Calculating mean and std
2025-03-25 08:47:39,577:INFO:Creating metrics dataframe
2025-03-25 08:47:39,578:INFO:Uploading results into container
2025-03-25 08:47:39,578:INFO:Uploading model into container now
2025-03-25 08:47:39,579:INFO:_master_model_container: 9
2025-03-25 08:47:39,579:INFO:_display_container: 2
2025-03-25 08:47:39,579:INFO:PassiveAggressiveRegressor(random_state=2242)
2025-03-25 08:47:39,579:INFO:create_model() successfully completed......................................
2025-03-25 08:47:39,672:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:39,672:INFO:Creating metrics dataframe
2025-03-25 08:47:39,678:INFO:Initializing Huber Regressor
2025-03-25 08:47:39,678:INFO:Total runtime is 0.14266188542048136 minutes
2025-03-25 08:47:39,680:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:39,680:INFO:Initializing create_model()
2025-03-25 08:47:39,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:39,680:INFO:Checking exceptions
2025-03-25 08:47:39,680:INFO:Importing libraries
2025-03-25 08:47:39,680:INFO:Copying training dataset
2025-03-25 08:47:39,690:INFO:Defining folds
2025-03-25 08:47:39,690:INFO:Declaring metric variables
2025-03-25 08:47:39,693:INFO:Importing untrained model
2025-03-25 08:47:39,696:INFO:Huber Regressor Imported successfully
2025-03-25 08:47:39,699:INFO:Starting cross validation
2025-03-25 08:47:39,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:41,550:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,573:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,584:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,586:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,624:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,624:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,680:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,695:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,717:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,745:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,767:INFO:Calculating mean and std
2025-03-25 08:47:41,768:INFO:Creating metrics dataframe
2025-03-25 08:47:41,769:INFO:Uploading results into container
2025-03-25 08:47:41,770:INFO:Uploading model into container now
2025-03-25 08:47:41,770:INFO:_master_model_container: 10
2025-03-25 08:47:41,770:INFO:_display_container: 2
2025-03-25 08:47:41,770:INFO:HuberRegressor()
2025-03-25 08:47:41,770:INFO:create_model() successfully completed......................................
2025-03-25 08:47:41,868:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:41,869:INFO:Creating metrics dataframe
2025-03-25 08:47:41,875:INFO:Initializing K Neighbors Regressor
2025-03-25 08:47:41,875:INFO:Total runtime is 0.1792699098587036 minutes
2025-03-25 08:47:41,878:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:41,878:INFO:Initializing create_model()
2025-03-25 08:47:41,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:41,878:INFO:Checking exceptions
2025-03-25 08:47:41,878:INFO:Importing libraries
2025-03-25 08:47:41,878:INFO:Copying training dataset
2025-03-25 08:47:41,886:INFO:Defining folds
2025-03-25 08:47:41,886:INFO:Declaring metric variables
2025-03-25 08:47:41,889:INFO:Importing untrained model
2025-03-25 08:47:41,891:INFO:K Neighbors Regressor Imported successfully
2025-03-25 08:47:41,894:INFO:Starting cross validation
2025-03-25 08:47:41,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:42,700:INFO:Calculating mean and std
2025-03-25 08:47:42,700:INFO:Creating metrics dataframe
2025-03-25 08:47:42,703:INFO:Uploading results into container
2025-03-25 08:47:42,704:INFO:Uploading model into container now
2025-03-25 08:47:42,704:INFO:_master_model_container: 11
2025-03-25 08:47:42,704:INFO:_display_container: 2
2025-03-25 08:47:42,704:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-25 08:47:42,705:INFO:create_model() successfully completed......................................
2025-03-25 08:47:42,799:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:42,799:INFO:Creating metrics dataframe
2025-03-25 08:47:42,804:INFO:Initializing Decision Tree Regressor
2025-03-25 08:47:42,804:INFO:Total runtime is 0.1947669784228007 minutes
2025-03-25 08:47:42,806:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:42,807:INFO:Initializing create_model()
2025-03-25 08:47:42,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:42,807:INFO:Checking exceptions
2025-03-25 08:47:42,807:INFO:Importing libraries
2025-03-25 08:47:42,807:INFO:Copying training dataset
2025-03-25 08:47:42,816:INFO:Defining folds
2025-03-25 08:47:42,816:INFO:Declaring metric variables
2025-03-25 08:47:42,819:INFO:Importing untrained model
2025-03-25 08:47:42,821:INFO:Decision Tree Regressor Imported successfully
2025-03-25 08:47:42,825:INFO:Starting cross validation
2025-03-25 08:47:42,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:43,154:INFO:Calculating mean and std
2025-03-25 08:47:43,155:INFO:Creating metrics dataframe
2025-03-25 08:47:43,156:INFO:Uploading results into container
2025-03-25 08:47:43,156:INFO:Uploading model into container now
2025-03-25 08:47:43,157:INFO:_master_model_container: 12
2025-03-25 08:47:43,157:INFO:_display_container: 2
2025-03-25 08:47:43,157:INFO:DecisionTreeRegressor(random_state=2242)
2025-03-25 08:47:43,157:INFO:create_model() successfully completed......................................
2025-03-25 08:47:43,250:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:43,250:INFO:Creating metrics dataframe
2025-03-25 08:47:43,257:INFO:Initializing Random Forest Regressor
2025-03-25 08:47:43,257:INFO:Total runtime is 0.202312171459198 minutes
2025-03-25 08:47:43,259:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:43,260:INFO:Initializing create_model()
2025-03-25 08:47:43,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:43,260:INFO:Checking exceptions
2025-03-25 08:47:43,260:INFO:Importing libraries
2025-03-25 08:47:43,260:INFO:Copying training dataset
2025-03-25 08:47:43,267:INFO:Defining folds
2025-03-25 08:47:43,267:INFO:Declaring metric variables
2025-03-25 08:47:43,270:INFO:Importing untrained model
2025-03-25 08:47:43,273:INFO:Random Forest Regressor Imported successfully
2025-03-25 08:47:43,277:INFO:Starting cross validation
2025-03-25 08:47:43,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:49,584:INFO:Calculating mean and std
2025-03-25 08:47:49,586:INFO:Creating metrics dataframe
2025-03-25 08:47:49,588:INFO:Uploading results into container
2025-03-25 08:47:49,588:INFO:Uploading model into container now
2025-03-25 08:47:49,589:INFO:_master_model_container: 13
2025-03-25 08:47:49,589:INFO:_display_container: 2
2025-03-25 08:47:49,589:INFO:RandomForestRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:47:49,590:INFO:create_model() successfully completed......................................
2025-03-25 08:47:49,692:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:49,692:INFO:Creating metrics dataframe
2025-03-25 08:47:49,699:INFO:Initializing Extra Trees Regressor
2025-03-25 08:47:49,699:INFO:Total runtime is 0.30966941912968954 minutes
2025-03-25 08:47:49,702:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:49,702:INFO:Initializing create_model()
2025-03-25 08:47:49,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:49,703:INFO:Checking exceptions
2025-03-25 08:47:49,703:INFO:Importing libraries
2025-03-25 08:47:49,703:INFO:Copying training dataset
2025-03-25 08:47:49,710:INFO:Defining folds
2025-03-25 08:47:49,710:INFO:Declaring metric variables
2025-03-25 08:47:49,714:INFO:Importing untrained model
2025-03-25 08:47:49,716:INFO:Extra Trees Regressor Imported successfully
2025-03-25 08:47:49,720:INFO:Starting cross validation
2025-03-25 08:47:49,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:53,858:INFO:Calculating mean and std
2025-03-25 08:47:53,859:INFO:Creating metrics dataframe
2025-03-25 08:47:53,861:INFO:Uploading results into container
2025-03-25 08:47:53,861:INFO:Uploading model into container now
2025-03-25 08:47:53,861:INFO:_master_model_container: 14
2025-03-25 08:47:53,862:INFO:_display_container: 2
2025-03-25 08:47:53,862:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:47:53,862:INFO:create_model() successfully completed......................................
2025-03-25 08:47:53,977:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:53,977:INFO:Creating metrics dataframe
2025-03-25 08:47:53,985:INFO:Initializing AdaBoost Regressor
2025-03-25 08:47:53,986:INFO:Total runtime is 0.3811225175857544 minutes
2025-03-25 08:47:53,989:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:53,989:INFO:Initializing create_model()
2025-03-25 08:47:53,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:53,990:INFO:Checking exceptions
2025-03-25 08:47:53,990:INFO:Importing libraries
2025-03-25 08:47:53,990:INFO:Copying training dataset
2025-03-25 08:47:53,999:INFO:Defining folds
2025-03-25 08:47:53,999:INFO:Declaring metric variables
2025-03-25 08:47:54,004:INFO:Importing untrained model
2025-03-25 08:47:54,009:INFO:AdaBoost Regressor Imported successfully
2025-03-25 08:47:54,016:INFO:Starting cross validation
2025-03-25 08:47:54,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:55,102:INFO:Calculating mean and std
2025-03-25 08:47:55,104:INFO:Creating metrics dataframe
2025-03-25 08:47:55,105:INFO:Uploading results into container
2025-03-25 08:47:55,106:INFO:Uploading model into container now
2025-03-25 08:47:55,106:INFO:_master_model_container: 15
2025-03-25 08:47:55,106:INFO:_display_container: 2
2025-03-25 08:47:55,106:INFO:AdaBoostRegressor(random_state=2242)
2025-03-25 08:47:55,107:INFO:create_model() successfully completed......................................
2025-03-25 08:47:55,225:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:55,225:INFO:Creating metrics dataframe
2025-03-25 08:47:55,234:INFO:Initializing Gradient Boosting Regressor
2025-03-25 08:47:55,234:INFO:Total runtime is 0.4019309719403585 minutes
2025-03-25 08:47:55,236:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:55,237:INFO:Initializing create_model()
2025-03-25 08:47:55,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:55,237:INFO:Checking exceptions
2025-03-25 08:47:55,237:INFO:Importing libraries
2025-03-25 08:47:55,237:INFO:Copying training dataset
2025-03-25 08:47:55,248:INFO:Defining folds
2025-03-25 08:47:55,248:INFO:Declaring metric variables
2025-03-25 08:47:55,252:INFO:Importing untrained model
2025-03-25 08:47:55,255:INFO:Gradient Boosting Regressor Imported successfully
2025-03-25 08:47:55,259:INFO:Starting cross validation
2025-03-25 08:47:55,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:57,458:INFO:Calculating mean and std
2025-03-25 08:47:57,459:INFO:Creating metrics dataframe
2025-03-25 08:47:57,460:INFO:Uploading results into container
2025-03-25 08:47:57,460:INFO:Uploading model into container now
2025-03-25 08:47:57,460:INFO:_master_model_container: 16
2025-03-25 08:47:57,460:INFO:_display_container: 2
2025-03-25 08:47:57,462:INFO:GradientBoostingRegressor(random_state=2242)
2025-03-25 08:47:57,462:INFO:create_model() successfully completed......................................
2025-03-25 08:47:57,554:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:57,554:INFO:Creating metrics dataframe
2025-03-25 08:47:57,562:INFO:Initializing Light Gradient Boosting Machine
2025-03-25 08:47:57,562:INFO:Total runtime is 0.44071967204411827 minutes
2025-03-25 08:47:57,564:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:57,564:INFO:Initializing create_model()
2025-03-25 08:47:57,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:57,564:INFO:Checking exceptions
2025-03-25 08:47:57,564:INFO:Importing libraries
2025-03-25 08:47:57,564:INFO:Copying training dataset
2025-03-25 08:47:57,572:INFO:Defining folds
2025-03-25 08:47:57,573:INFO:Declaring metric variables
2025-03-25 08:47:57,575:INFO:Importing untrained model
2025-03-25 08:47:57,577:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-25 08:47:57,582:INFO:Starting cross validation
2025-03-25 08:47:57,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:58,430:INFO:Calculating mean and std
2025-03-25 08:47:58,430:INFO:Creating metrics dataframe
2025-03-25 08:47:58,433:INFO:Uploading results into container
2025-03-25 08:47:58,433:INFO:Uploading model into container now
2025-03-25 08:47:58,433:INFO:_master_model_container: 17
2025-03-25 08:47:58,433:INFO:_display_container: 2
2025-03-25 08:47:58,435:INFO:LGBMRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:47:58,435:INFO:create_model() successfully completed......................................
2025-03-25 08:47:58,548:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:58,548:INFO:Creating metrics dataframe
2025-03-25 08:47:58,556:INFO:Initializing Dummy Regressor
2025-03-25 08:47:58,557:INFO:Total runtime is 0.45731576681137087 minutes
2025-03-25 08:47:58,560:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:58,560:INFO:Initializing create_model()
2025-03-25 08:47:58,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:58,560:INFO:Checking exceptions
2025-03-25 08:47:58,560:INFO:Importing libraries
2025-03-25 08:47:58,560:INFO:Copying training dataset
2025-03-25 08:47:58,568:INFO:Defining folds
2025-03-25 08:47:58,568:INFO:Declaring metric variables
2025-03-25 08:47:58,572:INFO:Importing untrained model
2025-03-25 08:47:58,573:INFO:Dummy Regressor Imported successfully
2025-03-25 08:47:58,577:INFO:Starting cross validation
2025-03-25 08:47:58,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:58,791:INFO:Calculating mean and std
2025-03-25 08:47:58,793:INFO:Creating metrics dataframe
2025-03-25 08:47:58,794:INFO:Uploading results into container
2025-03-25 08:47:58,795:INFO:Uploading model into container now
2025-03-25 08:47:58,795:INFO:_master_model_container: 18
2025-03-25 08:47:58,795:INFO:_display_container: 2
2025-03-25 08:47:58,796:INFO:DummyRegressor()
2025-03-25 08:47:58,796:INFO:create_model() successfully completed......................................
2025-03-25 08:47:58,890:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:58,890:INFO:Creating metrics dataframe
2025-03-25 08:47:58,897:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-25 08:47:58,903:INFO:Initializing create_model()
2025-03-25 08:47:58,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:58,903:INFO:Checking exceptions
2025-03-25 08:47:58,904:INFO:Importing libraries
2025-03-25 08:47:58,904:INFO:Copying training dataset
2025-03-25 08:47:58,910:INFO:Defining folds
2025-03-25 08:47:58,910:INFO:Declaring metric variables
2025-03-25 08:47:58,910:INFO:Importing untrained model
2025-03-25 08:47:58,910:INFO:Declaring custom model
2025-03-25 08:47:58,912:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-25 08:47:58,913:INFO:Cross validation set to False
2025-03-25 08:47:58,913:INFO:Fitting Model
2025-03-25 08:47:58,994:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-25 08:47:58,996:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.
2025-03-25 08:47:58,996:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:47:58,996:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:47:58,996:INFO:[LightGBM] [Info] Total Bins 564
2025-03-25 08:47:58,996:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-25 08:47:58,997:INFO:[LightGBM] [Info] Start training from score 3258.142167
2025-03-25 08:47:59,069:INFO:LGBMRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:47:59,069:INFO:create_model() successfully completed......................................
2025-03-25 08:47:59,193:INFO:_master_model_container: 18
2025-03-25 08:47:59,193:INFO:_display_container: 2
2025-03-25 08:47:59,194:INFO:LGBMRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:47:59,194:INFO:compare_models() successfully completed......................................
2025-03-25 08:48:47,525:INFO:Initializing plot_model()
2025-03-25 08:48:47,525:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, system=True)
2025-03-25 08:48:47,525:INFO:Checking exceptions
2025-03-25 08:48:47,530:INFO:Preloading libraries
2025-03-25 08:48:47,533:INFO:Copying training dataset
2025-03-25 08:48:47,534:INFO:Plot type: residuals
2025-03-25 08:48:47,790:INFO:Fitting Model
2025-03-25 08:48:47,845:INFO:Scoring test/hold-out set
2025-03-25 08:48:48,283:INFO:Visual Rendered Successfully
2025-03-25 08:48:48,385:INFO:plot_model() successfully completed......................................
2025-03-25 08:48:50,501:INFO:Initializing evaluate_model()
2025-03-25 08:48:50,501:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-25 08:48:50,510:INFO:Initializing plot_model()
2025-03-25 08:48:50,510:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:48:50,510:INFO:Checking exceptions
2025-03-25 08:48:50,514:INFO:Preloading libraries
2025-03-25 08:48:50,517:INFO:Copying training dataset
2025-03-25 08:48:50,517:INFO:Plot type: pipeline
2025-03-25 08:48:50,611:INFO:Visual Rendered Successfully
2025-03-25 08:48:50,707:INFO:plot_model() successfully completed......................................
2025-03-25 08:48:52,512:INFO:Initializing plot_model()
2025-03-25 08:48:52,513:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:48:52,513:INFO:Checking exceptions
2025-03-25 08:48:52,516:INFO:Preloading libraries
2025-03-25 08:48:52,518:INFO:Copying training dataset
2025-03-25 08:48:52,518:INFO:Plot type: residuals
2025-03-25 08:48:52,763:INFO:Fitting Model
2025-03-25 08:48:52,823:INFO:Scoring test/hold-out set
2025-03-25 08:48:53,170:INFO:Visual Rendered Successfully
2025-03-25 08:48:53,267:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:01,157:INFO:Initializing plot_model()
2025-03-25 08:49:01,158:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:01,158:INFO:Checking exceptions
2025-03-25 08:49:01,162:INFO:Preloading libraries
2025-03-25 08:49:01,164:INFO:Copying training dataset
2025-03-25 08:49:01,164:INFO:Plot type: error
2025-03-25 08:49:01,393:INFO:Fitting Model
2025-03-25 08:49:01,393:INFO:Scoring test/hold-out set
2025-03-25 08:49:01,601:INFO:Visual Rendered Successfully
2025-03-25 08:49:01,694:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:08,373:INFO:Initializing plot_model()
2025-03-25 08:49:08,373:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:08,374:INFO:Checking exceptions
2025-03-25 08:49:08,377:INFO:Preloading libraries
2025-03-25 08:49:08,380:INFO:Copying training dataset
2025-03-25 08:49:08,381:INFO:Plot type: rfe
2025-03-25 08:49:08,616:INFO:Fitting Model
2025-03-25 08:49:08,640:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000576 seconds.
2025-03-25 08:49:08,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:08,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:08,641:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:08,641:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:08,641:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:08,722:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-03-25 08:49:08,722:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:08,722:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:08,722:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:08,722:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:08,722:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:08,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.
2025-03-25 08:49:08,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:08,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:08,799:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:08,799:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:08,799:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:08,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.
2025-03-25 08:49:08,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:08,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:08,876:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:08,876:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:08,876:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:08,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
2025-03-25 08:49:08,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:08,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:08,958:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:08,958:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:08,958:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-03-25 08:49:09,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,033:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,033:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.
2025-03-25 08:49:09,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,108:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,108:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,108:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001010 seconds.
2025-03-25 08:49:09,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,187:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,187:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,187:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,264:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
2025-03-25 08:49:09,265:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,265:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,265:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,265:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,265:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,343:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-25 08:49:09,343:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,343:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,343:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,343:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,343:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,423:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.
2025-03-25 08:49:09,423:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,423:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,423:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,423:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,423:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.
2025-03-25 08:49:09,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,503:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,503:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,503:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-03-25 08:49:09,582:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,582:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,582:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,582:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,582:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,656:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-25 08:49:09,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,656:INFO:[LightGBM] [Info] Total Bins 548
2025-03-25 08:49:09,656:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-25 08:49:09,656:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-25 08:49:09,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,737:INFO:[LightGBM] [Info] Total Bins 546
2025-03-25 08:49:09,737:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-25 08:49:09,737:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,816:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-25 08:49:09,816:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,816:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,816:INFO:[LightGBM] [Info] Total Bins 544
2025-03-25 08:49:09,816:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-25 08:49:09,816:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.
2025-03-25 08:49:09,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,883:INFO:[LightGBM] [Info] Total Bins 542
2025-03-25 08:49:09,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-25 08:49:09,883:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,959:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-03-25 08:49:09,959:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,960:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,960:INFO:[LightGBM] [Info] Total Bins 540
2025-03-25 08:49:09,960:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-25 08:49:09,960:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,030:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-25 08:49:10,030:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,030:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,030:INFO:[LightGBM] [Info] Total Bins 538
2025-03-25 08:49:10,030:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-25 08:49:10,030:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,105:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000561 seconds.
2025-03-25 08:49:10,105:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,105:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,105:INFO:[LightGBM] [Info] Total Bins 536
2025-03-25 08:49:10,105:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-25 08:49:10,105:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,182:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-03-25 08:49:10,182:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,182:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,182:INFO:[LightGBM] [Info] Total Bins 534
2025-03-25 08:49:10,182:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-25 08:49:10,182:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.
2025-03-25 08:49:10,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,254:INFO:[LightGBM] [Info] Total Bins 532
2025-03-25 08:49:10,254:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-25 08:49:10,254:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,325:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-25 08:49:10,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,326:INFO:[LightGBM] [Info] Total Bins 530
2025-03-25 08:49:10,326:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-25 08:49:10,326:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,429:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000080 seconds.
2025-03-25 08:49:10,429:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,429:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,429:INFO:[LightGBM] [Info] Total Bins 528
2025-03-25 08:49:10,429:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-25 08:49:10,429:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,504:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.
2025-03-25 08:49:10,504:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,504:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,504:INFO:[LightGBM] [Info] Total Bins 526
2025-03-25 08:49:10,504:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-25 08:49:10,504:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000057 seconds.
2025-03-25 08:49:10,572:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,572:INFO:[LightGBM] [Info] Total Bins 299
2025-03-25 08:49:10,572:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-25 08:49:10,572:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.
2025-03-25 08:49:10,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,633:INFO:[LightGBM] [Info] Total Bins 255
2025-03-25 08:49:10,633:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 1
2025-03-25 08:49:10,633:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.
2025-03-25 08:49:10,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,720:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:10,720:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:10,720:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:10,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000520 seconds.
2025-03-25 08:49:10,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,799:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:10,799:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:10,799:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:10,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.
2025-03-25 08:49:10,877:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,877:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,877:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:10,877:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:10,877:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:10,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.
2025-03-25 08:49:10,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,955:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:10,955:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:10,955:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.
2025-03-25 08:49:11,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,033:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,033:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.
2025-03-25 08:49:11,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,108:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,108:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,109:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.
2025-03-25 08:49:11,205:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,205:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,205:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,205:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,205:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000548 seconds.
2025-03-25 08:49:11,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,285:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,285:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,285:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,285:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.
2025-03-25 08:49:11,362:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,362:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,362:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,362:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,362:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.
2025-03-25 08:49:11,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,442:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,442:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,442:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,517:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.
2025-03-25 08:49:11,517:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,517:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,518:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,518:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,518:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.
2025-03-25 08:49:11,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,597:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,597:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,597:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.
2025-03-25 08:49:11,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,676:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,676:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,676:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,753:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000583 seconds.
2025-03-25 08:49:11,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,754:INFO:[LightGBM] [Info] Total Bins 561
2025-03-25 08:49:11,754:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-25 08:49:11,754:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.
2025-03-25 08:49:11,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,836:INFO:[LightGBM] [Info] Total Bins 559
2025-03-25 08:49:11,836:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-25 08:49:11,836:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.
2025-03-25 08:49:11,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,923:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,923:INFO:[LightGBM] [Info] Total Bins 551
2025-03-25 08:49:11,923:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-25 08:49:11,923:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,017:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.
2025-03-25 08:49:12,017:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,018:INFO:[LightGBM] [Info] Total Bins 549
2025-03-25 08:49:12,018:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-25 08:49:12,018:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.
2025-03-25 08:49:12,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,100:INFO:[LightGBM] [Info] Total Bins 547
2025-03-25 08:49:12,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-25 08:49:12,102:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,192:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.
2025-03-25 08:49:12,192:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,192:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,192:INFO:[LightGBM] [Info] Total Bins 545
2025-03-25 08:49:12,192:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-25 08:49:12,192:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,272:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-25 08:49:12,272:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,272:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,272:INFO:[LightGBM] [Info] Total Bins 543
2025-03-25 08:49:12,272:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-25 08:49:12,272:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.
2025-03-25 08:49:12,360:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,360:INFO:[LightGBM] [Info] Total Bins 541
2025-03-25 08:49:12,360:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-25 08:49:12,360:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.
2025-03-25 08:49:12,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,443:INFO:[LightGBM] [Info] Total Bins 539
2025-03-25 08:49:12,443:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-25 08:49:12,443:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,535:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-25 08:49:12,535:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,535:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,535:INFO:[LightGBM] [Info] Total Bins 537
2025-03-25 08:49:12,535:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-25 08:49:12,536:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,622:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.
2025-03-25 08:49:12,622:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,622:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,622:INFO:[LightGBM] [Info] Total Bins 535
2025-03-25 08:49:12,622:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-25 08:49:12,622:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.
2025-03-25 08:49:12,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,703:INFO:[LightGBM] [Info] Total Bins 533
2025-03-25 08:49:12,703:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-25 08:49:12,703:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,784:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.
2025-03-25 08:49:12,784:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,784:INFO:[LightGBM] [Info] Total Bins 488
2025-03-25 08:49:12,785:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-25 08:49:12,785:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,868:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.
2025-03-25 08:49:12,868:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,868:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,868:INFO:[LightGBM] [Info] Total Bins 255
2025-03-25 08:49:12,868:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 1
2025-03-25 08:49:12,868:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,970:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000570 seconds.
2025-03-25 08:49:12,972:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,972:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,972:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:12,972:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:12,972:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.
2025-03-25 08:49:13,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,063:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,064:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,064:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.
2025-03-25 08:49:13,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,157:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,157:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,157:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000576 seconds.
2025-03-25 08:49:13,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,250:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,251:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,251:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-03-25 08:49:13,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,350:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,350:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,350:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,444:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.
2025-03-25 08:49:13,444:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,444:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,444:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,444:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,445:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,538:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.
2025-03-25 08:49:13,538:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,538:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,538:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,538:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,539:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,630:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.
2025-03-25 08:49:13,630:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,630:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,632:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,632:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,632:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.
2025-03-25 08:49:13,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,726:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,726:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,727:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,813:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.
2025-03-25 08:49:13,813:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,813:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,813:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,813:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,813:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-25 08:49:13,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,883:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,883:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,963:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-25 08:49:13,963:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,963:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,963:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,963:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,963:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:14,035:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-25 08:49:14,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:14,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:14,036:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:14,036:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:14,036:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:14,113:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-25 08:49:14,113:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:14,113:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:14,113:INFO:[LightGBM] [Info] Total Bins 554
2025-03-25 08:49:14,113:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-25 08:49:14,113:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:14,189:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-25 08:49:14,189:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:14,189:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:14,189:INFO:[LightGBM] [Info] Total Bins 552
2025-03-25 08:49:14,189:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-25 08:49:14,189:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:15,157:INFO:Initializing evaluate_model()
2025-03-25 08:49:15,157:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-25 08:49:15,164:INFO:Initializing plot_model()
2025-03-25 08:49:15,165:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:15,165:INFO:Checking exceptions
2025-03-25 08:49:15,167:INFO:Preloading libraries
2025-03-25 08:49:15,170:INFO:Copying training dataset
2025-03-25 08:49:15,170:INFO:Plot type: pipeline
2025-03-25 08:49:15,252:INFO:Visual Rendered Successfully
2025-03-25 08:49:15,386:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:15,407:INFO:Initializing evaluate_model()
2025-03-25 08:49:15,408:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-25 08:49:15,415:INFO:Initializing plot_model()
2025-03-25 08:49:15,416:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:15,416:INFO:Checking exceptions
2025-03-25 08:49:15,418:INFO:Preloading libraries
2025-03-25 08:49:15,422:INFO:Copying training dataset
2025-03-25 08:49:15,422:INFO:Plot type: pipeline
2025-03-25 08:49:15,513:INFO:Visual Rendered Successfully
2025-03-25 08:49:15,633:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:15,654:INFO:Initializing plot_model()
2025-03-25 08:49:15,654:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:15,655:INFO:Checking exceptions
2025-03-25 08:49:15,658:INFO:Preloading libraries
2025-03-25 08:49:15,661:INFO:Copying training dataset
2025-03-25 08:49:15,661:INFO:Plot type: feature_all
2025-03-25 08:49:15,754:WARNING:No coef_ found. Trying feature_importances_
2025-03-25 08:49:15,960:INFO:Visual Rendered Successfully
2025-03-25 08:49:16,082:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:16,699:INFO:Initializing plot_model()
2025-03-25 08:49:16,699:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:16,699:INFO:Checking exceptions
2025-03-25 08:49:16,703:INFO:Preloading libraries
2025-03-25 08:49:16,706:INFO:Copying training dataset
2025-03-25 08:49:16,706:INFO:Plot type: feature_all
2025-03-25 08:49:16,806:WARNING:No coef_ found. Trying feature_importances_
2025-03-25 08:49:17,000:INFO:Visual Rendered Successfully
2025-03-25 08:49:17,128:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:35,210:INFO:Initializing plot_model()
2025-03-25 08:49:35,210:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:35,210:INFO:Checking exceptions
2025-03-25 08:49:35,214:INFO:Preloading libraries
2025-03-25 08:49:35,217:INFO:Copying training dataset
2025-03-25 08:49:35,217:INFO:Plot type: error
2025-03-25 08:49:35,452:INFO:Fitting Model
2025-03-25 08:49:35,452:INFO:Scoring test/hold-out set
2025-03-25 08:49:35,652:INFO:Visual Rendered Successfully
2025-03-25 08:49:35,782:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:37,499:INFO:Initializing plot_model()
2025-03-25 08:49:37,499:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:37,500:INFO:Checking exceptions
2025-03-25 08:49:37,504:INFO:Preloading libraries
2025-03-25 08:49:37,507:INFO:Copying training dataset
2025-03-25 08:49:37,507:INFO:Plot type: residuals
2025-03-25 08:49:37,763:INFO:Fitting Model
2025-03-25 08:49:37,810:INFO:Scoring test/hold-out set
2025-03-25 08:49:38,167:INFO:Visual Rendered Successfully
2025-03-25 08:49:38,311:INFO:plot_model() successfully completed......................................
2025-03-25 08:50:31,720:INFO:Initializing tune_model()
2025-03-25 08:50:31,720:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>)
2025-03-25 08:50:31,720:INFO:Checking exceptions
2025-03-25 08:50:31,735:INFO:Copying training dataset
2025-03-25 08:50:31,744:INFO:Checking base model
2025-03-25 08:50:31,744:INFO:Base model : Light Gradient Boosting Machine
2025-03-25 08:50:31,748:INFO:Declaring metric variables
2025-03-25 08:50:31,751:INFO:Defining Hyperparameters
2025-03-25 08:50:31,884:INFO:Tuning with n_jobs=-1
2025-03-25 08:50:31,884:INFO:Initializing RandomizedSearchCV
2025-03-25 08:50:41,352:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 5, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.8}
2025-03-25 08:50:41,352:INFO:Hyperparameter search completed
2025-03-25 08:50:41,352:INFO:SubProcess create_model() called ==================================
2025-03-25 08:50:41,353:INFO:Initializing create_model()
2025-03-25 08:50:41,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA92341C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 4, 'reg_alpha': 5, 'num_leaves': 40, 'n_estimators': 150, 'min_split_gain': 0.6, 'min_child_samples': 91, 'learning_rate': 0.05, 'feature_fraction': 0.7, 'bagging_freq': 2, 'bagging_fraction': 0.8})
2025-03-25 08:50:41,353:INFO:Checking exceptions
2025-03-25 08:50:41,353:INFO:Importing libraries
2025-03-25 08:50:41,353:INFO:Copying training dataset
2025-03-25 08:50:41,363:INFO:Defining folds
2025-03-25 08:50:41,363:INFO:Declaring metric variables
2025-03-25 08:50:41,365:INFO:Importing untrained model
2025-03-25 08:50:41,365:INFO:Declaring custom model
2025-03-25 08:50:41,368:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-25 08:50:41,372:INFO:Starting cross validation
2025-03-25 08:50:41,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:50:43,010:INFO:Calculating mean and std
2025-03-25 08:50:43,010:INFO:Creating metrics dataframe
2025-03-25 08:50:43,015:INFO:Finalizing model
2025-03-25 08:50:43,117:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-03-25 08:50:43,117:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-03-25 08:50:43,117:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-03-25 08:50:43,129:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-25 08:50:43,130:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-03-25 08:50:43,130:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-03-25 08:50:43,130:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-03-25 08:50:43,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.
2025-03-25 08:50:43,132:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:50:43,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:50:43,132:INFO:[LightGBM] [Info] Total Bins 553
2025-03-25 08:50:43,132:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 13
2025-03-25 08:50:43,132:INFO:[LightGBM] [Info] Start training from score 3258.142167
2025-03-25 08:50:43,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,335:INFO:Uploading results into container
2025-03-25 08:50:43,336:INFO:Uploading model into container now
2025-03-25 08:50:43,336:INFO:_master_model_container: 19
2025-03-25 08:50:43,336:INFO:_display_container: 3
2025-03-25 08:50:43,337:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=91, min_split_gain=0.6,
              n_estimators=150, n_jobs=-1, num_leaves=40, random_state=2242,
              reg_alpha=5, reg_lambda=4)
2025-03-25 08:50:43,337:INFO:create_model() successfully completed......................................
2025-03-25 08:50:43,498:INFO:SubProcess create_model() end ==================================
2025-03-25 08:50:43,498:INFO:choose_better activated
2025-03-25 08:50:43,500:INFO:SubProcess create_model() called ==================================
2025-03-25 08:50:43,502:INFO:Initializing create_model()
2025-03-25 08:50:43,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:50:43,502:INFO:Checking exceptions
2025-03-25 08:50:43,503:INFO:Importing libraries
2025-03-25 08:50:43,503:INFO:Copying training dataset
2025-03-25 08:50:43,512:INFO:Defining folds
2025-03-25 08:50:43,512:INFO:Declaring metric variables
2025-03-25 08:50:43,512:INFO:Importing untrained model
2025-03-25 08:50:43,512:INFO:Declaring custom model
2025-03-25 08:50:43,513:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-25 08:50:43,513:INFO:Starting cross validation
2025-03-25 08:50:43,514:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:50:44,302:INFO:Calculating mean and std
2025-03-25 08:50:44,303:INFO:Creating metrics dataframe
2025-03-25 08:50:44,303:INFO:Finalizing model
2025-03-25 08:50:44,415:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-25 08:50:44,416:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.
2025-03-25 08:50:44,416:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:50:44,416:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:50:44,416:INFO:[LightGBM] [Info] Total Bins 564
2025-03-25 08:50:44,417:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-25 08:50:44,417:INFO:[LightGBM] [Info] Start training from score 3258.142167
2025-03-25 08:50:44,486:INFO:Uploading results into container
2025-03-25 08:50:44,487:INFO:Uploading model into container now
2025-03-25 08:50:44,487:INFO:_master_model_container: 20
2025-03-25 08:50:44,487:INFO:_display_container: 4
2025-03-25 08:50:44,488:INFO:LGBMRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:50:44,488:INFO:create_model() successfully completed......................................
2025-03-25 08:50:44,646:INFO:SubProcess create_model() end ==================================
2025-03-25 08:50:44,646:INFO:LGBMRegressor(n_jobs=-1, random_state=2242) result for R2 is 0.2206
2025-03-25 08:50:44,647:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=91, min_split_gain=0.6,
              n_estimators=150, n_jobs=-1, num_leaves=40, random_state=2242,
              reg_alpha=5, reg_lambda=4) result for R2 is 0.2157
2025-03-25 08:50:44,647:INFO:LGBMRegressor(n_jobs=-1, random_state=2242) is best model
2025-03-25 08:50:44,647:INFO:choose_better completed
2025-03-25 08:50:44,647:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-25 08:50:44,655:INFO:_master_model_container: 20
2025-03-25 08:50:44,655:INFO:_display_container: 3
2025-03-25 08:50:44,655:INFO:LGBMRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:50:44,655:INFO:tune_model() successfully completed......................................
2025-03-25 08:51:32,716:INFO:Initializing save_model()
2025-03-25 08:51:32,716:INFO:save_model(model=LGBMRegressor(n_jobs=-1, random_state=2242), model_name=traffic_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-25 08:51:32,716:INFO:Adding model into prep_pipe
2025-03-25 08:51:32,722:INFO:traffic_model.pkl saved in current working directory
2025-03-25 08:51:32,730:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=2242))])
2025-03-25 08:51:32,730:INFO:save_model() successfully completed......................................
2025-03-25 09:07:24,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:07:24,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:07:24,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:07:24,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:07:27,743:INFO:Initializing load_model()
2025-03-25 09:07:27,743:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-25 09:07:27,824:INFO:Initializing predict_model()
2025-03-25 09:07:27,825:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002066EEBC580>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=2242))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002066F7FB880>)
2025-03-25 09:07:27,825:INFO:Checking exceptions
2025-03-25 09:07:27,825:INFO:Preloading libraries
2025-03-25 09:07:27,826:INFO:Set up data.
2025-03-25 09:07:27,837:INFO:Set up index.
2025-03-25 09:08:46,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:08:46,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:08:46,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:08:46,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:08:47,943:INFO:Initializing load_model()
2025-03-25 09:08:47,944:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-25 09:08:48,000:INFO:Initializing predict_model()
2025-03-25 09:08:48,002:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000278BC0E5DB0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=2242))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000278C76CB760>)
2025-03-25 09:08:48,002:INFO:Checking exceptions
2025-03-25 09:08:48,002:INFO:Preloading libraries
2025-03-25 09:08:48,002:INFO:Set up data.
2025-03-25 09:08:48,014:INFO:Set up index.
