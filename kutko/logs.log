2025-03-24 14:53:38,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 14:53:38,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 14:53:38,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 14:53:38,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 14:53:53,427:INFO:PyCaret RegressionExperiment
2025-03-24 14:53:53,427:INFO:Logging name: reg-default-name
2025-03-24 14:53:53,428:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-24 14:53:53,428:INFO:version 3.3.2
2025-03-24 14:53:53,428:INFO:Initializing setup()
2025-03-24 14:53:53,428:INFO:self.USI: 7067
2025-03-24 14:53:53,428:INFO:self._variable_keys: {'_ml_usecase', 'html_param', 'fold_shuffle_param', 'transform_target_param', 'exp_id', 'X_test', 'X_train', 'memory', 'y_test', 'exp_name_log', 'gpu_param', 'USI', 'y', 'seed', 'fold_generator', 'X', 'idx', 'pipeline', 'target_param', 'gpu_n_jobs_param', 'n_jobs_param', 'fold_groups_param', 'logging_param', 'log_plots_param', '_available_plots', 'y_train', 'data'}
2025-03-24 14:53:53,428:INFO:Checking environment
2025-03-24 14:53:53,428:INFO:python_version: 3.10.16
2025-03-24 14:53:53,428:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-24 14:53:53,428:INFO:machine: AMD64
2025-03-24 14:53:53,428:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-24 14:53:53,431:INFO:Memory: svmem(total=33411727360, available=15402250240, percent=53.9, used=18009477120, free=15402250240)
2025-03-24 14:53:53,432:INFO:Physical Core: 6
2025-03-24 14:53:53,432:INFO:Logical Core: 12
2025-03-24 14:53:53,432:INFO:Checking libraries
2025-03-24 14:53:53,432:INFO:System:
2025-03-24 14:53:53,432:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-24 14:53:53,432:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-24 14:53:53,432:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-24 14:53:53,432:INFO:PyCaret required dependencies:
2025-03-24 14:53:53,433:INFO:                 pip: 25.0.1
2025-03-24 14:53:53,433:INFO:          setuptools: 75.8.2
2025-03-24 14:53:53,433:INFO:             pycaret: 3.3.2
2025-03-24 14:53:53,433:INFO:             IPython: 8.34.0
2025-03-24 14:53:53,433:INFO:          ipywidgets: 8.1.5
2025-03-24 14:53:53,433:INFO:                tqdm: 4.67.1
2025-03-24 14:53:53,433:INFO:               numpy: 1.26.4
2025-03-24 14:53:53,433:INFO:              pandas: 2.1.4
2025-03-24 14:53:53,433:INFO:              jinja2: 3.1.6
2025-03-24 14:53:53,433:INFO:               scipy: 1.11.4
2025-03-24 14:53:53,433:INFO:              joblib: 1.3.2
2025-03-24 14:53:53,433:INFO:             sklearn: 1.4.2
2025-03-24 14:53:53,433:INFO:                pyod: 2.0.2
2025-03-24 14:53:53,433:INFO:            imblearn: 0.13.0
2025-03-24 14:53:53,433:INFO:   category_encoders: 2.7.0
2025-03-24 14:53:53,433:INFO:            lightgbm: 4.6.0
2025-03-24 14:53:53,433:INFO:               numba: 0.61.0
2025-03-24 14:53:53,433:INFO:            requests: 2.32.3
2025-03-24 14:53:53,433:INFO:          matplotlib: 3.10.1
2025-03-24 14:53:53,433:INFO:          scikitplot: 0.3.7
2025-03-24 14:53:53,433:INFO:         yellowbrick: 1.5
2025-03-24 14:53:53,433:INFO:              plotly: 6.0.1
2025-03-24 14:53:53,433:INFO:    plotly-resampler: Not installed
2025-03-24 14:53:53,433:INFO:             kaleido: 0.2.1
2025-03-24 14:53:53,433:INFO:           schemdraw: 0.15
2025-03-24 14:53:53,433:INFO:         statsmodels: 0.14.4
2025-03-24 14:53:53,433:INFO:              sktime: 0.26.0
2025-03-24 14:53:53,433:INFO:               tbats: 1.1.3
2025-03-24 14:53:53,433:INFO:            pmdarima: 2.0.4
2025-03-24 14:53:53,433:INFO:              psutil: 7.0.0
2025-03-24 14:53:53,433:INFO:          markupsafe: 3.0.2
2025-03-24 14:53:53,433:INFO:             pickle5: Not installed
2025-03-24 14:53:53,433:INFO:         cloudpickle: 3.1.1
2025-03-24 14:53:53,433:INFO:         deprecation: 2.1.0
2025-03-24 14:53:53,433:INFO:              xxhash: 3.5.0
2025-03-24 14:53:53,433:INFO:           wurlitzer: 3.1.1
2025-03-24 14:53:53,433:INFO:PyCaret optional dependencies:
2025-03-24 14:53:53,441:INFO:                shap: Not installed
2025-03-24 14:53:53,442:INFO:           interpret: Not installed
2025-03-24 14:53:53,442:INFO:                umap: 0.5.7
2025-03-24 14:53:53,442:INFO:     ydata_profiling: Not installed
2025-03-24 14:53:53,442:INFO:  explainerdashboard: Not installed
2025-03-24 14:53:53,442:INFO:             autoviz: Not installed
2025-03-24 14:53:53,443:INFO:           fairlearn: Not installed
2025-03-24 14:53:53,443:INFO:          deepchecks: Not installed
2025-03-24 14:53:53,443:INFO:             xgboost: Not installed
2025-03-24 14:53:53,443:INFO:            catboost: Not installed
2025-03-24 14:53:53,443:INFO:              kmodes: Not installed
2025-03-24 14:53:53,443:INFO:             mlxtend: Not installed
2025-03-24 14:53:53,443:INFO:       statsforecast: Not installed
2025-03-24 14:53:53,443:INFO:        tune_sklearn: Not installed
2025-03-24 14:53:53,443:INFO:                 ray: Not installed
2025-03-24 14:53:53,443:INFO:            hyperopt: Not installed
2025-03-24 14:53:53,443:INFO:              optuna: Not installed
2025-03-24 14:53:53,443:INFO:               skopt: Not installed
2025-03-24 14:53:53,443:INFO:              mlflow: Not installed
2025-03-24 14:53:53,443:INFO:              gradio: Not installed
2025-03-24 14:53:53,443:INFO:             fastapi: Not installed
2025-03-24 14:53:53,443:INFO:             uvicorn: Not installed
2025-03-24 14:53:53,443:INFO:              m2cgen: Not installed
2025-03-24 14:53:53,443:INFO:           evidently: Not installed
2025-03-24 14:53:53,443:INFO:               fugue: Not installed
2025-03-24 14:53:53,443:INFO:           streamlit: Not installed
2025-03-24 14:53:53,443:INFO:             prophet: Not installed
2025-03-24 14:53:53,443:INFO:None
2025-03-24 14:53:53,443:INFO:Set up data.
2025-03-24 14:53:53,453:INFO:Set up folding strategy.
2025-03-24 14:53:53,453:INFO:Set up train/test split.
2025-03-24 14:53:53,460:INFO:Set up index.
2025-03-24 14:53:53,460:INFO:Assigning column types.
2025-03-24 14:53:53,465:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-24 14:53:53,465:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,468:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,470:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,509:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,551:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,554:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,557:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,619:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,620:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,620:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-24 14:53:53,622:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,626:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,663:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,697:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,769:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-24 14:53:53,775:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,810:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,835:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,841:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,904:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,905:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-24 14:53:53,944:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:53,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:53,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,007:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:54,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 14:53:54,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,033:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-24 14:53:54,073:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:54,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,137:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 14:53:54,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,163:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-24 14:53:54,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,303:INFO:Preparing preprocessing pipeline...
2025-03-24 14:53:54,303:INFO:Set up simple imputation.
2025-03-24 14:53:54,308:INFO:Set up encoding of categorical features.
2025-03-24 14:53:54,309:INFO:Set up column name cleaning.
2025-03-24 14:53:54,405:INFO:Finished creating preprocessing pipeline.
2025-03-24 14:53:54,410:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-24 14:53:54,410:INFO:Creating final display dataframe.
2025-03-24 14:53:54,625:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              7067
2025-03-24 14:53:54,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 14:53:54,766:INFO:setup() successfully completed in 1.34s...............
2025-03-24 14:53:54,766:INFO:Initializing compare_models()
2025-03-24 14:53:54,766:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-24 14:53:54,766:INFO:Checking exceptions
2025-03-24 14:53:54,768:INFO:Preparing display monitor
2025-03-24 14:53:54,783:INFO:Initializing Linear Regression
2025-03-24 14:53:54,783:INFO:Total runtime is 0.0 minutes
2025-03-24 14:53:54,785:INFO:SubProcess create_model() called ==================================
2025-03-24 14:53:54,785:INFO:Initializing create_model()
2025-03-24 14:53:54,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:53:54,785:INFO:Checking exceptions
2025-03-24 14:53:54,786:INFO:Importing libraries
2025-03-24 14:53:54,786:INFO:Copying training dataset
2025-03-24 14:53:54,795:INFO:Defining folds
2025-03-24 14:53:54,795:INFO:Declaring metric variables
2025-03-24 14:53:54,798:INFO:Importing untrained model
2025-03-24 14:53:54,800:INFO:Linear Regression Imported successfully
2025-03-24 14:53:54,805:INFO:Starting cross validation
2025-03-24 14:53:54,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:53:57,807:INFO:Calculating mean and std
2025-03-24 14:53:57,808:INFO:Creating metrics dataframe
2025-03-24 14:53:57,811:INFO:Uploading results into container
2025-03-24 14:53:57,812:INFO:Uploading model into container now
2025-03-24 14:53:57,813:INFO:_master_model_container: 1
2025-03-24 14:53:57,813:INFO:_display_container: 2
2025-03-24 14:53:57,813:INFO:LinearRegression(n_jobs=-1)
2025-03-24 14:53:57,813:INFO:create_model() successfully completed......................................
2025-03-24 14:53:57,902:INFO:SubProcess create_model() end ==================================
2025-03-24 14:53:57,902:INFO:Creating metrics dataframe
2025-03-24 14:53:57,906:INFO:Initializing Lasso Regression
2025-03-24 14:53:57,906:INFO:Total runtime is 0.052065594991048174 minutes
2025-03-24 14:53:57,909:INFO:SubProcess create_model() called ==================================
2025-03-24 14:53:57,909:INFO:Initializing create_model()
2025-03-24 14:53:57,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:53:57,910:INFO:Checking exceptions
2025-03-24 14:53:57,910:INFO:Importing libraries
2025-03-24 14:53:57,910:INFO:Copying training dataset
2025-03-24 14:53:57,916:INFO:Defining folds
2025-03-24 14:53:57,916:INFO:Declaring metric variables
2025-03-24 14:53:57,919:INFO:Importing untrained model
2025-03-24 14:53:57,920:INFO:Lasso Regression Imported successfully
2025-03-24 14:53:57,925:INFO:Starting cross validation
2025-03-24 14:53:57,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:53:59,668:INFO:Calculating mean and std
2025-03-24 14:53:59,669:INFO:Creating metrics dataframe
2025-03-24 14:53:59,671:INFO:Uploading results into container
2025-03-24 14:53:59,672:INFO:Uploading model into container now
2025-03-24 14:53:59,673:INFO:_master_model_container: 2
2025-03-24 14:53:59,673:INFO:_display_container: 2
2025-03-24 14:53:59,673:INFO:Lasso(random_state=123)
2025-03-24 14:53:59,673:INFO:create_model() successfully completed......................................
2025-03-24 14:53:59,738:INFO:SubProcess create_model() end ==================================
2025-03-24 14:53:59,738:INFO:Creating metrics dataframe
2025-03-24 14:53:59,742:INFO:Initializing Ridge Regression
2025-03-24 14:53:59,742:INFO:Total runtime is 0.08266065915425619 minutes
2025-03-24 14:53:59,744:INFO:SubProcess create_model() called ==================================
2025-03-24 14:53:59,744:INFO:Initializing create_model()
2025-03-24 14:53:59,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:53:59,744:INFO:Checking exceptions
2025-03-24 14:53:59,744:INFO:Importing libraries
2025-03-24 14:53:59,745:INFO:Copying training dataset
2025-03-24 14:53:59,751:INFO:Defining folds
2025-03-24 14:53:59,751:INFO:Declaring metric variables
2025-03-24 14:53:59,753:INFO:Importing untrained model
2025-03-24 14:53:59,755:INFO:Ridge Regression Imported successfully
2025-03-24 14:53:59,761:INFO:Starting cross validation
2025-03-24 14:53:59,762:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:00,024:INFO:Calculating mean and std
2025-03-24 14:54:00,025:INFO:Creating metrics dataframe
2025-03-24 14:54:00,026:INFO:Uploading results into container
2025-03-24 14:54:00,027:INFO:Uploading model into container now
2025-03-24 14:54:00,027:INFO:_master_model_container: 3
2025-03-24 14:54:00,027:INFO:_display_container: 2
2025-03-24 14:54:00,027:INFO:Ridge(random_state=123)
2025-03-24 14:54:00,027:INFO:create_model() successfully completed......................................
2025-03-24 14:54:00,095:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:00,095:INFO:Creating metrics dataframe
2025-03-24 14:54:00,100:INFO:Initializing Elastic Net
2025-03-24 14:54:00,100:INFO:Total runtime is 0.0886220137278239 minutes
2025-03-24 14:54:00,101:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:00,102:INFO:Initializing create_model()
2025-03-24 14:54:00,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:00,102:INFO:Checking exceptions
2025-03-24 14:54:00,102:INFO:Importing libraries
2025-03-24 14:54:00,102:INFO:Copying training dataset
2025-03-24 14:54:00,110:INFO:Defining folds
2025-03-24 14:54:00,110:INFO:Declaring metric variables
2025-03-24 14:54:00,112:INFO:Importing untrained model
2025-03-24 14:54:00,115:INFO:Elastic Net Imported successfully
2025-03-24 14:54:00,120:INFO:Starting cross validation
2025-03-24 14:54:00,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:00,369:INFO:Calculating mean and std
2025-03-24 14:54:00,370:INFO:Creating metrics dataframe
2025-03-24 14:54:00,371:INFO:Uploading results into container
2025-03-24 14:54:00,372:INFO:Uploading model into container now
2025-03-24 14:54:00,372:INFO:_master_model_container: 4
2025-03-24 14:54:00,372:INFO:_display_container: 2
2025-03-24 14:54:00,372:INFO:ElasticNet(random_state=123)
2025-03-24 14:54:00,372:INFO:create_model() successfully completed......................................
2025-03-24 14:54:00,440:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:00,440:INFO:Creating metrics dataframe
2025-03-24 14:54:00,446:INFO:Initializing Least Angle Regression
2025-03-24 14:54:00,446:INFO:Total runtime is 0.09439135392506917 minutes
2025-03-24 14:54:00,448:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:00,448:INFO:Initializing create_model()
2025-03-24 14:54:00,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:00,448:INFO:Checking exceptions
2025-03-24 14:54:00,448:INFO:Importing libraries
2025-03-24 14:54:00,448:INFO:Copying training dataset
2025-03-24 14:54:00,455:INFO:Defining folds
2025-03-24 14:54:00,455:INFO:Declaring metric variables
2025-03-24 14:54:00,457:INFO:Importing untrained model
2025-03-24 14:54:00,459:INFO:Least Angle Regression Imported successfully
2025-03-24 14:54:00,463:INFO:Starting cross validation
2025-03-24 14:54:00,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:00,710:INFO:Calculating mean and std
2025-03-24 14:54:00,711:INFO:Creating metrics dataframe
2025-03-24 14:54:00,712:INFO:Uploading results into container
2025-03-24 14:54:00,712:INFO:Uploading model into container now
2025-03-24 14:54:00,712:INFO:_master_model_container: 5
2025-03-24 14:54:00,712:INFO:_display_container: 2
2025-03-24 14:54:00,712:INFO:Lars(random_state=123)
2025-03-24 14:54:00,712:INFO:create_model() successfully completed......................................
2025-03-24 14:54:00,781:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:00,782:INFO:Creating metrics dataframe
2025-03-24 14:54:00,786:INFO:Initializing Lasso Least Angle Regression
2025-03-24 14:54:00,786:INFO:Total runtime is 0.10006282726923625 minutes
2025-03-24 14:54:00,788:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:00,788:INFO:Initializing create_model()
2025-03-24 14:54:00,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:00,788:INFO:Checking exceptions
2025-03-24 14:54:00,788:INFO:Importing libraries
2025-03-24 14:54:00,788:INFO:Copying training dataset
2025-03-24 14:54:00,795:INFO:Defining folds
2025-03-24 14:54:00,795:INFO:Declaring metric variables
2025-03-24 14:54:00,797:INFO:Importing untrained model
2025-03-24 14:54:00,799:INFO:Lasso Least Angle Regression Imported successfully
2025-03-24 14:54:00,802:INFO:Starting cross validation
2025-03-24 14:54:00,803:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:01,052:INFO:Calculating mean and std
2025-03-24 14:54:01,052:INFO:Creating metrics dataframe
2025-03-24 14:54:01,054:INFO:Uploading results into container
2025-03-24 14:54:01,055:INFO:Uploading model into container now
2025-03-24 14:54:01,055:INFO:_master_model_container: 6
2025-03-24 14:54:01,056:INFO:_display_container: 2
2025-03-24 14:54:01,056:INFO:LassoLars(random_state=123)
2025-03-24 14:54:01,056:INFO:create_model() successfully completed......................................
2025-03-24 14:54:01,120:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:01,120:INFO:Creating metrics dataframe
2025-03-24 14:54:01,125:INFO:Initializing Orthogonal Matching Pursuit
2025-03-24 14:54:01,125:INFO:Total runtime is 0.10571455558141073 minutes
2025-03-24 14:54:01,127:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:01,127:INFO:Initializing create_model()
2025-03-24 14:54:01,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:01,127:INFO:Checking exceptions
2025-03-24 14:54:01,127:INFO:Importing libraries
2025-03-24 14:54:01,127:INFO:Copying training dataset
2025-03-24 14:54:01,135:INFO:Defining folds
2025-03-24 14:54:01,135:INFO:Declaring metric variables
2025-03-24 14:54:01,136:INFO:Importing untrained model
2025-03-24 14:54:01,138:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-24 14:54:01,143:INFO:Starting cross validation
2025-03-24 14:54:01,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:01,402:INFO:Calculating mean and std
2025-03-24 14:54:01,403:INFO:Creating metrics dataframe
2025-03-24 14:54:01,404:INFO:Uploading results into container
2025-03-24 14:54:01,404:INFO:Uploading model into container now
2025-03-24 14:54:01,405:INFO:_master_model_container: 7
2025-03-24 14:54:01,405:INFO:_display_container: 2
2025-03-24 14:54:01,405:INFO:OrthogonalMatchingPursuit()
2025-03-24 14:54:01,405:INFO:create_model() successfully completed......................................
2025-03-24 14:54:01,473:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:01,474:INFO:Creating metrics dataframe
2025-03-24 14:54:01,479:INFO:Initializing Bayesian Ridge
2025-03-24 14:54:01,479:INFO:Total runtime is 0.11160955826441447 minutes
2025-03-24 14:54:01,480:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:01,480:INFO:Initializing create_model()
2025-03-24 14:54:01,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:01,480:INFO:Checking exceptions
2025-03-24 14:54:01,480:INFO:Importing libraries
2025-03-24 14:54:01,480:INFO:Copying training dataset
2025-03-24 14:54:01,488:INFO:Defining folds
2025-03-24 14:54:01,488:INFO:Declaring metric variables
2025-03-24 14:54:01,489:INFO:Importing untrained model
2025-03-24 14:54:01,492:INFO:Bayesian Ridge Imported successfully
2025-03-24 14:54:01,496:INFO:Starting cross validation
2025-03-24 14:54:01,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:01,781:INFO:Calculating mean and std
2025-03-24 14:54:01,781:INFO:Creating metrics dataframe
2025-03-24 14:54:01,783:INFO:Uploading results into container
2025-03-24 14:54:01,783:INFO:Uploading model into container now
2025-03-24 14:54:01,783:INFO:_master_model_container: 8
2025-03-24 14:54:01,784:INFO:_display_container: 2
2025-03-24 14:54:01,784:INFO:BayesianRidge()
2025-03-24 14:54:01,784:INFO:create_model() successfully completed......................................
2025-03-24 14:54:01,853:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:01,853:INFO:Creating metrics dataframe
2025-03-24 14:54:01,859:INFO:Initializing Passive Aggressive Regressor
2025-03-24 14:54:01,859:INFO:Total runtime is 0.11794429222742717 minutes
2025-03-24 14:54:01,862:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:01,862:INFO:Initializing create_model()
2025-03-24 14:54:01,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:01,862:INFO:Checking exceptions
2025-03-24 14:54:01,862:INFO:Importing libraries
2025-03-24 14:54:01,862:INFO:Copying training dataset
2025-03-24 14:54:01,870:INFO:Defining folds
2025-03-24 14:54:01,870:INFO:Declaring metric variables
2025-03-24 14:54:01,872:INFO:Importing untrained model
2025-03-24 14:54:01,875:INFO:Passive Aggressive Regressor Imported successfully
2025-03-24 14:54:01,879:INFO:Starting cross validation
2025-03-24 14:54:01,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:02,306:INFO:Calculating mean and std
2025-03-24 14:54:02,307:INFO:Creating metrics dataframe
2025-03-24 14:54:02,309:INFO:Uploading results into container
2025-03-24 14:54:02,309:INFO:Uploading model into container now
2025-03-24 14:54:02,309:INFO:_master_model_container: 9
2025-03-24 14:54:02,309:INFO:_display_container: 2
2025-03-24 14:54:02,309:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-24 14:54:02,310:INFO:create_model() successfully completed......................................
2025-03-24 14:54:02,373:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:02,374:INFO:Creating metrics dataframe
2025-03-24 14:54:02,379:INFO:Initializing Huber Regressor
2025-03-24 14:54:02,379:INFO:Total runtime is 0.1266133189201355 minutes
2025-03-24 14:54:02,381:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:02,381:INFO:Initializing create_model()
2025-03-24 14:54:02,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:02,381:INFO:Checking exceptions
2025-03-24 14:54:02,381:INFO:Importing libraries
2025-03-24 14:54:02,382:INFO:Copying training dataset
2025-03-24 14:54:02,389:INFO:Defining folds
2025-03-24 14:54:02,389:INFO:Declaring metric variables
2025-03-24 14:54:02,390:INFO:Importing untrained model
2025-03-24 14:54:02,393:INFO:Huber Regressor Imported successfully
2025-03-24 14:54:02,396:INFO:Starting cross validation
2025-03-24 14:54:02,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:04,133:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,156:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,173:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,184:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,191:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,200:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,213:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,233:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,294:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,310:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 14:54:04,338:INFO:Calculating mean and std
2025-03-24 14:54:04,339:INFO:Creating metrics dataframe
2025-03-24 14:54:04,341:INFO:Uploading results into container
2025-03-24 14:54:04,341:INFO:Uploading model into container now
2025-03-24 14:54:04,342:INFO:_master_model_container: 10
2025-03-24 14:54:04,342:INFO:_display_container: 2
2025-03-24 14:54:04,342:INFO:HuberRegressor()
2025-03-24 14:54:04,342:INFO:create_model() successfully completed......................................
2025-03-24 14:54:04,419:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:04,419:INFO:Creating metrics dataframe
2025-03-24 14:54:04,426:INFO:Initializing K Neighbors Regressor
2025-03-24 14:54:04,426:INFO:Total runtime is 0.1607317090034485 minutes
2025-03-24 14:54:04,429:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:04,430:INFO:Initializing create_model()
2025-03-24 14:54:04,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:04,430:INFO:Checking exceptions
2025-03-24 14:54:04,430:INFO:Importing libraries
2025-03-24 14:54:04,430:INFO:Copying training dataset
2025-03-24 14:54:04,436:INFO:Defining folds
2025-03-24 14:54:04,436:INFO:Declaring metric variables
2025-03-24 14:54:04,438:INFO:Importing untrained model
2025-03-24 14:54:04,441:INFO:K Neighbors Regressor Imported successfully
2025-03-24 14:54:04,446:INFO:Starting cross validation
2025-03-24 14:54:04,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:05,314:INFO:Calculating mean and std
2025-03-24 14:54:05,314:INFO:Creating metrics dataframe
2025-03-24 14:54:05,316:INFO:Uploading results into container
2025-03-24 14:54:05,317:INFO:Uploading model into container now
2025-03-24 14:54:05,317:INFO:_master_model_container: 11
2025-03-24 14:54:05,317:INFO:_display_container: 2
2025-03-24 14:54:05,318:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-24 14:54:05,318:INFO:create_model() successfully completed......................................
2025-03-24 14:54:05,386:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:05,386:INFO:Creating metrics dataframe
2025-03-24 14:54:05,391:INFO:Initializing Decision Tree Regressor
2025-03-24 14:54:05,392:INFO:Total runtime is 0.1768297791481018 minutes
2025-03-24 14:54:05,395:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:05,395:INFO:Initializing create_model()
2025-03-24 14:54:05,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:05,395:INFO:Checking exceptions
2025-03-24 14:54:05,395:INFO:Importing libraries
2025-03-24 14:54:05,395:INFO:Copying training dataset
2025-03-24 14:54:05,403:INFO:Defining folds
2025-03-24 14:54:05,403:INFO:Declaring metric variables
2025-03-24 14:54:05,405:INFO:Importing untrained model
2025-03-24 14:54:05,408:INFO:Decision Tree Regressor Imported successfully
2025-03-24 14:54:05,414:INFO:Starting cross validation
2025-03-24 14:54:05,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:05,769:INFO:Calculating mean and std
2025-03-24 14:54:05,770:INFO:Creating metrics dataframe
2025-03-24 14:54:05,771:INFO:Uploading results into container
2025-03-24 14:54:05,771:INFO:Uploading model into container now
2025-03-24 14:54:05,773:INFO:_master_model_container: 12
2025-03-24 14:54:05,773:INFO:_display_container: 2
2025-03-24 14:54:05,773:INFO:DecisionTreeRegressor(random_state=123)
2025-03-24 14:54:05,773:INFO:create_model() successfully completed......................................
2025-03-24 14:54:05,844:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:05,844:INFO:Creating metrics dataframe
2025-03-24 14:54:05,852:INFO:Initializing Random Forest Regressor
2025-03-24 14:54:05,852:INFO:Total runtime is 0.18449822664260865 minutes
2025-03-24 14:54:05,854:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:05,854:INFO:Initializing create_model()
2025-03-24 14:54:05,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:05,854:INFO:Checking exceptions
2025-03-24 14:54:05,854:INFO:Importing libraries
2025-03-24 14:54:05,854:INFO:Copying training dataset
2025-03-24 14:54:05,863:INFO:Defining folds
2025-03-24 14:54:05,863:INFO:Declaring metric variables
2025-03-24 14:54:05,864:INFO:Importing untrained model
2025-03-24 14:54:05,866:INFO:Random Forest Regressor Imported successfully
2025-03-24 14:54:05,872:INFO:Starting cross validation
2025-03-24 14:54:05,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:12,127:INFO:Calculating mean and std
2025-03-24 14:54:12,127:INFO:Creating metrics dataframe
2025-03-24 14:54:12,129:INFO:Uploading results into container
2025-03-24 14:54:12,129:INFO:Uploading model into container now
2025-03-24 14:54:12,129:INFO:_master_model_container: 13
2025-03-24 14:54:12,129:INFO:_display_container: 2
2025-03-24 14:54:12,130:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:12,130:INFO:create_model() successfully completed......................................
2025-03-24 14:54:12,205:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:12,205:INFO:Creating metrics dataframe
2025-03-24 14:54:12,213:INFO:Initializing Extra Trees Regressor
2025-03-24 14:54:12,213:INFO:Total runtime is 0.29050584634145105 minutes
2025-03-24 14:54:12,215:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:12,215:INFO:Initializing create_model()
2025-03-24 14:54:12,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:12,215:INFO:Checking exceptions
2025-03-24 14:54:12,215:INFO:Importing libraries
2025-03-24 14:54:12,215:INFO:Copying training dataset
2025-03-24 14:54:12,223:INFO:Defining folds
2025-03-24 14:54:12,223:INFO:Declaring metric variables
2025-03-24 14:54:12,226:INFO:Importing untrained model
2025-03-24 14:54:12,228:INFO:Extra Trees Regressor Imported successfully
2025-03-24 14:54:12,233:INFO:Starting cross validation
2025-03-24 14:54:12,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:16,439:INFO:Calculating mean and std
2025-03-24 14:54:16,439:INFO:Creating metrics dataframe
2025-03-24 14:54:16,443:INFO:Uploading results into container
2025-03-24 14:54:16,443:INFO:Uploading model into container now
2025-03-24 14:54:16,444:INFO:_master_model_container: 14
2025-03-24 14:54:16,444:INFO:_display_container: 2
2025-03-24 14:54:16,444:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:16,444:INFO:create_model() successfully completed......................................
2025-03-24 14:54:16,562:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:16,562:INFO:Creating metrics dataframe
2025-03-24 14:54:16,571:INFO:Initializing AdaBoost Regressor
2025-03-24 14:54:16,571:INFO:Total runtime is 0.36314464012781783 minutes
2025-03-24 14:54:16,575:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:16,575:INFO:Initializing create_model()
2025-03-24 14:54:16,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:16,575:INFO:Checking exceptions
2025-03-24 14:54:16,575:INFO:Importing libraries
2025-03-24 14:54:16,575:INFO:Copying training dataset
2025-03-24 14:54:16,588:INFO:Defining folds
2025-03-24 14:54:16,588:INFO:Declaring metric variables
2025-03-24 14:54:16,592:INFO:Importing untrained model
2025-03-24 14:54:16,596:INFO:AdaBoost Regressor Imported successfully
2025-03-24 14:54:16,603:INFO:Starting cross validation
2025-03-24 14:54:16,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:17,798:INFO:Calculating mean and std
2025-03-24 14:54:17,799:INFO:Creating metrics dataframe
2025-03-24 14:54:17,801:INFO:Uploading results into container
2025-03-24 14:54:17,801:INFO:Uploading model into container now
2025-03-24 14:54:17,802:INFO:_master_model_container: 15
2025-03-24 14:54:17,802:INFO:_display_container: 2
2025-03-24 14:54:17,802:INFO:AdaBoostRegressor(random_state=123)
2025-03-24 14:54:17,802:INFO:create_model() successfully completed......................................
2025-03-24 14:54:17,898:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:17,898:INFO:Creating metrics dataframe
2025-03-24 14:54:17,908:INFO:Initializing Gradient Boosting Regressor
2025-03-24 14:54:17,908:INFO:Total runtime is 0.3854273438453675 minutes
2025-03-24 14:54:17,912:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:17,912:INFO:Initializing create_model()
2025-03-24 14:54:17,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:17,912:INFO:Checking exceptions
2025-03-24 14:54:17,912:INFO:Importing libraries
2025-03-24 14:54:17,912:INFO:Copying training dataset
2025-03-24 14:54:17,925:INFO:Defining folds
2025-03-24 14:54:17,925:INFO:Declaring metric variables
2025-03-24 14:54:17,928:INFO:Importing untrained model
2025-03-24 14:54:17,931:INFO:Gradient Boosting Regressor Imported successfully
2025-03-24 14:54:17,936:INFO:Starting cross validation
2025-03-24 14:54:17,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:20,357:INFO:Calculating mean and std
2025-03-24 14:54:20,358:INFO:Creating metrics dataframe
2025-03-24 14:54:20,360:INFO:Uploading results into container
2025-03-24 14:54:20,360:INFO:Uploading model into container now
2025-03-24 14:54:20,360:INFO:_master_model_container: 16
2025-03-24 14:54:20,360:INFO:_display_container: 2
2025-03-24 14:54:20,360:INFO:GradientBoostingRegressor(random_state=123)
2025-03-24 14:54:20,360:INFO:create_model() successfully completed......................................
2025-03-24 14:54:20,430:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:20,430:INFO:Creating metrics dataframe
2025-03-24 14:54:20,437:INFO:Initializing Light Gradient Boosting Machine
2025-03-24 14:54:20,437:INFO:Total runtime is 0.42757436434427903 minutes
2025-03-24 14:54:20,439:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:20,439:INFO:Initializing create_model()
2025-03-24 14:54:20,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:20,439:INFO:Checking exceptions
2025-03-24 14:54:20,439:INFO:Importing libraries
2025-03-24 14:54:20,439:INFO:Copying training dataset
2025-03-24 14:54:20,447:INFO:Defining folds
2025-03-24 14:54:20,448:INFO:Declaring metric variables
2025-03-24 14:54:20,450:INFO:Importing untrained model
2025-03-24 14:54:20,451:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 14:54:20,456:INFO:Starting cross validation
2025-03-24 14:54:20,457:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:21,456:INFO:Calculating mean and std
2025-03-24 14:54:21,457:INFO:Creating metrics dataframe
2025-03-24 14:54:21,459:INFO:Uploading results into container
2025-03-24 14:54:21,459:INFO:Uploading model into container now
2025-03-24 14:54:21,460:INFO:_master_model_container: 17
2025-03-24 14:54:21,460:INFO:_display_container: 2
2025-03-24 14:54:21,460:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:21,460:INFO:create_model() successfully completed......................................
2025-03-24 14:54:21,547:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:21,548:INFO:Creating metrics dataframe
2025-03-24 14:54:21,554:INFO:Initializing Dummy Regressor
2025-03-24 14:54:21,554:INFO:Total runtime is 0.4461960474650066 minutes
2025-03-24 14:54:21,556:INFO:SubProcess create_model() called ==================================
2025-03-24 14:54:21,557:INFO:Initializing create_model()
2025-03-24 14:54:21,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C955C932B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:21,557:INFO:Checking exceptions
2025-03-24 14:54:21,557:INFO:Importing libraries
2025-03-24 14:54:21,557:INFO:Copying training dataset
2025-03-24 14:54:21,565:INFO:Defining folds
2025-03-24 14:54:21,565:INFO:Declaring metric variables
2025-03-24 14:54:21,568:INFO:Importing untrained model
2025-03-24 14:54:21,570:INFO:Dummy Regressor Imported successfully
2025-03-24 14:54:21,575:INFO:Starting cross validation
2025-03-24 14:54:21,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 14:54:21,827:INFO:Calculating mean and std
2025-03-24 14:54:21,828:INFO:Creating metrics dataframe
2025-03-24 14:54:21,830:INFO:Uploading results into container
2025-03-24 14:54:21,830:INFO:Uploading model into container now
2025-03-24 14:54:21,830:INFO:_master_model_container: 18
2025-03-24 14:54:21,830:INFO:_display_container: 2
2025-03-24 14:54:21,831:INFO:DummyRegressor()
2025-03-24 14:54:21,831:INFO:create_model() successfully completed......................................
2025-03-24 14:54:21,907:INFO:SubProcess create_model() end ==================================
2025-03-24 14:54:21,907:INFO:Creating metrics dataframe
2025-03-24 14:54:21,914:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-24 14:54:21,919:INFO:Initializing create_model()
2025-03-24 14:54:21,919:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:21,919:INFO:Checking exceptions
2025-03-24 14:54:21,920:INFO:Importing libraries
2025-03-24 14:54:21,920:INFO:Copying training dataset
2025-03-24 14:54:21,926:INFO:Defining folds
2025-03-24 14:54:21,927:INFO:Declaring metric variables
2025-03-24 14:54:21,927:INFO:Importing untrained model
2025-03-24 14:54:21,927:INFO:Declaring custom model
2025-03-24 14:54:21,927:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 14:54:21,928:INFO:Cross validation set to False
2025-03-24 14:54:21,928:INFO:Fitting Model
2025-03-24 14:54:22,018:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 14:54:22,020:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.
2025-03-24 14:54:22,020:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 14:54:22,020:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 14:54:22,020:INFO:[LightGBM] [Info] Total Bins 562
2025-03-24 14:54:22,020:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-24 14:54:22,020:INFO:[LightGBM] [Info] Start training from score 3248.074833
2025-03-24 14:54:22,092:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:22,092:INFO:create_model() successfully completed......................................
2025-03-24 14:54:22,187:INFO:_master_model_container: 18
2025-03-24 14:54:22,187:INFO:_display_container: 2
2025-03-24 14:54:22,188:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:22,189:INFO:compare_models() successfully completed......................................
2025-03-24 14:54:22,192:INFO:Initializing evaluate_model()
2025-03-24 14:54:22,192:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 14:54:22,204:INFO:Initializing plot_model()
2025-03-24 14:54:22,204:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, system=True)
2025-03-24 14:54:22,204:INFO:Checking exceptions
2025-03-24 14:54:22,207:INFO:Preloading libraries
2025-03-24 14:54:22,210:INFO:Copying training dataset
2025-03-24 14:54:22,210:INFO:Plot type: pipeline
2025-03-24 14:54:22,353:INFO:Visual Rendered Successfully
2025-03-24 14:54:22,422:INFO:plot_model() successfully completed......................................
2025-03-24 14:54:22,425:INFO:Initializing predict_model()
2025-03-24 14:54:22,425:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C94EDCBEB0>)
2025-03-24 14:54:22,425:INFO:Checking exceptions
2025-03-24 14:54:22,425:INFO:Preloading libraries
2025-03-24 14:54:22,542:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-24 14:54:22,630:INFO:Initializing finalize_model()
2025-03-24 14:54:22,630:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-24 14:54:22,630:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-24 14:54:22,635:INFO:Initializing create_model()
2025-03-24 14:54:22,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C94FBCEB90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 14:54:22,635:INFO:Checking exceptions
2025-03-24 14:54:22,636:INFO:Importing libraries
2025-03-24 14:54:22,636:INFO:Copying training dataset
2025-03-24 14:54:22,636:INFO:Defining folds
2025-03-24 14:54:22,636:INFO:Declaring metric variables
2025-03-24 14:54:22,637:INFO:Importing untrained model
2025-03-24 14:54:22,637:INFO:Declaring custom model
2025-03-24 14:54:22,637:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 14:54:22,638:INFO:Cross validation set to False
2025-03-24 14:54:22,638:INFO:Fitting Model
2025-03-24 14:54:22,744:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 14:54:22,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.
2025-03-24 14:54:22,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 14:54:22,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 14:54:22,747:INFO:[LightGBM] [Info] Total Bins 572
2025-03-24 14:54:22,747:INFO:[LightGBM] [Info] Number of data points in the train set: 48204, number of used features: 16
2025-03-24 14:54:22,747:INFO:[LightGBM] [Info] Start training from score 3259.818355
2025-03-24 14:54:22,807:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-03-24 14:54:22,807:INFO:create_model() successfully completed......................................
2025-03-24 14:54:22,884:INFO:_master_model_container: 18
2025-03-24 14:54:22,885:INFO:_display_container: 3
2025-03-24 14:54:22,893:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-03-24 14:54:22,893:INFO:finalize_model() successfully completed......................................
2025-03-24 14:54:22,972:INFO:Initializing save_model()
2025-03-24 14:54:22,972:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=traffic_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-24 14:54:22,973:INFO:Adding model into prep_pipe
2025-03-24 14:54:22,973:WARNING:Only Model saved as it was a pipeline.
2025-03-24 14:54:22,979:INFO:traffic_model.pkl saved in current working directory
2025-03-24 14:54:22,986:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-03-24 14:54:22,986:INFO:save_model() successfully completed......................................
2025-03-24 21:18:23,308:INFO:PyCaret RegressionExperiment
2025-03-24 21:18:23,308:INFO:Logging name: reg-default-name
2025-03-24 21:18:23,309:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-24 21:18:23,309:INFO:version 3.3.2
2025-03-24 21:18:23,309:INFO:Initializing setup()
2025-03-24 21:18:23,309:INFO:self.USI: fb62
2025-03-24 21:18:23,309:INFO:self._variable_keys: {'_ml_usecase', 'html_param', 'fold_shuffle_param', 'transform_target_param', 'exp_id', 'X_test', 'X_train', 'memory', 'y_test', 'exp_name_log', 'gpu_param', 'USI', 'y', 'seed', 'fold_generator', 'X', 'idx', 'pipeline', 'target_param', 'gpu_n_jobs_param', 'n_jobs_param', 'fold_groups_param', 'logging_param', 'log_plots_param', '_available_plots', 'y_train', 'data'}
2025-03-24 21:18:23,310:INFO:Checking environment
2025-03-24 21:18:23,310:INFO:python_version: 3.10.16
2025-03-24 21:18:23,310:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-24 21:18:23,310:INFO:machine: AMD64
2025-03-24 21:18:23,310:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-24 21:18:23,316:INFO:Memory: svmem(total=33411727360, available=15628259328, percent=53.2, used=17783468032, free=15628259328)
2025-03-24 21:18:23,316:INFO:Physical Core: 6
2025-03-24 21:18:23,316:INFO:Logical Core: 12
2025-03-24 21:18:23,316:INFO:Checking libraries
2025-03-24 21:18:23,317:INFO:System:
2025-03-24 21:18:23,317:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-24 21:18:23,317:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-24 21:18:23,317:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-24 21:18:23,317:INFO:PyCaret required dependencies:
2025-03-24 21:18:23,317:INFO:                 pip: 25.0.1
2025-03-24 21:18:23,317:INFO:          setuptools: 75.8.2
2025-03-24 21:18:23,317:INFO:             pycaret: 3.3.2
2025-03-24 21:18:23,317:INFO:             IPython: 8.34.0
2025-03-24 21:18:23,317:INFO:          ipywidgets: 8.1.5
2025-03-24 21:18:23,317:INFO:                tqdm: 4.67.1
2025-03-24 21:18:23,317:INFO:               numpy: 1.26.4
2025-03-24 21:18:23,317:INFO:              pandas: 2.1.4
2025-03-24 21:18:23,317:INFO:              jinja2: 3.1.6
2025-03-24 21:18:23,317:INFO:               scipy: 1.11.4
2025-03-24 21:18:23,317:INFO:              joblib: 1.3.2
2025-03-24 21:18:23,317:INFO:             sklearn: 1.4.2
2025-03-24 21:18:23,317:INFO:                pyod: 2.0.2
2025-03-24 21:18:23,318:INFO:            imblearn: 0.13.0
2025-03-24 21:18:23,318:INFO:   category_encoders: 2.7.0
2025-03-24 21:18:23,318:INFO:            lightgbm: 4.6.0
2025-03-24 21:18:23,318:INFO:               numba: 0.61.0
2025-03-24 21:18:23,318:INFO:            requests: 2.32.3
2025-03-24 21:18:23,318:INFO:          matplotlib: 3.10.1
2025-03-24 21:18:23,318:INFO:          scikitplot: 0.3.7
2025-03-24 21:18:23,318:INFO:         yellowbrick: 1.5
2025-03-24 21:18:23,318:INFO:              plotly: 6.0.1
2025-03-24 21:18:23,318:INFO:    plotly-resampler: Not installed
2025-03-24 21:18:23,318:INFO:             kaleido: 0.2.1
2025-03-24 21:18:23,318:INFO:           schemdraw: 0.15
2025-03-24 21:18:23,318:INFO:         statsmodels: 0.14.4
2025-03-24 21:18:23,318:INFO:              sktime: 0.26.0
2025-03-24 21:18:23,318:INFO:               tbats: 1.1.3
2025-03-24 21:18:23,318:INFO:            pmdarima: 2.0.4
2025-03-24 21:18:23,318:INFO:              psutil: 7.0.0
2025-03-24 21:18:23,318:INFO:          markupsafe: 3.0.2
2025-03-24 21:18:23,318:INFO:             pickle5: Not installed
2025-03-24 21:18:23,318:INFO:         cloudpickle: 3.1.1
2025-03-24 21:18:23,318:INFO:         deprecation: 2.1.0
2025-03-24 21:18:23,318:INFO:              xxhash: 3.5.0
2025-03-24 21:18:23,318:INFO:           wurlitzer: 3.1.1
2025-03-24 21:18:23,318:INFO:PyCaret optional dependencies:
2025-03-24 21:18:23,318:INFO:                shap: Not installed
2025-03-24 21:18:23,318:INFO:           interpret: Not installed
2025-03-24 21:18:23,318:INFO:                umap: 0.5.7
2025-03-24 21:18:23,318:INFO:     ydata_profiling: Not installed
2025-03-24 21:18:23,318:INFO:  explainerdashboard: Not installed
2025-03-24 21:18:23,318:INFO:             autoviz: Not installed
2025-03-24 21:18:23,318:INFO:           fairlearn: Not installed
2025-03-24 21:18:23,318:INFO:          deepchecks: Not installed
2025-03-24 21:18:23,318:INFO:             xgboost: Not installed
2025-03-24 21:18:23,318:INFO:            catboost: Not installed
2025-03-24 21:18:23,318:INFO:              kmodes: Not installed
2025-03-24 21:18:23,318:INFO:             mlxtend: Not installed
2025-03-24 21:18:23,318:INFO:       statsforecast: Not installed
2025-03-24 21:18:23,318:INFO:        tune_sklearn: Not installed
2025-03-24 21:18:23,318:INFO:                 ray: Not installed
2025-03-24 21:18:23,318:INFO:            hyperopt: Not installed
2025-03-24 21:18:23,318:INFO:              optuna: Not installed
2025-03-24 21:18:23,318:INFO:               skopt: Not installed
2025-03-24 21:18:23,318:INFO:              mlflow: Not installed
2025-03-24 21:18:23,318:INFO:              gradio: Not installed
2025-03-24 21:18:23,318:INFO:             fastapi: Not installed
2025-03-24 21:18:23,318:INFO:             uvicorn: Not installed
2025-03-24 21:18:23,318:INFO:              m2cgen: Not installed
2025-03-24 21:18:23,318:INFO:           evidently: Not installed
2025-03-24 21:18:23,318:INFO:               fugue: Not installed
2025-03-24 21:18:23,319:INFO:           streamlit: Not installed
2025-03-24 21:18:23,319:INFO:             prophet: Not installed
2025-03-24 21:18:23,319:INFO:None
2025-03-24 21:18:23,319:INFO:Set up data.
2025-03-24 21:18:23,329:INFO:Set up folding strategy.
2025-03-24 21:18:23,329:INFO:Set up train/test split.
2025-03-24 21:18:23,336:INFO:Set up index.
2025-03-24 21:18:23,336:INFO:Assigning column types.
2025-03-24 21:18:23,342:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-24 21:18:23,342:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,345:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,347:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,415:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,416:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,419:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,422:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,489:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-24 21:18:23,492:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,565:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,568:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,608:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,634:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,635:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-24 21:18:23,640:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,708:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,716:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,752:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,778:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,778:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-24 21:18:23,820:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,888:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,913:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,913:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-24 21:18:23,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:23,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:23,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:18:24,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,047:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-24 21:18:24,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,181:INFO:Preparing preprocessing pipeline...
2025-03-24 21:18:24,181:INFO:Set up simple imputation.
2025-03-24 21:18:24,184:INFO:Set up encoding of categorical features.
2025-03-24 21:18:24,185:INFO:Set up column name cleaning.
2025-03-24 21:18:24,289:INFO:Finished creating preprocessing pipeline.
2025-03-24 21:18:24,293:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-24 21:18:24,293:INFO:Creating final display dataframe.
2025-03-24 21:18:24,526:INFO:Setup _display_container:                     Description             Value
0                    Session id              1741
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              fb62
2025-03-24 21:18:24,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:18:24,668:INFO:setup() successfully completed in 1.36s...............
2025-03-24 21:19:01,835:INFO:Initializing compare_models()
2025-03-24 21:19:01,835:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-24 21:19:01,836:INFO:Checking exceptions
2025-03-24 21:19:01,839:INFO:Preparing display monitor
2025-03-24 21:19:01,855:INFO:Initializing Linear Regression
2025-03-24 21:19:01,855:INFO:Total runtime is 0.0 minutes
2025-03-24 21:19:01,857:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:01,858:INFO:Initializing create_model()
2025-03-24 21:19:01,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:01,858:INFO:Checking exceptions
2025-03-24 21:19:01,858:INFO:Importing libraries
2025-03-24 21:19:01,858:INFO:Copying training dataset
2025-03-24 21:19:01,866:INFO:Defining folds
2025-03-24 21:19:01,866:INFO:Declaring metric variables
2025-03-24 21:19:01,868:INFO:Importing untrained model
2025-03-24 21:19:01,870:INFO:Linear Regression Imported successfully
2025-03-24 21:19:01,873:INFO:Starting cross validation
2025-03-24 21:19:01,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:04,940:INFO:Calculating mean and std
2025-03-24 21:19:04,942:INFO:Creating metrics dataframe
2025-03-24 21:19:04,944:INFO:Uploading results into container
2025-03-24 21:19:04,944:INFO:Uploading model into container now
2025-03-24 21:19:04,945:INFO:_master_model_container: 1
2025-03-24 21:19:04,945:INFO:_display_container: 2
2025-03-24 21:19:04,946:INFO:LinearRegression(n_jobs=-1)
2025-03-24 21:19:04,946:INFO:create_model() successfully completed......................................
2025-03-24 21:19:05,097:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:05,097:INFO:Creating metrics dataframe
2025-03-24 21:19:05,103:INFO:Initializing Lasso Regression
2025-03-24 21:19:05,103:INFO:Total runtime is 0.054133248329162595 minutes
2025-03-24 21:19:05,105:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:05,105:INFO:Initializing create_model()
2025-03-24 21:19:05,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:05,105:INFO:Checking exceptions
2025-03-24 21:19:05,105:INFO:Importing libraries
2025-03-24 21:19:05,106:INFO:Copying training dataset
2025-03-24 21:19:05,114:INFO:Defining folds
2025-03-24 21:19:05,114:INFO:Declaring metric variables
2025-03-24 21:19:05,117:INFO:Importing untrained model
2025-03-24 21:19:05,120:INFO:Lasso Regression Imported successfully
2025-03-24 21:19:05,123:INFO:Starting cross validation
2025-03-24 21:19:05,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:06,880:INFO:Calculating mean and std
2025-03-24 21:19:06,880:INFO:Creating metrics dataframe
2025-03-24 21:19:06,883:INFO:Uploading results into container
2025-03-24 21:19:06,883:INFO:Uploading model into container now
2025-03-24 21:19:06,883:INFO:_master_model_container: 2
2025-03-24 21:19:06,883:INFO:_display_container: 2
2025-03-24 21:19:06,884:INFO:Lasso(random_state=1741)
2025-03-24 21:19:06,884:INFO:create_model() successfully completed......................................
2025-03-24 21:19:06,956:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:06,956:INFO:Creating metrics dataframe
2025-03-24 21:19:06,960:INFO:Initializing Ridge Regression
2025-03-24 21:19:06,960:INFO:Total runtime is 0.08509182135264079 minutes
2025-03-24 21:19:06,963:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:06,963:INFO:Initializing create_model()
2025-03-24 21:19:06,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:06,963:INFO:Checking exceptions
2025-03-24 21:19:06,963:INFO:Importing libraries
2025-03-24 21:19:06,964:INFO:Copying training dataset
2025-03-24 21:19:06,970:INFO:Defining folds
2025-03-24 21:19:06,970:INFO:Declaring metric variables
2025-03-24 21:19:06,972:INFO:Importing untrained model
2025-03-24 21:19:06,973:INFO:Ridge Regression Imported successfully
2025-03-24 21:19:06,977:INFO:Starting cross validation
2025-03-24 21:19:06,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:07,224:INFO:Calculating mean and std
2025-03-24 21:19:07,225:INFO:Creating metrics dataframe
2025-03-24 21:19:07,227:INFO:Uploading results into container
2025-03-24 21:19:07,227:INFO:Uploading model into container now
2025-03-24 21:19:07,227:INFO:_master_model_container: 3
2025-03-24 21:19:07,228:INFO:_display_container: 2
2025-03-24 21:19:07,228:INFO:Ridge(random_state=1741)
2025-03-24 21:19:07,228:INFO:create_model() successfully completed......................................
2025-03-24 21:19:07,302:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:07,303:INFO:Creating metrics dataframe
2025-03-24 21:19:07,306:INFO:Initializing Elastic Net
2025-03-24 21:19:07,307:INFO:Total runtime is 0.09087685743967693 minutes
2025-03-24 21:19:07,309:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:07,309:INFO:Initializing create_model()
2025-03-24 21:19:07,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:07,310:INFO:Checking exceptions
2025-03-24 21:19:07,310:INFO:Importing libraries
2025-03-24 21:19:07,310:INFO:Copying training dataset
2025-03-24 21:19:07,317:INFO:Defining folds
2025-03-24 21:19:07,317:INFO:Declaring metric variables
2025-03-24 21:19:07,319:INFO:Importing untrained model
2025-03-24 21:19:07,321:INFO:Elastic Net Imported successfully
2025-03-24 21:19:07,325:INFO:Starting cross validation
2025-03-24 21:19:07,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:07,582:INFO:Calculating mean and std
2025-03-24 21:19:07,583:INFO:Creating metrics dataframe
2025-03-24 21:19:07,584:INFO:Uploading results into container
2025-03-24 21:19:07,584:INFO:Uploading model into container now
2025-03-24 21:19:07,585:INFO:_master_model_container: 4
2025-03-24 21:19:07,585:INFO:_display_container: 2
2025-03-24 21:19:07,585:INFO:ElasticNet(random_state=1741)
2025-03-24 21:19:07,585:INFO:create_model() successfully completed......................................
2025-03-24 21:19:07,657:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:07,657:INFO:Creating metrics dataframe
2025-03-24 21:19:07,663:INFO:Initializing Least Angle Regression
2025-03-24 21:19:07,663:INFO:Total runtime is 0.09681055148442587 minutes
2025-03-24 21:19:07,665:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:07,666:INFO:Initializing create_model()
2025-03-24 21:19:07,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:07,666:INFO:Checking exceptions
2025-03-24 21:19:07,666:INFO:Importing libraries
2025-03-24 21:19:07,666:INFO:Copying training dataset
2025-03-24 21:19:07,673:INFO:Defining folds
2025-03-24 21:19:07,673:INFO:Declaring metric variables
2025-03-24 21:19:07,675:INFO:Importing untrained model
2025-03-24 21:19:07,677:INFO:Least Angle Regression Imported successfully
2025-03-24 21:19:07,681:INFO:Starting cross validation
2025-03-24 21:19:07,683:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:07,938:INFO:Calculating mean and std
2025-03-24 21:19:07,939:INFO:Creating metrics dataframe
2025-03-24 21:19:07,940:INFO:Uploading results into container
2025-03-24 21:19:07,940:INFO:Uploading model into container now
2025-03-24 21:19:07,940:INFO:_master_model_container: 5
2025-03-24 21:19:07,942:INFO:_display_container: 2
2025-03-24 21:19:07,942:INFO:Lars(random_state=1741)
2025-03-24 21:19:07,942:INFO:create_model() successfully completed......................................
2025-03-24 21:19:08,008:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:08,008:INFO:Creating metrics dataframe
2025-03-24 21:19:08,013:INFO:Initializing Lasso Least Angle Regression
2025-03-24 21:19:08,013:INFO:Total runtime is 0.10263184706370036 minutes
2025-03-24 21:19:08,015:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:08,015:INFO:Initializing create_model()
2025-03-24 21:19:08,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:08,015:INFO:Checking exceptions
2025-03-24 21:19:08,015:INFO:Importing libraries
2025-03-24 21:19:08,015:INFO:Copying training dataset
2025-03-24 21:19:08,022:INFO:Defining folds
2025-03-24 21:19:08,022:INFO:Declaring metric variables
2025-03-24 21:19:08,023:INFO:Importing untrained model
2025-03-24 21:19:08,026:INFO:Lasso Least Angle Regression Imported successfully
2025-03-24 21:19:08,029:INFO:Starting cross validation
2025-03-24 21:19:08,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:08,267:INFO:Calculating mean and std
2025-03-24 21:19:08,268:INFO:Creating metrics dataframe
2025-03-24 21:19:08,269:INFO:Uploading results into container
2025-03-24 21:19:08,269:INFO:Uploading model into container now
2025-03-24 21:19:08,270:INFO:_master_model_container: 6
2025-03-24 21:19:08,270:INFO:_display_container: 2
2025-03-24 21:19:08,270:INFO:LassoLars(random_state=1741)
2025-03-24 21:19:08,270:INFO:create_model() successfully completed......................................
2025-03-24 21:19:08,343:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:08,343:INFO:Creating metrics dataframe
2025-03-24 21:19:08,348:INFO:Initializing Orthogonal Matching Pursuit
2025-03-24 21:19:08,348:INFO:Total runtime is 0.10822073221206666 minutes
2025-03-24 21:19:08,351:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:08,351:INFO:Initializing create_model()
2025-03-24 21:19:08,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:08,351:INFO:Checking exceptions
2025-03-24 21:19:08,351:INFO:Importing libraries
2025-03-24 21:19:08,351:INFO:Copying training dataset
2025-03-24 21:19:08,358:INFO:Defining folds
2025-03-24 21:19:08,358:INFO:Declaring metric variables
2025-03-24 21:19:08,360:INFO:Importing untrained model
2025-03-24 21:19:08,362:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-24 21:19:08,366:INFO:Starting cross validation
2025-03-24 21:19:08,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:08,608:INFO:Calculating mean and std
2025-03-24 21:19:08,609:INFO:Creating metrics dataframe
2025-03-24 21:19:08,610:INFO:Uploading results into container
2025-03-24 21:19:08,611:INFO:Uploading model into container now
2025-03-24 21:19:08,611:INFO:_master_model_container: 7
2025-03-24 21:19:08,611:INFO:_display_container: 2
2025-03-24 21:19:08,611:INFO:OrthogonalMatchingPursuit()
2025-03-24 21:19:08,611:INFO:create_model() successfully completed......................................
2025-03-24 21:19:08,684:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:08,684:INFO:Creating metrics dataframe
2025-03-24 21:19:08,690:INFO:Initializing Bayesian Ridge
2025-03-24 21:19:08,690:INFO:Total runtime is 0.1139179031054179 minutes
2025-03-24 21:19:08,692:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:08,693:INFO:Initializing create_model()
2025-03-24 21:19:08,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:08,693:INFO:Checking exceptions
2025-03-24 21:19:08,693:INFO:Importing libraries
2025-03-24 21:19:08,693:INFO:Copying training dataset
2025-03-24 21:19:08,701:INFO:Defining folds
2025-03-24 21:19:08,701:INFO:Declaring metric variables
2025-03-24 21:19:08,703:INFO:Importing untrained model
2025-03-24 21:19:08,705:INFO:Bayesian Ridge Imported successfully
2025-03-24 21:19:08,710:INFO:Starting cross validation
2025-03-24 21:19:08,711:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:08,982:INFO:Calculating mean and std
2025-03-24 21:19:08,983:INFO:Creating metrics dataframe
2025-03-24 21:19:08,984:INFO:Uploading results into container
2025-03-24 21:19:08,985:INFO:Uploading model into container now
2025-03-24 21:19:08,985:INFO:_master_model_container: 8
2025-03-24 21:19:08,985:INFO:_display_container: 2
2025-03-24 21:19:08,985:INFO:BayesianRidge()
2025-03-24 21:19:08,985:INFO:create_model() successfully completed......................................
2025-03-24 21:19:09,054:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:09,054:INFO:Creating metrics dataframe
2025-03-24 21:19:09,060:INFO:Initializing Passive Aggressive Regressor
2025-03-24 21:19:09,060:INFO:Total runtime is 0.12008246978123983 minutes
2025-03-24 21:19:09,062:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:09,062:INFO:Initializing create_model()
2025-03-24 21:19:09,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:09,062:INFO:Checking exceptions
2025-03-24 21:19:09,062:INFO:Importing libraries
2025-03-24 21:19:09,062:INFO:Copying training dataset
2025-03-24 21:19:09,069:INFO:Defining folds
2025-03-24 21:19:09,069:INFO:Declaring metric variables
2025-03-24 21:19:09,070:INFO:Importing untrained model
2025-03-24 21:19:09,072:INFO:Passive Aggressive Regressor Imported successfully
2025-03-24 21:19:09,076:INFO:Starting cross validation
2025-03-24 21:19:09,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:09,447:INFO:Calculating mean and std
2025-03-24 21:19:09,448:INFO:Creating metrics dataframe
2025-03-24 21:19:09,449:INFO:Uploading results into container
2025-03-24 21:19:09,449:INFO:Uploading model into container now
2025-03-24 21:19:09,450:INFO:_master_model_container: 9
2025-03-24 21:19:09,450:INFO:_display_container: 2
2025-03-24 21:19:09,450:INFO:PassiveAggressiveRegressor(random_state=1741)
2025-03-24 21:19:09,450:INFO:create_model() successfully completed......................................
2025-03-24 21:19:09,521:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:09,521:INFO:Creating metrics dataframe
2025-03-24 21:19:09,527:INFO:Initializing Huber Regressor
2025-03-24 21:19:09,527:INFO:Total runtime is 0.12787710825602214 minutes
2025-03-24 21:19:09,529:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:09,529:INFO:Initializing create_model()
2025-03-24 21:19:09,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:09,530:INFO:Checking exceptions
2025-03-24 21:19:09,530:INFO:Importing libraries
2025-03-24 21:19:09,530:INFO:Copying training dataset
2025-03-24 21:19:09,537:INFO:Defining folds
2025-03-24 21:19:09,537:INFO:Declaring metric variables
2025-03-24 21:19:09,539:INFO:Importing untrained model
2025-03-24 21:19:09,541:INFO:Huber Regressor Imported successfully
2025-03-24 21:19:09,546:INFO:Starting cross validation
2025-03-24 21:19:09,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:11,039:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,084:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,088:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,103:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,113:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,121:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,134:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,136:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,215:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,222:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:19:11,254:INFO:Calculating mean and std
2025-03-24 21:19:11,255:INFO:Creating metrics dataframe
2025-03-24 21:19:11,256:INFO:Uploading results into container
2025-03-24 21:19:11,256:INFO:Uploading model into container now
2025-03-24 21:19:11,256:INFO:_master_model_container: 10
2025-03-24 21:19:11,256:INFO:_display_container: 2
2025-03-24 21:19:11,257:INFO:HuberRegressor()
2025-03-24 21:19:11,257:INFO:create_model() successfully completed......................................
2025-03-24 21:19:11,322:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:11,323:INFO:Creating metrics dataframe
2025-03-24 21:19:11,329:INFO:Initializing K Neighbors Regressor
2025-03-24 21:19:11,329:INFO:Total runtime is 0.1578987995783488 minutes
2025-03-24 21:19:11,331:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:11,332:INFO:Initializing create_model()
2025-03-24 21:19:11,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:11,332:INFO:Checking exceptions
2025-03-24 21:19:11,332:INFO:Importing libraries
2025-03-24 21:19:11,332:INFO:Copying training dataset
2025-03-24 21:19:11,339:INFO:Defining folds
2025-03-24 21:19:11,339:INFO:Declaring metric variables
2025-03-24 21:19:11,341:INFO:Importing untrained model
2025-03-24 21:19:11,343:INFO:K Neighbors Regressor Imported successfully
2025-03-24 21:19:11,347:INFO:Starting cross validation
2025-03-24 21:19:11,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:12,146:INFO:Calculating mean and std
2025-03-24 21:19:12,147:INFO:Creating metrics dataframe
2025-03-24 21:19:12,148:INFO:Uploading results into container
2025-03-24 21:19:12,148:INFO:Uploading model into container now
2025-03-24 21:19:12,149:INFO:_master_model_container: 11
2025-03-24 21:19:12,149:INFO:_display_container: 2
2025-03-24 21:19:12,149:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-24 21:19:12,149:INFO:create_model() successfully completed......................................
2025-03-24 21:19:12,216:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:12,216:INFO:Creating metrics dataframe
2025-03-24 21:19:12,221:INFO:Initializing Decision Tree Regressor
2025-03-24 21:19:12,222:INFO:Total runtime is 0.17278945446014404 minutes
2025-03-24 21:19:12,224:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:12,225:INFO:Initializing create_model()
2025-03-24 21:19:12,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:12,225:INFO:Checking exceptions
2025-03-24 21:19:12,225:INFO:Importing libraries
2025-03-24 21:19:12,225:INFO:Copying training dataset
2025-03-24 21:19:12,231:INFO:Defining folds
2025-03-24 21:19:12,231:INFO:Declaring metric variables
2025-03-24 21:19:12,233:INFO:Importing untrained model
2025-03-24 21:19:12,235:INFO:Decision Tree Regressor Imported successfully
2025-03-24 21:19:12,239:INFO:Starting cross validation
2025-03-24 21:19:12,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:12,549:INFO:Calculating mean and std
2025-03-24 21:19:12,550:INFO:Creating metrics dataframe
2025-03-24 21:19:12,550:INFO:Uploading results into container
2025-03-24 21:19:12,552:INFO:Uploading model into container now
2025-03-24 21:19:12,552:INFO:_master_model_container: 12
2025-03-24 21:19:12,552:INFO:_display_container: 2
2025-03-24 21:19:12,552:INFO:DecisionTreeRegressor(random_state=1741)
2025-03-24 21:19:12,552:INFO:create_model() successfully completed......................................
2025-03-24 21:19:12,618:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:12,618:INFO:Creating metrics dataframe
2025-03-24 21:19:12,623:INFO:Initializing Random Forest Regressor
2025-03-24 21:19:12,623:INFO:Total runtime is 0.1794646700223287 minutes
2025-03-24 21:19:12,625:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:12,626:INFO:Initializing create_model()
2025-03-24 21:19:12,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:12,626:INFO:Checking exceptions
2025-03-24 21:19:12,626:INFO:Importing libraries
2025-03-24 21:19:12,626:INFO:Copying training dataset
2025-03-24 21:19:12,632:INFO:Defining folds
2025-03-24 21:19:12,632:INFO:Declaring metric variables
2025-03-24 21:19:12,633:INFO:Importing untrained model
2025-03-24 21:19:12,635:INFO:Random Forest Regressor Imported successfully
2025-03-24 21:19:12,640:INFO:Starting cross validation
2025-03-24 21:19:12,642:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:18,893:INFO:Calculating mean and std
2025-03-24 21:19:18,894:INFO:Creating metrics dataframe
2025-03-24 21:19:18,896:INFO:Uploading results into container
2025-03-24 21:19:18,896:INFO:Uploading model into container now
2025-03-24 21:19:18,896:INFO:_master_model_container: 13
2025-03-24 21:19:18,896:INFO:_display_container: 2
2025-03-24 21:19:18,897:INFO:RandomForestRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:19:18,897:INFO:create_model() successfully completed......................................
2025-03-24 21:19:18,977:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:18,977:INFO:Creating metrics dataframe
2025-03-24 21:19:18,983:INFO:Initializing Extra Trees Regressor
2025-03-24 21:19:18,983:INFO:Total runtime is 0.2854660908381144 minutes
2025-03-24 21:19:18,986:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:18,986:INFO:Initializing create_model()
2025-03-24 21:19:18,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:18,986:INFO:Checking exceptions
2025-03-24 21:19:18,986:INFO:Importing libraries
2025-03-24 21:19:18,986:INFO:Copying training dataset
2025-03-24 21:19:18,995:INFO:Defining folds
2025-03-24 21:19:18,995:INFO:Declaring metric variables
2025-03-24 21:19:18,998:INFO:Importing untrained model
2025-03-24 21:19:19,002:INFO:Extra Trees Regressor Imported successfully
2025-03-24 21:19:19,005:INFO:Starting cross validation
2025-03-24 21:19:19,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:23,176:INFO:Calculating mean and std
2025-03-24 21:19:23,177:INFO:Creating metrics dataframe
2025-03-24 21:19:23,179:INFO:Uploading results into container
2025-03-24 21:19:23,179:INFO:Uploading model into container now
2025-03-24 21:19:23,179:INFO:_master_model_container: 14
2025-03-24 21:19:23,179:INFO:_display_container: 2
2025-03-24 21:19:23,180:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:19:23,180:INFO:create_model() successfully completed......................................
2025-03-24 21:19:23,262:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:23,262:INFO:Creating metrics dataframe
2025-03-24 21:19:23,269:INFO:Initializing AdaBoost Regressor
2025-03-24 21:19:23,269:INFO:Total runtime is 0.3569036285082499 minutes
2025-03-24 21:19:23,271:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:23,272:INFO:Initializing create_model()
2025-03-24 21:19:23,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:23,272:INFO:Checking exceptions
2025-03-24 21:19:23,272:INFO:Importing libraries
2025-03-24 21:19:23,272:INFO:Copying training dataset
2025-03-24 21:19:23,282:INFO:Defining folds
2025-03-24 21:19:23,282:INFO:Declaring metric variables
2025-03-24 21:19:23,285:INFO:Importing untrained model
2025-03-24 21:19:23,287:INFO:AdaBoost Regressor Imported successfully
2025-03-24 21:19:23,291:INFO:Starting cross validation
2025-03-24 21:19:23,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:24,385:INFO:Calculating mean and std
2025-03-24 21:19:24,386:INFO:Creating metrics dataframe
2025-03-24 21:19:24,387:INFO:Uploading results into container
2025-03-24 21:19:24,388:INFO:Uploading model into container now
2025-03-24 21:19:24,388:INFO:_master_model_container: 15
2025-03-24 21:19:24,388:INFO:_display_container: 2
2025-03-24 21:19:24,388:INFO:AdaBoostRegressor(random_state=1741)
2025-03-24 21:19:24,388:INFO:create_model() successfully completed......................................
2025-03-24 21:19:24,468:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:24,468:INFO:Creating metrics dataframe
2025-03-24 21:19:24,477:INFO:Initializing Gradient Boosting Regressor
2025-03-24 21:19:24,477:INFO:Total runtime is 0.37704548438390095 minutes
2025-03-24 21:19:24,480:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:24,482:INFO:Initializing create_model()
2025-03-24 21:19:24,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:24,482:INFO:Checking exceptions
2025-03-24 21:19:24,482:INFO:Importing libraries
2025-03-24 21:19:24,482:INFO:Copying training dataset
2025-03-24 21:19:24,494:INFO:Defining folds
2025-03-24 21:19:24,495:INFO:Declaring metric variables
2025-03-24 21:19:24,504:INFO:Importing untrained model
2025-03-24 21:19:24,508:INFO:Gradient Boosting Regressor Imported successfully
2025-03-24 21:19:24,518:INFO:Starting cross validation
2025-03-24 21:19:24,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:26,632:INFO:Calculating mean and std
2025-03-24 21:19:26,633:INFO:Creating metrics dataframe
2025-03-24 21:19:26,634:INFO:Uploading results into container
2025-03-24 21:19:26,634:INFO:Uploading model into container now
2025-03-24 21:19:26,635:INFO:_master_model_container: 16
2025-03-24 21:19:26,635:INFO:_display_container: 2
2025-03-24 21:19:26,635:INFO:GradientBoostingRegressor(random_state=1741)
2025-03-24 21:19:26,635:INFO:create_model() successfully completed......................................
2025-03-24 21:19:26,700:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:26,700:INFO:Creating metrics dataframe
2025-03-24 21:19:26,705:INFO:Initializing Light Gradient Boosting Machine
2025-03-24 21:19:26,705:INFO:Total runtime is 0.41417887608210247 minutes
2025-03-24 21:19:26,707:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:26,708:INFO:Initializing create_model()
2025-03-24 21:19:26,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:26,708:INFO:Checking exceptions
2025-03-24 21:19:26,708:INFO:Importing libraries
2025-03-24 21:19:26,708:INFO:Copying training dataset
2025-03-24 21:19:26,714:INFO:Defining folds
2025-03-24 21:19:26,715:INFO:Declaring metric variables
2025-03-24 21:19:26,717:INFO:Importing untrained model
2025-03-24 21:19:26,719:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:19:26,722:INFO:Starting cross validation
2025-03-24 21:19:26,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:27,529:INFO:Calculating mean and std
2025-03-24 21:19:27,530:INFO:Creating metrics dataframe
2025-03-24 21:19:27,532:INFO:Uploading results into container
2025-03-24 21:19:27,532:INFO:Uploading model into container now
2025-03-24 21:19:27,533:INFO:_master_model_container: 17
2025-03-24 21:19:27,533:INFO:_display_container: 2
2025-03-24 21:19:27,533:INFO:LGBMRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:19:27,533:INFO:create_model() successfully completed......................................
2025-03-24 21:19:27,619:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:27,619:INFO:Creating metrics dataframe
2025-03-24 21:19:27,626:INFO:Initializing Dummy Regressor
2025-03-24 21:19:27,626:INFO:Total runtime is 0.42952747742335 minutes
2025-03-24 21:19:27,628:INFO:SubProcess create_model() called ==================================
2025-03-24 21:19:27,628:INFO:Initializing create_model()
2025-03-24 21:19:27,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C956871F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:27,628:INFO:Checking exceptions
2025-03-24 21:19:27,628:INFO:Importing libraries
2025-03-24 21:19:27,628:INFO:Copying training dataset
2025-03-24 21:19:27,635:INFO:Defining folds
2025-03-24 21:19:27,635:INFO:Declaring metric variables
2025-03-24 21:19:27,638:INFO:Importing untrained model
2025-03-24 21:19:27,640:INFO:Dummy Regressor Imported successfully
2025-03-24 21:19:27,645:INFO:Starting cross validation
2025-03-24 21:19:27,646:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:19:27,837:INFO:Calculating mean and std
2025-03-24 21:19:27,838:INFO:Creating metrics dataframe
2025-03-24 21:19:27,839:INFO:Uploading results into container
2025-03-24 21:19:27,839:INFO:Uploading model into container now
2025-03-24 21:19:27,840:INFO:_master_model_container: 18
2025-03-24 21:19:27,840:INFO:_display_container: 2
2025-03-24 21:19:27,840:INFO:DummyRegressor()
2025-03-24 21:19:27,840:INFO:create_model() successfully completed......................................
2025-03-24 21:19:27,905:INFO:SubProcess create_model() end ==================================
2025-03-24 21:19:27,905:INFO:Creating metrics dataframe
2025-03-24 21:19:27,911:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-24 21:19:27,916:INFO:Initializing create_model()
2025-03-24 21:19:27,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:19:27,916:INFO:Checking exceptions
2025-03-24 21:19:27,917:INFO:Importing libraries
2025-03-24 21:19:27,917:INFO:Copying training dataset
2025-03-24 21:19:27,924:INFO:Defining folds
2025-03-24 21:19:27,924:INFO:Declaring metric variables
2025-03-24 21:19:27,924:INFO:Importing untrained model
2025-03-24 21:19:27,924:INFO:Declaring custom model
2025-03-24 21:19:27,924:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:19:27,926:INFO:Cross validation set to False
2025-03-24 21:19:27,926:INFO:Fitting Model
2025-03-24 21:19:28,005:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:19:28,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000591 seconds.
2025-03-24 21:19:28,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:19:28,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:19:28,006:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:19:28,007:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-24 21:19:28,007:INFO:[LightGBM] [Info] Start training from score 3253.240353
2025-03-24 21:19:28,049:INFO:LGBMRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:19:28,049:INFO:create_model() successfully completed......................................
2025-03-24 21:19:28,144:INFO:_master_model_container: 18
2025-03-24 21:19:28,144:INFO:_display_container: 2
2025-03-24 21:19:28,144:INFO:LGBMRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:19:28,144:INFO:compare_models() successfully completed......................................
2025-03-24 21:20:16,413:INFO:Initializing evaluate_model()
2025-03-24 21:20:16,413:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:20:16,424:INFO:Initializing plot_model()
2025-03-24 21:20:16,424:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:16,425:INFO:Checking exceptions
2025-03-24 21:20:16,428:INFO:Preloading libraries
2025-03-24 21:20:16,431:INFO:Copying training dataset
2025-03-24 21:20:16,431:INFO:Plot type: pipeline
2025-03-24 21:20:16,517:INFO:Visual Rendered Successfully
2025-03-24 21:20:16,585:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:23,982:INFO:Initializing plot_model()
2025-03-24 21:20:23,982:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:23,982:INFO:Checking exceptions
2025-03-24 21:20:23,986:INFO:Preloading libraries
2025-03-24 21:20:23,988:INFO:Copying training dataset
2025-03-24 21:20:23,988:INFO:Plot type: parameter
2025-03-24 21:20:23,991:INFO:Visual Rendered Successfully
2025-03-24 21:20:24,064:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:24,707:INFO:Initializing plot_model()
2025-03-24 21:20:24,707:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:24,707:INFO:Checking exceptions
2025-03-24 21:20:24,712:INFO:Preloading libraries
2025-03-24 21:20:24,715:INFO:Copying training dataset
2025-03-24 21:20:24,715:INFO:Plot type: residuals
2025-03-24 21:20:24,966:INFO:Fitting Model
2025-03-24 21:20:25,024:INFO:Scoring test/hold-out set
2025-03-24 21:20:25,448:INFO:Visual Rendered Successfully
2025-03-24 21:20:25,525:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:25,558:INFO:Initializing plot_model()
2025-03-24 21:20:25,558:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:25,558:INFO:Checking exceptions
2025-03-24 21:20:25,563:INFO:Preloading libraries
2025-03-24 21:20:25,578:INFO:Copying training dataset
2025-03-24 21:20:25,578:INFO:Plot type: parameter
2025-03-24 21:20:25,582:INFO:Visual Rendered Successfully
2025-03-24 21:20:25,664:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:25,789:INFO:Initializing plot_model()
2025-03-24 21:20:25,789:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:25,789:INFO:Checking exceptions
2025-03-24 21:20:25,793:INFO:Preloading libraries
2025-03-24 21:20:25,795:INFO:Copying training dataset
2025-03-24 21:20:25,795:INFO:Plot type: pipeline
2025-03-24 21:20:25,873:INFO:Visual Rendered Successfully
2025-03-24 21:20:25,944:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:31,735:INFO:Initializing plot_model()
2025-03-24 21:20:31,735:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:31,735:INFO:Checking exceptions
2025-03-24 21:20:31,738:INFO:Preloading libraries
2025-03-24 21:20:31,740:INFO:Copying training dataset
2025-03-24 21:20:31,741:INFO:Plot type: parameter
2025-03-24 21:20:31,744:INFO:Visual Rendered Successfully
2025-03-24 21:20:31,814:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:33,835:INFO:Initializing plot_model()
2025-03-24 21:20:33,836:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:33,836:INFO:Checking exceptions
2025-03-24 21:20:33,839:INFO:Preloading libraries
2025-03-24 21:20:33,841:INFO:Copying training dataset
2025-03-24 21:20:33,841:INFO:Plot type: residuals
2025-03-24 21:20:34,075:INFO:Fitting Model
2025-03-24 21:20:34,125:INFO:Scoring test/hold-out set
2025-03-24 21:20:34,466:INFO:Visual Rendered Successfully
2025-03-24 21:20:34,548:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:34,667:INFO:Initializing plot_model()
2025-03-24 21:20:34,667:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:34,667:INFO:Checking exceptions
2025-03-24 21:20:34,671:INFO:Preloading libraries
2025-03-24 21:20:34,673:INFO:Copying training dataset
2025-03-24 21:20:34,674:INFO:Plot type: error
2025-03-24 21:20:34,898:INFO:Fitting Model
2025-03-24 21:20:34,898:INFO:Scoring test/hold-out set
2025-03-24 21:20:35,108:INFO:Visual Rendered Successfully
2025-03-24 21:20:35,171:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:35,776:INFO:Initializing plot_model()
2025-03-24 21:20:35,777:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:35,777:INFO:Checking exceptions
2025-03-24 21:20:35,782:INFO:Preloading libraries
2025-03-24 21:20:35,787:INFO:Copying training dataset
2025-03-24 21:20:35,787:INFO:Plot type: cooks
2025-03-24 21:20:36,007:INFO:Fitting Model
2025-03-24 21:20:41,141:INFO:Initializing plot_model()
2025-03-24 21:20:41,141:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:41,142:INFO:Checking exceptions
2025-03-24 21:20:41,146:INFO:Preloading libraries
2025-03-24 21:20:41,148:INFO:Copying training dataset
2025-03-24 21:20:41,148:INFO:Plot type: rfe
2025-03-24 21:20:41,371:INFO:Fitting Model
2025-03-24 21:20:41,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000616 seconds.
2025-03-24 21:20:41,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,393:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,393:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,393:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.
2025-03-24 21:20:41,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,474:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,474:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,474:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,550:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.
2025-03-24 21:20:41,550:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,550:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,550:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,550:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,550:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,623:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.
2025-03-24 21:20:41,623:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,623:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,623:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,623:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,623:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.
2025-03-24 21:20:41,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,676:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,677:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,677:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,731:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-03-24 21:20:41,731:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,731:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,731:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,731:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,731:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2025-03-24 21:20:41,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,782:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,782:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,782:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.
2025-03-24 21:20:41,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,832:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,832:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,834:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,886:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-24 21:20:41,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,886:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,886:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,886:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.
2025-03-24 21:20:41,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,940:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,940:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,940:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:41,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-03-24 21:20:41,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:41,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:41,994:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:41,994:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:41,994:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.
2025-03-24 21:20:42,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,048:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:42,049:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,049:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,101:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-24 21:20:42,101:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,101:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,101:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:42,101:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,101:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-24 21:20:42,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,155:INFO:[LightGBM] [Info] Total Bins 553
2025-03-24 21:20:42,155:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-24 21:20:42,155:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-24 21:20:42,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,204:INFO:[LightGBM] [Info] Total Bins 551
2025-03-24 21:20:42,204:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-24 21:20:42,204:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-24 21:20:42,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,251:INFO:[LightGBM] [Info] Total Bins 549
2025-03-24 21:20:42,251:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-24 21:20:42,251:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,299:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-03-24 21:20:42,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,299:INFO:[LightGBM] [Info] Total Bins 547
2025-03-24 21:20:42,300:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-24 21:20:42,300:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-03-24 21:20:42,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,347:INFO:[LightGBM] [Info] Total Bins 545
2025-03-24 21:20:42,347:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-24 21:20:42,347:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,391:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-24 21:20:42,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,393:INFO:[LightGBM] [Info] Total Bins 543
2025-03-24 21:20:42,393:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-24 21:20:42,393:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-24 21:20:42,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,439:INFO:[LightGBM] [Info] Total Bins 541
2025-03-24 21:20:42,439:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-24 21:20:42,440:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-24 21:20:42,484:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,485:INFO:[LightGBM] [Info] Total Bins 539
2025-03-24 21:20:42,485:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-24 21:20:42,485:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-24 21:20:42,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,531:INFO:[LightGBM] [Info] Total Bins 537
2025-03-24 21:20:42,531:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-24 21:20:42,532:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,576:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.
2025-03-24 21:20:42,576:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,576:INFO:[LightGBM] [Info] Total Bins 535
2025-03-24 21:20:42,576:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-24 21:20:42,576:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000270 seconds.
2025-03-24 21:20:42,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,626:INFO:[LightGBM] [Info] Total Bins 533
2025-03-24 21:20:42,626:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-24 21:20:42,627:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,669:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.
2025-03-24 21:20:42,669:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,669:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,669:INFO:[LightGBM] [Info] Total Bins 531
2025-03-24 21:20:42,670:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-24 21:20:42,670:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,716:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.
2025-03-24 21:20:42,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,716:INFO:[LightGBM] [Info] Total Bins 488
2025-03-24 21:20:42,716:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-24 21:20:42,716:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.
2025-03-24 21:20:42,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,756:INFO:[LightGBM] [Info] Total Bins 255
2025-03-24 21:20:42,756:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 1
2025-03-24 21:20:42,756:INFO:[LightGBM] [Info] Start training from score 3253.658708
2025-03-24 21:20:42,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.
2025-03-24 21:20:42,813:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,813:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,813:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:42,813:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,813:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:42,865:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.
2025-03-24 21:20:42,865:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,865:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,865:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:42,865:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,866:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:42,917:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.
2025-03-24 21:20:42,917:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,917:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,918:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:42,918:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,918:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:42,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-03-24 21:20:42,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:42,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:42,981:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:42,981:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:42,981:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,036:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.
2025-03-24 21:20:43,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,037:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,037:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,037:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,090:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-24 21:20:43,090:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,090:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,090:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,090:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,090:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.
2025-03-24 21:20:43,144:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,144:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,144:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,144:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,197:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.
2025-03-24 21:20:43,197:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,197:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,197:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,197:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,197:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.
2025-03-24 21:20:43,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,250:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,250:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,250:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.
2025-03-24 21:20:43,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,301:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,301:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,301:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,353:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000541 seconds.
2025-03-24 21:20:43,353:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,353:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,353:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,353:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,353:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,403:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.
2025-03-24 21:20:43,403:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,403:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,403:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,403:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,403:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.
2025-03-24 21:20:43,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,454:INFO:[LightGBM] [Info] Total Bins 556
2025-03-24 21:20:43,454:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-24 21:20:43,454:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.
2025-03-24 21:20:43,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,505:INFO:[LightGBM] [Info] Total Bins 547
2025-03-24 21:20:43,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-24 21:20:43,505:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,556:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-24 21:20:43,556:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,556:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,557:INFO:[LightGBM] [Info] Total Bins 545
2025-03-24 21:20:43,557:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-24 21:20:43,557:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.
2025-03-24 21:20:43,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,610:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,610:INFO:[LightGBM] [Info] Total Bins 543
2025-03-24 21:20:43,610:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-24 21:20:43,610:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-24 21:20:43,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,664:INFO:[LightGBM] [Info] Total Bins 541
2025-03-24 21:20:43,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-24 21:20:43,664:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-24 21:20:43,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,714:INFO:[LightGBM] [Info] Total Bins 539
2025-03-24 21:20:43,714:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-24 21:20:43,714:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-03-24 21:20:43,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,760:INFO:[LightGBM] [Info] Total Bins 537
2025-03-24 21:20:43,760:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-24 21:20:43,760:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,810:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-24 21:20:43,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,810:INFO:[LightGBM] [Info] Total Bins 535
2025-03-24 21:20:43,810:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-24 21:20:43,810:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,859:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-24 21:20:43,859:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,859:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,859:INFO:[LightGBM] [Info] Total Bins 533
2025-03-24 21:20:43,859:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-24 21:20:43,859:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,907:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.
2025-03-24 21:20:43,907:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,907:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,907:INFO:[LightGBM] [Info] Total Bins 531
2025-03-24 21:20:43,907:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-24 21:20:43,907:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.
2025-03-24 21:20:43,954:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,954:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,954:INFO:[LightGBM] [Info] Total Bins 529
2025-03-24 21:20:43,954:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-24 21:20:43,954:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:43,999:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.
2025-03-24 21:20:43,999:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:43,999:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:43,999:INFO:[LightGBM] [Info] Total Bins 527
2025-03-24 21:20:43,999:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-24 21:20:44,000:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:44,045:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.
2025-03-24 21:20:44,045:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,045:INFO:[LightGBM] [Info] Total Bins 525
2025-03-24 21:20:44,045:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-24 21:20:44,045:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:44,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.
2025-03-24 21:20:44,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,089:INFO:[LightGBM] [Info] Total Bins 300
2025-03-24 21:20:44,089:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-24 21:20:44,089:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:44,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.
2025-03-24 21:20:44,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,131:INFO:[LightGBM] [Info] Total Bins 255
2025-03-24 21:20:44,131:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 1
2025-03-24 21:20:44,131:INFO:[LightGBM] [Info] Start training from score 3252.216287
2025-03-24 21:20:44,185:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-24 21:20:44,185:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,185:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,185:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,185:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,185:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.
2025-03-24 21:20:44,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,240:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,240:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,240:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.
2025-03-24 21:20:44,298:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,298:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,298:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,298:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,298:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-24 21:20:44,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,351:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,351:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,351:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,404:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-03-24 21:20:44,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,405:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,405:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,405:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,463:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000971 seconds.
2025-03-24 21:20:44,463:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,463:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,463:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,463:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,463:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,516:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000578 seconds.
2025-03-24 21:20:44,516:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,516:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,516:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,516:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,517:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,577:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000681 seconds.
2025-03-24 21:20:44,577:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,577:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,577:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,577:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,578:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-03-24 21:20:44,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,645:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,645:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,645:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.
2025-03-24 21:20:44,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,708:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,708:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,708:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,765:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-03-24 21:20:44,765:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,765:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,765:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,765:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,765:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,818:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.
2025-03-24 21:20:44,818:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,818:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,818:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,818:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,818:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-03-24 21:20:44,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,873:INFO:[LightGBM] [Info] Total Bins 561
2025-03-24 21:20:44,873:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:44,873:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-24 21:20:44,926:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,926:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,927:INFO:[LightGBM] [Info] Total Bins 552
2025-03-24 21:20:44,927:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-24 21:20:44,927:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:44,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-24 21:20:44,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:44,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:44,979:INFO:[LightGBM] [Info] Total Bins 550
2025-03-24 21:20:44,979:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-24 21:20:44,979:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-24 21:20:45,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,033:INFO:[LightGBM] [Info] Total Bins 548
2025-03-24 21:20:45,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-24 21:20:45,033:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,081:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-24 21:20:45,081:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,081:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,083:INFO:[LightGBM] [Info] Total Bins 546
2025-03-24 21:20:45,083:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-24 21:20:45,083:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-24 21:20:45,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,131:INFO:[LightGBM] [Info] Total Bins 544
2025-03-24 21:20:45,131:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-24 21:20:45,131:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,180:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000555 seconds.
2025-03-24 21:20:45,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,180:INFO:[LightGBM] [Info] Total Bins 542
2025-03-24 21:20:45,180:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-24 21:20:45,180:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,230:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.
2025-03-24 21:20:45,230:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,230:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,230:INFO:[LightGBM] [Info] Total Bins 540
2025-03-24 21:20:45,230:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-24 21:20:45,230:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,279:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000977 seconds.
2025-03-24 21:20:45,279:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,279:INFO:[LightGBM] [Info] Total Bins 538
2025-03-24 21:20:45,279:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-24 21:20:45,279:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,327:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-24 21:20:45,327:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,327:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,327:INFO:[LightGBM] [Info] Total Bins 536
2025-03-24 21:20:45,327:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-24 21:20:45,327:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-24 21:20:45,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,377:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,377:INFO:[LightGBM] [Info] Total Bins 534
2025-03-24 21:20:45,377:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-24 21:20:45,377:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,423:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.
2025-03-24 21:20:45,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,424:INFO:[LightGBM] [Info] Total Bins 532
2025-03-24 21:20:45,424:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-24 21:20:45,424:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,468:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.
2025-03-24 21:20:45,468:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,468:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,468:INFO:[LightGBM] [Info] Total Bins 530
2025-03-24 21:20:45,468:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-24 21:20:45,469:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000061 seconds.
2025-03-24 21:20:45,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,513:INFO:[LightGBM] [Info] Total Bins 301
2025-03-24 21:20:45,513:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-24 21:20:45,513:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,556:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.
2025-03-24 21:20:45,556:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,556:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,556:INFO:[LightGBM] [Info] Total Bins 255
2025-03-24 21:20:45,556:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-24 21:20:45,556:INFO:[LightGBM] [Info] Start training from score 3252.503392
2025-03-24 21:20:45,609:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-03-24 21:20:45,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,609:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,609:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,609:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,661:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000597 seconds.
2025-03-24 21:20:45,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,661:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,661:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,661:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000746 seconds.
2025-03-24 21:20:45,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,729:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,729:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,729:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,781:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.
2025-03-24 21:20:45,781:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,781:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,781:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,781:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,781:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-24 21:20:45,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,832:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,832:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,833:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-03-24 21:20:45,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,883:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,883:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-03-24 21:20:45,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,933:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,933:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,933:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:45,984:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.
2025-03-24 21:20:45,984:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:45,984:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:45,984:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:45,984:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:45,984:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,037:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-03-24 21:20:46,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,037:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:46,037:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,037:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-03-24 21:20:46,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,089:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:46,089:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,089:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-03-24 21:20:46,143:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,143:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,143:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:46,143:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,143:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-24 21:20:46,194:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,194:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,194:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:46,195:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,195:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,244:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.
2025-03-24 21:20:46,245:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,245:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,245:INFO:[LightGBM] [Info] Total Bins 558
2025-03-24 21:20:46,245:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,245:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.
2025-03-24 21:20:46,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,295:INFO:[LightGBM] [Info] Total Bins 550
2025-03-24 21:20:46,295:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-24 21:20:46,295:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.
2025-03-24 21:20:46,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,346:INFO:[LightGBM] [Info] Total Bins 548
2025-03-24 21:20:46,346:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-24 21:20:46,346:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,396:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-24 21:20:46,396:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,396:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,396:INFO:[LightGBM] [Info] Total Bins 546
2025-03-24 21:20:46,396:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-24 21:20:46,397:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.
2025-03-24 21:20:46,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,447:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,447:INFO:[LightGBM] [Info] Total Bins 544
2025-03-24 21:20:46,447:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-24 21:20:46,447:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-24 21:20:46,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,497:INFO:[LightGBM] [Info] Total Bins 542
2025-03-24 21:20:46,497:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-24 21:20:46,497:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,546:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-03-24 21:20:46,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,546:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,546:INFO:[LightGBM] [Info] Total Bins 540
2025-03-24 21:20:46,546:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-24 21:20:46,546:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000740 seconds.
2025-03-24 21:20:46,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,596:INFO:[LightGBM] [Info] Total Bins 538
2025-03-24 21:20:46,596:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-24 21:20:46,596:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.
2025-03-24 21:20:46,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,644:INFO:[LightGBM] [Info] Total Bins 536
2025-03-24 21:20:46,644:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-24 21:20:46,644:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.
2025-03-24 21:20:46,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-24 21:20:46,711:INFO:[LightGBM] [Info] Total Bins 534
2025-03-24 21:20:46,711:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-24 21:20:46,711:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.
2025-03-24 21:20:46,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,766:INFO:[LightGBM] [Info] Total Bins 532
2025-03-24 21:20:46,766:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-24 21:20:46,766:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.
2025-03-24 21:20:46,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,814:INFO:[LightGBM] [Info] Total Bins 530
2025-03-24 21:20:46,814:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-24 21:20:46,814:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.
2025-03-24 21:20:46,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,858:INFO:[LightGBM] [Info] Total Bins 528
2025-03-24 21:20:46,858:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-24 21:20:46,859:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.
2025-03-24 21:20:46,899:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,899:INFO:[LightGBM] [Info] Total Bins 301
2025-03-24 21:20:46,899:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-24 21:20:46,899:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000034 seconds.
2025-03-24 21:20:46,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,939:INFO:[LightGBM] [Info] Total Bins 255
2025-03-24 21:20:46,939:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-24 21:20:46,939:INFO:[LightGBM] [Info] Start training from score 3253.385933
2025-03-24 21:20:46,991:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.
2025-03-24 21:20:46,991:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:46,991:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:46,991:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:46,993:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:46,993:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.
2025-03-24 21:20:47,049:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,049:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,049:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,049:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,049:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.
2025-03-24 21:20:47,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,104:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,104:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,104:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,156:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-03-24 21:20:47,156:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,156:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,156:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,156:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,156:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.
2025-03-24 21:20:47,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,207:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,207:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,207:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,266:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2025-03-24 21:20:47,266:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,266:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,266:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,266:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,266:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.
2025-03-24 21:20:47,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,319:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,319:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,319:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,319:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,375:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.
2025-03-24 21:20:47,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,375:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,375:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,375:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,433:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000490 seconds.
2025-03-24 21:20:47,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,433:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,433:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,433:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,433:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-03-24 21:20:47,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,488:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,488:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,488:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,541:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-03-24 21:20:47,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,541:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,541:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,541:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000711 seconds.
2025-03-24 21:20:47,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,596:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,597:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,597:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.
2025-03-24 21:20:47,651:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,651:INFO:[LightGBM] [Info] Total Bins 560
2025-03-24 21:20:47,651:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:47,651:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.
2025-03-24 21:20:47,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,703:INFO:[LightGBM] [Info] Total Bins 552
2025-03-24 21:20:47,703:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-24 21:20:47,703:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,755:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.
2025-03-24 21:20:47,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,755:INFO:[LightGBM] [Info] Total Bins 550
2025-03-24 21:20:47,755:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-24 21:20:47,755:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-24 21:20:47,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,806:INFO:[LightGBM] [Info] Total Bins 548
2025-03-24 21:20:47,806:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-24 21:20:47,806:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,857:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.
2025-03-24 21:20:47,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,857:INFO:[LightGBM] [Info] Total Bins 546
2025-03-24 21:20:47,857:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-24 21:20:47,857:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.
2025-03-24 21:20:47,905:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,905:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,905:INFO:[LightGBM] [Info] Total Bins 544
2025-03-24 21:20:47,905:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-24 21:20:47,905:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:47,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-24 21:20:47,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:47,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:47,955:INFO:[LightGBM] [Info] Total Bins 542
2025-03-24 21:20:47,955:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-24 21:20:47,955:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-24 21:20:48,004:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,004:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,004:INFO:[LightGBM] [Info] Total Bins 540
2025-03-24 21:20:48,004:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-24 21:20:48,005:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-24 21:20:48,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,054:INFO:[LightGBM] [Info] Total Bins 538
2025-03-24 21:20:48,054:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-24 21:20:48,054:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-03-24 21:20:48,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,103:INFO:[LightGBM] [Info] Total Bins 536
2025-03-24 21:20:48,103:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-24 21:20:48,103:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-24 21:20:48,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,154:INFO:[LightGBM] [Info] Total Bins 534
2025-03-24 21:20:48,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-24 21:20:48,154:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.
2025-03-24 21:20:48,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,201:INFO:[LightGBM] [Info] Total Bins 532
2025-03-24 21:20:48,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-24 21:20:48,201:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.
2025-03-24 21:20:48,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,252:INFO:[LightGBM] [Info] Total Bins 530
2025-03-24 21:20:48,252:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-24 21:20:48,252:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.
2025-03-24 21:20:48,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,297:INFO:[LightGBM] [Info] Total Bins 484
2025-03-24 21:20:48,297:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-24 21:20:48,297:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,341:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.
2025-03-24 21:20:48,341:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,341:INFO:[LightGBM] [Info] Total Bins 255
2025-03-24 21:20:48,341:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-24 21:20:48,341:INFO:[LightGBM] [Info] Start training from score 3254.349809
2025-03-24 21:20:48,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.
2025-03-24 21:20:48,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,398:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:20:48,398:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:48,398:INFO:[LightGBM] [Info] Start training from score 3259.166063
2025-03-24 21:20:48,449:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-03-24 21:20:48,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,450:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,450:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:20:48,450:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:48,450:INFO:[LightGBM] [Info] Start training from score 3259.166063
2025-03-24 21:20:48,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-24 21:20:48,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,501:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:20:48,501:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:48,501:INFO:[LightGBM] [Info] Start training from score 3259.166063
2025-03-24 21:20:48,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-03-24 21:20:48,555:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,555:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,555:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:20:48,555:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:48,555:INFO:[LightGBM] [Info] Start training from score 3259.166063
2025-03-24 21:20:48,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.
2025-03-24 21:20:48,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:20:48,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:20:48,608:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:20:48,608:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-24 21:20:48,608:INFO:[LightGBM] [Info] Start training from score 3259.166063
2025-03-24 21:20:49,536:INFO:Initializing evaluate_model()
2025-03-24 21:20:49,536:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:20:49,543:INFO:Initializing plot_model()
2025-03-24 21:20:49,543:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:49,543:INFO:Checking exceptions
2025-03-24 21:20:49,546:INFO:Preloading libraries
2025-03-24 21:20:49,549:INFO:Copying training dataset
2025-03-24 21:20:49,549:INFO:Plot type: pipeline
2025-03-24 21:20:49,626:INFO:Visual Rendered Successfully
2025-03-24 21:20:49,726:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:49,733:INFO:Initializing plot_model()
2025-03-24 21:20:49,733:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:49,734:INFO:Checking exceptions
2025-03-24 21:20:49,737:INFO:Preloading libraries
2025-03-24 21:20:49,744:INFO:Copying training dataset
2025-03-24 21:20:49,744:INFO:Plot type: pipeline
2025-03-24 21:20:49,828:INFO:Visual Rendered Successfully
2025-03-24 21:20:49,922:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:53,957:INFO:Initializing evaluate_model()
2025-03-24 21:20:53,957:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:20:53,964:INFO:Initializing plot_model()
2025-03-24 21:20:53,965:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:53,965:INFO:Checking exceptions
2025-03-24 21:20:53,968:INFO:Preloading libraries
2025-03-24 21:20:53,970:INFO:Copying training dataset
2025-03-24 21:20:53,971:INFO:Plot type: pipeline
2025-03-24 21:20:54,057:INFO:Visual Rendered Successfully
2025-03-24 21:20:54,155:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:55,558:INFO:Initializing plot_model()
2025-03-24 21:20:55,558:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:55,558:INFO:Checking exceptions
2025-03-24 21:20:55,561:INFO:Preloading libraries
2025-03-24 21:20:55,564:INFO:Copying training dataset
2025-03-24 21:20:55,564:INFO:Plot type: parameter
2025-03-24 21:20:55,567:INFO:Visual Rendered Successfully
2025-03-24 21:20:55,675:INFO:plot_model() successfully completed......................................
2025-03-24 21:20:56,373:INFO:Initializing plot_model()
2025-03-24 21:20:56,373:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:20:56,374:INFO:Checking exceptions
2025-03-24 21:20:56,377:INFO:Preloading libraries
2025-03-24 21:20:56,379:INFO:Copying training dataset
2025-03-24 21:20:56,379:INFO:Plot type: vc
2025-03-24 21:20:56,380:INFO:Determining param_name
2025-03-24 21:20:56,380:INFO:param_name: max_depth
2025-03-24 21:20:56,616:INFO:Fitting Model
2025-03-24 21:21:02,051:INFO:Visual Rendered Successfully
2025-03-24 21:21:02,152:INFO:plot_model() successfully completed......................................
2025-03-24 21:21:02,157:INFO:Initializing evaluate_model()
2025-03-24 21:21:02,157:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:21:02,166:INFO:Initializing plot_model()
2025-03-24 21:21:02,166:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:21:02,166:INFO:Checking exceptions
2025-03-24 21:21:02,169:INFO:Preloading libraries
2025-03-24 21:21:02,173:INFO:Copying training dataset
2025-03-24 21:21:02,173:INFO:Plot type: pipeline
2025-03-24 21:21:02,251:INFO:Visual Rendered Successfully
2025-03-24 21:21:02,348:INFO:plot_model() successfully completed......................................
2025-03-24 21:21:04,939:INFO:Initializing plot_model()
2025-03-24 21:21:04,940:INFO:plot_model(plot=manifold, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:21:04,940:INFO:Checking exceptions
2025-03-24 21:21:04,943:INFO:Preloading libraries
2025-03-24 21:21:04,945:INFO:Copying training dataset
2025-03-24 21:21:04,945:INFO:Plot type: manifold
2025-03-24 21:21:05,187:INFO:Fitting & Transforming Model
2025-03-24 21:21:05,195:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] The system cannot find the file specified
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-03-24 21:21:05,196:WARNING:  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\joblib\externals\loky\backend\context.py", line 257, in _count_physical_cores
2025-03-24 21:21:05,196:WARNING:    cpu_info = subprocess.run(
2025-03-24 21:21:05,196:WARNING:  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\subprocess.py", line 503, in run
2025-03-24 21:21:05,196:WARNING:    with Popen(*popenargs, **kwargs) as process:
2025-03-24 21:21:05,196:WARNING:  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\subprocess.py", line 971, in __init__
2025-03-24 21:21:05,196:WARNING:    self._execute_child(args, executable, preexec_fn, close_fds,
2025-03-24 21:21:05,196:WARNING:  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\subprocess.py", line 1456, in _execute_child
2025-03-24 21:21:05,196:WARNING:    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
2025-03-24 21:21:39,369:INFO:Initializing evaluate_model()
2025-03-24 21:21:39,369:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:21:39,377:INFO:Initializing plot_model()
2025-03-24 21:21:39,377:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:21:39,377:INFO:Checking exceptions
2025-03-24 21:21:39,380:INFO:Preloading libraries
2025-03-24 21:21:39,383:INFO:Copying training dataset
2025-03-24 21:21:39,383:INFO:Plot type: pipeline
2025-03-24 21:21:39,459:INFO:Visual Rendered Successfully
2025-03-24 21:21:39,561:INFO:plot_model() successfully completed......................................
2025-03-24 21:21:39,575:INFO:Initializing plot_model()
2025-03-24 21:21:39,576:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:21:39,576:INFO:Checking exceptions
2025-03-24 21:21:39,578:INFO:Preloading libraries
2025-03-24 21:21:39,581:INFO:Copying training dataset
2025-03-24 21:21:39,581:INFO:Plot type: pipeline
2025-03-24 21:21:39,667:INFO:Visual Rendered Successfully
2025-03-24 21:21:39,763:INFO:plot_model() successfully completed......................................
2025-03-24 21:21:45,464:INFO:Initializing evaluate_model()
2025-03-24 21:21:45,464:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:21:45,473:INFO:Initializing plot_model()
2025-03-24 21:21:45,473:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, system=True)
2025-03-24 21:21:45,473:INFO:Checking exceptions
2025-03-24 21:21:45,477:INFO:Preloading libraries
2025-03-24 21:21:45,479:INFO:Copying training dataset
2025-03-24 21:21:45,479:INFO:Plot type: pipeline
2025-03-24 21:21:45,566:INFO:Visual Rendered Successfully
2025-03-24 21:21:45,668:INFO:plot_model() successfully completed......................................
2025-03-24 21:21:51,436:INFO:Initializing tune_model()
2025-03-24 21:21:51,436:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>)
2025-03-24 21:21:51,436:INFO:Checking exceptions
2025-03-24 21:21:51,448:INFO:Copying training dataset
2025-03-24 21:21:51,453:INFO:Checking base model
2025-03-24 21:21:51,453:INFO:Base model : Light Gradient Boosting Machine
2025-03-24 21:21:51,456:INFO:Declaring metric variables
2025-03-24 21:21:51,458:INFO:Defining Hyperparameters
2025-03-24 21:21:51,564:INFO:Tuning with n_jobs=-1
2025-03-24 21:21:51,564:INFO:Initializing RandomizedSearchCV
2025-03-24 21:22:12,945:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 60, 'actual_estimator__n_estimators': 210, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.7}
2025-03-24 21:22:12,946:INFO:Hyperparameter search completed
2025-03-24 21:22:12,946:INFO:SubProcess create_model() called ==================================
2025-03-24 21:22:12,947:INFO:Initializing create_model()
2025-03-24 21:22:12,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C95D050280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.05, 'num_leaves': 60, 'n_estimators': 210, 'min_split_gain': 0.5, 'min_child_samples': 6, 'learning_rate': 0.05, 'feature_fraction': 0.6, 'bagging_freq': 5, 'bagging_fraction': 0.7})
2025-03-24 21:22:12,947:INFO:Checking exceptions
2025-03-24 21:22:12,947:INFO:Importing libraries
2025-03-24 21:22:12,947:INFO:Copying training dataset
2025-03-24 21:22:12,957:INFO:Defining folds
2025-03-24 21:22:12,957:INFO:Declaring metric variables
2025-03-24 21:22:12,960:INFO:Importing untrained model
2025-03-24 21:22:12,960:INFO:Declaring custom model
2025-03-24 21:22:12,964:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:22:12,968:INFO:Starting cross validation
2025-03-24 21:22:12,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:22:15,621:INFO:Calculating mean and std
2025-03-24 21:22:15,622:INFO:Creating metrics dataframe
2025-03-24 21:22:15,626:INFO:Finalizing model
2025-03-24 21:22:15,724:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-03-24 21:22:15,724:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-03-24 21:22:15,724:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-24 21:22:15,735:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:22:15,736:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-03-24 21:22:15,736:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-03-24 21:22:15,736:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-24 21:22:15,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.
2025-03-24 21:22:15,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:22:15,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:22:15,737:INFO:[LightGBM] [Info] Total Bins 568
2025-03-24 21:22:15,737:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 16
2025-03-24 21:22:15,738:INFO:[LightGBM] [Info] Start training from score 3253.240353
2025-03-24 21:22:15,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:15,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:15,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:15,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:15,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:15,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-24 21:22:16,050:INFO:Uploading results into container
2025-03-24 21:22:16,051:INFO:Uploading model into container now
2025-03-24 21:22:16,052:INFO:_master_model_container: 19
2025-03-24 21:22:16,052:INFO:_display_container: 3
2025-03-24 21:22:16,052:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, feature_fraction=0.6,
              learning_rate=0.05, min_child_samples=6, min_split_gain=0.5,
              n_estimators=210, n_jobs=-1, num_leaves=60, random_state=1741,
              reg_alpha=0.05, reg_lambda=0.0005)
2025-03-24 21:22:16,053:INFO:create_model() successfully completed......................................
2025-03-24 21:22:16,176:INFO:SubProcess create_model() end ==================================
2025-03-24 21:22:16,176:INFO:choose_better activated
2025-03-24 21:22:16,178:INFO:SubProcess create_model() called ==================================
2025-03-24 21:22:16,180:INFO:Initializing create_model()
2025-03-24 21:22:16,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C9555A72E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1741), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:22:16,180:INFO:Checking exceptions
2025-03-24 21:22:16,181:INFO:Importing libraries
2025-03-24 21:22:16,181:INFO:Copying training dataset
2025-03-24 21:22:16,190:INFO:Defining folds
2025-03-24 21:22:16,190:INFO:Declaring metric variables
2025-03-24 21:22:16,190:INFO:Importing untrained model
2025-03-24 21:22:16,190:INFO:Declaring custom model
2025-03-24 21:22:16,191:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:22:16,191:INFO:Starting cross validation
2025-03-24 21:22:16,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:22:17,124:INFO:Calculating mean and std
2025-03-24 21:22:17,124:INFO:Creating metrics dataframe
2025-03-24 21:22:17,126:INFO:Finalizing model
2025-03-24 21:22:17,235:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:22:17,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.
2025-03-24 21:22:17,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:22:17,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:22:17,237:INFO:[LightGBM] [Info] Total Bins 566
2025-03-24 21:22:17,237:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-24 21:22:17,237:INFO:[LightGBM] [Info] Start training from score 3253.240353
2025-03-24 21:22:17,304:INFO:Uploading results into container
2025-03-24 21:22:17,305:INFO:Uploading model into container now
2025-03-24 21:22:17,305:INFO:_master_model_container: 20
2025-03-24 21:22:17,305:INFO:_display_container: 4
2025-03-24 21:22:17,305:INFO:LGBMRegressor(n_jobs=-1, random_state=1741)
2025-03-24 21:22:17,305:INFO:create_model() successfully completed......................................
2025-03-24 21:22:17,428:INFO:SubProcess create_model() end ==================================
2025-03-24 21:22:17,429:INFO:LGBMRegressor(n_jobs=-1, random_state=1741) result for R2 is 0.2166
2025-03-24 21:22:17,430:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, feature_fraction=0.6,
              learning_rate=0.05, min_child_samples=6, min_split_gain=0.5,
              n_estimators=210, n_jobs=-1, num_leaves=60, random_state=1741,
              reg_alpha=0.05, reg_lambda=0.0005) result for R2 is 0.2198
2025-03-24 21:22:17,430:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, feature_fraction=0.6,
              learning_rate=0.05, min_child_samples=6, min_split_gain=0.5,
              n_estimators=210, n_jobs=-1, num_leaves=60, random_state=1741,
              reg_alpha=0.05, reg_lambda=0.0005) is best model
2025-03-24 21:22:17,430:INFO:choose_better completed
2025-03-24 21:22:17,437:INFO:_master_model_container: 20
2025-03-24 21:22:17,437:INFO:_display_container: 3
2025-03-24 21:22:17,437:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, feature_fraction=0.6,
              learning_rate=0.05, min_child_samples=6, min_split_gain=0.5,
              n_estimators=210, n_jobs=-1, num_leaves=60, random_state=1741,
              reg_alpha=0.05, reg_lambda=0.0005)
2025-03-24 21:22:17,437:INFO:tune_model() successfully completed......................................
2025-03-24 21:22:17,586:INFO:Initializing save_model()
2025-03-24 21:22:17,586:INFO:save_model(model=LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, feature_fraction=0.6,
              learning_rate=0.05, min_child_samples=6, min_split_gain=0.5,
              n_estimators=210, n_jobs=-1, num_leaves=60, random_state=1741,
              reg_alpha=0.05, reg_lambda=0.0005), model_name=tuned_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-24 21:22:17,586:INFO:Adding model into prep_pipe
2025-03-24 21:22:17,607:INFO:tuned_model.pkl saved in current working directory
2025-03-24 21:22:17,617:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(inclu...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model',
                 LGBMRegressor(bagging_fraction=0.7, bagging_freq=5,
                               feature_fraction=0.6, learning_rate=0.05,
                               min_child_samples=6, min_split_gain=0.5,
                               n_estimators=210, n_jobs=-1, num_leaves=60,
                               random_state=1741, reg_alpha=0.05,
                               reg_lambda=0.0005))])
2025-03-24 21:22:17,617:INFO:save_model() successfully completed......................................
2025-03-24 21:29:58,511:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:29:58,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:29:58,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:29:58,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:30:00,611:INFO:Initializing load_model()
2025-03-24 21:30:00,611:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 21:30:38,315:INFO:Initializing load_model()
2025-03-24 21:30:38,315:INFO:load_model(model_name=tuned_model, platform=None, authentication=None, verbose=True)
2025-03-24 21:30:38,385:INFO:Initializing predict_model()
2025-03-24 21:30:38,385:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BE154C0DF0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(inclu...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model',
                 LGBMRegressor(bagging_fraction=0.7, bagging_freq=5,
                               feature_fraction=0.6, learning_rate=0.05,
                               min_child_samples=6, min_split_gain=0.5,
                               n_estimators=210, n_jobs=-1, num_leaves=60,
                               random_state=1741, reg_alpha=0.05,
                               reg_lambda=0.0005))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BE158ADAB0>)
2025-03-24 21:30:38,385:INFO:Checking exceptions
2025-03-24 21:30:38,385:INFO:Preloading libraries
2025-03-24 21:30:38,386:INFO:Set up data.
2025-03-24 21:30:38,397:INFO:Set up index.
2025-03-24 21:47:55,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:47:55,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:47:55,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:47:55,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:48:37,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:48:37,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:48:37,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:48:37,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:48:37,761:INFO:PyCaret RegressionExperiment
2025-03-24 21:48:37,761:INFO:Logging name: reg-default-name
2025-03-24 21:48:37,761:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-24 21:48:37,761:INFO:version 3.3.2
2025-03-24 21:48:37,762:INFO:Initializing setup()
2025-03-24 21:48:37,762:INFO:self.USI: 71b0
2025-03-24 21:48:37,762:INFO:self._variable_keys: {'_ml_usecase', '_available_plots', 'fold_shuffle_param', 'idx', 'fold_generator', 'html_param', 'pipeline', 'exp_name_log', 'logging_param', 'gpu_n_jobs_param', 'log_plots_param', 'memory', 'X_test', 'transform_target_param', 'seed', 'USI', 'exp_id', 'X_train', 'X', 'y', 'gpu_param', 'data', 'y_train', 'y_test', 'n_jobs_param', 'target_param', 'fold_groups_param'}
2025-03-24 21:48:37,762:INFO:Checking environment
2025-03-24 21:48:37,762:INFO:python_version: 3.10.16
2025-03-24 21:48:37,762:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-24 21:48:37,762:INFO:machine: AMD64
2025-03-24 21:48:37,762:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-24 21:48:37,766:INFO:Memory: svmem(total=33411727360, available=16526667776, percent=50.5, used=16885059584, free=16526667776)
2025-03-24 21:48:37,766:INFO:Physical Core: 6
2025-03-24 21:48:37,766:INFO:Logical Core: 12
2025-03-24 21:48:37,766:INFO:Checking libraries
2025-03-24 21:48:37,766:INFO:System:
2025-03-24 21:48:37,767:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-24 21:48:37,767:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-24 21:48:37,767:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-24 21:48:37,767:INFO:PyCaret required dependencies:
2025-03-24 21:48:37,767:INFO:                 pip: 25.0.1
2025-03-24 21:48:37,767:INFO:          setuptools: 75.8.2
2025-03-24 21:48:37,768:INFO:             pycaret: 3.3.2
2025-03-24 21:48:37,768:INFO:             IPython: 8.34.0
2025-03-24 21:48:37,768:INFO:          ipywidgets: 8.1.5
2025-03-24 21:48:37,768:INFO:                tqdm: 4.67.1
2025-03-24 21:48:37,768:INFO:               numpy: 1.26.4
2025-03-24 21:48:37,768:INFO:              pandas: 2.1.4
2025-03-24 21:48:37,768:INFO:              jinja2: 3.1.6
2025-03-24 21:48:37,768:INFO:               scipy: 1.11.4
2025-03-24 21:48:37,768:INFO:              joblib: 1.3.2
2025-03-24 21:48:37,768:INFO:             sklearn: 1.4.2
2025-03-24 21:48:37,768:INFO:                pyod: 2.0.2
2025-03-24 21:48:37,768:INFO:            imblearn: 0.13.0
2025-03-24 21:48:37,768:INFO:   category_encoders: 2.7.0
2025-03-24 21:48:37,768:INFO:            lightgbm: 4.6.0
2025-03-24 21:48:37,768:INFO:               numba: 0.61.0
2025-03-24 21:48:37,768:INFO:            requests: 2.32.3
2025-03-24 21:48:37,768:INFO:          matplotlib: 3.10.1
2025-03-24 21:48:37,768:INFO:          scikitplot: 0.3.7
2025-03-24 21:48:37,768:INFO:         yellowbrick: 1.5
2025-03-24 21:48:37,768:INFO:              plotly: 6.0.1
2025-03-24 21:48:37,768:INFO:    plotly-resampler: Not installed
2025-03-24 21:48:37,768:INFO:             kaleido: 0.2.1
2025-03-24 21:48:37,768:INFO:           schemdraw: 0.15
2025-03-24 21:48:37,768:INFO:         statsmodels: 0.14.4
2025-03-24 21:48:37,768:INFO:              sktime: 0.26.0
2025-03-24 21:48:37,768:INFO:               tbats: 1.1.3
2025-03-24 21:48:37,768:INFO:            pmdarima: 2.0.4
2025-03-24 21:48:37,768:INFO:              psutil: 7.0.0
2025-03-24 21:48:37,768:INFO:          markupsafe: 3.0.2
2025-03-24 21:48:37,768:INFO:             pickle5: Not installed
2025-03-24 21:48:37,768:INFO:         cloudpickle: 3.1.1
2025-03-24 21:48:37,768:INFO:         deprecation: 2.1.0
2025-03-24 21:48:37,768:INFO:              xxhash: 3.5.0
2025-03-24 21:48:37,768:INFO:           wurlitzer: 3.1.1
2025-03-24 21:48:37,768:INFO:PyCaret optional dependencies:
2025-03-24 21:48:37,776:INFO:                shap: Not installed
2025-03-24 21:48:37,776:INFO:           interpret: Not installed
2025-03-24 21:48:37,776:INFO:                umap: 0.5.7
2025-03-24 21:48:37,776:INFO:     ydata_profiling: Not installed
2025-03-24 21:48:37,776:INFO:  explainerdashboard: Not installed
2025-03-24 21:48:37,776:INFO:             autoviz: Not installed
2025-03-24 21:48:37,776:INFO:           fairlearn: Not installed
2025-03-24 21:48:37,776:INFO:          deepchecks: Not installed
2025-03-24 21:48:37,776:INFO:             xgboost: Not installed
2025-03-24 21:48:37,776:INFO:            catboost: Not installed
2025-03-24 21:48:37,776:INFO:              kmodes: Not installed
2025-03-24 21:48:37,776:INFO:             mlxtend: Not installed
2025-03-24 21:48:37,776:INFO:       statsforecast: Not installed
2025-03-24 21:48:37,776:INFO:        tune_sklearn: Not installed
2025-03-24 21:48:37,776:INFO:                 ray: Not installed
2025-03-24 21:48:37,776:INFO:            hyperopt: Not installed
2025-03-24 21:48:37,776:INFO:              optuna: Not installed
2025-03-24 21:48:37,776:INFO:               skopt: Not installed
2025-03-24 21:48:37,777:INFO:              mlflow: Not installed
2025-03-24 21:48:37,777:INFO:              gradio: Not installed
2025-03-24 21:48:37,777:INFO:             fastapi: Not installed
2025-03-24 21:48:37,777:INFO:             uvicorn: Not installed
2025-03-24 21:48:37,777:INFO:              m2cgen: Not installed
2025-03-24 21:48:37,777:INFO:           evidently: Not installed
2025-03-24 21:48:37,777:INFO:               fugue: Not installed
2025-03-24 21:48:37,777:INFO:           streamlit: 1.43.2
2025-03-24 21:48:37,777:INFO:             prophet: Not installed
2025-03-24 21:48:37,777:INFO:None
2025-03-24 21:48:37,777:INFO:Set up data.
2025-03-24 21:48:37,787:INFO:Set up folding strategy.
2025-03-24 21:48:37,787:INFO:Set up train/test split.
2025-03-24 21:48:37,793:INFO:Set up index.
2025-03-24 21:48:37,794:INFO:Assigning column types.
2025-03-24 21:48:37,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-24 21:48:37,800:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,802:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,804:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:37,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:37,912:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,915:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,918:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,952:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,977:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:37,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:37,978:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-24 21:48:37,981:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:48:37,983:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,019:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,046:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,109:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-24 21:48:38,114:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,178:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,237:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,238:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-24 21:48:38,276:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,340:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,364:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,365:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,365:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-24 21:48:38,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,471:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-24 21:48:38,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,496:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-24 21:48:38,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:38,624:INFO:Preparing preprocessing pipeline...
2025-03-24 21:48:38,624:INFO:Set up simple imputation.
2025-03-24 21:48:38,627:INFO:Set up encoding of categorical features.
2025-03-24 21:48:38,628:INFO:Set up column name cleaning.
2025-03-24 21:48:38,737:INFO:Finished creating preprocessing pipeline.
2025-03-24 21:48:38,741:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-24 21:48:38,741:INFO:Creating final display dataframe.
2025-03-24 21:48:38,959:INFO:Setup _display_container:                     Description             Value
0                    Session id              5755
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              71b0
2025-03-24 21:48:39,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:39,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:39,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:39,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-24 21:48:39,096:INFO:setup() successfully completed in 1.34s...............
2025-03-24 21:48:39,105:INFO:Initializing compare_models()
2025-03-24 21:48:39,105:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-24 21:48:39,106:INFO:Checking exceptions
2025-03-24 21:48:39,109:INFO:Preparing display monitor
2025-03-24 21:48:39,123:INFO:Initializing Linear Regression
2025-03-24 21:48:39,123:INFO:Total runtime is 0.0 minutes
2025-03-24 21:48:39,125:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:39,126:INFO:Initializing create_model()
2025-03-24 21:48:39,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:39,126:INFO:Checking exceptions
2025-03-24 21:48:39,126:INFO:Importing libraries
2025-03-24 21:48:39,126:INFO:Copying training dataset
2025-03-24 21:48:39,133:INFO:Defining folds
2025-03-24 21:48:39,133:INFO:Declaring metric variables
2025-03-24 21:48:39,135:INFO:Importing untrained model
2025-03-24 21:48:39,137:INFO:Linear Regression Imported successfully
2025-03-24 21:48:39,141:INFO:Starting cross validation
2025-03-24 21:48:39,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:42,143:INFO:Calculating mean and std
2025-03-24 21:48:42,144:INFO:Creating metrics dataframe
2025-03-24 21:48:42,146:INFO:Uploading results into container
2025-03-24 21:48:42,147:INFO:Uploading model into container now
2025-03-24 21:48:42,148:INFO:_master_model_container: 1
2025-03-24 21:48:42,148:INFO:_display_container: 2
2025-03-24 21:48:42,148:INFO:LinearRegression(n_jobs=-1)
2025-03-24 21:48:42,148:INFO:create_model() successfully completed......................................
2025-03-24 21:48:42,235:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:42,235:INFO:Creating metrics dataframe
2025-03-24 21:48:42,240:INFO:Initializing Lasso Regression
2025-03-24 21:48:42,240:INFO:Total runtime is 0.051948734124501544 minutes
2025-03-24 21:48:42,242:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:42,242:INFO:Initializing create_model()
2025-03-24 21:48:42,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:42,242:INFO:Checking exceptions
2025-03-24 21:48:42,242:INFO:Importing libraries
2025-03-24 21:48:42,242:INFO:Copying training dataset
2025-03-24 21:48:42,251:INFO:Defining folds
2025-03-24 21:48:42,251:INFO:Declaring metric variables
2025-03-24 21:48:42,254:INFO:Importing untrained model
2025-03-24 21:48:42,257:INFO:Lasso Regression Imported successfully
2025-03-24 21:48:42,266:INFO:Starting cross validation
2025-03-24 21:48:42,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:44,021:INFO:Calculating mean and std
2025-03-24 21:48:44,022:INFO:Creating metrics dataframe
2025-03-24 21:48:44,023:INFO:Uploading results into container
2025-03-24 21:48:44,024:INFO:Uploading model into container now
2025-03-24 21:48:44,024:INFO:_master_model_container: 2
2025-03-24 21:48:44,024:INFO:_display_container: 2
2025-03-24 21:48:44,025:INFO:Lasso(random_state=5755)
2025-03-24 21:48:44,025:INFO:create_model() successfully completed......................................
2025-03-24 21:48:44,098:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:44,099:INFO:Creating metrics dataframe
2025-03-24 21:48:44,104:INFO:Initializing Ridge Regression
2025-03-24 21:48:44,104:INFO:Total runtime is 0.08301487366358438 minutes
2025-03-24 21:48:44,107:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:44,107:INFO:Initializing create_model()
2025-03-24 21:48:44,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:44,107:INFO:Checking exceptions
2025-03-24 21:48:44,107:INFO:Importing libraries
2025-03-24 21:48:44,107:INFO:Copying training dataset
2025-03-24 21:48:44,115:INFO:Defining folds
2025-03-24 21:48:44,115:INFO:Declaring metric variables
2025-03-24 21:48:44,117:INFO:Importing untrained model
2025-03-24 21:48:44,119:INFO:Ridge Regression Imported successfully
2025-03-24 21:48:44,122:INFO:Starting cross validation
2025-03-24 21:48:44,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:44,347:INFO:Calculating mean and std
2025-03-24 21:48:44,347:INFO:Creating metrics dataframe
2025-03-24 21:48:44,349:INFO:Uploading results into container
2025-03-24 21:48:44,349:INFO:Uploading model into container now
2025-03-24 21:48:44,349:INFO:_master_model_container: 3
2025-03-24 21:48:44,350:INFO:_display_container: 2
2025-03-24 21:48:44,350:INFO:Ridge(random_state=5755)
2025-03-24 21:48:44,350:INFO:create_model() successfully completed......................................
2025-03-24 21:48:44,411:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:44,411:INFO:Creating metrics dataframe
2025-03-24 21:48:44,416:INFO:Initializing Elastic Net
2025-03-24 21:48:44,416:INFO:Total runtime is 0.08821722666422525 minutes
2025-03-24 21:48:44,418:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:44,418:INFO:Initializing create_model()
2025-03-24 21:48:44,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:44,418:INFO:Checking exceptions
2025-03-24 21:48:44,418:INFO:Importing libraries
2025-03-24 21:48:44,418:INFO:Copying training dataset
2025-03-24 21:48:44,426:INFO:Defining folds
2025-03-24 21:48:44,426:INFO:Declaring metric variables
2025-03-24 21:48:44,428:INFO:Importing untrained model
2025-03-24 21:48:44,430:INFO:Elastic Net Imported successfully
2025-03-24 21:48:44,434:INFO:Starting cross validation
2025-03-24 21:48:44,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:44,674:INFO:Calculating mean and std
2025-03-24 21:48:44,675:INFO:Creating metrics dataframe
2025-03-24 21:48:44,676:INFO:Uploading results into container
2025-03-24 21:48:44,677:INFO:Uploading model into container now
2025-03-24 21:48:44,677:INFO:_master_model_container: 4
2025-03-24 21:48:44,677:INFO:_display_container: 2
2025-03-24 21:48:44,677:INFO:ElasticNet(random_state=5755)
2025-03-24 21:48:44,677:INFO:create_model() successfully completed......................................
2025-03-24 21:48:44,740:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:44,740:INFO:Creating metrics dataframe
2025-03-24 21:48:44,745:INFO:Initializing Least Angle Regression
2025-03-24 21:48:44,745:INFO:Total runtime is 0.09369642337163289 minutes
2025-03-24 21:48:44,747:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:44,747:INFO:Initializing create_model()
2025-03-24 21:48:44,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:44,747:INFO:Checking exceptions
2025-03-24 21:48:44,747:INFO:Importing libraries
2025-03-24 21:48:44,748:INFO:Copying training dataset
2025-03-24 21:48:44,755:INFO:Defining folds
2025-03-24 21:48:44,755:INFO:Declaring metric variables
2025-03-24 21:48:44,756:INFO:Importing untrained model
2025-03-24 21:48:44,758:INFO:Least Angle Regression Imported successfully
2025-03-24 21:48:44,763:INFO:Starting cross validation
2025-03-24 21:48:44,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:44,985:INFO:Calculating mean and std
2025-03-24 21:48:44,986:INFO:Creating metrics dataframe
2025-03-24 21:48:44,987:INFO:Uploading results into container
2025-03-24 21:48:44,987:INFO:Uploading model into container now
2025-03-24 21:48:44,987:INFO:_master_model_container: 5
2025-03-24 21:48:44,987:INFO:_display_container: 2
2025-03-24 21:48:44,988:INFO:Lars(random_state=5755)
2025-03-24 21:48:44,988:INFO:create_model() successfully completed......................................
2025-03-24 21:48:45,052:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:45,053:INFO:Creating metrics dataframe
2025-03-24 21:48:45,057:INFO:Initializing Lasso Least Angle Regression
2025-03-24 21:48:45,057:INFO:Total runtime is 0.09889419873555501 minutes
2025-03-24 21:48:45,060:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:45,060:INFO:Initializing create_model()
2025-03-24 21:48:45,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:45,060:INFO:Checking exceptions
2025-03-24 21:48:45,060:INFO:Importing libraries
2025-03-24 21:48:45,060:INFO:Copying training dataset
2025-03-24 21:48:45,067:INFO:Defining folds
2025-03-24 21:48:45,067:INFO:Declaring metric variables
2025-03-24 21:48:45,069:INFO:Importing untrained model
2025-03-24 21:48:45,071:INFO:Lasso Least Angle Regression Imported successfully
2025-03-24 21:48:45,075:INFO:Starting cross validation
2025-03-24 21:48:45,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:45,294:INFO:Calculating mean and std
2025-03-24 21:48:45,295:INFO:Creating metrics dataframe
2025-03-24 21:48:45,297:INFO:Uploading results into container
2025-03-24 21:48:45,297:INFO:Uploading model into container now
2025-03-24 21:48:45,297:INFO:_master_model_container: 6
2025-03-24 21:48:45,297:INFO:_display_container: 2
2025-03-24 21:48:45,298:INFO:LassoLars(random_state=5755)
2025-03-24 21:48:45,298:INFO:create_model() successfully completed......................................
2025-03-24 21:48:45,358:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:45,358:INFO:Creating metrics dataframe
2025-03-24 21:48:45,363:INFO:Initializing Orthogonal Matching Pursuit
2025-03-24 21:48:45,363:INFO:Total runtime is 0.10400258302688598 minutes
2025-03-24 21:48:45,366:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:45,366:INFO:Initializing create_model()
2025-03-24 21:48:45,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:45,366:INFO:Checking exceptions
2025-03-24 21:48:45,366:INFO:Importing libraries
2025-03-24 21:48:45,366:INFO:Copying training dataset
2025-03-24 21:48:45,373:INFO:Defining folds
2025-03-24 21:48:45,373:INFO:Declaring metric variables
2025-03-24 21:48:45,376:INFO:Importing untrained model
2025-03-24 21:48:45,378:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-24 21:48:45,381:INFO:Starting cross validation
2025-03-24 21:48:45,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:45,606:INFO:Calculating mean and std
2025-03-24 21:48:45,607:INFO:Creating metrics dataframe
2025-03-24 21:48:45,608:INFO:Uploading results into container
2025-03-24 21:48:45,608:INFO:Uploading model into container now
2025-03-24 21:48:45,608:INFO:_master_model_container: 7
2025-03-24 21:48:45,609:INFO:_display_container: 2
2025-03-24 21:48:45,609:INFO:OrthogonalMatchingPursuit()
2025-03-24 21:48:45,609:INFO:create_model() successfully completed......................................
2025-03-24 21:48:45,670:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:45,670:INFO:Creating metrics dataframe
2025-03-24 21:48:45,676:INFO:Initializing Bayesian Ridge
2025-03-24 21:48:45,676:INFO:Total runtime is 0.10921567281087238 minutes
2025-03-24 21:48:45,678:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:45,678:INFO:Initializing create_model()
2025-03-24 21:48:45,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:45,678:INFO:Checking exceptions
2025-03-24 21:48:45,678:INFO:Importing libraries
2025-03-24 21:48:45,678:INFO:Copying training dataset
2025-03-24 21:48:45,686:INFO:Defining folds
2025-03-24 21:48:45,686:INFO:Declaring metric variables
2025-03-24 21:48:45,687:INFO:Importing untrained model
2025-03-24 21:48:45,689:INFO:Bayesian Ridge Imported successfully
2025-03-24 21:48:45,693:INFO:Starting cross validation
2025-03-24 21:48:45,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:45,947:INFO:Calculating mean and std
2025-03-24 21:48:45,948:INFO:Creating metrics dataframe
2025-03-24 21:48:45,949:INFO:Uploading results into container
2025-03-24 21:48:45,950:INFO:Uploading model into container now
2025-03-24 21:48:45,950:INFO:_master_model_container: 8
2025-03-24 21:48:45,950:INFO:_display_container: 2
2025-03-24 21:48:45,950:INFO:BayesianRidge()
2025-03-24 21:48:45,950:INFO:create_model() successfully completed......................................
2025-03-24 21:48:46,017:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:46,017:INFO:Creating metrics dataframe
2025-03-24 21:48:46,022:INFO:Initializing Passive Aggressive Regressor
2025-03-24 21:48:46,022:INFO:Total runtime is 0.11497770945231119 minutes
2025-03-24 21:48:46,024:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:46,024:INFO:Initializing create_model()
2025-03-24 21:48:46,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:46,025:INFO:Checking exceptions
2025-03-24 21:48:46,025:INFO:Importing libraries
2025-03-24 21:48:46,025:INFO:Copying training dataset
2025-03-24 21:48:46,031:INFO:Defining folds
2025-03-24 21:48:46,031:INFO:Declaring metric variables
2025-03-24 21:48:46,032:INFO:Importing untrained model
2025-03-24 21:48:46,036:INFO:Passive Aggressive Regressor Imported successfully
2025-03-24 21:48:46,040:INFO:Starting cross validation
2025-03-24 21:48:46,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:46,413:INFO:Calculating mean and std
2025-03-24 21:48:46,413:INFO:Creating metrics dataframe
2025-03-24 21:48:46,414:INFO:Uploading results into container
2025-03-24 21:48:46,415:INFO:Uploading model into container now
2025-03-24 21:48:46,415:INFO:_master_model_container: 9
2025-03-24 21:48:46,415:INFO:_display_container: 2
2025-03-24 21:48:46,415:INFO:PassiveAggressiveRegressor(random_state=5755)
2025-03-24 21:48:46,415:INFO:create_model() successfully completed......................................
2025-03-24 21:48:46,478:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:46,478:INFO:Creating metrics dataframe
2025-03-24 21:48:46,482:INFO:Initializing Huber Regressor
2025-03-24 21:48:46,484:INFO:Total runtime is 0.12268313964207966 minutes
2025-03-24 21:48:46,485:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:46,485:INFO:Initializing create_model()
2025-03-24 21:48:46,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:46,486:INFO:Checking exceptions
2025-03-24 21:48:46,486:INFO:Importing libraries
2025-03-24 21:48:46,486:INFO:Copying training dataset
2025-03-24 21:48:46,493:INFO:Defining folds
2025-03-24 21:48:46,493:INFO:Declaring metric variables
2025-03-24 21:48:46,494:INFO:Importing untrained model
2025-03-24 21:48:46,496:INFO:Huber Regressor Imported successfully
2025-03-24 21:48:46,500:INFO:Starting cross validation
2025-03-24 21:48:46,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:48,021:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,056:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,096:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,153:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,188:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,191:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,211:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,237:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,310:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,391:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-24 21:48:48,416:INFO:Calculating mean and std
2025-03-24 21:48:48,417:INFO:Creating metrics dataframe
2025-03-24 21:48:48,418:INFO:Uploading results into container
2025-03-24 21:48:48,418:INFO:Uploading model into container now
2025-03-24 21:48:48,418:INFO:_master_model_container: 10
2025-03-24 21:48:48,418:INFO:_display_container: 2
2025-03-24 21:48:48,419:INFO:HuberRegressor()
2025-03-24 21:48:48,419:INFO:create_model() successfully completed......................................
2025-03-24 21:48:48,494:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:48,494:INFO:Creating metrics dataframe
2025-03-24 21:48:48,501:INFO:Initializing K Neighbors Regressor
2025-03-24 21:48:48,502:INFO:Total runtime is 0.15631857713063557 minutes
2025-03-24 21:48:48,504:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:48,504:INFO:Initializing create_model()
2025-03-24 21:48:48,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:48,505:INFO:Checking exceptions
2025-03-24 21:48:48,505:INFO:Importing libraries
2025-03-24 21:48:48,505:INFO:Copying training dataset
2025-03-24 21:48:48,512:INFO:Defining folds
2025-03-24 21:48:48,512:INFO:Declaring metric variables
2025-03-24 21:48:48,514:INFO:Importing untrained model
2025-03-24 21:48:48,516:INFO:K Neighbors Regressor Imported successfully
2025-03-24 21:48:48,520:INFO:Starting cross validation
2025-03-24 21:48:48,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:49,309:INFO:Calculating mean and std
2025-03-24 21:48:49,309:INFO:Creating metrics dataframe
2025-03-24 21:48:49,311:INFO:Uploading results into container
2025-03-24 21:48:49,311:INFO:Uploading model into container now
2025-03-24 21:48:49,311:INFO:_master_model_container: 11
2025-03-24 21:48:49,312:INFO:_display_container: 2
2025-03-24 21:48:49,312:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-24 21:48:49,312:INFO:create_model() successfully completed......................................
2025-03-24 21:48:49,376:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:49,376:INFO:Creating metrics dataframe
2025-03-24 21:48:49,381:INFO:Initializing Decision Tree Regressor
2025-03-24 21:48:49,382:INFO:Total runtime is 0.17098120053609211 minutes
2025-03-24 21:48:49,383:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:49,384:INFO:Initializing create_model()
2025-03-24 21:48:49,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:49,384:INFO:Checking exceptions
2025-03-24 21:48:49,384:INFO:Importing libraries
2025-03-24 21:48:49,384:INFO:Copying training dataset
2025-03-24 21:48:49,391:INFO:Defining folds
2025-03-24 21:48:49,391:INFO:Declaring metric variables
2025-03-24 21:48:49,393:INFO:Importing untrained model
2025-03-24 21:48:49,395:INFO:Decision Tree Regressor Imported successfully
2025-03-24 21:48:49,398:INFO:Starting cross validation
2025-03-24 21:48:49,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:49,714:INFO:Calculating mean and std
2025-03-24 21:48:49,715:INFO:Creating metrics dataframe
2025-03-24 21:48:49,716:INFO:Uploading results into container
2025-03-24 21:48:49,716:INFO:Uploading model into container now
2025-03-24 21:48:49,716:INFO:_master_model_container: 12
2025-03-24 21:48:49,716:INFO:_display_container: 2
2025-03-24 21:48:49,717:INFO:DecisionTreeRegressor(random_state=5755)
2025-03-24 21:48:49,717:INFO:create_model() successfully completed......................................
2025-03-24 21:48:49,777:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:49,777:INFO:Creating metrics dataframe
2025-03-24 21:48:49,783:INFO:Initializing Random Forest Regressor
2025-03-24 21:48:49,783:INFO:Total runtime is 0.177664311726888 minutes
2025-03-24 21:48:49,786:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:49,786:INFO:Initializing create_model()
2025-03-24 21:48:49,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:49,786:INFO:Checking exceptions
2025-03-24 21:48:49,786:INFO:Importing libraries
2025-03-24 21:48:49,786:INFO:Copying training dataset
2025-03-24 21:48:49,793:INFO:Defining folds
2025-03-24 21:48:49,793:INFO:Declaring metric variables
2025-03-24 21:48:49,795:INFO:Importing untrained model
2025-03-24 21:48:49,797:INFO:Random Forest Regressor Imported successfully
2025-03-24 21:48:49,801:INFO:Starting cross validation
2025-03-24 21:48:49,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:55,985:INFO:Calculating mean and std
2025-03-24 21:48:55,986:INFO:Creating metrics dataframe
2025-03-24 21:48:55,988:INFO:Uploading results into container
2025-03-24 21:48:55,988:INFO:Uploading model into container now
2025-03-24 21:48:55,988:INFO:_master_model_container: 13
2025-03-24 21:48:55,988:INFO:_display_container: 2
2025-03-24 21:48:55,989:INFO:RandomForestRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:48:55,989:INFO:create_model() successfully completed......................................
2025-03-24 21:48:56,063:INFO:SubProcess create_model() end ==================================
2025-03-24 21:48:56,064:INFO:Creating metrics dataframe
2025-03-24 21:48:56,070:INFO:Initializing Extra Trees Regressor
2025-03-24 21:48:56,070:INFO:Total runtime is 0.28244372208913165 minutes
2025-03-24 21:48:56,072:INFO:SubProcess create_model() called ==================================
2025-03-24 21:48:56,073:INFO:Initializing create_model()
2025-03-24 21:48:56,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:48:56,073:INFO:Checking exceptions
2025-03-24 21:48:56,073:INFO:Importing libraries
2025-03-24 21:48:56,073:INFO:Copying training dataset
2025-03-24 21:48:56,081:INFO:Defining folds
2025-03-24 21:48:56,081:INFO:Declaring metric variables
2025-03-24 21:48:56,082:INFO:Importing untrained model
2025-03-24 21:48:56,084:INFO:Extra Trees Regressor Imported successfully
2025-03-24 21:48:56,088:INFO:Starting cross validation
2025-03-24 21:48:56,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:48:59,907:INFO:Calculating mean and std
2025-03-24 21:48:59,908:INFO:Creating metrics dataframe
2025-03-24 21:48:59,910:INFO:Uploading results into container
2025-03-24 21:48:59,910:INFO:Uploading model into container now
2025-03-24 21:48:59,910:INFO:_master_model_container: 14
2025-03-24 21:48:59,910:INFO:_display_container: 2
2025-03-24 21:48:59,911:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:48:59,911:INFO:create_model() successfully completed......................................
2025-03-24 21:49:00,016:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:00,016:INFO:Creating metrics dataframe
2025-03-24 21:49:00,023:INFO:Initializing AdaBoost Regressor
2025-03-24 21:49:00,023:INFO:Total runtime is 0.3483403205871582 minutes
2025-03-24 21:49:00,025:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:00,025:INFO:Initializing create_model()
2025-03-24 21:49:00,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:00,026:INFO:Checking exceptions
2025-03-24 21:49:00,026:INFO:Importing libraries
2025-03-24 21:49:00,026:INFO:Copying training dataset
2025-03-24 21:49:00,035:INFO:Defining folds
2025-03-24 21:49:00,035:INFO:Declaring metric variables
2025-03-24 21:49:00,038:INFO:Importing untrained model
2025-03-24 21:49:00,041:INFO:AdaBoost Regressor Imported successfully
2025-03-24 21:49:00,046:INFO:Starting cross validation
2025-03-24 21:49:00,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:00,992:INFO:Calculating mean and std
2025-03-24 21:49:00,993:INFO:Creating metrics dataframe
2025-03-24 21:49:00,995:INFO:Uploading results into container
2025-03-24 21:49:00,995:INFO:Uploading model into container now
2025-03-24 21:49:00,996:INFO:_master_model_container: 15
2025-03-24 21:49:00,996:INFO:_display_container: 2
2025-03-24 21:49:00,996:INFO:AdaBoostRegressor(random_state=5755)
2025-03-24 21:49:00,996:INFO:create_model() successfully completed......................................
2025-03-24 21:49:01,068:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:01,068:INFO:Creating metrics dataframe
2025-03-24 21:49:01,075:INFO:Initializing Gradient Boosting Regressor
2025-03-24 21:49:01,075:INFO:Total runtime is 0.36586999893188477 minutes
2025-03-24 21:49:01,076:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:01,076:INFO:Initializing create_model()
2025-03-24 21:49:01,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:01,076:INFO:Checking exceptions
2025-03-24 21:49:01,078:INFO:Importing libraries
2025-03-24 21:49:01,078:INFO:Copying training dataset
2025-03-24 21:49:01,084:INFO:Defining folds
2025-03-24 21:49:01,084:INFO:Declaring metric variables
2025-03-24 21:49:01,086:INFO:Importing untrained model
2025-03-24 21:49:01,089:INFO:Gradient Boosting Regressor Imported successfully
2025-03-24 21:49:01,093:INFO:Starting cross validation
2025-03-24 21:49:01,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:03,082:INFO:Calculating mean and std
2025-03-24 21:49:03,083:INFO:Creating metrics dataframe
2025-03-24 21:49:03,084:INFO:Uploading results into container
2025-03-24 21:49:03,084:INFO:Uploading model into container now
2025-03-24 21:49:03,084:INFO:_master_model_container: 16
2025-03-24 21:49:03,084:INFO:_display_container: 2
2025-03-24 21:49:03,085:INFO:GradientBoostingRegressor(random_state=5755)
2025-03-24 21:49:03,085:INFO:create_model() successfully completed......................................
2025-03-24 21:49:03,150:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:03,150:INFO:Creating metrics dataframe
2025-03-24 21:49:03,157:INFO:Initializing Light Gradient Boosting Machine
2025-03-24 21:49:03,157:INFO:Total runtime is 0.4005635976791382 minutes
2025-03-24 21:49:03,158:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:03,159:INFO:Initializing create_model()
2025-03-24 21:49:03,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:03,159:INFO:Checking exceptions
2025-03-24 21:49:03,159:INFO:Importing libraries
2025-03-24 21:49:03,159:INFO:Copying training dataset
2025-03-24 21:49:03,165:INFO:Defining folds
2025-03-24 21:49:03,165:INFO:Declaring metric variables
2025-03-24 21:49:03,169:INFO:Importing untrained model
2025-03-24 21:49:03,171:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:49:03,175:INFO:Starting cross validation
2025-03-24 21:49:03,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:03,968:INFO:Calculating mean and std
2025-03-24 21:49:03,969:INFO:Creating metrics dataframe
2025-03-24 21:49:03,970:INFO:Uploading results into container
2025-03-24 21:49:03,971:INFO:Uploading model into container now
2025-03-24 21:49:03,971:INFO:_master_model_container: 17
2025-03-24 21:49:03,971:INFO:_display_container: 2
2025-03-24 21:49:03,972:INFO:LGBMRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:49:03,972:INFO:create_model() successfully completed......................................
2025-03-24 21:49:04,048:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:04,048:INFO:Creating metrics dataframe
2025-03-24 21:49:04,057:INFO:Initializing Dummy Regressor
2025-03-24 21:49:04,057:INFO:Total runtime is 0.4155646642049154 minutes
2025-03-24 21:49:04,059:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:04,059:INFO:Initializing create_model()
2025-03-24 21:49:04,059:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA63B040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:04,059:INFO:Checking exceptions
2025-03-24 21:49:04,059:INFO:Importing libraries
2025-03-24 21:49:04,060:INFO:Copying training dataset
2025-03-24 21:49:04,068:INFO:Defining folds
2025-03-24 21:49:04,068:INFO:Declaring metric variables
2025-03-24 21:49:04,069:INFO:Importing untrained model
2025-03-24 21:49:04,071:INFO:Dummy Regressor Imported successfully
2025-03-24 21:49:04,075:INFO:Starting cross validation
2025-03-24 21:49:04,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:04,279:INFO:Calculating mean and std
2025-03-24 21:49:04,279:INFO:Creating metrics dataframe
2025-03-24 21:49:04,281:INFO:Uploading results into container
2025-03-24 21:49:04,281:INFO:Uploading model into container now
2025-03-24 21:49:04,281:INFO:_master_model_container: 18
2025-03-24 21:49:04,281:INFO:_display_container: 2
2025-03-24 21:49:04,281:INFO:DummyRegressor()
2025-03-24 21:49:04,282:INFO:create_model() successfully completed......................................
2025-03-24 21:49:04,348:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:04,348:INFO:Creating metrics dataframe
2025-03-24 21:49:04,355:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-24 21:49:04,359:INFO:Initializing create_model()
2025-03-24 21:49:04,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:04,360:INFO:Checking exceptions
2025-03-24 21:49:04,360:INFO:Importing libraries
2025-03-24 21:49:04,361:INFO:Copying training dataset
2025-03-24 21:49:04,367:INFO:Defining folds
2025-03-24 21:49:04,367:INFO:Declaring metric variables
2025-03-24 21:49:04,369:INFO:Importing untrained model
2025-03-24 21:49:04,369:INFO:Declaring custom model
2025-03-24 21:49:04,369:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:49:04,370:INFO:Cross validation set to False
2025-03-24 21:49:04,370:INFO:Fitting Model
2025-03-24 21:49:04,454:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:49:04,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.
2025-03-24 21:49:04,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:49:04,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:49:04,457:INFO:[LightGBM] [Info] Total Bins 559
2025-03-24 21:49:04,457:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-24 21:49:04,457:INFO:[LightGBM] [Info] Start training from score 3266.233596
2025-03-24 21:49:04,509:INFO:LGBMRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:49:04,509:INFO:create_model() successfully completed......................................
2025-03-24 21:49:04,607:INFO:_master_model_container: 18
2025-03-24 21:49:04,607:INFO:_display_container: 2
2025-03-24 21:49:04,607:INFO:LGBMRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:49:04,607:INFO:compare_models() successfully completed......................................
2025-03-24 21:49:04,644:INFO:Initializing evaluate_model()
2025-03-24 21:49:04,644:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-24 21:49:04,655:INFO:Initializing plot_model()
2025-03-24 21:49:04,655:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, system=True)
2025-03-24 21:49:04,655:INFO:Checking exceptions
2025-03-24 21:49:04,659:INFO:Preloading libraries
2025-03-24 21:49:04,665:INFO:Copying training dataset
2025-03-24 21:49:04,665:INFO:Plot type: pipeline
2025-03-24 21:49:04,801:INFO:Visual Rendered Successfully
2025-03-24 21:49:04,868:INFO:plot_model() successfully completed......................................
2025-03-24 21:49:04,891:INFO:Initializing tune_model()
2025-03-24 21:49:04,891:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=5755), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>)
2025-03-24 21:49:04,891:INFO:Checking exceptions
2025-03-24 21:49:04,903:INFO:Copying training dataset
2025-03-24 21:49:04,909:INFO:Checking base model
2025-03-24 21:49:04,909:INFO:Base model : Light Gradient Boosting Machine
2025-03-24 21:49:04,912:INFO:Declaring metric variables
2025-03-24 21:49:04,914:INFO:Defining Hyperparameters
2025-03-24 21:49:04,991:INFO:Tuning with n_jobs=-1
2025-03-24 21:49:04,991:INFO:Initializing RandomizedSearchCV
2025-03-24 21:49:28,844:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 8, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2025-03-24 21:49:28,845:INFO:Hyperparameter search completed
2025-03-24 21:49:28,845:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:28,847:INFO:Initializing create_model()
2025-03-24 21:49:28,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA35BEE60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 10, 'reg_alpha': 0.0005, 'num_leaves': 8, 'n_estimators': 90, 'min_split_gain': 0.3, 'min_child_samples': 61, 'learning_rate': 0.15, 'feature_fraction': 0.9, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2025-03-24 21:49:28,847:INFO:Checking exceptions
2025-03-24 21:49:28,847:INFO:Importing libraries
2025-03-24 21:49:28,847:INFO:Copying training dataset
2025-03-24 21:49:28,858:INFO:Defining folds
2025-03-24 21:49:28,858:INFO:Declaring metric variables
2025-03-24 21:49:28,860:INFO:Importing untrained model
2025-03-24 21:49:28,860:INFO:Declaring custom model
2025-03-24 21:49:28,864:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:49:28,868:INFO:Starting cross validation
2025-03-24 21:49:28,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:29,387:INFO:Calculating mean and std
2025-03-24 21:49:29,388:INFO:Creating metrics dataframe
2025-03-24 21:49:29,393:INFO:Finalizing model
2025-03-24 21:49:29,503:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-03-24 21:49:29,503:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-03-24 21:49:29,503:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-03-24 21:49:29,518:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:49:29,518:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-03-24 21:49:29,518:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-03-24 21:49:29,518:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-03-24 21:49:29,519:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-24 21:49:29,519:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:49:29,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:49:29,519:INFO:[LightGBM] [Info] Total Bins 548
2025-03-24 21:49:29,520:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 13
2025-03-24 21:49:29,520:INFO:[LightGBM] [Info] Start training from score 3266.233596
2025-03-24 21:49:29,573:INFO:Uploading results into container
2025-03-24 21:49:29,574:INFO:Uploading model into container now
2025-03-24 21:49:29,575:INFO:_master_model_container: 19
2025-03-24 21:49:29,575:INFO:_display_container: 3
2025-03-24 21:49:29,577:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.9,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.3,
              n_estimators=90, n_jobs=-1, num_leaves=8, random_state=5755,
              reg_alpha=0.0005, reg_lambda=10)
2025-03-24 21:49:29,577:INFO:create_model() successfully completed......................................
2025-03-24 21:49:29,660:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:29,660:INFO:choose_better activated
2025-03-24 21:49:29,663:INFO:SubProcess create_model() called ==================================
2025-03-24 21:49:29,663:INFO:Initializing create_model()
2025-03-24 21:49:29,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-24 21:49:29,664:INFO:Checking exceptions
2025-03-24 21:49:29,665:INFO:Importing libraries
2025-03-24 21:49:29,665:INFO:Copying training dataset
2025-03-24 21:49:29,675:INFO:Defining folds
2025-03-24 21:49:29,675:INFO:Declaring metric variables
2025-03-24 21:49:29,675:INFO:Importing untrained model
2025-03-24 21:49:29,675:INFO:Declaring custom model
2025-03-24 21:49:29,676:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-24 21:49:29,676:INFO:Starting cross validation
2025-03-24 21:49:29,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-24 21:49:30,569:INFO:Calculating mean and std
2025-03-24 21:49:30,569:INFO:Creating metrics dataframe
2025-03-24 21:49:30,571:INFO:Finalizing model
2025-03-24 21:49:30,677:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-24 21:49:30,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-24 21:49:30,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-24 21:49:30,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-24 21:49:30,678:INFO:[LightGBM] [Info] Total Bins 559
2025-03-24 21:49:30,678:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-24 21:49:30,678:INFO:[LightGBM] [Info] Start training from score 3266.233596
2025-03-24 21:49:30,748:INFO:Uploading results into container
2025-03-24 21:49:30,748:INFO:Uploading model into container now
2025-03-24 21:49:30,749:INFO:_master_model_container: 20
2025-03-24 21:49:30,749:INFO:_display_container: 4
2025-03-24 21:49:30,749:INFO:LGBMRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:49:30,749:INFO:create_model() successfully completed......................................
2025-03-24 21:49:30,825:INFO:SubProcess create_model() end ==================================
2025-03-24 21:49:30,827:INFO:LGBMRegressor(n_jobs=-1, random_state=5755) result for R2 is 0.214
2025-03-24 21:49:30,828:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.9,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.3,
              n_estimators=90, n_jobs=-1, num_leaves=8, random_state=5755,
              reg_alpha=0.0005, reg_lambda=10) result for R2 is 0.2026
2025-03-24 21:49:30,828:INFO:LGBMRegressor(n_jobs=-1, random_state=5755) is best model
2025-03-24 21:49:30,828:INFO:choose_better completed
2025-03-24 21:49:30,828:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-24 21:49:30,835:INFO:_master_model_container: 20
2025-03-24 21:49:30,835:INFO:_display_container: 3
2025-03-24 21:49:30,837:INFO:LGBMRegressor(n_jobs=-1, random_state=5755)
2025-03-24 21:49:30,837:INFO:tune_model() successfully completed......................................
2025-03-24 21:49:30,957:INFO:Initializing save_model()
2025-03-24 21:49:30,957:INFO:save_model(model=LGBMRegressor(n_jobs=-1, random_state=5755), model_name=traffic_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-24 21:49:30,957:INFO:Adding model into prep_pipe
2025-03-24 21:49:30,967:INFO:traffic_model.pkl saved in current working directory
2025-03-24 21:49:30,975:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))])
2025-03-24 21:49:30,975:INFO:save_model() successfully completed......................................
2025-03-24 21:49:41,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:49:41,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:49:41,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:49:41,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:51:11,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:51:11,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:51:11,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:51:11,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:52:15,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:52:15,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:52:15,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:52:15,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:53:32,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:53:32,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:53:32,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:53:32,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:55:10,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:55:10,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:55:10,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:55:10,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:55:12,832:INFO:Initializing load_model()
2025-03-24 21:55:12,833:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 21:55:12,897:INFO:Initializing predict_model()
2025-03-24 21:55:12,897:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025D3EF523B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025D3EFB5EA0>)
2025-03-24 21:55:12,897:INFO:Checking exceptions
2025-03-24 21:55:12,897:INFO:Preloading libraries
2025-03-24 21:55:12,897:INFO:Set up data.
2025-03-24 21:55:12,908:INFO:Set up index.
2025-03-24 21:59:07,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:59:07,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:59:07,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:59:07,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 21:59:09,570:INFO:Initializing load_model()
2025-03-24 21:59:09,570:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 21:59:09,628:INFO:Initializing predict_model()
2025-03-24 21:59:09,628:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002623A3D0790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002623BC372E0>)
2025-03-24 21:59:09,628:INFO:Checking exceptions
2025-03-24 21:59:09,628:INFO:Preloading libraries
2025-03-24 21:59:09,628:INFO:Set up data.
2025-03-24 21:59:09,639:INFO:Set up index.
2025-03-24 22:00:05,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:05,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:05,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:05,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:07,617:INFO:Initializing load_model()
2025-03-24 22:00:07,618:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:00:07,676:INFO:Initializing predict_model()
2025-03-24 22:00:07,677:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A4DB241480>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A4DB1FACB0>)
2025-03-24 22:00:07,677:INFO:Checking exceptions
2025-03-24 22:00:07,677:INFO:Preloading libraries
2025-03-24 22:00:07,677:INFO:Set up data.
2025-03-24 22:00:07,687:INFO:Set up index.
2025-03-24 22:00:30,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:30,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:30,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:30,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:00:33,147:INFO:Initializing load_model()
2025-03-24 22:00:33,147:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:00:33,201:INFO:Initializing predict_model()
2025-03-24 22:00:33,201:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001274B0AA1D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001274B9EFE20>)
2025-03-24 22:00:33,201:INFO:Checking exceptions
2025-03-24 22:00:33,203:INFO:Preloading libraries
2025-03-24 22:00:33,203:INFO:Set up data.
2025-03-24 22:00:33,213:INFO:Set up index.
2025-03-24 22:01:11,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:11,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:11,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:11,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:13,348:INFO:Initializing load_model()
2025-03-24 22:01:13,348:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:01:13,405:INFO:Initializing predict_model()
2025-03-24 22:01:13,405:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C8426FD60>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C84207520>)
2025-03-24 22:01:13,405:INFO:Checking exceptions
2025-03-24 22:01:13,405:INFO:Preloading libraries
2025-03-24 22:01:13,405:INFO:Set up data.
2025-03-24 22:01:13,416:INFO:Set up index.
2025-03-24 22:01:31,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:31,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:31,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:31,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:32,982:INFO:Initializing load_model()
2025-03-24 22:01:32,983:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:01:33,040:INFO:Initializing predict_model()
2025-03-24 22:01:33,040:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F380EF06D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F380E37880>)
2025-03-24 22:01:33,041:INFO:Checking exceptions
2025-03-24 22:01:33,041:INFO:Preloading libraries
2025-03-24 22:01:33,041:INFO:Set up data.
2025-03-24 22:01:33,051:INFO:Set up index.
2025-03-24 22:01:52,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:52,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:52,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:52,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:01:54,811:INFO:Initializing load_model()
2025-03-24 22:01:54,811:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:01:54,869:INFO:Initializing predict_model()
2025-03-24 22:01:54,869:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BBE9CA8250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BBE9BFF490>)
2025-03-24 22:01:54,869:INFO:Checking exceptions
2025-03-24 22:01:54,869:INFO:Preloading libraries
2025-03-24 22:01:54,870:INFO:Set up data.
2025-03-24 22:01:54,880:INFO:Set up index.
2025-03-24 22:02:10,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:02:10,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:02:10,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:02:10,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:02:11,913:INFO:Initializing load_model()
2025-03-24 22:02:11,914:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:02:11,970:INFO:Initializing predict_model()
2025-03-24 22:02:11,970:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023600047E50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002360001F9A0>)
2025-03-24 22:02:11,970:INFO:Checking exceptions
2025-03-24 22:02:11,970:INFO:Preloading libraries
2025-03-24 22:02:11,971:INFO:Set up data.
2025-03-24 22:02:11,980:INFO:Set up index.
2025-03-24 22:03:15,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:03:15,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:03:15,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:03:15,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:03:17,859:INFO:Initializing load_model()
2025-03-24 22:03:17,860:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:03:17,913:INFO:Initializing predict_model()
2025-03-24 22:03:17,913:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F81DCAB1F0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F81DC77910>)
2025-03-24 22:03:17,914:INFO:Checking exceptions
2025-03-24 22:03:17,914:INFO:Preloading libraries
2025-03-24 22:03:17,914:INFO:Set up data.
2025-03-24 22:03:17,924:INFO:Set up index.
2025-03-24 22:05:33,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:05:33,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:05:33,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:05:33,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:05:36,192:INFO:Initializing load_model()
2025-03-24 22:05:36,192:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:05:36,247:INFO:Initializing predict_model()
2025-03-24 22:05:36,248:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A7AC76CD30>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A7AC72EB00>)
2025-03-24 22:05:36,248:INFO:Checking exceptions
2025-03-24 22:05:36,248:INFO:Preloading libraries
2025-03-24 22:05:36,248:INFO:Set up data.
2025-03-24 22:05:36,257:INFO:Set up index.
2025-03-24 22:07:46,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:07:46,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:07:46,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:07:46,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-24 22:07:47,970:INFO:Initializing load_model()
2025-03-24 22:07:47,971:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 22:07:48,027:INFO:Initializing predict_model()
2025-03-24 22:07:48,027:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C437D6C250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C437CCB6D0>)
2025-03-24 22:07:48,028:INFO:Checking exceptions
2025-03-24 22:07:48,028:INFO:Preloading libraries
2025-03-24 22:07:48,028:INFO:Set up data.
2025-03-24 22:07:48,037:INFO:Set up index.
2025-03-24 23:23:49,023:INFO:Initializing load_model()
2025-03-24 23:23:49,023:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-24 23:23:49,039:INFO:Initializing predict_model()
2025-03-24 23:23:49,039:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C439024A90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=5755))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C43900F760>)
2025-03-24 23:23:49,039:INFO:Checking exceptions
2025-03-24 23:23:49,039:INFO:Preloading libraries
2025-03-24 23:23:49,039:INFO:Set up data.
2025-03-24 23:23:49,051:INFO:Set up index.
2025-03-25 08:47:28,493:INFO:PyCaret RegressionExperiment
2025-03-25 08:47:28,493:INFO:Logging name: reg-default-name
2025-03-25 08:47:28,494:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-25 08:47:28,494:INFO:version 3.3.2
2025-03-25 08:47:28,494:INFO:Initializing setup()
2025-03-25 08:47:28,494:INFO:self.USI: 830a
2025-03-25 08:47:28,495:INFO:self._variable_keys: {'_ml_usecase', '_available_plots', 'fold_shuffle_param', 'idx', 'fold_generator', 'html_param', 'pipeline', 'exp_name_log', 'logging_param', 'gpu_n_jobs_param', 'log_plots_param', 'memory', 'X_test', 'transform_target_param', 'seed', 'USI', 'exp_id', 'X_train', 'X', 'y', 'gpu_param', 'data', 'y_train', 'y_test', 'n_jobs_param', 'target_param', 'fold_groups_param'}
2025-03-25 08:47:28,495:INFO:Checking environment
2025-03-25 08:47:28,495:INFO:python_version: 3.10.16
2025-03-25 08:47:28,495:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-25 08:47:28,495:INFO:machine: AMD64
2025-03-25 08:47:28,496:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-25 08:47:28,500:INFO:Memory: svmem(total=33411727360, available=11881947136, percent=64.4, used=21529780224, free=11881947136)
2025-03-25 08:47:28,500:INFO:Physical Core: 6
2025-03-25 08:47:28,500:INFO:Logical Core: 12
2025-03-25 08:47:28,500:INFO:Checking libraries
2025-03-25 08:47:28,500:INFO:System:
2025-03-25 08:47:28,500:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-25 08:47:28,500:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-25 08:47:28,500:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-25 08:47:28,500:INFO:PyCaret required dependencies:
2025-03-25 08:47:28,500:INFO:                 pip: 25.0.1
2025-03-25 08:47:28,500:INFO:          setuptools: 75.8.2
2025-03-25 08:47:28,500:INFO:             pycaret: 3.3.2
2025-03-25 08:47:28,500:INFO:             IPython: 8.34.0
2025-03-25 08:47:28,500:INFO:          ipywidgets: 8.1.5
2025-03-25 08:47:28,502:INFO:                tqdm: 4.67.1
2025-03-25 08:47:28,502:INFO:               numpy: 1.26.4
2025-03-25 08:47:28,502:INFO:              pandas: 2.1.4
2025-03-25 08:47:28,502:INFO:              jinja2: 3.1.6
2025-03-25 08:47:28,502:INFO:               scipy: 1.11.4
2025-03-25 08:47:28,502:INFO:              joblib: 1.3.2
2025-03-25 08:47:28,502:INFO:             sklearn: 1.4.2
2025-03-25 08:47:28,502:INFO:                pyod: 2.0.2
2025-03-25 08:47:28,502:INFO:            imblearn: 0.13.0
2025-03-25 08:47:28,502:INFO:   category_encoders: 2.7.0
2025-03-25 08:47:28,502:INFO:            lightgbm: 4.6.0
2025-03-25 08:47:28,502:INFO:               numba: 0.61.0
2025-03-25 08:47:28,502:INFO:            requests: 2.32.3
2025-03-25 08:47:28,502:INFO:          matplotlib: 3.10.1
2025-03-25 08:47:28,502:INFO:          scikitplot: 0.3.7
2025-03-25 08:47:28,502:INFO:         yellowbrick: 1.5
2025-03-25 08:47:28,502:INFO:              plotly: 6.0.1
2025-03-25 08:47:28,502:INFO:    plotly-resampler: Not installed
2025-03-25 08:47:28,502:INFO:             kaleido: 0.2.1
2025-03-25 08:47:28,502:INFO:           schemdraw: 0.15
2025-03-25 08:47:28,502:INFO:         statsmodels: 0.14.4
2025-03-25 08:47:28,502:INFO:              sktime: 0.26.0
2025-03-25 08:47:28,502:INFO:               tbats: 1.1.3
2025-03-25 08:47:28,502:INFO:            pmdarima: 2.0.4
2025-03-25 08:47:28,502:INFO:              psutil: 7.0.0
2025-03-25 08:47:28,502:INFO:          markupsafe: 3.0.2
2025-03-25 08:47:28,502:INFO:             pickle5: Not installed
2025-03-25 08:47:28,502:INFO:         cloudpickle: 3.1.1
2025-03-25 08:47:28,502:INFO:         deprecation: 2.1.0
2025-03-25 08:47:28,502:INFO:              xxhash: 3.5.0
2025-03-25 08:47:28,502:INFO:           wurlitzer: 3.1.1
2025-03-25 08:47:28,502:INFO:PyCaret optional dependencies:
2025-03-25 08:47:28,502:INFO:                shap: Not installed
2025-03-25 08:47:28,502:INFO:           interpret: Not installed
2025-03-25 08:47:28,502:INFO:                umap: 0.5.7
2025-03-25 08:47:28,502:INFO:     ydata_profiling: Not installed
2025-03-25 08:47:28,502:INFO:  explainerdashboard: Not installed
2025-03-25 08:47:28,502:INFO:             autoviz: Not installed
2025-03-25 08:47:28,502:INFO:           fairlearn: Not installed
2025-03-25 08:47:28,502:INFO:          deepchecks: Not installed
2025-03-25 08:47:28,502:INFO:             xgboost: Not installed
2025-03-25 08:47:28,502:INFO:            catboost: Not installed
2025-03-25 08:47:28,502:INFO:              kmodes: Not installed
2025-03-25 08:47:28,502:INFO:             mlxtend: Not installed
2025-03-25 08:47:28,502:INFO:       statsforecast: Not installed
2025-03-25 08:47:28,502:INFO:        tune_sklearn: Not installed
2025-03-25 08:47:28,502:INFO:                 ray: Not installed
2025-03-25 08:47:28,502:INFO:            hyperopt: Not installed
2025-03-25 08:47:28,502:INFO:              optuna: Not installed
2025-03-25 08:47:28,502:INFO:               skopt: Not installed
2025-03-25 08:47:28,502:INFO:              mlflow: Not installed
2025-03-25 08:47:28,502:INFO:              gradio: Not installed
2025-03-25 08:47:28,503:INFO:             fastapi: Not installed
2025-03-25 08:47:28,503:INFO:             uvicorn: Not installed
2025-03-25 08:47:28,503:INFO:              m2cgen: Not installed
2025-03-25 08:47:28,503:INFO:           evidently: Not installed
2025-03-25 08:47:28,503:INFO:               fugue: Not installed
2025-03-25 08:47:28,503:INFO:           streamlit: 1.43.2
2025-03-25 08:47:28,503:INFO:             prophet: Not installed
2025-03-25 08:47:28,503:INFO:None
2025-03-25 08:47:28,503:INFO:Set up data.
2025-03-25 08:47:28,510:INFO:Set up folding strategy.
2025-03-25 08:47:28,510:INFO:Set up train/test split.
2025-03-25 08:47:28,516:INFO:Set up index.
2025-03-25 08:47:28,517:INFO:Assigning column types.
2025-03-25 08:47:28,520:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-25 08:47:28,520:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,523:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,526:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,564:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,593:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,595:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,598:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,664:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-25 08:47:28,666:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,669:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,706:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,736:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,776:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,802:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,803:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-25 08:47:28,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,845:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,878:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:28,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:28,946:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-25 08:47:28,989:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,062:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,090:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-25 08:47:29,132:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-25 08:47:29,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,228:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-25 08:47:29,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,371:INFO:Preparing preprocessing pipeline...
2025-03-25 08:47:29,372:INFO:Set up simple imputation.
2025-03-25 08:47:29,376:INFO:Set up encoding of categorical features.
2025-03-25 08:47:29,376:INFO:Set up column name cleaning.
2025-03-25 08:47:29,487:INFO:Finished creating preprocessing pipeline.
2025-03-25 08:47:29,491:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-25 08:47:29,491:INFO:Creating final display dataframe.
2025-03-25 08:47:29,710:INFO:Setup _display_container:                     Description             Value
0                    Session id              2242
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              830a
2025-03-25 08:47:29,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 08:47:29,860:INFO:setup() successfully completed in 1.37s...............
2025-03-25 08:47:31,097:INFO:Initializing compare_models()
2025-03-25 08:47:31,098:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-25 08:47:31,098:INFO:Checking exceptions
2025-03-25 08:47:31,102:INFO:Preparing display monitor
2025-03-25 08:47:31,118:INFO:Initializing Linear Regression
2025-03-25 08:47:31,118:INFO:Total runtime is 0.0 minutes
2025-03-25 08:47:31,120:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:31,120:INFO:Initializing create_model()
2025-03-25 08:47:31,120:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:31,120:INFO:Checking exceptions
2025-03-25 08:47:31,120:INFO:Importing libraries
2025-03-25 08:47:31,120:INFO:Copying training dataset
2025-03-25 08:47:31,128:INFO:Defining folds
2025-03-25 08:47:31,128:INFO:Declaring metric variables
2025-03-25 08:47:31,132:INFO:Importing untrained model
2025-03-25 08:47:31,134:INFO:Linear Regression Imported successfully
2025-03-25 08:47:31,138:INFO:Starting cross validation
2025-03-25 08:47:31,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:34,460:INFO:Calculating mean and std
2025-03-25 08:47:34,462:INFO:Creating metrics dataframe
2025-03-25 08:47:34,463:INFO:Uploading results into container
2025-03-25 08:47:34,464:INFO:Uploading model into container now
2025-03-25 08:47:34,465:INFO:_master_model_container: 1
2025-03-25 08:47:34,465:INFO:_display_container: 2
2025-03-25 08:47:34,466:INFO:LinearRegression(n_jobs=-1)
2025-03-25 08:47:34,466:INFO:create_model() successfully completed......................................
2025-03-25 08:47:34,600:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:34,600:INFO:Creating metrics dataframe
2025-03-25 08:47:34,604:INFO:Initializing Lasso Regression
2025-03-25 08:47:34,604:INFO:Total runtime is 0.058097438017527266 minutes
2025-03-25 08:47:34,607:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:34,607:INFO:Initializing create_model()
2025-03-25 08:47:34,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:34,607:INFO:Checking exceptions
2025-03-25 08:47:34,607:INFO:Importing libraries
2025-03-25 08:47:34,607:INFO:Copying training dataset
2025-03-25 08:47:34,615:INFO:Defining folds
2025-03-25 08:47:34,616:INFO:Declaring metric variables
2025-03-25 08:47:34,619:INFO:Importing untrained model
2025-03-25 08:47:34,621:INFO:Lasso Regression Imported successfully
2025-03-25 08:47:34,625:INFO:Starting cross validation
2025-03-25 08:47:34,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:36,531:INFO:Calculating mean and std
2025-03-25 08:47:36,532:INFO:Creating metrics dataframe
2025-03-25 08:47:36,533:INFO:Uploading results into container
2025-03-25 08:47:36,534:INFO:Uploading model into container now
2025-03-25 08:47:36,534:INFO:_master_model_container: 2
2025-03-25 08:47:36,534:INFO:_display_container: 2
2025-03-25 08:47:36,535:INFO:Lasso(random_state=2242)
2025-03-25 08:47:36,535:INFO:create_model() successfully completed......................................
2025-03-25 08:47:36,640:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:36,640:INFO:Creating metrics dataframe
2025-03-25 08:47:36,645:INFO:Initializing Ridge Regression
2025-03-25 08:47:36,645:INFO:Total runtime is 0.0921022375424703 minutes
2025-03-25 08:47:36,647:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:36,647:INFO:Initializing create_model()
2025-03-25 08:47:36,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:36,648:INFO:Checking exceptions
2025-03-25 08:47:36,648:INFO:Importing libraries
2025-03-25 08:47:36,648:INFO:Copying training dataset
2025-03-25 08:47:36,655:INFO:Defining folds
2025-03-25 08:47:36,655:INFO:Declaring metric variables
2025-03-25 08:47:36,658:INFO:Importing untrained model
2025-03-25 08:47:36,660:INFO:Ridge Regression Imported successfully
2025-03-25 08:47:36,664:INFO:Starting cross validation
2025-03-25 08:47:36,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:36,971:INFO:Calculating mean and std
2025-03-25 08:47:36,972:INFO:Creating metrics dataframe
2025-03-25 08:47:36,974:INFO:Uploading results into container
2025-03-25 08:47:36,974:INFO:Uploading model into container now
2025-03-25 08:47:36,974:INFO:_master_model_container: 3
2025-03-25 08:47:36,975:INFO:_display_container: 2
2025-03-25 08:47:36,975:INFO:Ridge(random_state=2242)
2025-03-25 08:47:36,975:INFO:create_model() successfully completed......................................
2025-03-25 08:47:37,078:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:37,078:INFO:Creating metrics dataframe
2025-03-25 08:47:37,083:INFO:Initializing Elastic Net
2025-03-25 08:47:37,083:INFO:Total runtime is 0.09940207799275716 minutes
2025-03-25 08:47:37,085:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:37,085:INFO:Initializing create_model()
2025-03-25 08:47:37,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:37,085:INFO:Checking exceptions
2025-03-25 08:47:37,085:INFO:Importing libraries
2025-03-25 08:47:37,085:INFO:Copying training dataset
2025-03-25 08:47:37,093:INFO:Defining folds
2025-03-25 08:47:37,093:INFO:Declaring metric variables
2025-03-25 08:47:37,096:INFO:Importing untrained model
2025-03-25 08:47:37,099:INFO:Elastic Net Imported successfully
2025-03-25 08:47:37,105:INFO:Starting cross validation
2025-03-25 08:47:37,106:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:37,404:INFO:Calculating mean and std
2025-03-25 08:47:37,405:INFO:Creating metrics dataframe
2025-03-25 08:47:37,407:INFO:Uploading results into container
2025-03-25 08:47:37,407:INFO:Uploading model into container now
2025-03-25 08:47:37,408:INFO:_master_model_container: 4
2025-03-25 08:47:37,408:INFO:_display_container: 2
2025-03-25 08:47:37,408:INFO:ElasticNet(random_state=2242)
2025-03-25 08:47:37,409:INFO:create_model() successfully completed......................................
2025-03-25 08:47:37,508:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:37,509:INFO:Creating metrics dataframe
2025-03-25 08:47:37,514:INFO:Initializing Least Angle Regression
2025-03-25 08:47:37,514:INFO:Total runtime is 0.10658913056055705 minutes
2025-03-25 08:47:37,516:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:37,517:INFO:Initializing create_model()
2025-03-25 08:47:37,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:37,517:INFO:Checking exceptions
2025-03-25 08:47:37,517:INFO:Importing libraries
2025-03-25 08:47:37,517:INFO:Copying training dataset
2025-03-25 08:47:37,528:INFO:Defining folds
2025-03-25 08:47:37,528:INFO:Declaring metric variables
2025-03-25 08:47:37,531:INFO:Importing untrained model
2025-03-25 08:47:37,534:INFO:Least Angle Regression Imported successfully
2025-03-25 08:47:37,539:INFO:Starting cross validation
2025-03-25 08:47:37,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:37,812:INFO:Calculating mean and std
2025-03-25 08:47:37,812:INFO:Creating metrics dataframe
2025-03-25 08:47:37,814:INFO:Uploading results into container
2025-03-25 08:47:37,814:INFO:Uploading model into container now
2025-03-25 08:47:37,814:INFO:_master_model_container: 5
2025-03-25 08:47:37,814:INFO:_display_container: 2
2025-03-25 08:47:37,815:INFO:Lars(random_state=2242)
2025-03-25 08:47:37,815:INFO:create_model() successfully completed......................................
2025-03-25 08:47:37,915:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:37,915:INFO:Creating metrics dataframe
2025-03-25 08:47:37,922:INFO:Initializing Lasso Least Angle Regression
2025-03-25 08:47:37,922:INFO:Total runtime is 0.11338719526926677 minutes
2025-03-25 08:47:37,924:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:37,924:INFO:Initializing create_model()
2025-03-25 08:47:37,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:37,924:INFO:Checking exceptions
2025-03-25 08:47:37,924:INFO:Importing libraries
2025-03-25 08:47:37,924:INFO:Copying training dataset
2025-03-25 08:47:37,932:INFO:Defining folds
2025-03-25 08:47:37,932:INFO:Declaring metric variables
2025-03-25 08:47:37,935:INFO:Importing untrained model
2025-03-25 08:47:37,938:INFO:Lasso Least Angle Regression Imported successfully
2025-03-25 08:47:37,943:INFO:Starting cross validation
2025-03-25 08:47:37,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:38,214:INFO:Calculating mean and std
2025-03-25 08:47:38,215:INFO:Creating metrics dataframe
2025-03-25 08:47:38,217:INFO:Uploading results into container
2025-03-25 08:47:38,218:INFO:Uploading model into container now
2025-03-25 08:47:38,218:INFO:_master_model_container: 6
2025-03-25 08:47:38,218:INFO:_display_container: 2
2025-03-25 08:47:38,218:INFO:LassoLars(random_state=2242)
2025-03-25 08:47:38,219:INFO:create_model() successfully completed......................................
2025-03-25 08:47:38,317:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:38,317:INFO:Creating metrics dataframe
2025-03-25 08:47:38,323:INFO:Initializing Orthogonal Matching Pursuit
2025-03-25 08:47:38,323:INFO:Total runtime is 0.12008169492085775 minutes
2025-03-25 08:47:38,325:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:38,325:INFO:Initializing create_model()
2025-03-25 08:47:38,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:38,326:INFO:Checking exceptions
2025-03-25 08:47:38,326:INFO:Importing libraries
2025-03-25 08:47:38,326:INFO:Copying training dataset
2025-03-25 08:47:38,334:INFO:Defining folds
2025-03-25 08:47:38,334:INFO:Declaring metric variables
2025-03-25 08:47:38,337:INFO:Importing untrained model
2025-03-25 08:47:38,340:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-25 08:47:38,343:INFO:Starting cross validation
2025-03-25 08:47:38,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:38,591:INFO:Calculating mean and std
2025-03-25 08:47:38,592:INFO:Creating metrics dataframe
2025-03-25 08:47:38,593:INFO:Uploading results into container
2025-03-25 08:47:38,593:INFO:Uploading model into container now
2025-03-25 08:47:38,594:INFO:_master_model_container: 7
2025-03-25 08:47:38,594:INFO:_display_container: 2
2025-03-25 08:47:38,594:INFO:OrthogonalMatchingPursuit()
2025-03-25 08:47:38,594:INFO:create_model() successfully completed......................................
2025-03-25 08:47:38,694:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:38,694:INFO:Creating metrics dataframe
2025-03-25 08:47:38,700:INFO:Initializing Bayesian Ridge
2025-03-25 08:47:38,700:INFO:Total runtime is 0.12635663350423176 minutes
2025-03-25 08:47:38,702:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:38,702:INFO:Initializing create_model()
2025-03-25 08:47:38,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:38,702:INFO:Checking exceptions
2025-03-25 08:47:38,703:INFO:Importing libraries
2025-03-25 08:47:38,703:INFO:Copying training dataset
2025-03-25 08:47:38,710:INFO:Defining folds
2025-03-25 08:47:38,710:INFO:Declaring metric variables
2025-03-25 08:47:38,713:INFO:Importing untrained model
2025-03-25 08:47:38,716:INFO:Bayesian Ridge Imported successfully
2025-03-25 08:47:38,723:INFO:Starting cross validation
2025-03-25 08:47:38,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:39,009:INFO:Calculating mean and std
2025-03-25 08:47:39,010:INFO:Creating metrics dataframe
2025-03-25 08:47:39,010:INFO:Uploading results into container
2025-03-25 08:47:39,012:INFO:Uploading model into container now
2025-03-25 08:47:39,012:INFO:_master_model_container: 8
2025-03-25 08:47:39,012:INFO:_display_container: 2
2025-03-25 08:47:39,013:INFO:BayesianRidge()
2025-03-25 08:47:39,013:INFO:create_model() successfully completed......................................
2025-03-25 08:47:39,104:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:39,104:INFO:Creating metrics dataframe
2025-03-25 08:47:39,109:INFO:Initializing Passive Aggressive Regressor
2025-03-25 08:47:39,109:INFO:Total runtime is 0.13317962090174357 minutes
2025-03-25 08:47:39,112:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:39,112:INFO:Initializing create_model()
2025-03-25 08:47:39,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:39,112:INFO:Checking exceptions
2025-03-25 08:47:39,112:INFO:Importing libraries
2025-03-25 08:47:39,112:INFO:Copying training dataset
2025-03-25 08:47:39,120:INFO:Defining folds
2025-03-25 08:47:39,120:INFO:Declaring metric variables
2025-03-25 08:47:39,123:INFO:Importing untrained model
2025-03-25 08:47:39,125:INFO:Passive Aggressive Regressor Imported successfully
2025-03-25 08:47:39,129:INFO:Starting cross validation
2025-03-25 08:47:39,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:39,576:INFO:Calculating mean and std
2025-03-25 08:47:39,577:INFO:Creating metrics dataframe
2025-03-25 08:47:39,578:INFO:Uploading results into container
2025-03-25 08:47:39,578:INFO:Uploading model into container now
2025-03-25 08:47:39,579:INFO:_master_model_container: 9
2025-03-25 08:47:39,579:INFO:_display_container: 2
2025-03-25 08:47:39,579:INFO:PassiveAggressiveRegressor(random_state=2242)
2025-03-25 08:47:39,579:INFO:create_model() successfully completed......................................
2025-03-25 08:47:39,672:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:39,672:INFO:Creating metrics dataframe
2025-03-25 08:47:39,678:INFO:Initializing Huber Regressor
2025-03-25 08:47:39,678:INFO:Total runtime is 0.14266188542048136 minutes
2025-03-25 08:47:39,680:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:39,680:INFO:Initializing create_model()
2025-03-25 08:47:39,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:39,680:INFO:Checking exceptions
2025-03-25 08:47:39,680:INFO:Importing libraries
2025-03-25 08:47:39,680:INFO:Copying training dataset
2025-03-25 08:47:39,690:INFO:Defining folds
2025-03-25 08:47:39,690:INFO:Declaring metric variables
2025-03-25 08:47:39,693:INFO:Importing untrained model
2025-03-25 08:47:39,696:INFO:Huber Regressor Imported successfully
2025-03-25 08:47:39,699:INFO:Starting cross validation
2025-03-25 08:47:39,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:41,550:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,573:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,584:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,586:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,624:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,624:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,680:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,695:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,717:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,745:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-25 08:47:41,767:INFO:Calculating mean and std
2025-03-25 08:47:41,768:INFO:Creating metrics dataframe
2025-03-25 08:47:41,769:INFO:Uploading results into container
2025-03-25 08:47:41,770:INFO:Uploading model into container now
2025-03-25 08:47:41,770:INFO:_master_model_container: 10
2025-03-25 08:47:41,770:INFO:_display_container: 2
2025-03-25 08:47:41,770:INFO:HuberRegressor()
2025-03-25 08:47:41,770:INFO:create_model() successfully completed......................................
2025-03-25 08:47:41,868:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:41,869:INFO:Creating metrics dataframe
2025-03-25 08:47:41,875:INFO:Initializing K Neighbors Regressor
2025-03-25 08:47:41,875:INFO:Total runtime is 0.1792699098587036 minutes
2025-03-25 08:47:41,878:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:41,878:INFO:Initializing create_model()
2025-03-25 08:47:41,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:41,878:INFO:Checking exceptions
2025-03-25 08:47:41,878:INFO:Importing libraries
2025-03-25 08:47:41,878:INFO:Copying training dataset
2025-03-25 08:47:41,886:INFO:Defining folds
2025-03-25 08:47:41,886:INFO:Declaring metric variables
2025-03-25 08:47:41,889:INFO:Importing untrained model
2025-03-25 08:47:41,891:INFO:K Neighbors Regressor Imported successfully
2025-03-25 08:47:41,894:INFO:Starting cross validation
2025-03-25 08:47:41,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:42,700:INFO:Calculating mean and std
2025-03-25 08:47:42,700:INFO:Creating metrics dataframe
2025-03-25 08:47:42,703:INFO:Uploading results into container
2025-03-25 08:47:42,704:INFO:Uploading model into container now
2025-03-25 08:47:42,704:INFO:_master_model_container: 11
2025-03-25 08:47:42,704:INFO:_display_container: 2
2025-03-25 08:47:42,704:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-25 08:47:42,705:INFO:create_model() successfully completed......................................
2025-03-25 08:47:42,799:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:42,799:INFO:Creating metrics dataframe
2025-03-25 08:47:42,804:INFO:Initializing Decision Tree Regressor
2025-03-25 08:47:42,804:INFO:Total runtime is 0.1947669784228007 minutes
2025-03-25 08:47:42,806:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:42,807:INFO:Initializing create_model()
2025-03-25 08:47:42,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:42,807:INFO:Checking exceptions
2025-03-25 08:47:42,807:INFO:Importing libraries
2025-03-25 08:47:42,807:INFO:Copying training dataset
2025-03-25 08:47:42,816:INFO:Defining folds
2025-03-25 08:47:42,816:INFO:Declaring metric variables
2025-03-25 08:47:42,819:INFO:Importing untrained model
2025-03-25 08:47:42,821:INFO:Decision Tree Regressor Imported successfully
2025-03-25 08:47:42,825:INFO:Starting cross validation
2025-03-25 08:47:42,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:43,154:INFO:Calculating mean and std
2025-03-25 08:47:43,155:INFO:Creating metrics dataframe
2025-03-25 08:47:43,156:INFO:Uploading results into container
2025-03-25 08:47:43,156:INFO:Uploading model into container now
2025-03-25 08:47:43,157:INFO:_master_model_container: 12
2025-03-25 08:47:43,157:INFO:_display_container: 2
2025-03-25 08:47:43,157:INFO:DecisionTreeRegressor(random_state=2242)
2025-03-25 08:47:43,157:INFO:create_model() successfully completed......................................
2025-03-25 08:47:43,250:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:43,250:INFO:Creating metrics dataframe
2025-03-25 08:47:43,257:INFO:Initializing Random Forest Regressor
2025-03-25 08:47:43,257:INFO:Total runtime is 0.202312171459198 minutes
2025-03-25 08:47:43,259:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:43,260:INFO:Initializing create_model()
2025-03-25 08:47:43,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:43,260:INFO:Checking exceptions
2025-03-25 08:47:43,260:INFO:Importing libraries
2025-03-25 08:47:43,260:INFO:Copying training dataset
2025-03-25 08:47:43,267:INFO:Defining folds
2025-03-25 08:47:43,267:INFO:Declaring metric variables
2025-03-25 08:47:43,270:INFO:Importing untrained model
2025-03-25 08:47:43,273:INFO:Random Forest Regressor Imported successfully
2025-03-25 08:47:43,277:INFO:Starting cross validation
2025-03-25 08:47:43,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:49,584:INFO:Calculating mean and std
2025-03-25 08:47:49,586:INFO:Creating metrics dataframe
2025-03-25 08:47:49,588:INFO:Uploading results into container
2025-03-25 08:47:49,588:INFO:Uploading model into container now
2025-03-25 08:47:49,589:INFO:_master_model_container: 13
2025-03-25 08:47:49,589:INFO:_display_container: 2
2025-03-25 08:47:49,589:INFO:RandomForestRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:47:49,590:INFO:create_model() successfully completed......................................
2025-03-25 08:47:49,692:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:49,692:INFO:Creating metrics dataframe
2025-03-25 08:47:49,699:INFO:Initializing Extra Trees Regressor
2025-03-25 08:47:49,699:INFO:Total runtime is 0.30966941912968954 minutes
2025-03-25 08:47:49,702:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:49,702:INFO:Initializing create_model()
2025-03-25 08:47:49,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:49,703:INFO:Checking exceptions
2025-03-25 08:47:49,703:INFO:Importing libraries
2025-03-25 08:47:49,703:INFO:Copying training dataset
2025-03-25 08:47:49,710:INFO:Defining folds
2025-03-25 08:47:49,710:INFO:Declaring metric variables
2025-03-25 08:47:49,714:INFO:Importing untrained model
2025-03-25 08:47:49,716:INFO:Extra Trees Regressor Imported successfully
2025-03-25 08:47:49,720:INFO:Starting cross validation
2025-03-25 08:47:49,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:53,858:INFO:Calculating mean and std
2025-03-25 08:47:53,859:INFO:Creating metrics dataframe
2025-03-25 08:47:53,861:INFO:Uploading results into container
2025-03-25 08:47:53,861:INFO:Uploading model into container now
2025-03-25 08:47:53,861:INFO:_master_model_container: 14
2025-03-25 08:47:53,862:INFO:_display_container: 2
2025-03-25 08:47:53,862:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:47:53,862:INFO:create_model() successfully completed......................................
2025-03-25 08:47:53,977:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:53,977:INFO:Creating metrics dataframe
2025-03-25 08:47:53,985:INFO:Initializing AdaBoost Regressor
2025-03-25 08:47:53,986:INFO:Total runtime is 0.3811225175857544 minutes
2025-03-25 08:47:53,989:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:53,989:INFO:Initializing create_model()
2025-03-25 08:47:53,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:53,990:INFO:Checking exceptions
2025-03-25 08:47:53,990:INFO:Importing libraries
2025-03-25 08:47:53,990:INFO:Copying training dataset
2025-03-25 08:47:53,999:INFO:Defining folds
2025-03-25 08:47:53,999:INFO:Declaring metric variables
2025-03-25 08:47:54,004:INFO:Importing untrained model
2025-03-25 08:47:54,009:INFO:AdaBoost Regressor Imported successfully
2025-03-25 08:47:54,016:INFO:Starting cross validation
2025-03-25 08:47:54,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:55,102:INFO:Calculating mean and std
2025-03-25 08:47:55,104:INFO:Creating metrics dataframe
2025-03-25 08:47:55,105:INFO:Uploading results into container
2025-03-25 08:47:55,106:INFO:Uploading model into container now
2025-03-25 08:47:55,106:INFO:_master_model_container: 15
2025-03-25 08:47:55,106:INFO:_display_container: 2
2025-03-25 08:47:55,106:INFO:AdaBoostRegressor(random_state=2242)
2025-03-25 08:47:55,107:INFO:create_model() successfully completed......................................
2025-03-25 08:47:55,225:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:55,225:INFO:Creating metrics dataframe
2025-03-25 08:47:55,234:INFO:Initializing Gradient Boosting Regressor
2025-03-25 08:47:55,234:INFO:Total runtime is 0.4019309719403585 minutes
2025-03-25 08:47:55,236:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:55,237:INFO:Initializing create_model()
2025-03-25 08:47:55,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:55,237:INFO:Checking exceptions
2025-03-25 08:47:55,237:INFO:Importing libraries
2025-03-25 08:47:55,237:INFO:Copying training dataset
2025-03-25 08:47:55,248:INFO:Defining folds
2025-03-25 08:47:55,248:INFO:Declaring metric variables
2025-03-25 08:47:55,252:INFO:Importing untrained model
2025-03-25 08:47:55,255:INFO:Gradient Boosting Regressor Imported successfully
2025-03-25 08:47:55,259:INFO:Starting cross validation
2025-03-25 08:47:55,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:57,458:INFO:Calculating mean and std
2025-03-25 08:47:57,459:INFO:Creating metrics dataframe
2025-03-25 08:47:57,460:INFO:Uploading results into container
2025-03-25 08:47:57,460:INFO:Uploading model into container now
2025-03-25 08:47:57,460:INFO:_master_model_container: 16
2025-03-25 08:47:57,460:INFO:_display_container: 2
2025-03-25 08:47:57,462:INFO:GradientBoostingRegressor(random_state=2242)
2025-03-25 08:47:57,462:INFO:create_model() successfully completed......................................
2025-03-25 08:47:57,554:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:57,554:INFO:Creating metrics dataframe
2025-03-25 08:47:57,562:INFO:Initializing Light Gradient Boosting Machine
2025-03-25 08:47:57,562:INFO:Total runtime is 0.44071967204411827 minutes
2025-03-25 08:47:57,564:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:57,564:INFO:Initializing create_model()
2025-03-25 08:47:57,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:57,564:INFO:Checking exceptions
2025-03-25 08:47:57,564:INFO:Importing libraries
2025-03-25 08:47:57,564:INFO:Copying training dataset
2025-03-25 08:47:57,572:INFO:Defining folds
2025-03-25 08:47:57,573:INFO:Declaring metric variables
2025-03-25 08:47:57,575:INFO:Importing untrained model
2025-03-25 08:47:57,577:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-25 08:47:57,582:INFO:Starting cross validation
2025-03-25 08:47:57,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:58,430:INFO:Calculating mean and std
2025-03-25 08:47:58,430:INFO:Creating metrics dataframe
2025-03-25 08:47:58,433:INFO:Uploading results into container
2025-03-25 08:47:58,433:INFO:Uploading model into container now
2025-03-25 08:47:58,433:INFO:_master_model_container: 17
2025-03-25 08:47:58,433:INFO:_display_container: 2
2025-03-25 08:47:58,435:INFO:LGBMRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:47:58,435:INFO:create_model() successfully completed......................................
2025-03-25 08:47:58,548:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:58,548:INFO:Creating metrics dataframe
2025-03-25 08:47:58,556:INFO:Initializing Dummy Regressor
2025-03-25 08:47:58,557:INFO:Total runtime is 0.45731576681137087 minutes
2025-03-25 08:47:58,560:INFO:SubProcess create_model() called ==================================
2025-03-25 08:47:58,560:INFO:Initializing create_model()
2025-03-25 08:47:58,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA8DE9A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:58,560:INFO:Checking exceptions
2025-03-25 08:47:58,560:INFO:Importing libraries
2025-03-25 08:47:58,560:INFO:Copying training dataset
2025-03-25 08:47:58,568:INFO:Defining folds
2025-03-25 08:47:58,568:INFO:Declaring metric variables
2025-03-25 08:47:58,572:INFO:Importing untrained model
2025-03-25 08:47:58,573:INFO:Dummy Regressor Imported successfully
2025-03-25 08:47:58,577:INFO:Starting cross validation
2025-03-25 08:47:58,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:47:58,791:INFO:Calculating mean and std
2025-03-25 08:47:58,793:INFO:Creating metrics dataframe
2025-03-25 08:47:58,794:INFO:Uploading results into container
2025-03-25 08:47:58,795:INFO:Uploading model into container now
2025-03-25 08:47:58,795:INFO:_master_model_container: 18
2025-03-25 08:47:58,795:INFO:_display_container: 2
2025-03-25 08:47:58,796:INFO:DummyRegressor()
2025-03-25 08:47:58,796:INFO:create_model() successfully completed......................................
2025-03-25 08:47:58,890:INFO:SubProcess create_model() end ==================================
2025-03-25 08:47:58,890:INFO:Creating metrics dataframe
2025-03-25 08:47:58,897:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-25 08:47:58,903:INFO:Initializing create_model()
2025-03-25 08:47:58,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:47:58,903:INFO:Checking exceptions
2025-03-25 08:47:58,904:INFO:Importing libraries
2025-03-25 08:47:58,904:INFO:Copying training dataset
2025-03-25 08:47:58,910:INFO:Defining folds
2025-03-25 08:47:58,910:INFO:Declaring metric variables
2025-03-25 08:47:58,910:INFO:Importing untrained model
2025-03-25 08:47:58,910:INFO:Declaring custom model
2025-03-25 08:47:58,912:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-25 08:47:58,913:INFO:Cross validation set to False
2025-03-25 08:47:58,913:INFO:Fitting Model
2025-03-25 08:47:58,994:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-25 08:47:58,996:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.
2025-03-25 08:47:58,996:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:47:58,996:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:47:58,996:INFO:[LightGBM] [Info] Total Bins 564
2025-03-25 08:47:58,996:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-25 08:47:58,997:INFO:[LightGBM] [Info] Start training from score 3258.142167
2025-03-25 08:47:59,069:INFO:LGBMRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:47:59,069:INFO:create_model() successfully completed......................................
2025-03-25 08:47:59,193:INFO:_master_model_container: 18
2025-03-25 08:47:59,193:INFO:_display_container: 2
2025-03-25 08:47:59,194:INFO:LGBMRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:47:59,194:INFO:compare_models() successfully completed......................................
2025-03-25 08:48:47,525:INFO:Initializing plot_model()
2025-03-25 08:48:47,525:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=5755), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA8D6D510>, system=True)
2025-03-25 08:48:47,525:INFO:Checking exceptions
2025-03-25 08:48:47,530:INFO:Preloading libraries
2025-03-25 08:48:47,533:INFO:Copying training dataset
2025-03-25 08:48:47,534:INFO:Plot type: residuals
2025-03-25 08:48:47,790:INFO:Fitting Model
2025-03-25 08:48:47,845:INFO:Scoring test/hold-out set
2025-03-25 08:48:48,283:INFO:Visual Rendered Successfully
2025-03-25 08:48:48,385:INFO:plot_model() successfully completed......................................
2025-03-25 08:48:50,501:INFO:Initializing evaluate_model()
2025-03-25 08:48:50,501:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-25 08:48:50,510:INFO:Initializing plot_model()
2025-03-25 08:48:50,510:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:48:50,510:INFO:Checking exceptions
2025-03-25 08:48:50,514:INFO:Preloading libraries
2025-03-25 08:48:50,517:INFO:Copying training dataset
2025-03-25 08:48:50,517:INFO:Plot type: pipeline
2025-03-25 08:48:50,611:INFO:Visual Rendered Successfully
2025-03-25 08:48:50,707:INFO:plot_model() successfully completed......................................
2025-03-25 08:48:52,512:INFO:Initializing plot_model()
2025-03-25 08:48:52,513:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:48:52,513:INFO:Checking exceptions
2025-03-25 08:48:52,516:INFO:Preloading libraries
2025-03-25 08:48:52,518:INFO:Copying training dataset
2025-03-25 08:48:52,518:INFO:Plot type: residuals
2025-03-25 08:48:52,763:INFO:Fitting Model
2025-03-25 08:48:52,823:INFO:Scoring test/hold-out set
2025-03-25 08:48:53,170:INFO:Visual Rendered Successfully
2025-03-25 08:48:53,267:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:01,157:INFO:Initializing plot_model()
2025-03-25 08:49:01,158:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:01,158:INFO:Checking exceptions
2025-03-25 08:49:01,162:INFO:Preloading libraries
2025-03-25 08:49:01,164:INFO:Copying training dataset
2025-03-25 08:49:01,164:INFO:Plot type: error
2025-03-25 08:49:01,393:INFO:Fitting Model
2025-03-25 08:49:01,393:INFO:Scoring test/hold-out set
2025-03-25 08:49:01,601:INFO:Visual Rendered Successfully
2025-03-25 08:49:01,694:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:08,373:INFO:Initializing plot_model()
2025-03-25 08:49:08,373:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:08,374:INFO:Checking exceptions
2025-03-25 08:49:08,377:INFO:Preloading libraries
2025-03-25 08:49:08,380:INFO:Copying training dataset
2025-03-25 08:49:08,381:INFO:Plot type: rfe
2025-03-25 08:49:08,616:INFO:Fitting Model
2025-03-25 08:49:08,640:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000576 seconds.
2025-03-25 08:49:08,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:08,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:08,641:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:08,641:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:08,641:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:08,722:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-03-25 08:49:08,722:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:08,722:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:08,722:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:08,722:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:08,722:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:08,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.
2025-03-25 08:49:08,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:08,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:08,799:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:08,799:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:08,799:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:08,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.
2025-03-25 08:49:08,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:08,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:08,876:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:08,876:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:08,876:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:08,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
2025-03-25 08:49:08,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:08,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:08,958:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:08,958:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:08,958:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-03-25 08:49:09,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,033:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,033:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.
2025-03-25 08:49:09,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,108:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,108:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,108:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001010 seconds.
2025-03-25 08:49:09,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,187:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,187:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,187:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,264:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
2025-03-25 08:49:09,265:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,265:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,265:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,265:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,265:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,343:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-25 08:49:09,343:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,343:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,343:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,343:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,343:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,423:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.
2025-03-25 08:49:09,423:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,423:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,423:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,423:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,423:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.
2025-03-25 08:49:09,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,503:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,503:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,503:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-03-25 08:49:09,582:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,582:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,582:INFO:[LightGBM] [Info] Total Bins 557
2025-03-25 08:49:09,582:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:09,582:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,656:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-25 08:49:09,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,656:INFO:[LightGBM] [Info] Total Bins 548
2025-03-25 08:49:09,656:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-25 08:49:09,656:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-25 08:49:09,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,737:INFO:[LightGBM] [Info] Total Bins 546
2025-03-25 08:49:09,737:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-25 08:49:09,737:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,816:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-25 08:49:09,816:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,816:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,816:INFO:[LightGBM] [Info] Total Bins 544
2025-03-25 08:49:09,816:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-25 08:49:09,816:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.
2025-03-25 08:49:09,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,883:INFO:[LightGBM] [Info] Total Bins 542
2025-03-25 08:49:09,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-25 08:49:09,883:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:09,959:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-03-25 08:49:09,959:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:09,960:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:09,960:INFO:[LightGBM] [Info] Total Bins 540
2025-03-25 08:49:09,960:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-25 08:49:09,960:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,030:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-25 08:49:10,030:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,030:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,030:INFO:[LightGBM] [Info] Total Bins 538
2025-03-25 08:49:10,030:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-25 08:49:10,030:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,105:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000561 seconds.
2025-03-25 08:49:10,105:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,105:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,105:INFO:[LightGBM] [Info] Total Bins 536
2025-03-25 08:49:10,105:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-25 08:49:10,105:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,182:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-03-25 08:49:10,182:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,182:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,182:INFO:[LightGBM] [Info] Total Bins 534
2025-03-25 08:49:10,182:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-25 08:49:10,182:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.
2025-03-25 08:49:10,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,254:INFO:[LightGBM] [Info] Total Bins 532
2025-03-25 08:49:10,254:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-25 08:49:10,254:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,325:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-25 08:49:10,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,326:INFO:[LightGBM] [Info] Total Bins 530
2025-03-25 08:49:10,326:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-25 08:49:10,326:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,429:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000080 seconds.
2025-03-25 08:49:10,429:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,429:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,429:INFO:[LightGBM] [Info] Total Bins 528
2025-03-25 08:49:10,429:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-25 08:49:10,429:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,504:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.
2025-03-25 08:49:10,504:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,504:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,504:INFO:[LightGBM] [Info] Total Bins 526
2025-03-25 08:49:10,504:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-25 08:49:10,504:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000057 seconds.
2025-03-25 08:49:10,572:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,572:INFO:[LightGBM] [Info] Total Bins 299
2025-03-25 08:49:10,572:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-25 08:49:10,572:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.
2025-03-25 08:49:10,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,633:INFO:[LightGBM] [Info] Total Bins 255
2025-03-25 08:49:10,633:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 1
2025-03-25 08:49:10,633:INFO:[LightGBM] [Info] Start training from score 3262.372806
2025-03-25 08:49:10,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.
2025-03-25 08:49:10,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,720:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:10,720:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:10,720:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:10,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000520 seconds.
2025-03-25 08:49:10,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,799:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:10,799:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:10,799:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:10,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.
2025-03-25 08:49:10,877:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,877:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,877:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:10,877:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:10,877:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:10,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.
2025-03-25 08:49:10,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:10,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:10,955:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:10,955:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:10,955:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.
2025-03-25 08:49:11,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,033:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,033:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.
2025-03-25 08:49:11,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,108:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,108:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,109:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.
2025-03-25 08:49:11,205:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,205:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,205:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,205:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,205:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000548 seconds.
2025-03-25 08:49:11,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,285:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,285:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,285:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,285:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.
2025-03-25 08:49:11,362:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,362:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,362:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,362:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,362:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.
2025-03-25 08:49:11,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,442:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,442:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,442:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,517:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.
2025-03-25 08:49:11,517:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,517:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,518:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,518:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,518:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.
2025-03-25 08:49:11,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,597:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,597:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,597:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.
2025-03-25 08:49:11,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,676:INFO:[LightGBM] [Info] Total Bins 563
2025-03-25 08:49:11,676:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-25 08:49:11,676:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,753:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000583 seconds.
2025-03-25 08:49:11,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,754:INFO:[LightGBM] [Info] Total Bins 561
2025-03-25 08:49:11,754:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-25 08:49:11,754:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.
2025-03-25 08:49:11,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,836:INFO:[LightGBM] [Info] Total Bins 559
2025-03-25 08:49:11,836:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-25 08:49:11,836:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:11,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.
2025-03-25 08:49:11,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:11,923:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:11,923:INFO:[LightGBM] [Info] Total Bins 551
2025-03-25 08:49:11,923:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-25 08:49:11,923:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,017:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.
2025-03-25 08:49:12,017:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,018:INFO:[LightGBM] [Info] Total Bins 549
2025-03-25 08:49:12,018:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-25 08:49:12,018:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.
2025-03-25 08:49:12,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,100:INFO:[LightGBM] [Info] Total Bins 547
2025-03-25 08:49:12,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-25 08:49:12,102:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,192:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.
2025-03-25 08:49:12,192:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,192:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,192:INFO:[LightGBM] [Info] Total Bins 545
2025-03-25 08:49:12,192:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-25 08:49:12,192:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,272:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-25 08:49:12,272:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,272:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,272:INFO:[LightGBM] [Info] Total Bins 543
2025-03-25 08:49:12,272:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-25 08:49:12,272:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.
2025-03-25 08:49:12,360:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,360:INFO:[LightGBM] [Info] Total Bins 541
2025-03-25 08:49:12,360:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-25 08:49:12,360:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.
2025-03-25 08:49:12,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,443:INFO:[LightGBM] [Info] Total Bins 539
2025-03-25 08:49:12,443:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-25 08:49:12,443:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,535:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-25 08:49:12,535:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,535:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,535:INFO:[LightGBM] [Info] Total Bins 537
2025-03-25 08:49:12,535:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-25 08:49:12,536:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,622:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.
2025-03-25 08:49:12,622:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,622:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,622:INFO:[LightGBM] [Info] Total Bins 535
2025-03-25 08:49:12,622:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-25 08:49:12,622:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.
2025-03-25 08:49:12,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,703:INFO:[LightGBM] [Info] Total Bins 533
2025-03-25 08:49:12,703:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-25 08:49:12,703:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,784:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.
2025-03-25 08:49:12,784:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,784:INFO:[LightGBM] [Info] Total Bins 488
2025-03-25 08:49:12,785:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-25 08:49:12,785:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,868:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.
2025-03-25 08:49:12,868:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,868:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,868:INFO:[LightGBM] [Info] Total Bins 255
2025-03-25 08:49:12,868:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 1
2025-03-25 08:49:12,868:INFO:[LightGBM] [Info] Start training from score 3258.002272
2025-03-25 08:49:12,970:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000570 seconds.
2025-03-25 08:49:12,972:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:12,972:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:12,972:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:12,972:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:12,972:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.
2025-03-25 08:49:13,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,063:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,064:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,064:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.
2025-03-25 08:49:13,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,157:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,157:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,157:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000576 seconds.
2025-03-25 08:49:13,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,250:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,251:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,251:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-03-25 08:49:13,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,350:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,350:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,350:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,444:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.
2025-03-25 08:49:13,444:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,444:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,444:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,444:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,445:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,538:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.
2025-03-25 08:49:13,538:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,538:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,538:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,538:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,539:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,630:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.
2025-03-25 08:49:13,630:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,630:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,632:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,632:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,632:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.
2025-03-25 08:49:13,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,726:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,726:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,727:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,813:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.
2025-03-25 08:49:13,813:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,813:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,813:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,813:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,813:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-25 08:49:13,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,883:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,883:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:13,963:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-25 08:49:13,963:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:13,963:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:13,963:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:13,963:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:13,963:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:14,035:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-25 08:49:14,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:14,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:14,036:INFO:[LightGBM] [Info] Total Bins 562
2025-03-25 08:49:14,036:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-25 08:49:14,036:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:14,113:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-25 08:49:14,113:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:14,113:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:14,113:INFO:[LightGBM] [Info] Total Bins 554
2025-03-25 08:49:14,113:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-25 08:49:14,113:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:14,189:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-25 08:49:14,189:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:49:14,189:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:49:14,189:INFO:[LightGBM] [Info] Total Bins 552
2025-03-25 08:49:14,189:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-25 08:49:14,189:INFO:[LightGBM] [Info] Start training from score 3253.857514
2025-03-25 08:49:15,157:INFO:Initializing evaluate_model()
2025-03-25 08:49:15,157:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-25 08:49:15,164:INFO:Initializing plot_model()
2025-03-25 08:49:15,165:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:15,165:INFO:Checking exceptions
2025-03-25 08:49:15,167:INFO:Preloading libraries
2025-03-25 08:49:15,170:INFO:Copying training dataset
2025-03-25 08:49:15,170:INFO:Plot type: pipeline
2025-03-25 08:49:15,252:INFO:Visual Rendered Successfully
2025-03-25 08:49:15,386:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:15,407:INFO:Initializing evaluate_model()
2025-03-25 08:49:15,408:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-25 08:49:15,415:INFO:Initializing plot_model()
2025-03-25 08:49:15,416:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:15,416:INFO:Checking exceptions
2025-03-25 08:49:15,418:INFO:Preloading libraries
2025-03-25 08:49:15,422:INFO:Copying training dataset
2025-03-25 08:49:15,422:INFO:Plot type: pipeline
2025-03-25 08:49:15,513:INFO:Visual Rendered Successfully
2025-03-25 08:49:15,633:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:15,654:INFO:Initializing plot_model()
2025-03-25 08:49:15,654:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:15,655:INFO:Checking exceptions
2025-03-25 08:49:15,658:INFO:Preloading libraries
2025-03-25 08:49:15,661:INFO:Copying training dataset
2025-03-25 08:49:15,661:INFO:Plot type: feature_all
2025-03-25 08:49:15,754:WARNING:No coef_ found. Trying feature_importances_
2025-03-25 08:49:15,960:INFO:Visual Rendered Successfully
2025-03-25 08:49:16,082:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:16,699:INFO:Initializing plot_model()
2025-03-25 08:49:16,699:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:16,699:INFO:Checking exceptions
2025-03-25 08:49:16,703:INFO:Preloading libraries
2025-03-25 08:49:16,706:INFO:Copying training dataset
2025-03-25 08:49:16,706:INFO:Plot type: feature_all
2025-03-25 08:49:16,806:WARNING:No coef_ found. Trying feature_importances_
2025-03-25 08:49:17,000:INFO:Visual Rendered Successfully
2025-03-25 08:49:17,128:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:35,210:INFO:Initializing plot_model()
2025-03-25 08:49:35,210:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:35,210:INFO:Checking exceptions
2025-03-25 08:49:35,214:INFO:Preloading libraries
2025-03-25 08:49:35,217:INFO:Copying training dataset
2025-03-25 08:49:35,217:INFO:Plot type: error
2025-03-25 08:49:35,452:INFO:Fitting Model
2025-03-25 08:49:35,452:INFO:Scoring test/hold-out set
2025-03-25 08:49:35,652:INFO:Visual Rendered Successfully
2025-03-25 08:49:35,782:INFO:plot_model() successfully completed......................................
2025-03-25 08:49:37,499:INFO:Initializing plot_model()
2025-03-25 08:49:37,499:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, system=True)
2025-03-25 08:49:37,500:INFO:Checking exceptions
2025-03-25 08:49:37,504:INFO:Preloading libraries
2025-03-25 08:49:37,507:INFO:Copying training dataset
2025-03-25 08:49:37,507:INFO:Plot type: residuals
2025-03-25 08:49:37,763:INFO:Fitting Model
2025-03-25 08:49:37,810:INFO:Scoring test/hold-out set
2025-03-25 08:49:38,167:INFO:Visual Rendered Successfully
2025-03-25 08:49:38,311:INFO:plot_model() successfully completed......................................
2025-03-25 08:50:31,720:INFO:Initializing tune_model()
2025-03-25 08:50:31,720:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>)
2025-03-25 08:50:31,720:INFO:Checking exceptions
2025-03-25 08:50:31,735:INFO:Copying training dataset
2025-03-25 08:50:31,744:INFO:Checking base model
2025-03-25 08:50:31,744:INFO:Base model : Light Gradient Boosting Machine
2025-03-25 08:50:31,748:INFO:Declaring metric variables
2025-03-25 08:50:31,751:INFO:Defining Hyperparameters
2025-03-25 08:50:31,884:INFO:Tuning with n_jobs=-1
2025-03-25 08:50:31,884:INFO:Initializing RandomizedSearchCV
2025-03-25 08:50:41,352:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 5, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.8}
2025-03-25 08:50:41,352:INFO:Hyperparameter search completed
2025-03-25 08:50:41,352:INFO:SubProcess create_model() called ==================================
2025-03-25 08:50:41,353:INFO:Initializing create_model()
2025-03-25 08:50:41,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA92341C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 4, 'reg_alpha': 5, 'num_leaves': 40, 'n_estimators': 150, 'min_split_gain': 0.6, 'min_child_samples': 91, 'learning_rate': 0.05, 'feature_fraction': 0.7, 'bagging_freq': 2, 'bagging_fraction': 0.8})
2025-03-25 08:50:41,353:INFO:Checking exceptions
2025-03-25 08:50:41,353:INFO:Importing libraries
2025-03-25 08:50:41,353:INFO:Copying training dataset
2025-03-25 08:50:41,363:INFO:Defining folds
2025-03-25 08:50:41,363:INFO:Declaring metric variables
2025-03-25 08:50:41,365:INFO:Importing untrained model
2025-03-25 08:50:41,365:INFO:Declaring custom model
2025-03-25 08:50:41,368:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-25 08:50:41,372:INFO:Starting cross validation
2025-03-25 08:50:41,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:50:43,010:INFO:Calculating mean and std
2025-03-25 08:50:43,010:INFO:Creating metrics dataframe
2025-03-25 08:50:43,015:INFO:Finalizing model
2025-03-25 08:50:43,117:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-03-25 08:50:43,117:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-03-25 08:50:43,117:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-03-25 08:50:43,129:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-25 08:50:43,130:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-03-25 08:50:43,130:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-03-25 08:50:43,130:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-03-25 08:50:43,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.
2025-03-25 08:50:43,132:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:50:43,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:50:43,132:INFO:[LightGBM] [Info] Total Bins 553
2025-03-25 08:50:43,132:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 13
2025-03-25 08:50:43,132:INFO:[LightGBM] [Info] Start training from score 3258.142167
2025-03-25 08:50:43,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-25 08:50:43,335:INFO:Uploading results into container
2025-03-25 08:50:43,336:INFO:Uploading model into container now
2025-03-25 08:50:43,336:INFO:_master_model_container: 19
2025-03-25 08:50:43,336:INFO:_display_container: 3
2025-03-25 08:50:43,337:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=91, min_split_gain=0.6,
              n_estimators=150, n_jobs=-1, num_leaves=40, random_state=2242,
              reg_alpha=5, reg_lambda=4)
2025-03-25 08:50:43,337:INFO:create_model() successfully completed......................................
2025-03-25 08:50:43,498:INFO:SubProcess create_model() end ==================================
2025-03-25 08:50:43,498:INFO:choose_better activated
2025-03-25 08:50:43,500:INFO:SubProcess create_model() called ==================================
2025-03-25 08:50:43,502:INFO:Initializing create_model()
2025-03-25 08:50:43,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAAA951FF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=2242), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 08:50:43,502:INFO:Checking exceptions
2025-03-25 08:50:43,503:INFO:Importing libraries
2025-03-25 08:50:43,503:INFO:Copying training dataset
2025-03-25 08:50:43,512:INFO:Defining folds
2025-03-25 08:50:43,512:INFO:Declaring metric variables
2025-03-25 08:50:43,512:INFO:Importing untrained model
2025-03-25 08:50:43,512:INFO:Declaring custom model
2025-03-25 08:50:43,513:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-25 08:50:43,513:INFO:Starting cross validation
2025-03-25 08:50:43,514:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 08:50:44,302:INFO:Calculating mean and std
2025-03-25 08:50:44,303:INFO:Creating metrics dataframe
2025-03-25 08:50:44,303:INFO:Finalizing model
2025-03-25 08:50:44,415:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-25 08:50:44,416:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.
2025-03-25 08:50:44,416:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-25 08:50:44,416:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-25 08:50:44,416:INFO:[LightGBM] [Info] Total Bins 564
2025-03-25 08:50:44,417:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-25 08:50:44,417:INFO:[LightGBM] [Info] Start training from score 3258.142167
2025-03-25 08:50:44,486:INFO:Uploading results into container
2025-03-25 08:50:44,487:INFO:Uploading model into container now
2025-03-25 08:50:44,487:INFO:_master_model_container: 20
2025-03-25 08:50:44,487:INFO:_display_container: 4
2025-03-25 08:50:44,488:INFO:LGBMRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:50:44,488:INFO:create_model() successfully completed......................................
2025-03-25 08:50:44,646:INFO:SubProcess create_model() end ==================================
2025-03-25 08:50:44,646:INFO:LGBMRegressor(n_jobs=-1, random_state=2242) result for R2 is 0.2206
2025-03-25 08:50:44,647:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.7,
              learning_rate=0.05, min_child_samples=91, min_split_gain=0.6,
              n_estimators=150, n_jobs=-1, num_leaves=40, random_state=2242,
              reg_alpha=5, reg_lambda=4) result for R2 is 0.2157
2025-03-25 08:50:44,647:INFO:LGBMRegressor(n_jobs=-1, random_state=2242) is best model
2025-03-25 08:50:44,647:INFO:choose_better completed
2025-03-25 08:50:44,647:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-25 08:50:44,655:INFO:_master_model_container: 20
2025-03-25 08:50:44,655:INFO:_display_container: 3
2025-03-25 08:50:44,655:INFO:LGBMRegressor(n_jobs=-1, random_state=2242)
2025-03-25 08:50:44,655:INFO:tune_model() successfully completed......................................
2025-03-25 08:51:32,716:INFO:Initializing save_model()
2025-03-25 08:51:32,716:INFO:save_model(model=LGBMRegressor(n_jobs=-1, random_state=2242), model_name=traffic_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-25 08:51:32,716:INFO:Adding model into prep_pipe
2025-03-25 08:51:32,722:INFO:traffic_model.pkl saved in current working directory
2025-03-25 08:51:32,730:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=2242))])
2025-03-25 08:51:32,730:INFO:save_model() successfully completed......................................
2025-03-25 09:07:24,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:07:24,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:07:24,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:07:24,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:07:27,743:INFO:Initializing load_model()
2025-03-25 09:07:27,743:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-25 09:07:27,824:INFO:Initializing predict_model()
2025-03-25 09:07:27,825:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002066EEBC580>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=2242))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002066F7FB880>)
2025-03-25 09:07:27,825:INFO:Checking exceptions
2025-03-25 09:07:27,825:INFO:Preloading libraries
2025-03-25 09:07:27,826:INFO:Set up data.
2025-03-25 09:07:27,837:INFO:Set up index.
2025-03-25 09:08:46,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:08:46,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:08:46,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:08:46,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 09:08:47,943:INFO:Initializing load_model()
2025-03-25 09:08:47,944:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-25 09:08:48,000:INFO:Initializing predict_model()
2025-03-25 09:08:48,002:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000278BC0E5DB0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=2242))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000278C76CB760>)
2025-03-25 09:08:48,002:INFO:Checking exceptions
2025-03-25 09:08:48,002:INFO:Preloading libraries
2025-03-25 09:08:48,002:INFO:Set up data.
2025-03-25 09:08:48,014:INFO:Set up index.
2025-03-29 14:53:58,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 14:53:58,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 14:53:58,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 14:53:58,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 14:54:02,000:INFO:Initializing load_model()
2025-03-29 14:54:02,000:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-29 14:54:02,153:INFO:Initializing predict_model()
2025-03-29 14:54:02,153:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864F05D50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=2242))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015865174F70>)
2025-03-29 14:54:02,153:INFO:Checking exceptions
2025-03-29 14:54:02,154:INFO:Preloading libraries
2025-03-29 14:54:02,154:INFO:Set up data.
2025-03-29 14:54:02,164:INFO:Set up index.
2025-03-29 14:57:31,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 14:57:31,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 14:57:31,018:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 14:57:31,018:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 14:57:33,002:INFO:Initializing load_model()
2025-03-29 14:57:33,002:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-29 14:57:33,056:INFO:Initializing predict_model()
2025-03-29 14:57:33,056:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014C8E83BF70>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=2242))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014C8D6731C0>)
2025-03-29 14:57:33,056:INFO:Checking exceptions
2025-03-29 14:57:33,056:INFO:Preloading libraries
2025-03-29 14:57:33,056:INFO:Set up data.
2025-03-29 14:57:33,067:INFO:Set up index.
2025-03-29 15:03:17,031:INFO:PyCaret RegressionExperiment
2025-03-29 15:03:17,032:INFO:Logging name: reg-default-name
2025-03-29 15:03:17,032:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 15:03:17,032:INFO:version 3.3.2
2025-03-29 15:03:17,032:INFO:Initializing setup()
2025-03-29 15:03:17,032:INFO:self.USI: 994c
2025-03-29 15:03:17,032:INFO:self._variable_keys: {'seed', 'fold_shuffle_param', 'y', 'memory', 'fold_generator', 'n_jobs_param', 'X', 'gpu_n_jobs_param', 'y_train', 'data', 'X_test', 'idx', 'logging_param', 'log_plots_param', 'exp_id', 'USI', '_ml_usecase', 'y_test', 'exp_name_log', 'pipeline', '_available_plots', 'fold_groups_param', 'gpu_param', 'X_train', 'target_param', 'transform_target_param', 'html_param'}
2025-03-29 15:03:17,032:INFO:Checking environment
2025-03-29 15:03:17,032:INFO:python_version: 3.10.16
2025-03-29 15:03:17,033:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 15:03:17,033:INFO:machine: AMD64
2025-03-29 15:03:17,033:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 15:03:17,036:INFO:Memory: svmem(total=33411727360, available=17934741504, percent=46.3, used=15476985856, free=17934741504)
2025-03-29 15:03:17,036:INFO:Physical Core: 6
2025-03-29 15:03:17,036:INFO:Logical Core: 12
2025-03-29 15:03:17,036:INFO:Checking libraries
2025-03-29 15:03:17,036:INFO:System:
2025-03-29 15:03:17,037:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 15:03:17,037:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 15:03:17,037:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 15:03:17,037:INFO:PyCaret required dependencies:
2025-03-29 15:03:17,037:INFO:                 pip: 25.0.1
2025-03-29 15:03:17,037:INFO:          setuptools: 75.8.2
2025-03-29 15:03:17,037:INFO:             pycaret: 3.3.2
2025-03-29 15:03:17,037:INFO:             IPython: 8.34.0
2025-03-29 15:03:17,037:INFO:          ipywidgets: 8.1.5
2025-03-29 15:03:17,037:INFO:                tqdm: 4.67.1
2025-03-29 15:03:17,037:INFO:               numpy: 1.26.4
2025-03-29 15:03:17,037:INFO:              pandas: 2.1.4
2025-03-29 15:03:17,037:INFO:              jinja2: 3.1.6
2025-03-29 15:03:17,037:INFO:               scipy: 1.11.4
2025-03-29 15:03:17,037:INFO:              joblib: 1.3.2
2025-03-29 15:03:17,037:INFO:             sklearn: 1.4.2
2025-03-29 15:03:17,037:INFO:                pyod: 2.0.2
2025-03-29 15:03:17,037:INFO:            imblearn: 0.13.0
2025-03-29 15:03:17,037:INFO:   category_encoders: 2.7.0
2025-03-29 15:03:17,037:INFO:            lightgbm: 4.6.0
2025-03-29 15:03:17,037:INFO:               numba: 0.61.0
2025-03-29 15:03:17,037:INFO:            requests: 2.32.3
2025-03-29 15:03:17,037:INFO:          matplotlib: 3.10.1
2025-03-29 15:03:17,037:INFO:          scikitplot: 0.3.7
2025-03-29 15:03:17,037:INFO:         yellowbrick: 1.5
2025-03-29 15:03:17,037:INFO:              plotly: 6.0.1
2025-03-29 15:03:17,037:INFO:    plotly-resampler: Not installed
2025-03-29 15:03:17,037:INFO:             kaleido: 0.2.1
2025-03-29 15:03:17,037:INFO:           schemdraw: 0.15
2025-03-29 15:03:17,037:INFO:         statsmodels: 0.14.4
2025-03-29 15:03:17,037:INFO:              sktime: 0.26.0
2025-03-29 15:03:17,037:INFO:               tbats: 1.1.3
2025-03-29 15:03:17,037:INFO:            pmdarima: 2.0.4
2025-03-29 15:03:17,037:INFO:              psutil: 7.0.0
2025-03-29 15:03:17,037:INFO:          markupsafe: 3.0.2
2025-03-29 15:03:17,037:INFO:             pickle5: Not installed
2025-03-29 15:03:17,037:INFO:         cloudpickle: 3.1.1
2025-03-29 15:03:17,037:INFO:         deprecation: 2.1.0
2025-03-29 15:03:17,037:INFO:              xxhash: 3.5.0
2025-03-29 15:03:17,037:INFO:           wurlitzer: 3.1.1
2025-03-29 15:03:17,037:INFO:PyCaret optional dependencies:
2025-03-29 15:03:17,044:INFO:                shap: Not installed
2025-03-29 15:03:17,044:INFO:           interpret: Not installed
2025-03-29 15:03:17,044:INFO:                umap: 0.5.7
2025-03-29 15:03:17,044:INFO:     ydata_profiling: Not installed
2025-03-29 15:03:17,044:INFO:  explainerdashboard: Not installed
2025-03-29 15:03:17,044:INFO:             autoviz: Not installed
2025-03-29 15:03:17,044:INFO:           fairlearn: Not installed
2025-03-29 15:03:17,044:INFO:          deepchecks: Not installed
2025-03-29 15:03:17,044:INFO:             xgboost: Not installed
2025-03-29 15:03:17,044:INFO:            catboost: Not installed
2025-03-29 15:03:17,044:INFO:              kmodes: Not installed
2025-03-29 15:03:17,044:INFO:             mlxtend: Not installed
2025-03-29 15:03:17,044:INFO:       statsforecast: Not installed
2025-03-29 15:03:17,044:INFO:        tune_sklearn: Not installed
2025-03-29 15:03:17,045:INFO:                 ray: Not installed
2025-03-29 15:03:17,045:INFO:            hyperopt: Not installed
2025-03-29 15:03:17,045:INFO:              optuna: Not installed
2025-03-29 15:03:17,045:INFO:               skopt: Not installed
2025-03-29 15:03:17,045:INFO:              mlflow: Not installed
2025-03-29 15:03:17,045:INFO:              gradio: Not installed
2025-03-29 15:03:17,045:INFO:             fastapi: Not installed
2025-03-29 15:03:17,045:INFO:             uvicorn: Not installed
2025-03-29 15:03:17,045:INFO:              m2cgen: Not installed
2025-03-29 15:03:17,045:INFO:           evidently: Not installed
2025-03-29 15:03:17,045:INFO:               fugue: Not installed
2025-03-29 15:03:17,045:INFO:           streamlit: 1.43.2
2025-03-29 15:03:17,045:INFO:             prophet: Not installed
2025-03-29 15:03:17,045:INFO:None
2025-03-29 15:03:17,045:INFO:Set up data.
2025-03-29 15:03:17,054:INFO:Set up folding strategy.
2025-03-29 15:03:17,054:INFO:Set up train/test split.
2025-03-29 15:03:17,060:INFO:Set up index.
2025-03-29 15:03:17,061:INFO:Assigning column types.
2025-03-29 15:03:17,065:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 15:03:17,065:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,068:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,070:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,108:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,132:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,133:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,136:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,138:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,214:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 15:03:17,217:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,219:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,256:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,281:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,285:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,288:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,322:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,347:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,347:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 15:03:17,352:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,416:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,451:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,475:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,476:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 15:03:17,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,540:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,583:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,607:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,608:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 15:03:17,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,712:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:03:17,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,739:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 15:03:17,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:17,870:INFO:Preparing preprocessing pipeline...
2025-03-29 15:03:17,870:INFO:Set up simple imputation.
2025-03-29 15:03:17,874:INFO:Set up encoding of categorical features.
2025-03-29 15:03:17,875:INFO:Set up column name cleaning.
2025-03-29 15:03:17,986:INFO:Finished creating preprocessing pipeline.
2025-03-29 15:03:17,990:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-29 15:03:17,990:INFO:Creating final display dataframe.
2025-03-29 15:03:18,215:INFO:Setup _display_container:                     Description             Value
0                    Session id              1949
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              994c
2025-03-29 15:03:18,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:18,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:18,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:18,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:03:18,350:INFO:setup() successfully completed in 1.32s...............
2025-03-29 15:03:23,221:INFO:Initializing compare_models()
2025-03-29 15:03:23,221:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-29 15:03:23,221:INFO:Checking exceptions
2025-03-29 15:03:23,224:INFO:Preparing display monitor
2025-03-29 15:03:23,238:INFO:Initializing Linear Regression
2025-03-29 15:03:23,238:INFO:Total runtime is 0.0 minutes
2025-03-29 15:03:23,241:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:23,241:INFO:Initializing create_model()
2025-03-29 15:03:23,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:23,241:INFO:Checking exceptions
2025-03-29 15:03:23,241:INFO:Importing libraries
2025-03-29 15:03:23,242:INFO:Copying training dataset
2025-03-29 15:03:23,248:INFO:Defining folds
2025-03-29 15:03:23,248:INFO:Declaring metric variables
2025-03-29 15:03:23,250:INFO:Importing untrained model
2025-03-29 15:03:23,252:INFO:Linear Regression Imported successfully
2025-03-29 15:03:23,257:INFO:Starting cross validation
2025-03-29 15:03:23,268:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:26,462:INFO:Calculating mean and std
2025-03-29 15:03:26,463:INFO:Creating metrics dataframe
2025-03-29 15:03:26,465:INFO:Uploading results into container
2025-03-29 15:03:26,466:INFO:Uploading model into container now
2025-03-29 15:03:26,466:INFO:_master_model_container: 1
2025-03-29 15:03:26,466:INFO:_display_container: 2
2025-03-29 15:03:26,467:INFO:LinearRegression(n_jobs=-1)
2025-03-29 15:03:26,467:INFO:create_model() successfully completed......................................
2025-03-29 15:03:26,570:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:26,571:INFO:Creating metrics dataframe
2025-03-29 15:03:26,574:INFO:Initializing Lasso Regression
2025-03-29 15:03:26,574:INFO:Total runtime is 0.05559998353322347 minutes
2025-03-29 15:03:26,577:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:26,577:INFO:Initializing create_model()
2025-03-29 15:03:26,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:26,577:INFO:Checking exceptions
2025-03-29 15:03:26,577:INFO:Importing libraries
2025-03-29 15:03:26,577:INFO:Copying training dataset
2025-03-29 15:03:26,585:INFO:Defining folds
2025-03-29 15:03:26,585:INFO:Declaring metric variables
2025-03-29 15:03:26,588:INFO:Importing untrained model
2025-03-29 15:03:26,590:INFO:Lasso Regression Imported successfully
2025-03-29 15:03:26,593:INFO:Starting cross validation
2025-03-29 15:03:26,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:28,351:INFO:Calculating mean and std
2025-03-29 15:03:28,352:INFO:Creating metrics dataframe
2025-03-29 15:03:28,354:INFO:Uploading results into container
2025-03-29 15:03:28,354:INFO:Uploading model into container now
2025-03-29 15:03:28,354:INFO:_master_model_container: 2
2025-03-29 15:03:28,354:INFO:_display_container: 2
2025-03-29 15:03:28,355:INFO:Lasso(random_state=1949)
2025-03-29 15:03:28,355:INFO:create_model() successfully completed......................................
2025-03-29 15:03:28,441:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:28,441:INFO:Creating metrics dataframe
2025-03-29 15:03:28,446:INFO:Initializing Ridge Regression
2025-03-29 15:03:28,446:INFO:Total runtime is 0.08679999510447184 minutes
2025-03-29 15:03:28,448:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:28,449:INFO:Initializing create_model()
2025-03-29 15:03:28,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:28,449:INFO:Checking exceptions
2025-03-29 15:03:28,449:INFO:Importing libraries
2025-03-29 15:03:28,449:INFO:Copying training dataset
2025-03-29 15:03:28,456:INFO:Defining folds
2025-03-29 15:03:28,456:INFO:Declaring metric variables
2025-03-29 15:03:28,458:INFO:Importing untrained model
2025-03-29 15:03:28,460:INFO:Ridge Regression Imported successfully
2025-03-29 15:03:28,464:INFO:Starting cross validation
2025-03-29 15:03:28,465:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:28,689:INFO:Calculating mean and std
2025-03-29 15:03:28,690:INFO:Creating metrics dataframe
2025-03-29 15:03:28,691:INFO:Uploading results into container
2025-03-29 15:03:28,691:INFO:Uploading model into container now
2025-03-29 15:03:28,692:INFO:_master_model_container: 3
2025-03-29 15:03:28,692:INFO:_display_container: 2
2025-03-29 15:03:28,692:INFO:Ridge(random_state=1949)
2025-03-29 15:03:28,692:INFO:create_model() successfully completed......................................
2025-03-29 15:03:28,776:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:28,776:INFO:Creating metrics dataframe
2025-03-29 15:03:28,780:INFO:Initializing Elastic Net
2025-03-29 15:03:28,781:INFO:Total runtime is 0.09238331317901612 minutes
2025-03-29 15:03:28,783:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:28,783:INFO:Initializing create_model()
2025-03-29 15:03:28,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:28,783:INFO:Checking exceptions
2025-03-29 15:03:28,783:INFO:Importing libraries
2025-03-29 15:03:28,783:INFO:Copying training dataset
2025-03-29 15:03:28,790:INFO:Defining folds
2025-03-29 15:03:28,790:INFO:Declaring metric variables
2025-03-29 15:03:28,793:INFO:Importing untrained model
2025-03-29 15:03:28,795:INFO:Elastic Net Imported successfully
2025-03-29 15:03:28,799:INFO:Starting cross validation
2025-03-29 15:03:28,801:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:29,048:INFO:Calculating mean and std
2025-03-29 15:03:29,049:INFO:Creating metrics dataframe
2025-03-29 15:03:29,050:INFO:Uploading results into container
2025-03-29 15:03:29,050:INFO:Uploading model into container now
2025-03-29 15:03:29,050:INFO:_master_model_container: 4
2025-03-29 15:03:29,051:INFO:_display_container: 2
2025-03-29 15:03:29,051:INFO:ElasticNet(random_state=1949)
2025-03-29 15:03:29,051:INFO:create_model() successfully completed......................................
2025-03-29 15:03:29,134:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:29,134:INFO:Creating metrics dataframe
2025-03-29 15:03:29,139:INFO:Initializing Least Angle Regression
2025-03-29 15:03:29,139:INFO:Total runtime is 0.09834999640782674 minutes
2025-03-29 15:03:29,141:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:29,141:INFO:Initializing create_model()
2025-03-29 15:03:29,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:29,141:INFO:Checking exceptions
2025-03-29 15:03:29,141:INFO:Importing libraries
2025-03-29 15:03:29,141:INFO:Copying training dataset
2025-03-29 15:03:29,149:INFO:Defining folds
2025-03-29 15:03:29,149:INFO:Declaring metric variables
2025-03-29 15:03:29,151:INFO:Importing untrained model
2025-03-29 15:03:29,154:INFO:Least Angle Regression Imported successfully
2025-03-29 15:03:29,157:INFO:Starting cross validation
2025-03-29 15:03:29,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:29,378:INFO:Calculating mean and std
2025-03-29 15:03:29,379:INFO:Creating metrics dataframe
2025-03-29 15:03:29,381:INFO:Uploading results into container
2025-03-29 15:03:29,381:INFO:Uploading model into container now
2025-03-29 15:03:29,381:INFO:_master_model_container: 5
2025-03-29 15:03:29,381:INFO:_display_container: 2
2025-03-29 15:03:29,382:INFO:Lars(random_state=1949)
2025-03-29 15:03:29,382:INFO:create_model() successfully completed......................................
2025-03-29 15:03:29,468:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:29,468:INFO:Creating metrics dataframe
2025-03-29 15:03:29,473:INFO:Initializing Lasso Least Angle Regression
2025-03-29 15:03:29,473:INFO:Total runtime is 0.10391668478647868 minutes
2025-03-29 15:03:29,475:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:29,476:INFO:Initializing create_model()
2025-03-29 15:03:29,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:29,476:INFO:Checking exceptions
2025-03-29 15:03:29,476:INFO:Importing libraries
2025-03-29 15:03:29,476:INFO:Copying training dataset
2025-03-29 15:03:29,483:INFO:Defining folds
2025-03-29 15:03:29,483:INFO:Declaring metric variables
2025-03-29 15:03:29,487:INFO:Importing untrained model
2025-03-29 15:03:29,491:INFO:Lasso Least Angle Regression Imported successfully
2025-03-29 15:03:29,497:INFO:Starting cross validation
2025-03-29 15:03:29,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:29,721:INFO:Calculating mean and std
2025-03-29 15:03:29,722:INFO:Creating metrics dataframe
2025-03-29 15:03:29,724:INFO:Uploading results into container
2025-03-29 15:03:29,724:INFO:Uploading model into container now
2025-03-29 15:03:29,725:INFO:_master_model_container: 6
2025-03-29 15:03:29,725:INFO:_display_container: 2
2025-03-29 15:03:29,725:INFO:LassoLars(random_state=1949)
2025-03-29 15:03:29,725:INFO:create_model() successfully completed......................................
2025-03-29 15:03:29,807:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:29,807:INFO:Creating metrics dataframe
2025-03-29 15:03:29,812:INFO:Initializing Orthogonal Matching Pursuit
2025-03-29 15:03:29,813:INFO:Total runtime is 0.109583314259847 minutes
2025-03-29 15:03:29,815:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:29,815:INFO:Initializing create_model()
2025-03-29 15:03:29,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:29,815:INFO:Checking exceptions
2025-03-29 15:03:29,815:INFO:Importing libraries
2025-03-29 15:03:29,815:INFO:Copying training dataset
2025-03-29 15:03:29,822:INFO:Defining folds
2025-03-29 15:03:29,822:INFO:Declaring metric variables
2025-03-29 15:03:29,824:INFO:Importing untrained model
2025-03-29 15:03:29,826:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-29 15:03:29,830:INFO:Starting cross validation
2025-03-29 15:03:29,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:30,064:INFO:Calculating mean and std
2025-03-29 15:03:30,065:INFO:Creating metrics dataframe
2025-03-29 15:03:30,066:INFO:Uploading results into container
2025-03-29 15:03:30,067:INFO:Uploading model into container now
2025-03-29 15:03:30,067:INFO:_master_model_container: 7
2025-03-29 15:03:30,067:INFO:_display_container: 2
2025-03-29 15:03:30,067:INFO:OrthogonalMatchingPursuit()
2025-03-29 15:03:30,067:INFO:create_model() successfully completed......................................
2025-03-29 15:03:30,149:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:30,149:INFO:Creating metrics dataframe
2025-03-29 15:03:30,154:INFO:Initializing Bayesian Ridge
2025-03-29 15:03:30,154:INFO:Total runtime is 0.11526798009872437 minutes
2025-03-29 15:03:30,156:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:30,157:INFO:Initializing create_model()
2025-03-29 15:03:30,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:30,157:INFO:Checking exceptions
2025-03-29 15:03:30,157:INFO:Importing libraries
2025-03-29 15:03:30,157:INFO:Copying training dataset
2025-03-29 15:03:30,164:INFO:Defining folds
2025-03-29 15:03:30,165:INFO:Declaring metric variables
2025-03-29 15:03:30,167:INFO:Importing untrained model
2025-03-29 15:03:30,169:INFO:Bayesian Ridge Imported successfully
2025-03-29 15:03:30,172:INFO:Starting cross validation
2025-03-29 15:03:30,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:30,494:INFO:Calculating mean and std
2025-03-29 15:03:30,495:INFO:Creating metrics dataframe
2025-03-29 15:03:30,496:INFO:Uploading results into container
2025-03-29 15:03:30,497:INFO:Uploading model into container now
2025-03-29 15:03:30,497:INFO:_master_model_container: 8
2025-03-29 15:03:30,497:INFO:_display_container: 2
2025-03-29 15:03:30,497:INFO:BayesianRidge()
2025-03-29 15:03:30,497:INFO:create_model() successfully completed......................................
2025-03-29 15:03:30,582:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:30,582:INFO:Creating metrics dataframe
2025-03-29 15:03:30,588:INFO:Initializing Passive Aggressive Regressor
2025-03-29 15:03:30,588:INFO:Total runtime is 0.12250132163365682 minutes
2025-03-29 15:03:30,590:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:30,590:INFO:Initializing create_model()
2025-03-29 15:03:30,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:30,590:INFO:Checking exceptions
2025-03-29 15:03:30,590:INFO:Importing libraries
2025-03-29 15:03:30,590:INFO:Copying training dataset
2025-03-29 15:03:30,598:INFO:Defining folds
2025-03-29 15:03:30,598:INFO:Declaring metric variables
2025-03-29 15:03:30,601:INFO:Importing untrained model
2025-03-29 15:03:30,603:INFO:Passive Aggressive Regressor Imported successfully
2025-03-29 15:03:30,607:INFO:Starting cross validation
2025-03-29 15:03:30,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:31,008:INFO:Calculating mean and std
2025-03-29 15:03:31,009:INFO:Creating metrics dataframe
2025-03-29 15:03:31,010:INFO:Uploading results into container
2025-03-29 15:03:31,010:INFO:Uploading model into container now
2025-03-29 15:03:31,011:INFO:_master_model_container: 9
2025-03-29 15:03:31,011:INFO:_display_container: 2
2025-03-29 15:03:31,011:INFO:PassiveAggressiveRegressor(random_state=1949)
2025-03-29 15:03:31,011:INFO:create_model() successfully completed......................................
2025-03-29 15:03:31,094:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:31,095:INFO:Creating metrics dataframe
2025-03-29 15:03:31,101:INFO:Initializing Huber Regressor
2025-03-29 15:03:31,101:INFO:Total runtime is 0.1310513218243917 minutes
2025-03-29 15:03:31,103:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:31,103:INFO:Initializing create_model()
2025-03-29 15:03:31,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:31,103:INFO:Checking exceptions
2025-03-29 15:03:31,103:INFO:Importing libraries
2025-03-29 15:03:31,103:INFO:Copying training dataset
2025-03-29 15:03:31,112:INFO:Defining folds
2025-03-29 15:03:31,112:INFO:Declaring metric variables
2025-03-29 15:03:31,115:INFO:Importing untrained model
2025-03-29 15:03:31,117:INFO:Huber Regressor Imported successfully
2025-03-29 15:03:31,122:INFO:Starting cross validation
2025-03-29 15:03:31,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:32,725:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:03:32,768:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:03:32,771:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:03:32,789:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:03:32,804:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:03:32,825:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:03:32,826:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:03:32,853:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:03:32,951:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:03:32,994:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:03:33,026:INFO:Calculating mean and std
2025-03-29 15:03:33,027:INFO:Creating metrics dataframe
2025-03-29 15:03:33,028:INFO:Uploading results into container
2025-03-29 15:03:33,029:INFO:Uploading model into container now
2025-03-29 15:03:33,029:INFO:_master_model_container: 10
2025-03-29 15:03:33,029:INFO:_display_container: 2
2025-03-29 15:03:33,029:INFO:HuberRegressor()
2025-03-29 15:03:33,030:INFO:create_model() successfully completed......................................
2025-03-29 15:03:33,112:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:33,112:INFO:Creating metrics dataframe
2025-03-29 15:03:33,117:INFO:Initializing K Neighbors Regressor
2025-03-29 15:03:33,117:INFO:Total runtime is 0.16465131441752118 minutes
2025-03-29 15:03:33,120:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:33,120:INFO:Initializing create_model()
2025-03-29 15:03:33,120:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:33,120:INFO:Checking exceptions
2025-03-29 15:03:33,120:INFO:Importing libraries
2025-03-29 15:03:33,120:INFO:Copying training dataset
2025-03-29 15:03:33,128:INFO:Defining folds
2025-03-29 15:03:33,128:INFO:Declaring metric variables
2025-03-29 15:03:33,130:INFO:Importing untrained model
2025-03-29 15:03:33,132:INFO:K Neighbors Regressor Imported successfully
2025-03-29 15:03:33,136:INFO:Starting cross validation
2025-03-29 15:03:33,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:33,960:INFO:Calculating mean and std
2025-03-29 15:03:33,961:INFO:Creating metrics dataframe
2025-03-29 15:03:33,962:INFO:Uploading results into container
2025-03-29 15:03:33,963:INFO:Uploading model into container now
2025-03-29 15:03:33,963:INFO:_master_model_container: 11
2025-03-29 15:03:33,963:INFO:_display_container: 2
2025-03-29 15:03:33,963:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-29 15:03:33,963:INFO:create_model() successfully completed......................................
2025-03-29 15:03:34,046:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:34,046:INFO:Creating metrics dataframe
2025-03-29 15:03:34,052:INFO:Initializing Decision Tree Regressor
2025-03-29 15:03:34,052:INFO:Total runtime is 0.18023466666539512 minutes
2025-03-29 15:03:34,054:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:34,055:INFO:Initializing create_model()
2025-03-29 15:03:34,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:34,055:INFO:Checking exceptions
2025-03-29 15:03:34,055:INFO:Importing libraries
2025-03-29 15:03:34,055:INFO:Copying training dataset
2025-03-29 15:03:34,063:INFO:Defining folds
2025-03-29 15:03:34,063:INFO:Declaring metric variables
2025-03-29 15:03:34,069:INFO:Importing untrained model
2025-03-29 15:03:34,072:INFO:Decision Tree Regressor Imported successfully
2025-03-29 15:03:34,079:INFO:Starting cross validation
2025-03-29 15:03:34,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:34,390:INFO:Calculating mean and std
2025-03-29 15:03:34,391:INFO:Creating metrics dataframe
2025-03-29 15:03:34,392:INFO:Uploading results into container
2025-03-29 15:03:34,393:INFO:Uploading model into container now
2025-03-29 15:03:34,393:INFO:_master_model_container: 12
2025-03-29 15:03:34,393:INFO:_display_container: 2
2025-03-29 15:03:34,393:INFO:DecisionTreeRegressor(random_state=1949)
2025-03-29 15:03:34,394:INFO:create_model() successfully completed......................................
2025-03-29 15:03:34,479:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:34,479:INFO:Creating metrics dataframe
2025-03-29 15:03:34,485:INFO:Initializing Random Forest Regressor
2025-03-29 15:03:34,485:INFO:Total runtime is 0.18745133876800538 minutes
2025-03-29 15:03:34,487:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:34,487:INFO:Initializing create_model()
2025-03-29 15:03:34,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:34,488:INFO:Checking exceptions
2025-03-29 15:03:34,488:INFO:Importing libraries
2025-03-29 15:03:34,488:INFO:Copying training dataset
2025-03-29 15:03:34,495:INFO:Defining folds
2025-03-29 15:03:34,496:INFO:Declaring metric variables
2025-03-29 15:03:34,498:INFO:Importing untrained model
2025-03-29 15:03:34,501:INFO:Random Forest Regressor Imported successfully
2025-03-29 15:03:34,505:INFO:Starting cross validation
2025-03-29 15:03:34,506:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:40,849:INFO:Calculating mean and std
2025-03-29 15:03:40,850:INFO:Creating metrics dataframe
2025-03-29 15:03:40,851:INFO:Uploading results into container
2025-03-29 15:03:40,851:INFO:Uploading model into container now
2025-03-29 15:03:40,852:INFO:_master_model_container: 13
2025-03-29 15:03:40,852:INFO:_display_container: 2
2025-03-29 15:03:40,852:INFO:RandomForestRegressor(n_jobs=-1, random_state=1949)
2025-03-29 15:03:40,853:INFO:create_model() successfully completed......................................
2025-03-29 15:03:40,954:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:40,954:INFO:Creating metrics dataframe
2025-03-29 15:03:40,961:INFO:Initializing Extra Trees Regressor
2025-03-29 15:03:40,961:INFO:Total runtime is 0.29537795384724935 minutes
2025-03-29 15:03:40,964:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:40,964:INFO:Initializing create_model()
2025-03-29 15:03:40,965:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:40,965:INFO:Checking exceptions
2025-03-29 15:03:40,965:INFO:Importing libraries
2025-03-29 15:03:40,965:INFO:Copying training dataset
2025-03-29 15:03:40,974:INFO:Defining folds
2025-03-29 15:03:40,974:INFO:Declaring metric variables
2025-03-29 15:03:40,978:INFO:Importing untrained model
2025-03-29 15:03:40,982:INFO:Extra Trees Regressor Imported successfully
2025-03-29 15:03:40,986:INFO:Starting cross validation
2025-03-29 15:03:40,988:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:44,863:INFO:Calculating mean and std
2025-03-29 15:03:44,864:INFO:Creating metrics dataframe
2025-03-29 15:03:44,865:INFO:Uploading results into container
2025-03-29 15:03:44,866:INFO:Uploading model into container now
2025-03-29 15:03:44,866:INFO:_master_model_container: 14
2025-03-29 15:03:44,866:INFO:_display_container: 2
2025-03-29 15:03:44,867:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1949)
2025-03-29 15:03:44,867:INFO:create_model() successfully completed......................................
2025-03-29 15:03:44,988:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:44,988:INFO:Creating metrics dataframe
2025-03-29 15:03:44,995:INFO:Initializing AdaBoost Regressor
2025-03-29 15:03:44,995:INFO:Total runtime is 0.362624720732371 minutes
2025-03-29 15:03:44,997:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:44,998:INFO:Initializing create_model()
2025-03-29 15:03:44,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:44,998:INFO:Checking exceptions
2025-03-29 15:03:44,998:INFO:Importing libraries
2025-03-29 15:03:44,998:INFO:Copying training dataset
2025-03-29 15:03:45,006:INFO:Defining folds
2025-03-29 15:03:45,006:INFO:Declaring metric variables
2025-03-29 15:03:45,008:INFO:Importing untrained model
2025-03-29 15:03:45,011:INFO:AdaBoost Regressor Imported successfully
2025-03-29 15:03:45,015:INFO:Starting cross validation
2025-03-29 15:03:45,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:45,935:INFO:Calculating mean and std
2025-03-29 15:03:45,936:INFO:Creating metrics dataframe
2025-03-29 15:03:45,937:INFO:Uploading results into container
2025-03-29 15:03:45,937:INFO:Uploading model into container now
2025-03-29 15:03:45,937:INFO:_master_model_container: 15
2025-03-29 15:03:45,937:INFO:_display_container: 2
2025-03-29 15:03:45,938:INFO:AdaBoostRegressor(random_state=1949)
2025-03-29 15:03:45,938:INFO:create_model() successfully completed......................................
2025-03-29 15:03:46,034:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:46,034:INFO:Creating metrics dataframe
2025-03-29 15:03:46,041:INFO:Initializing Gradient Boosting Regressor
2025-03-29 15:03:46,041:INFO:Total runtime is 0.38005810578664145 minutes
2025-03-29 15:03:46,043:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:46,044:INFO:Initializing create_model()
2025-03-29 15:03:46,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:46,044:INFO:Checking exceptions
2025-03-29 15:03:46,044:INFO:Importing libraries
2025-03-29 15:03:46,044:INFO:Copying training dataset
2025-03-29 15:03:46,051:INFO:Defining folds
2025-03-29 15:03:46,052:INFO:Declaring metric variables
2025-03-29 15:03:46,054:INFO:Importing untrained model
2025-03-29 15:03:46,057:INFO:Gradient Boosting Regressor Imported successfully
2025-03-29 15:03:46,062:INFO:Starting cross validation
2025-03-29 15:03:46,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:48,073:INFO:Calculating mean and std
2025-03-29 15:03:48,074:INFO:Creating metrics dataframe
2025-03-29 15:03:48,076:INFO:Uploading results into container
2025-03-29 15:03:48,076:INFO:Uploading model into container now
2025-03-29 15:03:48,076:INFO:_master_model_container: 16
2025-03-29 15:03:48,076:INFO:_display_container: 2
2025-03-29 15:03:48,077:INFO:GradientBoostingRegressor(random_state=1949)
2025-03-29 15:03:48,077:INFO:create_model() successfully completed......................................
2025-03-29 15:03:48,165:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:48,165:INFO:Creating metrics dataframe
2025-03-29 15:03:48,172:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 15:03:48,172:INFO:Total runtime is 0.4155747135480245 minutes
2025-03-29 15:03:48,173:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:48,174:INFO:Initializing create_model()
2025-03-29 15:03:48,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:48,174:INFO:Checking exceptions
2025-03-29 15:03:48,174:INFO:Importing libraries
2025-03-29 15:03:48,174:INFO:Copying training dataset
2025-03-29 15:03:48,182:INFO:Defining folds
2025-03-29 15:03:48,182:INFO:Declaring metric variables
2025-03-29 15:03:48,184:INFO:Importing untrained model
2025-03-29 15:03:48,187:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:03:48,190:INFO:Starting cross validation
2025-03-29 15:03:48,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:49,090:INFO:Calculating mean and std
2025-03-29 15:03:49,091:INFO:Creating metrics dataframe
2025-03-29 15:03:49,093:INFO:Uploading results into container
2025-03-29 15:03:49,093:INFO:Uploading model into container now
2025-03-29 15:03:49,093:INFO:_master_model_container: 17
2025-03-29 15:03:49,093:INFO:_display_container: 2
2025-03-29 15:03:49,094:INFO:LGBMRegressor(n_jobs=-1, random_state=1949)
2025-03-29 15:03:49,094:INFO:create_model() successfully completed......................................
2025-03-29 15:03:49,193:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:49,194:INFO:Creating metrics dataframe
2025-03-29 15:03:49,201:INFO:Initializing Dummy Regressor
2025-03-29 15:03:49,201:INFO:Total runtime is 0.43272473812103274 minutes
2025-03-29 15:03:49,203:INFO:SubProcess create_model() called ==================================
2025-03-29 15:03:49,203:INFO:Initializing create_model()
2025-03-29 15:03:49,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015864EEC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:49,203:INFO:Checking exceptions
2025-03-29 15:03:49,203:INFO:Importing libraries
2025-03-29 15:03:49,203:INFO:Copying training dataset
2025-03-29 15:03:49,210:INFO:Defining folds
2025-03-29 15:03:49,210:INFO:Declaring metric variables
2025-03-29 15:03:49,213:INFO:Importing untrained model
2025-03-29 15:03:49,215:INFO:Dummy Regressor Imported successfully
2025-03-29 15:03:49,218:INFO:Starting cross validation
2025-03-29 15:03:49,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:03:49,420:INFO:Calculating mean and std
2025-03-29 15:03:49,421:INFO:Creating metrics dataframe
2025-03-29 15:03:49,423:INFO:Uploading results into container
2025-03-29 15:03:49,423:INFO:Uploading model into container now
2025-03-29 15:03:49,423:INFO:_master_model_container: 18
2025-03-29 15:03:49,423:INFO:_display_container: 2
2025-03-29 15:03:49,423:INFO:DummyRegressor()
2025-03-29 15:03:49,424:INFO:create_model() successfully completed......................................
2025-03-29 15:03:49,505:INFO:SubProcess create_model() end ==================================
2025-03-29 15:03:49,505:INFO:Creating metrics dataframe
2025-03-29 15:03:49,511:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-03-29 15:03:49,517:INFO:Initializing create_model()
2025-03-29 15:03:49,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=LGBMRegressor(n_jobs=-1, random_state=1949), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:03:49,517:INFO:Checking exceptions
2025-03-29 15:03:49,519:INFO:Importing libraries
2025-03-29 15:03:49,519:INFO:Copying training dataset
2025-03-29 15:03:49,529:INFO:Defining folds
2025-03-29 15:03:49,529:INFO:Declaring metric variables
2025-03-29 15:03:49,529:INFO:Importing untrained model
2025-03-29 15:03:49,530:INFO:Declaring custom model
2025-03-29 15:03:49,530:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:03:49,531:INFO:Cross validation set to False
2025-03-29 15:03:49,531:INFO:Fitting Model
2025-03-29 15:03:49,608:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:03:49,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.
2025-03-29 15:03:49,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:03:49,610:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:03:49,610:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:03:49,610:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:03:49,610:INFO:[LightGBM] [Info] Start training from score 3258.799182
2025-03-29 15:03:49,674:INFO:LGBMRegressor(n_jobs=-1, random_state=1949)
2025-03-29 15:03:49,674:INFO:create_model() successfully completed......................................
2025-03-29 15:03:49,783:INFO:_master_model_container: 18
2025-03-29 15:03:49,783:INFO:_display_container: 2
2025-03-29 15:03:49,784:INFO:LGBMRegressor(n_jobs=-1, random_state=1949)
2025-03-29 15:03:49,784:INFO:compare_models() successfully completed......................................
2025-03-29 15:05:18,375:INFO:Initializing evaluate_model()
2025-03-29 15:05:18,375:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=LGBMRegressor(n_jobs=-1, random_state=1949), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-29 15:05:18,388:INFO:Initializing plot_model()
2025-03-29 15:05:18,388:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1949), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, system=True)
2025-03-29 15:05:18,388:INFO:Checking exceptions
2025-03-29 15:05:18,391:INFO:Preloading libraries
2025-03-29 15:05:18,394:INFO:Copying training dataset
2025-03-29 15:05:18,394:INFO:Plot type: pipeline
2025-03-29 15:05:18,505:INFO:Visual Rendered Successfully
2025-03-29 15:05:18,592:INFO:plot_model() successfully completed......................................
2025-03-29 15:05:23,648:INFO:Initializing plot_model()
2025-03-29 15:05:23,648:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1949), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, system=True)
2025-03-29 15:05:23,648:INFO:Checking exceptions
2025-03-29 15:05:23,652:INFO:Preloading libraries
2025-03-29 15:05:23,654:INFO:Copying training dataset
2025-03-29 15:05:23,654:INFO:Plot type: parameter
2025-03-29 15:05:23,657:INFO:Visual Rendered Successfully
2025-03-29 15:05:23,753:INFO:plot_model() successfully completed......................................
2025-03-29 15:05:30,482:INFO:Initializing plot_model()
2025-03-29 15:05:30,483:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1949), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, system=True)
2025-03-29 15:05:30,483:INFO:Checking exceptions
2025-03-29 15:05:30,485:INFO:Preloading libraries
2025-03-29 15:05:30,488:INFO:Copying training dataset
2025-03-29 15:05:30,488:INFO:Plot type: residuals
2025-03-29 15:05:30,733:INFO:Fitting Model
2025-03-29 15:05:30,791:INFO:Scoring test/hold-out set
2025-03-29 15:05:31,213:INFO:Visual Rendered Successfully
2025-03-29 15:05:31,304:INFO:plot_model() successfully completed......................................
2025-03-29 15:05:31,373:INFO:Initializing plot_model()
2025-03-29 15:05:31,374:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1949), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, system=True)
2025-03-29 15:05:31,374:INFO:Checking exceptions
2025-03-29 15:05:31,377:INFO:Preloading libraries
2025-03-29 15:05:31,379:INFO:Copying training dataset
2025-03-29 15:05:31,380:INFO:Plot type: error
2025-03-29 15:05:31,622:INFO:Fitting Model
2025-03-29 15:05:31,622:INFO:Scoring test/hold-out set
2025-03-29 15:05:31,826:INFO:Visual Rendered Successfully
2025-03-29 15:05:31,915:INFO:plot_model() successfully completed......................................
2025-03-29 15:05:42,455:INFO:Initializing tune_model()
2025-03-29 15:05:42,455:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=1949), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>)
2025-03-29 15:05:42,455:INFO:Checking exceptions
2025-03-29 15:05:42,468:INFO:Copying training dataset
2025-03-29 15:05:42,475:INFO:Checking base model
2025-03-29 15:05:42,475:INFO:Base model : Light Gradient Boosting Machine
2025-03-29 15:05:42,477:INFO:Declaring metric variables
2025-03-29 15:05:42,480:INFO:Defining Hyperparameters
2025-03-29 15:05:42,580:INFO:Tuning with n_jobs=-1
2025-03-29 15:05:42,581:INFO:Initializing RandomizedSearchCV
2025-03-29 15:06:04,560:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.8}
2025-03-29 15:06:04,561:INFO:Hyperparameter search completed
2025-03-29 15:06:04,561:INFO:SubProcess create_model() called ==================================
2025-03-29 15:06:04,562:INFO:Initializing create_model()
2025-03-29 15:06:04,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=LGBMRegressor(n_jobs=-1, random_state=1949), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015863C93EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 5, 'reg_alpha': 1, 'num_leaves': 150, 'n_estimators': 100, 'min_split_gain': 0, 'min_child_samples': 31, 'learning_rate': 0.05, 'feature_fraction': 1.0, 'bagging_freq': 4, 'bagging_fraction': 0.8})
2025-03-29 15:06:04,562:INFO:Checking exceptions
2025-03-29 15:06:04,562:INFO:Importing libraries
2025-03-29 15:06:04,562:INFO:Copying training dataset
2025-03-29 15:06:04,572:INFO:Defining folds
2025-03-29 15:06:04,572:INFO:Declaring metric variables
2025-03-29 15:06:04,574:INFO:Importing untrained model
2025-03-29 15:06:04,574:INFO:Declaring custom model
2025-03-29 15:06:04,577:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:06:04,582:INFO:Starting cross validation
2025-03-29 15:06:04,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:06:07,048:INFO:Calculating mean and std
2025-03-29 15:06:07,049:INFO:Creating metrics dataframe
2025-03-29 15:06:07,053:INFO:Finalizing model
2025-03-29 15:06:07,147:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-03-29 15:06:07,147:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-03-29 15:06:07,147:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2025-03-29 15:06:07,159:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:06:07,160:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-03-29 15:06:07,160:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-03-29 15:06:07,160:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2025-03-29 15:06:07,161:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:06:07,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:06:07,161:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:06:07,161:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:06:07,161:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:06:07,162:INFO:[LightGBM] [Info] Start training from score 3258.799182
2025-03-29 15:06:07,394:INFO:Uploading results into container
2025-03-29 15:06:07,395:INFO:Uploading model into container now
2025-03-29 15:06:07,395:INFO:_master_model_container: 19
2025-03-29 15:06:07,395:INFO:_display_container: 3
2025-03-29 15:06:07,396:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=4, feature_fraction=1.0,
              learning_rate=0.05, min_child_samples=31, min_split_gain=0,
              n_jobs=-1, num_leaves=150, random_state=1949, reg_alpha=1,
              reg_lambda=5)
2025-03-29 15:06:07,396:INFO:create_model() successfully completed......................................
2025-03-29 15:06:07,494:INFO:SubProcess create_model() end ==================================
2025-03-29 15:06:07,494:INFO:choose_better activated
2025-03-29 15:06:07,497:INFO:SubProcess create_model() called ==================================
2025-03-29 15:06:07,497:INFO:Initializing create_model()
2025-03-29 15:06:07,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=LGBMRegressor(n_jobs=-1, random_state=1949), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:06:07,497:INFO:Checking exceptions
2025-03-29 15:06:07,498:INFO:Importing libraries
2025-03-29 15:06:07,499:INFO:Copying training dataset
2025-03-29 15:06:07,506:INFO:Defining folds
2025-03-29 15:06:07,506:INFO:Declaring metric variables
2025-03-29 15:06:07,506:INFO:Importing untrained model
2025-03-29 15:06:07,506:INFO:Declaring custom model
2025-03-29 15:06:07,507:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:06:07,507:INFO:Starting cross validation
2025-03-29 15:06:07,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:06:08,279:INFO:Calculating mean and std
2025-03-29 15:06:08,279:INFO:Creating metrics dataframe
2025-03-29 15:06:08,281:INFO:Finalizing model
2025-03-29 15:06:08,382:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:06:08,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-03-29 15:06:08,384:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:06:08,384:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:06:08,384:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:06:08,384:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:06:08,384:INFO:[LightGBM] [Info] Start training from score 3258.799182
2025-03-29 15:06:08,436:INFO:Uploading results into container
2025-03-29 15:06:08,436:INFO:Uploading model into container now
2025-03-29 15:06:08,437:INFO:_master_model_container: 20
2025-03-29 15:06:08,437:INFO:_display_container: 4
2025-03-29 15:06:08,437:INFO:LGBMRegressor(n_jobs=-1, random_state=1949)
2025-03-29 15:06:08,437:INFO:create_model() successfully completed......................................
2025-03-29 15:06:08,532:INFO:SubProcess create_model() end ==================================
2025-03-29 15:06:08,533:INFO:LGBMRegressor(n_jobs=-1, random_state=1949) result for R2 is 0.2189
2025-03-29 15:06:08,533:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=4, feature_fraction=1.0,
              learning_rate=0.05, min_child_samples=31, min_split_gain=0,
              n_jobs=-1, num_leaves=150, random_state=1949, reg_alpha=1,
              reg_lambda=5) result for R2 is 0.2175
2025-03-29 15:06:08,534:INFO:LGBMRegressor(n_jobs=-1, random_state=1949) is best model
2025-03-29 15:06:08,534:INFO:choose_better completed
2025-03-29 15:06:08,534:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-29 15:06:08,541:INFO:_master_model_container: 20
2025-03-29 15:06:08,541:INFO:_display_container: 3
2025-03-29 15:06:08,541:INFO:LGBMRegressor(n_jobs=-1, random_state=1949)
2025-03-29 15:06:08,541:INFO:tune_model() successfully completed......................................
2025-03-29 15:06:08,659:INFO:Initializing save_model()
2025-03-29 15:06:08,660:INFO:save_model(model=LGBMRegressor(n_jobs=-1, random_state=1949), model_name=traffic_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-29 15:06:08,660:INFO:Adding model into prep_pipe
2025-03-29 15:06:08,667:INFO:traffic_model.pkl saved in current working directory
2025-03-29 15:06:08,674:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=1949))])
2025-03-29 15:06:08,674:INFO:save_model() successfully completed......................................
2025-03-29 15:06:24,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:06:24,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:06:24,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:06:24,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:06:27,138:INFO:Initializing load_model()
2025-03-29 15:06:27,138:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-29 15:06:27,201:INFO:Initializing predict_model()
2025-03-29 15:06:27,201:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E8289C8AC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=1949))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002E8293035B0>)
2025-03-29 15:06:27,201:INFO:Checking exceptions
2025-03-29 15:06:27,201:INFO:Preloading libraries
2025-03-29 15:06:27,201:INFO:Set up data.
2025-03-29 15:06:27,211:INFO:Set up index.
2025-03-29 15:07:05,610:INFO:Initializing load_model()
2025-03-29 15:07:05,610:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-29 15:07:05,625:INFO:Initializing predict_model()
2025-03-29 15:07:05,625:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015864EEE530>, estimator=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=1949))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015865243B50>)
2025-03-29 15:07:05,625:INFO:Checking exceptions
2025-03-29 15:07:05,625:INFO:Preloading libraries
2025-03-29 15:07:05,627:INFO:Set up data.
2025-03-29 15:07:05,638:INFO:Set up index.
2025-03-29 15:07:05,722:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning:

'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.


2025-03-29 15:09:29,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:09:29,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:09:29,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:09:29,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:11:57,197:INFO:Initializing load_model()
2025-03-29 15:11:57,197:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-29 15:11:57,210:INFO:Initializing predict_model()
2025-03-29 15:11:57,210:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E82932AC20>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=1949))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002E82B061000>)
2025-03-29 15:11:57,210:INFO:Checking exceptions
2025-03-29 15:11:57,210:INFO:Preloading libraries
2025-03-29 15:11:57,210:INFO:Set up data.
2025-03-29 15:11:57,220:INFO:Set up index.
2025-03-29 15:14:14,796:INFO:PyCaret ClassificationExperiment
2025-03-29 15:14:14,796:INFO:Logging name: clf-default-name
2025-03-29 15:14:14,796:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-29 15:14:14,796:INFO:version 3.3.2
2025-03-29 15:14:14,796:INFO:Initializing setup()
2025-03-29 15:14:14,796:INFO:self.USI: 2435
2025-03-29 15:14:14,796:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', '_available_plots', 'USI', 'gpu_n_jobs_param', 'memory', 'html_param', 'pipeline', 'X_train', 'logging_param', '_ml_usecase', 'y_train', 'y', 'fold_generator', 'X_test', 'y_test', 'is_multiclass', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', 'idx', 'X', 'data', 'n_jobs_param', 'seed', 'exp_name_log', 'fold_groups_param', 'target_param'}
2025-03-29 15:14:14,796:INFO:Checking environment
2025-03-29 15:14:14,797:INFO:python_version: 3.10.16
2025-03-29 15:14:14,797:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 15:14:14,797:INFO:machine: AMD64
2025-03-29 15:14:14,797:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 15:14:14,800:INFO:Memory: svmem(total=33411727360, available=17053065216, percent=49.0, used=16358662144, free=17053065216)
2025-03-29 15:14:14,800:INFO:Physical Core: 6
2025-03-29 15:14:14,800:INFO:Logical Core: 12
2025-03-29 15:14:14,800:INFO:Checking libraries
2025-03-29 15:14:14,800:INFO:System:
2025-03-29 15:14:14,800:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 15:14:14,800:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 15:14:14,800:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 15:14:14,800:INFO:PyCaret required dependencies:
2025-03-29 15:14:14,801:INFO:                 pip: 25.0.1
2025-03-29 15:14:14,801:INFO:          setuptools: 75.8.2
2025-03-29 15:14:14,801:INFO:             pycaret: 3.3.2
2025-03-29 15:14:14,801:INFO:             IPython: 8.34.0
2025-03-29 15:14:14,801:INFO:          ipywidgets: 8.1.5
2025-03-29 15:14:14,801:INFO:                tqdm: 4.67.1
2025-03-29 15:14:14,801:INFO:               numpy: 1.26.4
2025-03-29 15:14:14,801:INFO:              pandas: 2.1.4
2025-03-29 15:14:14,801:INFO:              jinja2: 3.1.6
2025-03-29 15:14:14,801:INFO:               scipy: 1.11.4
2025-03-29 15:14:14,801:INFO:              joblib: 1.3.2
2025-03-29 15:14:14,801:INFO:             sklearn: 1.4.2
2025-03-29 15:14:14,801:INFO:                pyod: 2.0.2
2025-03-29 15:14:14,801:INFO:            imblearn: 0.13.0
2025-03-29 15:14:14,801:INFO:   category_encoders: 2.7.0
2025-03-29 15:14:14,801:INFO:            lightgbm: 4.6.0
2025-03-29 15:14:14,801:INFO:               numba: 0.61.0
2025-03-29 15:14:14,801:INFO:            requests: 2.32.3
2025-03-29 15:14:14,801:INFO:          matplotlib: 3.10.1
2025-03-29 15:14:14,802:INFO:          scikitplot: 0.3.7
2025-03-29 15:14:14,802:INFO:         yellowbrick: 1.5
2025-03-29 15:14:14,802:INFO:              plotly: 6.0.1
2025-03-29 15:14:14,802:INFO:    plotly-resampler: Not installed
2025-03-29 15:14:14,802:INFO:             kaleido: 0.2.1
2025-03-29 15:14:14,802:INFO:           schemdraw: 0.15
2025-03-29 15:14:14,802:INFO:         statsmodels: 0.14.4
2025-03-29 15:14:14,802:INFO:              sktime: 0.26.0
2025-03-29 15:14:14,802:INFO:               tbats: 1.1.3
2025-03-29 15:14:14,802:INFO:            pmdarima: 2.0.4
2025-03-29 15:14:14,802:INFO:              psutil: 7.0.0
2025-03-29 15:14:14,802:INFO:          markupsafe: 3.0.2
2025-03-29 15:14:14,802:INFO:             pickle5: Not installed
2025-03-29 15:14:14,802:INFO:         cloudpickle: 3.1.1
2025-03-29 15:14:14,802:INFO:         deprecation: 2.1.0
2025-03-29 15:14:14,802:INFO:              xxhash: 3.5.0
2025-03-29 15:14:14,802:INFO:           wurlitzer: 3.1.1
2025-03-29 15:14:14,802:INFO:PyCaret optional dependencies:
2025-03-29 15:14:14,809:INFO:                shap: Not installed
2025-03-29 15:14:14,809:INFO:           interpret: Not installed
2025-03-29 15:14:14,809:INFO:                umap: 0.5.7
2025-03-29 15:14:14,809:INFO:     ydata_profiling: Not installed
2025-03-29 15:14:14,809:INFO:  explainerdashboard: Not installed
2025-03-29 15:14:14,809:INFO:             autoviz: Not installed
2025-03-29 15:14:14,809:INFO:           fairlearn: Not installed
2025-03-29 15:14:14,809:INFO:          deepchecks: Not installed
2025-03-29 15:14:14,809:INFO:             xgboost: Not installed
2025-03-29 15:14:14,809:INFO:            catboost: Not installed
2025-03-29 15:14:14,809:INFO:              kmodes: Not installed
2025-03-29 15:14:14,809:INFO:             mlxtend: Not installed
2025-03-29 15:14:14,809:INFO:       statsforecast: Not installed
2025-03-29 15:14:14,809:INFO:        tune_sklearn: Not installed
2025-03-29 15:14:14,809:INFO:                 ray: Not installed
2025-03-29 15:14:14,809:INFO:            hyperopt: Not installed
2025-03-29 15:14:14,809:INFO:              optuna: Not installed
2025-03-29 15:14:14,809:INFO:               skopt: Not installed
2025-03-29 15:14:14,809:INFO:              mlflow: Not installed
2025-03-29 15:14:14,809:INFO:              gradio: Not installed
2025-03-29 15:14:14,809:INFO:             fastapi: Not installed
2025-03-29 15:14:14,809:INFO:             uvicorn: Not installed
2025-03-29 15:14:14,809:INFO:              m2cgen: Not installed
2025-03-29 15:14:14,809:INFO:           evidently: Not installed
2025-03-29 15:14:14,809:INFO:               fugue: Not installed
2025-03-29 15:14:14,809:INFO:           streamlit: 1.43.2
2025-03-29 15:14:14,809:INFO:             prophet: Not installed
2025-03-29 15:14:14,809:INFO:None
2025-03-29 15:14:14,809:INFO:Set up data.
2025-03-29 15:15:06,351:INFO:PyCaret ClassificationExperiment
2025-03-29 15:15:06,351:INFO:Logging name: clf-default-name
2025-03-29 15:15:06,351:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-29 15:15:06,351:INFO:version 3.3.2
2025-03-29 15:15:06,351:INFO:Initializing setup()
2025-03-29 15:15:06,352:INFO:self.USI: 76c6
2025-03-29 15:15:06,352:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', '_available_plots', 'USI', 'gpu_n_jobs_param', 'memory', 'html_param', 'pipeline', 'X_train', 'logging_param', '_ml_usecase', 'y_train', 'y', 'fold_generator', 'X_test', 'y_test', 'is_multiclass', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', 'idx', 'X', 'data', 'n_jobs_param', 'seed', 'exp_name_log', 'fold_groups_param', 'target_param'}
2025-03-29 15:15:06,352:INFO:Checking environment
2025-03-29 15:15:06,352:INFO:python_version: 3.10.16
2025-03-29 15:15:06,352:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 15:15:06,352:INFO:machine: AMD64
2025-03-29 15:15:06,352:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 15:15:06,356:INFO:Memory: svmem(total=33411727360, available=17008689152, percent=49.1, used=16403038208, free=17008689152)
2025-03-29 15:15:06,356:INFO:Physical Core: 6
2025-03-29 15:15:06,356:INFO:Logical Core: 12
2025-03-29 15:15:06,357:INFO:Checking libraries
2025-03-29 15:15:06,357:INFO:System:
2025-03-29 15:15:06,357:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 15:15:06,357:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 15:15:06,357:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 15:15:06,357:INFO:PyCaret required dependencies:
2025-03-29 15:15:06,357:INFO:                 pip: 25.0.1
2025-03-29 15:15:06,357:INFO:          setuptools: 75.8.2
2025-03-29 15:15:06,357:INFO:             pycaret: 3.3.2
2025-03-29 15:15:06,357:INFO:             IPython: 8.34.0
2025-03-29 15:15:06,357:INFO:          ipywidgets: 8.1.5
2025-03-29 15:15:06,357:INFO:                tqdm: 4.67.1
2025-03-29 15:15:06,357:INFO:               numpy: 1.26.4
2025-03-29 15:15:06,357:INFO:              pandas: 2.1.4
2025-03-29 15:15:06,357:INFO:              jinja2: 3.1.6
2025-03-29 15:15:06,357:INFO:               scipy: 1.11.4
2025-03-29 15:15:06,357:INFO:              joblib: 1.3.2
2025-03-29 15:15:06,357:INFO:             sklearn: 1.4.2
2025-03-29 15:15:06,357:INFO:                pyod: 2.0.2
2025-03-29 15:15:06,357:INFO:            imblearn: 0.13.0
2025-03-29 15:15:06,357:INFO:   category_encoders: 2.7.0
2025-03-29 15:15:06,357:INFO:            lightgbm: 4.6.0
2025-03-29 15:15:06,357:INFO:               numba: 0.61.0
2025-03-29 15:15:06,357:INFO:            requests: 2.32.3
2025-03-29 15:15:06,357:INFO:          matplotlib: 3.10.1
2025-03-29 15:15:06,357:INFO:          scikitplot: 0.3.7
2025-03-29 15:15:06,357:INFO:         yellowbrick: 1.5
2025-03-29 15:15:06,357:INFO:              plotly: 6.0.1
2025-03-29 15:15:06,357:INFO:    plotly-resampler: Not installed
2025-03-29 15:15:06,357:INFO:             kaleido: 0.2.1
2025-03-29 15:15:06,357:INFO:           schemdraw: 0.15
2025-03-29 15:15:06,357:INFO:         statsmodels: 0.14.4
2025-03-29 15:15:06,357:INFO:              sktime: 0.26.0
2025-03-29 15:15:06,357:INFO:               tbats: 1.1.3
2025-03-29 15:15:06,357:INFO:            pmdarima: 2.0.4
2025-03-29 15:15:06,357:INFO:              psutil: 7.0.0
2025-03-29 15:15:06,357:INFO:          markupsafe: 3.0.2
2025-03-29 15:15:06,357:INFO:             pickle5: Not installed
2025-03-29 15:15:06,357:INFO:         cloudpickle: 3.1.1
2025-03-29 15:15:06,357:INFO:         deprecation: 2.1.0
2025-03-29 15:15:06,357:INFO:              xxhash: 3.5.0
2025-03-29 15:15:06,357:INFO:           wurlitzer: 3.1.1
2025-03-29 15:15:06,357:INFO:PyCaret optional dependencies:
2025-03-29 15:15:06,357:INFO:                shap: Not installed
2025-03-29 15:15:06,357:INFO:           interpret: Not installed
2025-03-29 15:15:06,358:INFO:                umap: 0.5.7
2025-03-29 15:15:06,358:INFO:     ydata_profiling: Not installed
2025-03-29 15:15:06,358:INFO:  explainerdashboard: Not installed
2025-03-29 15:15:06,358:INFO:             autoviz: Not installed
2025-03-29 15:15:06,358:INFO:           fairlearn: Not installed
2025-03-29 15:15:06,358:INFO:          deepchecks: Not installed
2025-03-29 15:15:06,358:INFO:             xgboost: Not installed
2025-03-29 15:15:06,358:INFO:            catboost: Not installed
2025-03-29 15:15:06,358:INFO:              kmodes: Not installed
2025-03-29 15:15:06,358:INFO:             mlxtend: Not installed
2025-03-29 15:15:06,358:INFO:       statsforecast: Not installed
2025-03-29 15:15:06,358:INFO:        tune_sklearn: Not installed
2025-03-29 15:15:06,358:INFO:                 ray: Not installed
2025-03-29 15:15:06,358:INFO:            hyperopt: Not installed
2025-03-29 15:15:06,358:INFO:              optuna: Not installed
2025-03-29 15:15:06,358:INFO:               skopt: Not installed
2025-03-29 15:15:06,358:INFO:              mlflow: Not installed
2025-03-29 15:15:06,358:INFO:              gradio: Not installed
2025-03-29 15:15:06,358:INFO:             fastapi: Not installed
2025-03-29 15:15:06,358:INFO:             uvicorn: Not installed
2025-03-29 15:15:06,358:INFO:              m2cgen: Not installed
2025-03-29 15:15:06,358:INFO:           evidently: Not installed
2025-03-29 15:15:06,358:INFO:               fugue: Not installed
2025-03-29 15:15:06,358:INFO:           streamlit: 1.43.2
2025-03-29 15:15:06,358:INFO:             prophet: Not installed
2025-03-29 15:15:06,358:INFO:None
2025-03-29 15:15:06,358:INFO:Set up data.
2025-03-29 15:15:06,366:INFO:Set up folding strategy.
2025-03-29 15:15:06,366:INFO:Set up train/test split.
2025-03-29 15:15:06,392:INFO:Set up index.
2025-03-29 15:15:06,393:INFO:Assigning column types.
2025-03-29 15:15:06,396:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 15:15:06,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:15:06,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-29 15:15:06,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:15:06,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-29 15:15:06,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,533:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 15:15:06,558:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-29 15:15:06,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,598:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-29 15:15:06,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,614:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-29 15:15:06,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:06,697:INFO:Preparing preprocessing pipeline...
2025-03-29 15:15:06,698:INFO:Set up label encoding.
2025-03-29 15:15:06,698:INFO:Set up simple imputation.
2025-03-29 15:15:06,701:INFO:Set up encoding of categorical features.
2025-03-29 15:15:06,701:INFO:Set up feature normalization.
2025-03-29 15:15:06,702:INFO:Set up column name cleaning.
2025-03-29 15:15:06,824:INFO:Finished creating preprocessing pipeline.
2025-03-29 15:15:06,829:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              co...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-03-29 15:15:06,829:INFO:Creating final display dataframe.
2025-03-29 15:15:07,097:INFO:Setup _display_container:                     Description                       Value
0                    Session id                         123
1                        Target               Traffic_Level
2                   Target type                  Multiclass
3                Target mapping  High: 0, Low: 1, Medium: 2
4           Original data shape                  (48202, 8)
5        Transformed data shape                 (48202, 29)
6   Transformed train set shape                 (33741, 29)
7    Transformed test set shape                 (14461, 29)
8              Numeric features                           5
9          Categorical features                           2
10                   Preprocess                        True
11              Imputation type                      simple
12           Numeric imputation                        mean
13       Categorical imputation                        mode
14     Maximum one-hot encoding                          25
15              Encoding method                        None
16                    Normalize                        True
17             Normalize method                      zscore
18               Fold Generator             StratifiedKFold
19                  Fold Number                          10
20                     CPU Jobs                          -1
21                      Use GPU                       False
22               Log Experiment                       False
23              Experiment Name            clf-default-name
24                          USI                        76c6
2025-03-29 15:15:07,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:07,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:07,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:07,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:15:07,187:INFO:setup() successfully completed in 0.84s...............
2025-03-29 15:15:07,187:INFO:Initializing compare_models()
2025-03-29 15:15:07,187:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-29 15:15:07,188:INFO:Checking exceptions
2025-03-29 15:15:07,192:INFO:Preparing display monitor
2025-03-29 15:15:07,207:INFO:Initializing Logistic Regression
2025-03-29 15:15:07,207:INFO:Total runtime is 0.0 minutes
2025-03-29 15:15:07,211:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:07,211:INFO:Initializing create_model()
2025-03-29 15:15:07,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:07,211:INFO:Checking exceptions
2025-03-29 15:15:07,212:INFO:Importing libraries
2025-03-29 15:15:07,212:INFO:Copying training dataset
2025-03-29 15:15:07,221:INFO:Defining folds
2025-03-29 15:15:07,221:INFO:Declaring metric variables
2025-03-29 15:15:07,224:INFO:Importing untrained model
2025-03-29 15:15:07,228:INFO:Logistic Regression Imported successfully
2025-03-29 15:15:07,231:INFO:Starting cross validation
2025-03-29 15:15:07,233:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:10,264:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:10,273:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:10,274:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,274:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,274:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,275:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:10,275:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:10,277:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:10,281:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,282:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,283:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,283:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,287:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,290:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,291:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,292:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:10,296:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:10,296:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,297:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:10,298:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,299:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,299:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,300:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,300:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,303:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,304:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,305:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,308:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,310:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,314:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,314:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,315:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,315:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,315:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,321:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,327:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,331:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,338:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:10,371:INFO:Calculating mean and std
2025-03-29 15:15:10,372:INFO:Creating metrics dataframe
2025-03-29 15:15:10,374:INFO:Uploading results into container
2025-03-29 15:15:10,375:INFO:Uploading model into container now
2025-03-29 15:15:10,375:INFO:_master_model_container: 1
2025-03-29 15:15:10,375:INFO:_display_container: 2
2025-03-29 15:15:10,376:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-29 15:15:10,376:INFO:create_model() successfully completed......................................
2025-03-29 15:15:10,496:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:10,496:INFO:Creating metrics dataframe
2025-03-29 15:15:10,500:INFO:Initializing K Neighbors Classifier
2025-03-29 15:15:10,500:INFO:Total runtime is 0.05488226811091105 minutes
2025-03-29 15:15:10,502:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:10,502:INFO:Initializing create_model()
2025-03-29 15:15:10,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:10,502:INFO:Checking exceptions
2025-03-29 15:15:10,503:INFO:Importing libraries
2025-03-29 15:15:10,503:INFO:Copying training dataset
2025-03-29 15:15:10,510:INFO:Defining folds
2025-03-29 15:15:10,510:INFO:Declaring metric variables
2025-03-29 15:15:10,512:INFO:Importing untrained model
2025-03-29 15:15:10,514:INFO:K Neighbors Classifier Imported successfully
2025-03-29 15:15:10,518:INFO:Starting cross validation
2025-03-29 15:15:10,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:11,862:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,864:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,865:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,867:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,878:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,880:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,882:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,884:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,886:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,895:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,896:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,896:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,897:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,901:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,902:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,905:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,912:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,913:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,919:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,920:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,926:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,926:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,932:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:11,936:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,174:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,176:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,185:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,187:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,196:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,198:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,223:INFO:Calculating mean and std
2025-03-29 15:15:13,224:INFO:Creating metrics dataframe
2025-03-29 15:15:13,225:INFO:Uploading results into container
2025-03-29 15:15:13,226:INFO:Uploading model into container now
2025-03-29 15:15:13,226:INFO:_master_model_container: 2
2025-03-29 15:15:13,226:INFO:_display_container: 2
2025-03-29 15:15:13,226:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-29 15:15:13,227:INFO:create_model() successfully completed......................................
2025-03-29 15:15:13,309:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:13,309:INFO:Creating metrics dataframe
2025-03-29 15:15:13,313:INFO:Initializing Naive Bayes
2025-03-29 15:15:13,314:INFO:Total runtime is 0.10178226629892985 minutes
2025-03-29 15:15:13,316:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:13,316:INFO:Initializing create_model()
2025-03-29 15:15:13,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:13,316:INFO:Checking exceptions
2025-03-29 15:15:13,316:INFO:Importing libraries
2025-03-29 15:15:13,316:INFO:Copying training dataset
2025-03-29 15:15:13,323:INFO:Defining folds
2025-03-29 15:15:13,323:INFO:Declaring metric variables
2025-03-29 15:15:13,325:INFO:Importing untrained model
2025-03-29 15:15:13,327:INFO:Naive Bayes Imported successfully
2025-03-29 15:15:13,331:INFO:Starting cross validation
2025-03-29 15:15:13,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:13,610:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,616:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,616:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,618:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,621:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,622:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,624:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,625:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,629:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,631:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,631:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,632:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,632:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,634:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,635:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,638:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,638:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,640:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,641:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,646:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,647:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,647:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,648:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,649:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,649:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,651:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,656:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,656:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,664:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,664:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:13,686:INFO:Calculating mean and std
2025-03-29 15:15:13,686:INFO:Creating metrics dataframe
2025-03-29 15:15:13,688:INFO:Uploading results into container
2025-03-29 15:15:13,688:INFO:Uploading model into container now
2025-03-29 15:15:13,688:INFO:_master_model_container: 3
2025-03-29 15:15:13,689:INFO:_display_container: 2
2025-03-29 15:15:13,689:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-29 15:15:13,689:INFO:create_model() successfully completed......................................
2025-03-29 15:15:13,770:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:13,770:INFO:Creating metrics dataframe
2025-03-29 15:15:13,774:INFO:Initializing Decision Tree Classifier
2025-03-29 15:15:13,774:INFO:Total runtime is 0.10944899717966715 minutes
2025-03-29 15:15:13,776:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:13,776:INFO:Initializing create_model()
2025-03-29 15:15:13,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:13,776:INFO:Checking exceptions
2025-03-29 15:15:13,776:INFO:Importing libraries
2025-03-29 15:15:13,776:INFO:Copying training dataset
2025-03-29 15:15:13,782:INFO:Defining folds
2025-03-29 15:15:13,782:INFO:Declaring metric variables
2025-03-29 15:15:13,784:INFO:Importing untrained model
2025-03-29 15:15:13,785:INFO:Decision Tree Classifier Imported successfully
2025-03-29 15:15:13,790:INFO:Starting cross validation
2025-03-29 15:15:13,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:14,139:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,139:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,143:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,144:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,146:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,148:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,148:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,151:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,151:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,152:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,153:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,159:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,159:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,161:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,163:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,163:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,165:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,166:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,167:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,167:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,169:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,172:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,173:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,176:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,179:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,179:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,181:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,182:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,183:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,193:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,209:INFO:Calculating mean and std
2025-03-29 15:15:14,210:INFO:Creating metrics dataframe
2025-03-29 15:15:14,211:INFO:Uploading results into container
2025-03-29 15:15:14,211:INFO:Uploading model into container now
2025-03-29 15:15:14,211:INFO:_master_model_container: 4
2025-03-29 15:15:14,211:INFO:_display_container: 2
2025-03-29 15:15:14,212:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-03-29 15:15:14,212:INFO:create_model() successfully completed......................................
2025-03-29 15:15:14,293:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:14,293:INFO:Creating metrics dataframe
2025-03-29 15:15:14,298:INFO:Initializing SVM - Linear Kernel
2025-03-29 15:15:14,298:INFO:Total runtime is 0.11818011204401652 minutes
2025-03-29 15:15:14,300:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:14,300:INFO:Initializing create_model()
2025-03-29 15:15:14,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:14,300:INFO:Checking exceptions
2025-03-29 15:15:14,300:INFO:Importing libraries
2025-03-29 15:15:14,300:INFO:Copying training dataset
2025-03-29 15:15:14,308:INFO:Defining folds
2025-03-29 15:15:14,308:INFO:Declaring metric variables
2025-03-29 15:15:14,310:INFO:Importing untrained model
2025-03-29 15:15:14,312:INFO:SVM - Linear Kernel Imported successfully
2025-03-29 15:15:14,316:INFO:Starting cross validation
2025-03-29 15:15:14,318:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:14,916:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:14,923:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,939:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,955:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,969:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:14,976:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:14,991:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,010:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,066:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,071:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,083:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,096:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,097:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,100:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,100:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,102:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,107:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,111:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,113:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,118:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,118:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,123:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,129:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,132:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,133:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,133:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,141:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,143:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,146:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,147:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,147:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,159:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,160:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,175:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,176:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,197:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,201:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,212:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,222:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,236:INFO:Calculating mean and std
2025-03-29 15:15:15,236:INFO:Creating metrics dataframe
2025-03-29 15:15:15,238:INFO:Uploading results into container
2025-03-29 15:15:15,239:INFO:Uploading model into container now
2025-03-29 15:15:15,239:INFO:_master_model_container: 5
2025-03-29 15:15:15,239:INFO:_display_container: 2
2025-03-29 15:15:15,239:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-29 15:15:15,240:INFO:create_model() successfully completed......................................
2025-03-29 15:15:15,324:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:15,324:INFO:Creating metrics dataframe
2025-03-29 15:15:15,328:INFO:Initializing Ridge Classifier
2025-03-29 15:15:15,328:INFO:Total runtime is 0.13534785509109498 minutes
2025-03-29 15:15:15,330:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:15,331:INFO:Initializing create_model()
2025-03-29 15:15:15,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:15,331:INFO:Checking exceptions
2025-03-29 15:15:15,331:INFO:Importing libraries
2025-03-29 15:15:15,331:INFO:Copying training dataset
2025-03-29 15:15:15,337:INFO:Defining folds
2025-03-29 15:15:15,337:INFO:Declaring metric variables
2025-03-29 15:15:15,339:INFO:Importing untrained model
2025-03-29 15:15:15,341:INFO:Ridge Classifier Imported successfully
2025-03-29 15:15:15,346:INFO:Starting cross validation
2025-03-29 15:15:15,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:15,616:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,618:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,621:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,621:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,621:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,625:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,626:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,627:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,628:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,629:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,631:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,631:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,635:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,637:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,637:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,637:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:15,638:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,638:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,639:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,642:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,642:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,644:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,644:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,645:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,645:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,646:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:15,652:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,652:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,653:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,655:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,655:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:15,657:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,658:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,658:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,661:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,661:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:15,662:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,662:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,664:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:15,668:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:15,668:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,670:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,671:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,673:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,674:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:15,696:INFO:Calculating mean and std
2025-03-29 15:15:15,696:INFO:Creating metrics dataframe
2025-03-29 15:15:15,698:INFO:Uploading results into container
2025-03-29 15:15:15,698:INFO:Uploading model into container now
2025-03-29 15:15:15,699:INFO:_master_model_container: 6
2025-03-29 15:15:15,699:INFO:_display_container: 2
2025-03-29 15:15:15,699:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-03-29 15:15:15,699:INFO:create_model() successfully completed......................................
2025-03-29 15:15:15,782:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:15,782:INFO:Creating metrics dataframe
2025-03-29 15:15:15,787:INFO:Initializing Random Forest Classifier
2025-03-29 15:15:15,787:INFO:Total runtime is 0.14299798011779785 minutes
2025-03-29 15:15:15,789:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:15,789:INFO:Initializing create_model()
2025-03-29 15:15:15,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:15,789:INFO:Checking exceptions
2025-03-29 15:15:15,789:INFO:Importing libraries
2025-03-29 15:15:15,790:INFO:Copying training dataset
2025-03-29 15:15:15,796:INFO:Defining folds
2025-03-29 15:15:15,796:INFO:Declaring metric variables
2025-03-29 15:15:15,798:INFO:Importing untrained model
2025-03-29 15:15:15,800:INFO:Random Forest Classifier Imported successfully
2025-03-29 15:15:15,804:INFO:Starting cross validation
2025-03-29 15:15:15,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:19,447:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,463:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,464:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,464:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,465:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,466:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,471:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,481:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,481:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,482:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,483:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,484:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,490:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,492:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,492:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,508:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,512:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,513:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,516:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,517:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,518:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,533:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,537:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,556:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,568:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,570:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,580:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,580:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,590:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:19,620:INFO:Calculating mean and std
2025-03-29 15:15:19,620:INFO:Creating metrics dataframe
2025-03-29 15:15:19,622:INFO:Uploading results into container
2025-03-29 15:15:19,623:INFO:Uploading model into container now
2025-03-29 15:15:19,623:INFO:_master_model_container: 7
2025-03-29 15:15:19,623:INFO:_display_container: 2
2025-03-29 15:15:19,623:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-29 15:15:19,624:INFO:create_model() successfully completed......................................
2025-03-29 15:15:19,735:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:19,735:INFO:Creating metrics dataframe
2025-03-29 15:15:19,741:INFO:Initializing Quadratic Discriminant Analysis
2025-03-29 15:15:19,741:INFO:Total runtime is 0.20890058676401774 minutes
2025-03-29 15:15:19,743:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:19,744:INFO:Initializing create_model()
2025-03-29 15:15:19,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:19,744:INFO:Checking exceptions
2025-03-29 15:15:19,744:INFO:Importing libraries
2025-03-29 15:15:19,744:INFO:Copying training dataset
2025-03-29 15:15:19,751:INFO:Defining folds
2025-03-29 15:15:19,752:INFO:Declaring metric variables
2025-03-29 15:15:19,754:INFO:Importing untrained model
2025-03-29 15:15:19,758:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-29 15:15:19,763:INFO:Starting cross validation
2025-03-29 15:15:19,764:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:19,993:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 15:15:20,000:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 15:15:20,002:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 15:15:20,017:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 15:15:20,021:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 15:15:20,021:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 15:15:20,024:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 15:15:20,024:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 15:15:20,028:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 15:15:20,030:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 15:15:20,061:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:20,063:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:20,068:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:20,069:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,071:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,076:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:20,076:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,079:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:20,080:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:20,081:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:20,081:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:20,082:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:20,083:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,085:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,086:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,087:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,087:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,088:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,088:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,088:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:20,089:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,093:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,095:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,100:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,100:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,101:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,103:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,103:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,104:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,104:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,105:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,109:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,110:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,116:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,116:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,117:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,118:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,121:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,121:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,127:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:20,150:INFO:Calculating mean and std
2025-03-29 15:15:20,151:INFO:Creating metrics dataframe
2025-03-29 15:15:20,153:INFO:Uploading results into container
2025-03-29 15:15:20,154:INFO:Uploading model into container now
2025-03-29 15:15:20,154:INFO:_master_model_container: 8
2025-03-29 15:15:20,154:INFO:_display_container: 2
2025-03-29 15:15:20,154:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-29 15:15:20,154:INFO:create_model() successfully completed......................................
2025-03-29 15:15:20,252:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:20,252:INFO:Creating metrics dataframe
2025-03-29 15:15:20,259:INFO:Initializing Ada Boost Classifier
2025-03-29 15:15:20,259:INFO:Total runtime is 0.21753919919331868 minutes
2025-03-29 15:15:20,261:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:20,261:INFO:Initializing create_model()
2025-03-29 15:15:20,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:20,261:INFO:Checking exceptions
2025-03-29 15:15:20,261:INFO:Importing libraries
2025-03-29 15:15:20,261:INFO:Copying training dataset
2025-03-29 15:15:20,270:INFO:Defining folds
2025-03-29 15:15:20,270:INFO:Declaring metric variables
2025-03-29 15:15:20,273:INFO:Importing untrained model
2025-03-29 15:15:20,275:INFO:Ada Boost Classifier Imported successfully
2025-03-29 15:15:20,279:INFO:Starting cross validation
2025-03-29 15:15:20,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:20,510:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 15:15:20,510:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 15:15:20,510:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 15:15:20,510:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 15:15:20,511:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 15:15:20,515:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 15:15:20,518:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 15:15:20,520:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 15:15:20,520:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 15:15:20,522:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 15:15:21,432:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:21,434:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:21,437:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:21,440:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,440:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:21,440:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:21,440:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,442:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,444:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:21,446:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,447:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,448:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:21,451:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,451:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,452:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,454:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,456:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:21,457:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:21,459:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,460:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,463:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,463:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,463:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,463:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,464:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:21,465:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,468:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,468:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,470:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,474:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,475:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,476:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,478:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,479:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,480:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,484:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,485:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,493:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,493:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,501:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:21,518:INFO:Calculating mean and std
2025-03-29 15:15:21,519:INFO:Creating metrics dataframe
2025-03-29 15:15:21,520:INFO:Uploading results into container
2025-03-29 15:15:21,521:INFO:Uploading model into container now
2025-03-29 15:15:21,521:INFO:_master_model_container: 9
2025-03-29 15:15:21,521:INFO:_display_container: 2
2025-03-29 15:15:21,521:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-03-29 15:15:21,521:INFO:create_model() successfully completed......................................
2025-03-29 15:15:21,599:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:21,599:INFO:Creating metrics dataframe
2025-03-29 15:15:21,605:INFO:Initializing Gradient Boosting Classifier
2025-03-29 15:15:21,605:INFO:Total runtime is 0.23997258345286052 minutes
2025-03-29 15:15:21,607:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:21,607:INFO:Initializing create_model()
2025-03-29 15:15:21,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:21,607:INFO:Checking exceptions
2025-03-29 15:15:21,607:INFO:Importing libraries
2025-03-29 15:15:21,607:INFO:Copying training dataset
2025-03-29 15:15:21,613:INFO:Defining folds
2025-03-29 15:15:21,614:INFO:Declaring metric variables
2025-03-29 15:15:21,616:INFO:Importing untrained model
2025-03-29 15:15:21,617:INFO:Gradient Boosting Classifier Imported successfully
2025-03-29 15:15:21,621:INFO:Starting cross validation
2025-03-29 15:15:21,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:27,584:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:27,592:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,607:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,611:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:27,616:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,624:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,628:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,629:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:27,636:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,640:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,651:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,663:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:27,665:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:27,669:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,669:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,671:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:27,674:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:27,675:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:27,676:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:27,678:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,679:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,680:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,680:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,681:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,685:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,690:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,690:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,692:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,693:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,696:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,696:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,698:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:27,699:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,700:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,703:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,703:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,704:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,719:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,730:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:27,758:INFO:Calculating mean and std
2025-03-29 15:15:27,759:INFO:Creating metrics dataframe
2025-03-29 15:15:27,760:INFO:Uploading results into container
2025-03-29 15:15:27,760:INFO:Uploading model into container now
2025-03-29 15:15:27,760:INFO:_master_model_container: 10
2025-03-29 15:15:27,760:INFO:_display_container: 2
2025-03-29 15:15:27,761:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 15:15:27,761:INFO:create_model() successfully completed......................................
2025-03-29 15:15:27,841:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:27,841:INFO:Creating metrics dataframe
2025-03-29 15:15:27,846:INFO:Initializing Linear Discriminant Analysis
2025-03-29 15:15:27,847:INFO:Total runtime is 0.34400619665781657 minutes
2025-03-29 15:15:27,848:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:27,849:INFO:Initializing create_model()
2025-03-29 15:15:27,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:27,849:INFO:Checking exceptions
2025-03-29 15:15:27,849:INFO:Importing libraries
2025-03-29 15:15:27,849:INFO:Copying training dataset
2025-03-29 15:15:27,855:INFO:Defining folds
2025-03-29 15:15:27,855:INFO:Declaring metric variables
2025-03-29 15:15:27,857:INFO:Importing untrained model
2025-03-29 15:15:27,859:INFO:Linear Discriminant Analysis Imported successfully
2025-03-29 15:15:27,864:INFO:Starting cross validation
2025-03-29 15:15:27,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:28,177:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:28,180:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:28,182:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:28,182:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,185:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:28,187:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:28,187:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,189:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,190:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:28,190:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,191:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:28,194:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:28,194:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,196:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-29 15:15:28,197:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,197:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,198:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,200:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,203:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,203:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,203:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,206:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,206:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,211:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,211:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,212:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,214:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,215:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,216:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,220:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,220:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,222:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,223:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,223:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,227:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,228:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,233:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,235:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,236:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:28,255:INFO:Calculating mean and std
2025-03-29 15:15:28,255:INFO:Creating metrics dataframe
2025-03-29 15:15:28,257:INFO:Uploading results into container
2025-03-29 15:15:28,257:INFO:Uploading model into container now
2025-03-29 15:15:28,258:INFO:_master_model_container: 11
2025-03-29 15:15:28,258:INFO:_display_container: 2
2025-03-29 15:15:28,258:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-29 15:15:28,258:INFO:create_model() successfully completed......................................
2025-03-29 15:15:28,335:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:28,335:INFO:Creating metrics dataframe
2025-03-29 15:15:28,341:INFO:Initializing Extra Trees Classifier
2025-03-29 15:15:28,341:INFO:Total runtime is 0.3522395054499308 minutes
2025-03-29 15:15:28,343:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:28,343:INFO:Initializing create_model()
2025-03-29 15:15:28,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:28,343:INFO:Checking exceptions
2025-03-29 15:15:28,343:INFO:Importing libraries
2025-03-29 15:15:28,343:INFO:Copying training dataset
2025-03-29 15:15:28,349:INFO:Defining folds
2025-03-29 15:15:28,349:INFO:Declaring metric variables
2025-03-29 15:15:28,351:INFO:Importing untrained model
2025-03-29 15:15:28,353:INFO:Extra Trees Classifier Imported successfully
2025-03-29 15:15:28,357:INFO:Starting cross validation
2025-03-29 15:15:28,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:31,032:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,033:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,034:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,057:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,074:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,080:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,089:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,093:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,093:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,092:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,110:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,117:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,123:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,135:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,135:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,135:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,135:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,140:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,142:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,145:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,147:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,151:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,157:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,168:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,172:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,181:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,184:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,193:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,199:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:31,217:INFO:Calculating mean and std
2025-03-29 15:15:31,218:INFO:Creating metrics dataframe
2025-03-29 15:15:31,219:INFO:Uploading results into container
2025-03-29 15:15:31,220:INFO:Uploading model into container now
2025-03-29 15:15:31,220:INFO:_master_model_container: 12
2025-03-29 15:15:31,220:INFO:_display_container: 2
2025-03-29 15:15:31,221:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-03-29 15:15:31,221:INFO:create_model() successfully completed......................................
2025-03-29 15:15:31,313:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:31,314:INFO:Creating metrics dataframe
2025-03-29 15:15:31,320:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 15:15:31,320:INFO:Total runtime is 0.4018918712933858 minutes
2025-03-29 15:15:31,322:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:31,322:INFO:Initializing create_model()
2025-03-29 15:15:31,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:31,322:INFO:Checking exceptions
2025-03-29 15:15:31,322:INFO:Importing libraries
2025-03-29 15:15:31,322:INFO:Copying training dataset
2025-03-29 15:15:31,329:INFO:Defining folds
2025-03-29 15:15:31,329:INFO:Declaring metric variables
2025-03-29 15:15:31,331:INFO:Importing untrained model
2025-03-29 15:15:31,333:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:15:31,337:INFO:Starting cross validation
2025-03-29 15:15:31,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:33,099:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,101:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,118:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,118:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,134:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,137:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,174:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,175:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,190:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,192:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,206:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,207:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,210:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,226:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,243:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,255:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,272:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,289:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,317:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,321:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,334:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,337:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,351:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,355:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,383:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,399:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,414:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,485:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,500:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,515:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,543:INFO:Calculating mean and std
2025-03-29 15:15:33,544:INFO:Creating metrics dataframe
2025-03-29 15:15:33,545:INFO:Uploading results into container
2025-03-29 15:15:33,546:INFO:Uploading model into container now
2025-03-29 15:15:33,546:INFO:_master_model_container: 13
2025-03-29 15:15:33,546:INFO:_display_container: 2
2025-03-29 15:15:33,547:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-29 15:15:33,547:INFO:create_model() successfully completed......................................
2025-03-29 15:15:33,636:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:33,636:INFO:Creating metrics dataframe
2025-03-29 15:15:33,643:INFO:Initializing Dummy Classifier
2025-03-29 15:15:33,643:INFO:Total runtime is 0.4406049013137817 minutes
2025-03-29 15:15:33,645:INFO:SubProcess create_model() called ==================================
2025-03-29 15:15:33,645:INFO:Initializing create_model()
2025-03-29 15:15:33,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023903746C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:33,645:INFO:Checking exceptions
2025-03-29 15:15:33,645:INFO:Importing libraries
2025-03-29 15:15:33,645:INFO:Copying training dataset
2025-03-29 15:15:33,652:INFO:Defining folds
2025-03-29 15:15:33,652:INFO:Declaring metric variables
2025-03-29 15:15:33,655:INFO:Importing untrained model
2025-03-29 15:15:33,657:INFO:Dummy Classifier Imported successfully
2025-03-29 15:15:33,662:INFO:Starting cross validation
2025-03-29 15:15:33,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:15:33,901:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,905:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,909:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,912:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,915:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,918:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,918:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,918:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,920:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,920:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,920:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,921:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,925:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,927:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,927:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:33,928:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:33,930:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:33,931:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,934:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,934:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,934:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,934:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,935:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,936:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:33,937:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,937:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,940:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:33,941:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,943:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,943:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:33,944:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:33,944:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:33,944:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:33,945:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,948:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,950:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 15:15:33,950:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,951:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,951:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,956:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:33,988:INFO:Calculating mean and std
2025-03-29 15:15:33,989:INFO:Creating metrics dataframe
2025-03-29 15:15:33,990:INFO:Uploading results into container
2025-03-29 15:15:33,990:INFO:Uploading model into container now
2025-03-29 15:15:33,990:INFO:_master_model_container: 14
2025-03-29 15:15:33,990:INFO:_display_container: 2
2025-03-29 15:15:33,991:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-03-29 15:15:33,991:INFO:create_model() successfully completed......................................
2025-03-29 15:15:34,071:INFO:SubProcess create_model() end ==================================
2025-03-29 15:15:34,072:INFO:Creating metrics dataframe
2025-03-29 15:15:34,079:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-29 15:15:34,084:INFO:Initializing create_model()
2025-03-29 15:15:34,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:34,084:INFO:Checking exceptions
2025-03-29 15:15:34,085:INFO:Importing libraries
2025-03-29 15:15:34,085:INFO:Copying training dataset
2025-03-29 15:15:34,091:INFO:Defining folds
2025-03-29 15:15:34,091:INFO:Declaring metric variables
2025-03-29 15:15:34,091:INFO:Importing untrained model
2025-03-29 15:15:34,091:INFO:Declaring custom model
2025-03-29 15:15:34,092:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:15:34,093:INFO:Cross validation set to False
2025-03-29 15:15:34,093:INFO:Fitting Model
2025-03-29 15:15:34,200:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:15:34,202:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000705 seconds.
2025-03-29 15:15:34,202:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:15:34,202:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:15:34,202:INFO:[LightGBM] [Info] Total Bins 578
2025-03-29 15:15:34,202:INFO:[LightGBM] [Info] Number of data points in the train set: 33741, number of used features: 15
2025-03-29 15:15:34,203:INFO:[LightGBM] [Info] Start training from score -1.387154
2025-03-29 15:15:34,203:INFO:[LightGBM] [Info] Start training from score -1.386205
2025-03-29 15:15:34,203:INFO:[LightGBM] [Info] Start training from score -0.692762
2025-03-29 15:15:34,342:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-29 15:15:34,342:INFO:create_model() successfully completed......................................
2025-03-29 15:15:34,439:INFO:Initializing create_model()
2025-03-29 15:15:34,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:34,439:INFO:Checking exceptions
2025-03-29 15:15:34,441:INFO:Importing libraries
2025-03-29 15:15:34,441:INFO:Copying training dataset
2025-03-29 15:15:34,449:INFO:Defining folds
2025-03-29 15:15:34,449:INFO:Declaring metric variables
2025-03-29 15:15:34,449:INFO:Importing untrained model
2025-03-29 15:15:34,449:INFO:Declaring custom model
2025-03-29 15:15:34,450:INFO:Gradient Boosting Classifier Imported successfully
2025-03-29 15:15:34,451:INFO:Cross validation set to False
2025-03-29 15:15:34,451:INFO:Fitting Model
2025-03-29 15:15:38,952:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 15:15:38,952:INFO:create_model() successfully completed......................................
2025-03-29 15:15:39,036:INFO:Initializing create_model()
2025-03-29 15:15:39,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:39,036:INFO:Checking exceptions
2025-03-29 15:15:39,037:INFO:Importing libraries
2025-03-29 15:15:39,037:INFO:Copying training dataset
2025-03-29 15:15:39,044:INFO:Defining folds
2025-03-29 15:15:39,045:INFO:Declaring metric variables
2025-03-29 15:15:39,045:INFO:Importing untrained model
2025-03-29 15:15:39,045:INFO:Declaring custom model
2025-03-29 15:15:39,045:INFO:Ridge Classifier Imported successfully
2025-03-29 15:15:39,046:INFO:Cross validation set to False
2025-03-29 15:15:39,046:INFO:Fitting Model
2025-03-29 15:15:39,144:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-03-29 15:15:39,144:INFO:create_model() successfully completed......................................
2025-03-29 15:15:39,244:INFO:_master_model_container: 14
2025-03-29 15:15:39,244:INFO:_display_container: 2
2025-03-29 15:15:39,245:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)]
2025-03-29 15:15:39,245:INFO:compare_models() successfully completed......................................
2025-03-29 15:15:39,246:INFO:Initializing evaluate_model()
2025-03-29 15:15:39,246:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-29 15:15:39,256:INFO:Initializing plot_model()
2025-03-29 15:15:39,256:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:15:39,256:INFO:Checking exceptions
2025-03-29 15:15:39,259:INFO:Preloading libraries
2025-03-29 15:15:39,273:INFO:Copying training dataset
2025-03-29 15:15:39,273:INFO:Plot type: pipeline
2025-03-29 15:15:39,400:INFO:Visual Rendered Successfully
2025-03-29 15:15:39,482:INFO:plot_model() successfully completed......................................
2025-03-29 15:15:39,484:INFO:Initializing finalize_model()
2025-03-29 15:15:39,484:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-29 15:15:39,485:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-29 15:15:39,489:INFO:Initializing create_model()
2025-03-29 15:15:39,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:15:39,489:INFO:Checking exceptions
2025-03-29 15:15:39,490:INFO:Importing libraries
2025-03-29 15:15:39,490:INFO:Copying training dataset
2025-03-29 15:15:39,490:INFO:Defining folds
2025-03-29 15:15:39,490:INFO:Declaring metric variables
2025-03-29 15:15:39,490:INFO:Importing untrained model
2025-03-29 15:15:39,491:INFO:Declaring custom model
2025-03-29 15:15:39,491:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:15:39,492:INFO:Cross validation set to False
2025-03-29 15:15:39,492:INFO:Fitting Model
2025-03-29 15:15:39,647:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:15:39,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001179 seconds.
2025-03-29 15:15:39,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:15:39,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:15:39,650:INFO:[LightGBM] [Info] Total Bins 590
2025-03-29 15:15:39,651:INFO:[LightGBM] [Info] Number of data points in the train set: 48202, number of used features: 16
2025-03-29 15:15:39,651:INFO:[LightGBM] [Info] Start training from score -1.387166
2025-03-29 15:15:39,651:INFO:[LightGBM] [Info] Start training from score -1.386253
2025-03-29 15:15:39,651:INFO:[LightGBM] [Info] Start training from score -0.692732
2025-03-29 15:15:39,900:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-03-29 15:15:39,901:INFO:create_model() successfully completed......................................
2025-03-29 15:15:39,999:INFO:_master_model_container: 14
2025-03-29 15:15:39,999:INFO:_display_container: 2
2025-03-29 15:15:40,005:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-03-29 15:15:40,005:INFO:finalize_model() successfully completed......................................
2025-03-29 15:15:40,094:INFO:Initializing predict_model()
2025-03-29 15:15:40,094:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000239064ACB80>)
2025-03-29 15:15:40,094:INFO:Checking exceptions
2025-03-29 15:15:40,094:INFO:Preloading libraries
2025-03-29 15:15:40,313:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:40,370:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:40,413:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Medium') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-03-29 15:15:40,581:INFO:Initializing save_model()
2025-03-29 15:15:40,581:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=traffic_classification_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              co...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-29 15:15:40,581:INFO:Adding model into prep_pipe
2025-03-29 15:15:40,581:WARNING:Only Model saved as it was a pipeline.
2025-03-29 15:15:40,596:INFO:traffic_classification_model.pkl saved in current working directory
2025-03-29 15:15:40,604:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_featu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-03-29 15:15:40,605:INFO:save_model() successfully completed......................................
2025-03-29 15:15:40,722:INFO:Initializing get_config()
2025-03-29 15:15:40,723:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, variable=X_train)
2025-03-29 15:15:40,723:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-03-29 15:15:40,723:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-03-29 15:15:40,730:INFO:Variable:  returned as           holiday        temp  rain_1h  snow_1h  clouds_all weather_main  Rush Hour
41237  No Holiday  255.009995     0.00      0.0           1        Clear          0
4412   No Holiday  267.420013     0.00      0.0          75       Clouds          1
38298  No Holiday  280.290009     0.00      0.0          40       Clouds          0
29022  No Holiday  265.880005     0.00      0.0          90         Snow          0
8465   No Holiday  290.109985     0.00      0.0           1        Clear          1
...           ...         ...      ...      ...         ...          ...        ...
36482  No Holiday  296.299988     0.00      0.0          75       Clouds          0
3845   No Holiday  266.510010     0.00      0.0          90         Snow          0
12191  No Holiday  264.010010     0.76      0.0          90         Rain          1
10933  No Holiday  260.100006     1.27      0.0          90         Mist          0
46418  No Holiday  295.220001     0.00      0.0          90         Rain          1

[33741 rows x 7 columns]
2025-03-29 15:15:40,730:INFO:get_config() successfully completed......................................
2025-03-29 15:15:46,431:INFO:Initializing plot_model()
2025-03-29 15:15:46,431:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:15:46,431:INFO:Checking exceptions
2025-03-29 15:15:46,434:INFO:Preloading libraries
2025-03-29 15:15:46,445:INFO:Copying training dataset
2025-03-29 15:15:46,445:INFO:Plot type: parameter
2025-03-29 15:15:46,448:INFO:Visual Rendered Successfully
2025-03-29 15:15:46,561:INFO:plot_model() successfully completed......................................
2025-03-29 15:15:47,420:INFO:Initializing plot_model()
2025-03-29 15:15:47,420:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:15:47,421:INFO:Checking exceptions
2025-03-29 15:15:47,424:INFO:Preloading libraries
2025-03-29 15:15:47,434:INFO:Copying training dataset
2025-03-29 15:15:47,434:INFO:Plot type: auc
2025-03-29 15:15:47,719:INFO:Fitting Model
2025-03-29 15:15:47,720:INFO:Scoring test/hold-out set
2025-03-29 15:15:47,877:INFO:Visual Rendered Successfully
2025-03-29 15:15:47,981:INFO:plot_model() successfully completed......................................
2025-03-29 15:15:48,214:INFO:Initializing plot_model()
2025-03-29 15:15:48,215:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:15:48,215:INFO:Checking exceptions
2025-03-29 15:15:48,218:INFO:Preloading libraries
2025-03-29 15:15:48,228:INFO:Copying training dataset
2025-03-29 15:15:48,228:INFO:Plot type: confusion_matrix
2025-03-29 15:15:48,496:INFO:Fitting Model
2025-03-29 15:15:48,497:INFO:Scoring test/hold-out set
2025-03-29 15:15:48,596:INFO:Visual Rendered Successfully
2025-03-29 15:15:48,694:INFO:plot_model() successfully completed......................................
2025-03-29 15:15:49,376:INFO:Initializing plot_model()
2025-03-29 15:15:49,377:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:15:49,377:INFO:Checking exceptions
2025-03-29 15:15:50,585:INFO:Initializing plot_model()
2025-03-29 15:15:50,585:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:15:50,585:INFO:Checking exceptions
2025-03-29 15:15:50,590:INFO:Preloading libraries
2025-03-29 15:15:50,599:INFO:Copying training dataset
2025-03-29 15:15:50,599:INFO:Plot type: error
2025-03-29 15:15:50,886:INFO:Fitting Model
2025-03-29 15:15:50,887:INFO:Scoring test/hold-out set
2025-03-29 15:15:51,035:INFO:Visual Rendered Successfully
2025-03-29 15:15:51,140:INFO:plot_model() successfully completed......................................
2025-03-29 15:15:51,166:INFO:Initializing plot_model()
2025-03-29 15:15:51,166:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:15:51,166:INFO:Checking exceptions
2025-03-29 15:15:51,169:INFO:Preloading libraries
2025-03-29 15:15:51,181:INFO:Copying training dataset
2025-03-29 15:15:51,181:INFO:Plot type: pr
2025-03-29 15:15:51,449:INFO:Fitting Model
2025-03-29 15:15:51,476:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:15:51,476:INFO:[LightGBM] [Info] Number of positive: 8428, number of negative: 25313
2025-03-29 15:15:51,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000782 seconds.
2025-03-29 15:15:51,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:15:51,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:15:51,478:INFO:[LightGBM] [Info] Total Bins 578
2025-03-29 15:15:51,478:INFO:[LightGBM] [Info] Number of data points in the train set: 33741, number of used features: 15
2025-03-29 15:15:51,479:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249785 -> initscore=-1.099759
2025-03-29 15:15:51,479:INFO:[LightGBM] [Info] Start training from score -1.099759
2025-03-29 15:15:51,546:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:15:51,546:INFO:[LightGBM] [Info] Number of positive: 8436, number of negative: 25305
2025-03-29 15:15:51,548:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000800 seconds.
2025-03-29 15:15:51,548:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:15:51,548:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:15:51,548:INFO:[LightGBM] [Info] Total Bins 578
2025-03-29 15:15:51,548:INFO:[LightGBM] [Info] Number of data points in the train set: 33741, number of used features: 15
2025-03-29 15:15:51,548:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250022 -> initscore=-1.098494
2025-03-29 15:15:51,548:INFO:[LightGBM] [Info] Start training from score -1.098494
2025-03-29 15:15:51,615:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:15:51,616:INFO:[LightGBM] [Info] Number of positive: 16877, number of negative: 16864
2025-03-29 15:15:51,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.
2025-03-29 15:15:51,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:15:51,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:15:51,617:INFO:[LightGBM] [Info] Total Bins 578
2025-03-29 15:15:51,617:INFO:[LightGBM] [Info] Number of data points in the train set: 33741, number of used features: 15
2025-03-29 15:15:51,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771
2025-03-29 15:15:51,618:INFO:[LightGBM] [Info] Start training from score 0.000771
2025-03-29 15:15:51,663:INFO:Scoring test/hold-out set
2025-03-29 15:15:51,810:INFO:Visual Rendered Successfully
2025-03-29 15:15:51,919:INFO:plot_model() successfully completed......................................
2025-03-29 15:15:52,273:INFO:Initializing plot_model()
2025-03-29 15:15:52,273:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:15:52,273:INFO:Checking exceptions
2025-03-29 15:15:52,276:INFO:Preloading libraries
2025-03-29 15:15:52,285:INFO:Copying training dataset
2025-03-29 15:15:52,285:INFO:Plot type: parameter
2025-03-29 15:15:52,288:INFO:Visual Rendered Successfully
2025-03-29 15:15:52,406:INFO:plot_model() successfully completed......................................
2025-03-29 15:15:52,731:INFO:Initializing plot_model()
2025-03-29 15:15:52,731:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:15:52,731:INFO:Checking exceptions
2025-03-29 15:15:52,734:INFO:Preloading libraries
2025-03-29 15:15:52,745:INFO:Copying training dataset
2025-03-29 15:15:52,745:INFO:Plot type: pipeline
2025-03-29 15:15:52,847:INFO:Visual Rendered Successfully
2025-03-29 15:15:52,952:INFO:plot_model() successfully completed......................................
2025-03-29 15:17:00,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:17:00,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:17:00,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:17:00,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:17:02,922:INFO:Initializing load_model()
2025-03-29 15:17:02,922:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-29 15:17:02,978:INFO:Initializing predict_model()
2025-03-29 15:17:02,978:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DAB3324CD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=1949))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DAB3307E20>)
2025-03-29 15:17:02,978:INFO:Checking exceptions
2025-03-29 15:17:02,978:INFO:Preloading libraries
2025-03-29 15:17:02,979:INFO:Set up data.
2025-03-29 15:17:02,989:INFO:Set up index.
2025-03-29 15:17:14,560:INFO:Initializing plot_model()
2025-03-29 15:17:14,560:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:14,560:INFO:Checking exceptions
2025-03-29 15:17:14,563:INFO:Preloading libraries
2025-03-29 15:17:14,573:INFO:Copying training dataset
2025-03-29 15:17:14,573:INFO:Plot type: parameter
2025-03-29 15:17:14,577:INFO:Visual Rendered Successfully
2025-03-29 15:17:14,698:INFO:plot_model() successfully completed......................................
2025-03-29 15:17:15,769:INFO:Initializing plot_model()
2025-03-29 15:17:15,769:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:15,769:INFO:Checking exceptions
2025-03-29 15:17:15,772:INFO:Preloading libraries
2025-03-29 15:17:15,785:INFO:Copying training dataset
2025-03-29 15:17:15,785:INFO:Plot type: auc
2025-03-29 15:17:16,078:INFO:Fitting Model
2025-03-29 15:17:16,079:INFO:Scoring test/hold-out set
2025-03-29 15:17:16,236:INFO:Visual Rendered Successfully
2025-03-29 15:17:16,348:INFO:plot_model() successfully completed......................................
2025-03-29 15:17:16,392:INFO:Initializing plot_model()
2025-03-29 15:17:16,392:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:16,393:INFO:Checking exceptions
2025-03-29 15:17:16,398:INFO:Preloading libraries
2025-03-29 15:17:16,416:INFO:Copying training dataset
2025-03-29 15:17:16,416:INFO:Plot type: confusion_matrix
2025-03-29 15:17:16,695:INFO:Fitting Model
2025-03-29 15:17:16,695:INFO:Scoring test/hold-out set
2025-03-29 15:17:16,805:INFO:Visual Rendered Successfully
2025-03-29 15:17:16,914:INFO:plot_model() successfully completed......................................
2025-03-29 15:17:17,576:INFO:Initializing plot_model()
2025-03-29 15:17:17,576:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:17,576:INFO:Checking exceptions
2025-03-29 15:17:19,232:INFO:Initializing plot_model()
2025-03-29 15:17:19,232:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:19,232:INFO:Checking exceptions
2025-03-29 15:17:19,237:INFO:Preloading libraries
2025-03-29 15:17:19,261:INFO:Copying training dataset
2025-03-29 15:17:19,261:INFO:Plot type: pr
2025-03-29 15:17:19,546:INFO:Fitting Model
2025-03-29 15:17:19,572:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:17:19,572:INFO:[LightGBM] [Info] Number of positive: 8428, number of negative: 25313
2025-03-29 15:17:19,574:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000730 seconds.
2025-03-29 15:17:19,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:17:19,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:17:19,574:INFO:[LightGBM] [Info] Total Bins 578
2025-03-29 15:17:19,574:INFO:[LightGBM] [Info] Number of data points in the train set: 33741, number of used features: 15
2025-03-29 15:17:19,575:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249785 -> initscore=-1.099759
2025-03-29 15:17:19,575:INFO:[LightGBM] [Info] Start training from score -1.099759
2025-03-29 15:17:19,651:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:17:19,651:INFO:[LightGBM] [Info] Number of positive: 8436, number of negative: 25305
2025-03-29 15:17:19,653:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000776 seconds.
2025-03-29 15:17:19,653:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:17:19,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:17:19,653:INFO:[LightGBM] [Info] Total Bins 578
2025-03-29 15:17:19,653:INFO:[LightGBM] [Info] Number of data points in the train set: 33741, number of used features: 15
2025-03-29 15:17:19,653:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250022 -> initscore=-1.098494
2025-03-29 15:17:19,653:INFO:[LightGBM] [Info] Start training from score -1.098494
2025-03-29 15:17:19,737:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:17:19,737:INFO:[LightGBM] [Info] Number of positive: 16877, number of negative: 16864
2025-03-29 15:17:19,739:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000793 seconds.
2025-03-29 15:17:19,739:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:17:19,739:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:17:19,739:INFO:[LightGBM] [Info] Total Bins 578
2025-03-29 15:17:19,739:INFO:[LightGBM] [Info] Number of data points in the train set: 33741, number of used features: 15
2025-03-29 15:17:19,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771
2025-03-29 15:17:19,740:INFO:[LightGBM] [Info] Start training from score 0.000771
2025-03-29 15:17:19,792:INFO:Scoring test/hold-out set
2025-03-29 15:17:19,937:INFO:Visual Rendered Successfully
2025-03-29 15:17:20,048:INFO:plot_model() successfully completed......................................
2025-03-29 15:17:20,072:INFO:Initializing plot_model()
2025-03-29 15:17:20,072:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:20,072:INFO:Checking exceptions
2025-03-29 15:17:20,075:INFO:Preloading libraries
2025-03-29 15:17:20,088:INFO:Copying training dataset
2025-03-29 15:17:20,088:INFO:Plot type: error
2025-03-29 15:17:20,359:INFO:Fitting Model
2025-03-29 15:17:20,359:INFO:Scoring test/hold-out set
2025-03-29 15:17:20,498:INFO:Visual Rendered Successfully
2025-03-29 15:17:20,615:INFO:plot_model() successfully completed......................................
2025-03-29 15:17:25,811:INFO:Initializing plot_model()
2025-03-29 15:17:25,812:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:25,812:INFO:Checking exceptions
2025-03-29 15:17:25,815:INFO:Preloading libraries
2025-03-29 15:17:25,825:INFO:Copying training dataset
2025-03-29 15:17:25,826:INFO:Plot type: class_report
2025-03-29 15:17:26,111:INFO:Fitting Model
2025-03-29 15:17:26,111:INFO:Scoring test/hold-out set
2025-03-29 15:17:26,255:INFO:Visual Rendered Successfully
2025-03-29 15:17:26,362:INFO:plot_model() successfully completed......................................
2025-03-29 15:17:26,494:INFO:Initializing plot_model()
2025-03-29 15:17:26,494:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:26,494:INFO:Checking exceptions
2025-03-29 15:17:27,011:INFO:Initializing plot_model()
2025-03-29 15:17:27,011:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:27,011:INFO:Checking exceptions
2025-03-29 15:17:27,015:INFO:Preloading libraries
2025-03-29 15:17:27,025:INFO:Copying training dataset
2025-03-29 15:17:27,025:INFO:Plot type: class_report
2025-03-29 15:17:27,309:INFO:Fitting Model
2025-03-29 15:17:27,310:INFO:Scoring test/hold-out set
2025-03-29 15:17:27,441:INFO:Visual Rendered Successfully
2025-03-29 15:17:27,542:INFO:plot_model() successfully completed......................................
2025-03-29 15:17:32,030:INFO:Initializing plot_model()
2025-03-29 15:17:32,030:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:32,030:INFO:Checking exceptions
2025-03-29 15:17:32,720:INFO:Initializing plot_model()
2025-03-29 15:17:32,720:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:32,720:INFO:Checking exceptions
2025-03-29 15:17:32,723:INFO:Preloading libraries
2025-03-29 15:17:32,733:INFO:Copying training dataset
2025-03-29 15:17:32,733:INFO:Plot type: learning
2025-03-29 15:17:33,006:INFO:Fitting Model
2025-03-29 15:17:50,394:INFO:Visual Rendered Successfully
2025-03-29 15:17:50,511:INFO:plot_model() successfully completed......................................
2025-03-29 15:17:50,540:INFO:Initializing plot_model()
2025-03-29 15:17:50,540:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:50,540:INFO:Checking exceptions
2025-03-29 15:17:50,544:INFO:Preloading libraries
2025-03-29 15:17:50,557:INFO:Copying training dataset
2025-03-29 15:17:50,557:INFO:Plot type: class_report
2025-03-29 15:17:50,832:INFO:Fitting Model
2025-03-29 15:17:50,833:INFO:Scoring test/hold-out set
2025-03-29 15:17:50,972:INFO:Visual Rendered Successfully
2025-03-29 15:17:51,074:INFO:plot_model() successfully completed......................................
2025-03-29 15:17:53,068:INFO:Initializing plot_model()
2025-03-29 15:17:53,068:INFO:plot_model(plot=vc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:17:53,068:INFO:Checking exceptions
2025-03-29 15:17:53,072:INFO:Preloading libraries
2025-03-29 15:17:53,086:INFO:Copying training dataset
2025-03-29 15:17:53,086:INFO:Plot type: vc
2025-03-29 15:17:53,087:INFO:Determining param_name
2025-03-29 15:17:53,087:INFO:param_name: max_depth
2025-03-29 15:17:53,372:INFO:Fitting Model
2025-03-29 15:18:07,307:INFO:Visual Rendered Successfully
2025-03-29 15:18:07,418:INFO:plot_model() successfully completed......................................
2025-03-29 15:18:07,444:INFO:Initializing plot_model()
2025-03-29 15:18:07,444:INFO:plot_model(plot=dimension, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:07,444:INFO:Checking exceptions
2025-03-29 15:18:07,448:INFO:Preloading libraries
2025-03-29 15:18:07,458:INFO:Copying training dataset
2025-03-29 15:18:07,458:INFO:Plot type: dimension
2025-03-29 15:18:07,577:INFO:Fitting StandardScaler()
2025-03-29 15:18:07,658:INFO:Fitting PCA()
2025-03-29 15:18:07,945:INFO:Fitting & Transforming Model
2025-03-29 15:18:08,388:INFO:Visual Rendered Successfully
2025-03-29 15:18:08,496:INFO:plot_model() successfully completed......................................
2025-03-29 15:18:10,740:INFO:Initializing plot_model()
2025-03-29 15:18:10,740:INFO:plot_model(plot=vc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:10,740:INFO:Checking exceptions
2025-03-29 15:18:10,744:INFO:Preloading libraries
2025-03-29 15:18:10,758:INFO:Copying training dataset
2025-03-29 15:18:10,758:INFO:Plot type: vc
2025-03-29 15:18:10,759:INFO:Determining param_name
2025-03-29 15:18:10,759:INFO:param_name: max_depth
2025-03-29 15:18:11,046:INFO:Fitting Model
2025-03-29 15:18:25,057:INFO:Visual Rendered Successfully
2025-03-29 15:18:25,178:INFO:plot_model() successfully completed......................................
2025-03-29 15:18:25,204:INFO:Initializing plot_model()
2025-03-29 15:18:25,204:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:25,204:INFO:Checking exceptions
2025-03-29 15:18:25,208:INFO:Preloading libraries
2025-03-29 15:18:25,220:INFO:Copying training dataset
2025-03-29 15:18:25,220:INFO:Plot type: feature
2025-03-29 15:18:25,221:WARNING:No coef_ found. Trying feature_importances_
2025-03-29 15:18:25,388:INFO:Visual Rendered Successfully
2025-03-29 15:18:25,504:INFO:plot_model() successfully completed......................................
2025-03-29 15:18:27,030:INFO:Initializing plot_model()
2025-03-29 15:18:27,030:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:27,030:INFO:Checking exceptions
2025-03-29 15:18:27,034:INFO:Preloading libraries
2025-03-29 15:18:27,044:INFO:Copying training dataset
2025-03-29 15:18:27,044:INFO:Plot type: feature_all
2025-03-29 15:18:27,147:WARNING:No coef_ found. Trying feature_importances_
2025-03-29 15:18:27,358:INFO:Visual Rendered Successfully
2025-03-29 15:18:27,463:INFO:plot_model() successfully completed......................................
2025-03-29 15:18:43,345:INFO:Initializing plot_model()
2025-03-29 15:18:43,345:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:43,345:INFO:Checking exceptions
2025-03-29 15:18:43,348:INFO:Preloading libraries
2025-03-29 15:18:43,358:INFO:Copying training dataset
2025-03-29 15:18:43,358:INFO:Plot type: boundary
2025-03-29 15:18:43,527:INFO:Fitting StandardScaler()
2025-03-29 15:18:43,538:INFO:Fitting PCA()
2025-03-29 15:18:43,721:INFO:Fitting Model
2025-03-29 15:18:45,023:INFO:Initializing plot_model()
2025-03-29 15:18:45,023:INFO:plot_model(plot=lift, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:45,024:INFO:Checking exceptions
2025-03-29 15:18:45,027:INFO:Preloading libraries
2025-03-29 15:18:45,037:INFO:Copying training dataset
2025-03-29 15:18:45,037:INFO:Plot type: lift
2025-03-29 15:18:45,037:INFO:Generating predictions / predict_proba on X_test
2025-03-29 15:18:45,999:INFO:Initializing plot_model()
2025-03-29 15:18:45,999:INFO:plot_model(plot=gain, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:45,999:INFO:Checking exceptions
2025-03-29 15:18:46,002:INFO:Preloading libraries
2025-03-29 15:18:46,013:INFO:Copying training dataset
2025-03-29 15:18:46,013:INFO:Plot type: gain
2025-03-29 15:18:46,013:INFO:Generating predictions / predict_proba on X_test
2025-03-29 15:18:47,004:INFO:Initializing plot_model()
2025-03-29 15:18:47,004:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:47,004:INFO:Checking exceptions
2025-03-29 15:18:47,949:INFO:Initializing plot_model()
2025-03-29 15:18:47,949:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:47,949:INFO:Checking exceptions
2025-03-29 15:18:47,952:INFO:Preloading libraries
2025-03-29 15:18:47,962:INFO:Copying training dataset
2025-03-29 15:18:47,962:INFO:Plot type: ks
2025-03-29 15:18:47,963:INFO:Generating predictions / predict_proba on X_test
2025-03-29 15:18:48,961:INFO:Initializing plot_model()
2025-03-29 15:18:48,961:INFO:plot_model(plot=calibration, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:48,961:INFO:Checking exceptions
2025-03-29 15:18:50,185:INFO:Initializing plot_model()
2025-03-29 15:18:50,186:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:50,186:INFO:Checking exceptions
2025-03-29 15:18:52,779:INFO:Initializing plot_model()
2025-03-29 15:18:52,780:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023902092FE0>, system=True)
2025-03-29 15:18:52,780:INFO:Checking exceptions
2025-03-29 15:18:52,783:INFO:Preloading libraries
2025-03-29 15:18:52,792:INFO:Copying training dataset
2025-03-29 15:18:52,792:INFO:Plot type: learning
2025-03-29 15:18:53,055:INFO:Fitting Model
2025-03-29 15:19:10,673:INFO:Visual Rendered Successfully
2025-03-29 15:19:10,801:INFO:plot_model() successfully completed......................................
2025-03-29 15:32:58,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:32:58,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:32:58,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:32:58,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:32:58,510:INFO:PyCaret RegressionExperiment
2025-03-29 15:32:58,511:INFO:Logging name: traffic_regression
2025-03-29 15:32:58,511:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 15:32:58,511:INFO:version 3.3.2
2025-03-29 15:32:58,511:INFO:Initializing setup()
2025-03-29 15:32:58,511:INFO:self.USI: 5d27
2025-03-29 15:32:58,512:INFO:self._variable_keys: {'pipeline', '_available_plots', 'fold_groups_param', 'transform_target_param', 'data', 'target_param', 'log_plots_param', 'exp_id', 'fold_generator', 'y', 'gpu_param', 'X', 'n_jobs_param', 'y_test', 'idx', 'memory', 'logging_param', 'seed', 'y_train', 'html_param', 'USI', 'X_train', '_ml_usecase', 'fold_shuffle_param', 'exp_name_log', 'gpu_n_jobs_param', 'X_test'}
2025-03-29 15:32:58,512:INFO:Checking environment
2025-03-29 15:32:58,512:INFO:python_version: 3.10.16
2025-03-29 15:32:58,512:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 15:32:58,512:INFO:machine: AMD64
2025-03-29 15:32:58,512:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 15:32:58,516:INFO:Memory: svmem(total=33411727360, available=16723750912, percent=49.9, used=16687976448, free=16723750912)
2025-03-29 15:32:58,516:INFO:Physical Core: 6
2025-03-29 15:32:58,516:INFO:Logical Core: 12
2025-03-29 15:32:58,516:INFO:Checking libraries
2025-03-29 15:32:58,516:INFO:System:
2025-03-29 15:32:58,516:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 15:32:58,516:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 15:32:58,516:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 15:32:58,516:INFO:PyCaret required dependencies:
2025-03-29 15:32:58,517:INFO:                 pip: 25.0.1
2025-03-29 15:32:58,517:INFO:          setuptools: 75.8.2
2025-03-29 15:32:58,517:INFO:             pycaret: 3.3.2
2025-03-29 15:32:58,517:INFO:             IPython: 8.34.0
2025-03-29 15:32:58,517:INFO:          ipywidgets: 8.1.5
2025-03-29 15:32:58,517:INFO:                tqdm: 4.67.1
2025-03-29 15:32:58,517:INFO:               numpy: 1.26.4
2025-03-29 15:32:58,517:INFO:              pandas: 2.1.4
2025-03-29 15:32:58,517:INFO:              jinja2: 3.1.6
2025-03-29 15:32:58,517:INFO:               scipy: 1.11.4
2025-03-29 15:32:58,517:INFO:              joblib: 1.3.2
2025-03-29 15:32:58,517:INFO:             sklearn: 1.4.2
2025-03-29 15:32:58,517:INFO:                pyod: 2.0.2
2025-03-29 15:32:58,518:INFO:            imblearn: 0.13.0
2025-03-29 15:32:58,518:INFO:   category_encoders: 2.7.0
2025-03-29 15:32:58,518:INFO:            lightgbm: 4.6.0
2025-03-29 15:32:58,518:INFO:               numba: 0.61.0
2025-03-29 15:32:58,518:INFO:            requests: 2.32.3
2025-03-29 15:32:58,518:INFO:          matplotlib: 3.10.1
2025-03-29 15:32:58,518:INFO:          scikitplot: 0.3.7
2025-03-29 15:32:58,518:INFO:         yellowbrick: 1.5
2025-03-29 15:32:58,518:INFO:              plotly: 6.0.1
2025-03-29 15:32:58,518:INFO:    plotly-resampler: Not installed
2025-03-29 15:32:58,518:INFO:             kaleido: 0.2.1
2025-03-29 15:32:58,518:INFO:           schemdraw: 0.15
2025-03-29 15:32:58,518:INFO:         statsmodels: 0.14.4
2025-03-29 15:32:58,518:INFO:              sktime: 0.26.0
2025-03-29 15:32:58,518:INFO:               tbats: 1.1.3
2025-03-29 15:32:58,518:INFO:            pmdarima: 2.0.4
2025-03-29 15:32:58,518:INFO:              psutil: 7.0.0
2025-03-29 15:32:58,518:INFO:          markupsafe: 3.0.2
2025-03-29 15:32:58,518:INFO:             pickle5: Not installed
2025-03-29 15:32:58,518:INFO:         cloudpickle: 3.1.1
2025-03-29 15:32:58,518:INFO:         deprecation: 2.1.0
2025-03-29 15:32:58,518:INFO:              xxhash: 3.5.0
2025-03-29 15:32:58,518:INFO:           wurlitzer: 3.1.1
2025-03-29 15:32:58,518:INFO:PyCaret optional dependencies:
2025-03-29 15:32:58,751:INFO:                shap: Not installed
2025-03-29 15:32:58,751:INFO:           interpret: Not installed
2025-03-29 15:32:58,751:INFO:                umap: 0.5.7
2025-03-29 15:32:58,751:INFO:     ydata_profiling: Not installed
2025-03-29 15:32:58,751:INFO:  explainerdashboard: Not installed
2025-03-29 15:32:58,751:INFO:             autoviz: Not installed
2025-03-29 15:32:58,751:INFO:           fairlearn: Not installed
2025-03-29 15:32:58,751:INFO:          deepchecks: Not installed
2025-03-29 15:32:58,751:INFO:             xgboost: Not installed
2025-03-29 15:32:58,751:INFO:            catboost: Not installed
2025-03-29 15:32:58,751:INFO:              kmodes: Not installed
2025-03-29 15:32:58,751:INFO:             mlxtend: Not installed
2025-03-29 15:32:58,751:INFO:       statsforecast: Not installed
2025-03-29 15:32:58,751:INFO:        tune_sklearn: Not installed
2025-03-29 15:32:58,751:INFO:                 ray: Not installed
2025-03-29 15:32:58,751:INFO:            hyperopt: Not installed
2025-03-29 15:32:58,751:INFO:              optuna: Not installed
2025-03-29 15:32:58,751:INFO:               skopt: Not installed
2025-03-29 15:32:58,751:INFO:              mlflow: 2.21.2
2025-03-29 15:32:58,751:INFO:              gradio: Not installed
2025-03-29 15:32:58,751:INFO:             fastapi: 0.115.12
2025-03-29 15:32:58,751:INFO:             uvicorn: 0.34.0
2025-03-29 15:32:58,752:INFO:              m2cgen: Not installed
2025-03-29 15:32:58,752:INFO:           evidently: Not installed
2025-03-29 15:32:58,752:INFO:               fugue: Not installed
2025-03-29 15:32:58,752:INFO:           streamlit: 1.43.2
2025-03-29 15:32:58,752:INFO:             prophet: Not installed
2025-03-29 15:32:58,752:INFO:None
2025-03-29 15:32:58,752:INFO:Set up data.
2025-03-29 15:32:58,760:INFO:Set up folding strategy.
2025-03-29 15:32:58,760:INFO:Set up train/test split.
2025-03-29 15:32:58,766:INFO:Set up index.
2025-03-29 15:32:58,767:INFO:Assigning column types.
2025-03-29 15:32:58,771:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 15:32:58,771:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:32:58,774:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:32:58,776:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:32:58,812:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:32:58,837:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:32:58,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:58,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:58,986:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:32:58,989:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:32:58,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,052:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 15:32:59,055:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,057:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,125:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,129:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,164:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,189:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 15:32:59,196:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,230:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,295:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,319:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,320:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 15:32:59,359:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,424:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,449:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,450:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 15:32:59,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,557:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:32:59,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,583:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 15:32:59,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:32:59,711:INFO:Preparing preprocessing pipeline...
2025-03-29 15:32:59,711:INFO:Set up simple imputation.
2025-03-29 15:32:59,715:INFO:Set up encoding of categorical features.
2025-03-29 15:32:59,715:INFO:Set up column transformation.
2025-03-29 15:32:59,715:INFO:Set up feature normalization.
2025-03-29 15:32:59,716:INFO:Set up column name cleaning.
2025-03-29 15:32:59,826:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-03-29 15:32:59,833:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\numpy\core\_methods.py:187: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2025-03-29 15:33:00,251:INFO:Finished creating preprocessing pipeline.
2025-03-29 15:33:00,256:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('o...
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-29 15:33:00,256:INFO:Creating final display dataframe.
2025-03-29 15:33:00,572:INFO:Setup _display_container:                     Description               Value
0                    Session id                 123
1                        Target      traffic_volume
2                   Target type          Regression
3           Original data shape          (48204, 8)
4        Transformed data shape         (48204, 28)
5   Transformed train set shape         (33742, 28)
6    Transformed test set shape         (14462, 28)
7               Ignore features                   1
8              Numeric features                   5
9          Categorical features                   2
10     Rows with missing values               99.9%
11                   Preprocess                True
12              Imputation type              simple
13           Numeric imputation                mean
14       Categorical imputation                mode
15     Maximum one-hot encoding                  25
16              Encoding method                None
17               Transformation                True
18        Transformation method         yeo-johnson
19                    Normalize                True
20             Normalize method              zscore
21               Fold Generator               KFold
22                  Fold Number                  10
23                     CPU Jobs                  -1
24                      Use GPU               False
25               Log Experiment        MlflowLogger
26              Experiment Name  traffic_regression
27                          USI                5d27
2025-03-29 15:33:00,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:33:00,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:33:00,711:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:33:00,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:33:00,711:INFO:Logging experiment in loggers
2025-03-29 15:35:47,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:35:47,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:35:47,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:35:47,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:35:49,641:INFO:Initializing load_model()
2025-03-29 15:35:49,642:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-29 15:36:06,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:36:06,111:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:36:06,111:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:36:06,111:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 15:36:06,219:INFO:PyCaret RegressionExperiment
2025-03-29 15:36:06,219:INFO:Logging name: reg-default-name
2025-03-29 15:36:06,219:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 15:36:06,219:INFO:version 3.3.2
2025-03-29 15:36:06,219:INFO:Initializing setup()
2025-03-29 15:36:06,219:INFO:self.USI: 080b
2025-03-29 15:36:06,219:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 15:36:06,219:INFO:Checking environment
2025-03-29 15:36:06,219:INFO:python_version: 3.10.16
2025-03-29 15:36:06,219:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 15:36:06,219:INFO:machine: AMD64
2025-03-29 15:36:06,219:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 15:36:06,223:INFO:Memory: svmem(total=33411727360, available=17385062400, percent=48.0, used=16026664960, free=17385062400)
2025-03-29 15:36:06,223:INFO:Physical Core: 6
2025-03-29 15:36:06,223:INFO:Logical Core: 12
2025-03-29 15:36:06,223:INFO:Checking libraries
2025-03-29 15:36:06,223:INFO:System:
2025-03-29 15:36:06,223:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 15:36:06,223:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 15:36:06,223:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 15:36:06,223:INFO:PyCaret required dependencies:
2025-03-29 15:36:06,224:INFO:                 pip: 25.0.1
2025-03-29 15:36:06,224:INFO:          setuptools: 75.8.2
2025-03-29 15:36:06,224:INFO:             pycaret: 3.3.2
2025-03-29 15:36:06,224:INFO:             IPython: 8.34.0
2025-03-29 15:36:06,224:INFO:          ipywidgets: 8.1.5
2025-03-29 15:36:06,224:INFO:                tqdm: 4.67.1
2025-03-29 15:36:06,224:INFO:               numpy: 1.26.4
2025-03-29 15:36:06,224:INFO:              pandas: 2.1.4
2025-03-29 15:36:06,224:INFO:              jinja2: 3.1.6
2025-03-29 15:36:06,224:INFO:               scipy: 1.11.4
2025-03-29 15:36:06,224:INFO:              joblib: 1.3.2
2025-03-29 15:36:06,224:INFO:             sklearn: 1.4.2
2025-03-29 15:36:06,224:INFO:                pyod: 2.0.2
2025-03-29 15:36:06,224:INFO:            imblearn: 0.13.0
2025-03-29 15:36:06,224:INFO:   category_encoders: 2.7.0
2025-03-29 15:36:06,224:INFO:            lightgbm: 4.6.0
2025-03-29 15:36:06,224:INFO:               numba: 0.61.0
2025-03-29 15:36:06,224:INFO:            requests: 2.32.3
2025-03-29 15:36:06,224:INFO:          matplotlib: 3.10.1
2025-03-29 15:36:06,224:INFO:          scikitplot: 0.3.7
2025-03-29 15:36:06,224:INFO:         yellowbrick: 1.5
2025-03-29 15:36:06,224:INFO:              plotly: 6.0.1
2025-03-29 15:36:06,224:INFO:    plotly-resampler: Not installed
2025-03-29 15:36:06,224:INFO:             kaleido: 0.2.1
2025-03-29 15:36:06,224:INFO:           schemdraw: 0.15
2025-03-29 15:36:06,224:INFO:         statsmodels: 0.14.4
2025-03-29 15:36:06,225:INFO:              sktime: 0.26.0
2025-03-29 15:36:06,225:INFO:               tbats: 1.1.3
2025-03-29 15:36:06,225:INFO:            pmdarima: 2.0.4
2025-03-29 15:36:06,225:INFO:              psutil: 7.0.0
2025-03-29 15:36:06,225:INFO:          markupsafe: 3.0.2
2025-03-29 15:36:06,225:INFO:             pickle5: Not installed
2025-03-29 15:36:06,225:INFO:         cloudpickle: 3.1.1
2025-03-29 15:36:06,225:INFO:         deprecation: 2.1.0
2025-03-29 15:36:06,225:INFO:              xxhash: 3.5.0
2025-03-29 15:36:06,225:INFO:           wurlitzer: 3.1.1
2025-03-29 15:36:06,225:INFO:PyCaret optional dependencies:
2025-03-29 15:36:06,453:INFO:                shap: Not installed
2025-03-29 15:36:06,453:INFO:           interpret: Not installed
2025-03-29 15:36:06,453:INFO:                umap: 0.5.7
2025-03-29 15:36:06,453:INFO:     ydata_profiling: Not installed
2025-03-29 15:36:06,453:INFO:  explainerdashboard: Not installed
2025-03-29 15:36:06,453:INFO:             autoviz: Not installed
2025-03-29 15:36:06,453:INFO:           fairlearn: Not installed
2025-03-29 15:36:06,453:INFO:          deepchecks: Not installed
2025-03-29 15:36:06,453:INFO:             xgboost: Not installed
2025-03-29 15:36:06,453:INFO:            catboost: Not installed
2025-03-29 15:36:06,453:INFO:              kmodes: Not installed
2025-03-29 15:36:06,453:INFO:             mlxtend: Not installed
2025-03-29 15:36:06,453:INFO:       statsforecast: Not installed
2025-03-29 15:36:06,453:INFO:        tune_sklearn: Not installed
2025-03-29 15:36:06,453:INFO:                 ray: Not installed
2025-03-29 15:36:06,453:INFO:            hyperopt: Not installed
2025-03-29 15:36:06,453:INFO:              optuna: Not installed
2025-03-29 15:36:06,453:INFO:               skopt: Not installed
2025-03-29 15:36:06,453:INFO:              mlflow: 2.21.2
2025-03-29 15:36:06,453:INFO:              gradio: Not installed
2025-03-29 15:36:06,453:INFO:             fastapi: 0.115.12
2025-03-29 15:36:06,453:INFO:             uvicorn: 0.34.0
2025-03-29 15:36:06,453:INFO:              m2cgen: Not installed
2025-03-29 15:36:06,453:INFO:           evidently: Not installed
2025-03-29 15:36:06,453:INFO:               fugue: Not installed
2025-03-29 15:36:06,453:INFO:           streamlit: 1.43.2
2025-03-29 15:36:06,453:INFO:             prophet: Not installed
2025-03-29 15:36:06,453:INFO:None
2025-03-29 15:36:06,453:INFO:Set up data.
2025-03-29 15:36:06,462:INFO:Set up folding strategy.
2025-03-29 15:36:06,462:INFO:Set up train/test split.
2025-03-29 15:36:06,468:INFO:Set up index.
2025-03-29 15:36:06,468:INFO:Assigning column types.
2025-03-29 15:36:06,472:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 15:36:06,472:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,475:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,477:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,511:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,535:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,573:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,576:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,578:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,636:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,637:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 15:36:06,639:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,642:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,699:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,702:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,764:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 15:36:06,768:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,826:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,831:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,864:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,888:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,889:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 15:36:06,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,951:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:36:06,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:06,990:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:36:07,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:36:07,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,015:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 15:36:07,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:36:07,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:36:07,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,141:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 15:36:07,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,203:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,266:INFO:Preparing preprocessing pipeline...
2025-03-29 15:36:07,266:INFO:Set up simple imputation.
2025-03-29 15:36:07,269:INFO:Set up encoding of categorical features.
2025-03-29 15:36:07,270:INFO:Set up column name cleaning.
2025-03-29 15:36:07,357:INFO:Finished creating preprocessing pipeline.
2025-03-29 15:36:07,362:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-29 15:36:07,362:INFO:Creating final display dataframe.
2025-03-29 15:36:07,558:INFO:Setup _display_container:                     Description             Value
0                    Session id              1903
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 27)
5   Transformed train set shape       (33742, 27)
6    Transformed test set shape       (14462, 27)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              080b
2025-03-29 15:36:07,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:36:07,697:INFO:setup() successfully completed in 1.48s...............
2025-03-29 15:36:07,708:INFO:Initializing compare_models()
2025-03-29 15:36:07,708:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-29 15:36:07,708:INFO:Checking exceptions
2025-03-29 15:36:07,711:INFO:Preparing display monitor
2025-03-29 15:36:07,736:INFO:Initializing Linear Regression
2025-03-29 15:36:07,736:INFO:Total runtime is 0.0 minutes
2025-03-29 15:36:07,740:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:07,740:INFO:Initializing create_model()
2025-03-29 15:36:07,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:07,740:INFO:Checking exceptions
2025-03-29 15:36:07,740:INFO:Importing libraries
2025-03-29 15:36:07,740:INFO:Copying training dataset
2025-03-29 15:36:07,752:INFO:Defining folds
2025-03-29 15:36:07,752:INFO:Declaring metric variables
2025-03-29 15:36:07,756:INFO:Importing untrained model
2025-03-29 15:36:07,759:INFO:Linear Regression Imported successfully
2025-03-29 15:36:07,764:INFO:Starting cross validation
2025-03-29 15:36:07,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:10,950:INFO:Calculating mean and std
2025-03-29 15:36:10,951:INFO:Creating metrics dataframe
2025-03-29 15:36:10,952:INFO:Uploading results into container
2025-03-29 15:36:10,953:INFO:Uploading model into container now
2025-03-29 15:36:10,954:INFO:_master_model_container: 1
2025-03-29 15:36:10,954:INFO:_display_container: 2
2025-03-29 15:36:10,954:INFO:LinearRegression(n_jobs=-1)
2025-03-29 15:36:10,954:INFO:create_model() successfully completed......................................
2025-03-29 15:36:11,062:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:11,063:INFO:Creating metrics dataframe
2025-03-29 15:36:11,066:INFO:Initializing Lasso Regression
2025-03-29 15:36:11,067:INFO:Total runtime is 0.055520904064178464 minutes
2025-03-29 15:36:11,068:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:11,069:INFO:Initializing create_model()
2025-03-29 15:36:11,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:11,069:INFO:Checking exceptions
2025-03-29 15:36:11,069:INFO:Importing libraries
2025-03-29 15:36:11,069:INFO:Copying training dataset
2025-03-29 15:36:11,077:INFO:Defining folds
2025-03-29 15:36:11,077:INFO:Declaring metric variables
2025-03-29 15:36:11,079:INFO:Importing untrained model
2025-03-29 15:36:11,081:INFO:Lasso Regression Imported successfully
2025-03-29 15:36:11,085:INFO:Starting cross validation
2025-03-29 15:36:11,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:12,805:INFO:Calculating mean and std
2025-03-29 15:36:12,806:INFO:Creating metrics dataframe
2025-03-29 15:36:12,807:INFO:Uploading results into container
2025-03-29 15:36:12,808:INFO:Uploading model into container now
2025-03-29 15:36:12,809:INFO:_master_model_container: 2
2025-03-29 15:36:12,809:INFO:_display_container: 2
2025-03-29 15:36:12,809:INFO:Lasso(random_state=1903)
2025-03-29 15:36:12,809:INFO:create_model() successfully completed......................................
2025-03-29 15:36:12,908:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:12,909:INFO:Creating metrics dataframe
2025-03-29 15:36:12,913:INFO:Initializing Ridge Regression
2025-03-29 15:36:12,913:INFO:Total runtime is 0.0862916111946106 minutes
2025-03-29 15:36:12,915:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:12,915:INFO:Initializing create_model()
2025-03-29 15:36:12,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:12,915:INFO:Checking exceptions
2025-03-29 15:36:12,915:INFO:Importing libraries
2025-03-29 15:36:12,915:INFO:Copying training dataset
2025-03-29 15:36:12,922:INFO:Defining folds
2025-03-29 15:36:12,922:INFO:Declaring metric variables
2025-03-29 15:36:12,924:INFO:Importing untrained model
2025-03-29 15:36:12,926:INFO:Ridge Regression Imported successfully
2025-03-29 15:36:12,931:INFO:Starting cross validation
2025-03-29 15:36:12,933:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:13,142:INFO:Calculating mean and std
2025-03-29 15:36:13,143:INFO:Creating metrics dataframe
2025-03-29 15:36:13,144:INFO:Uploading results into container
2025-03-29 15:36:13,144:INFO:Uploading model into container now
2025-03-29 15:36:13,144:INFO:_master_model_container: 3
2025-03-29 15:36:13,144:INFO:_display_container: 2
2025-03-29 15:36:13,145:INFO:Ridge(random_state=1903)
2025-03-29 15:36:13,145:INFO:create_model() successfully completed......................................
2025-03-29 15:36:13,241:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:13,241:INFO:Creating metrics dataframe
2025-03-29 15:36:13,246:INFO:Initializing Elastic Net
2025-03-29 15:36:13,246:INFO:Total runtime is 0.09182607730229696 minutes
2025-03-29 15:36:13,248:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:13,248:INFO:Initializing create_model()
2025-03-29 15:36:13,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:13,248:INFO:Checking exceptions
2025-03-29 15:36:13,248:INFO:Importing libraries
2025-03-29 15:36:13,248:INFO:Copying training dataset
2025-03-29 15:36:13,255:INFO:Defining folds
2025-03-29 15:36:13,255:INFO:Declaring metric variables
2025-03-29 15:36:13,257:INFO:Importing untrained model
2025-03-29 15:36:13,260:INFO:Elastic Net Imported successfully
2025-03-29 15:36:13,263:INFO:Starting cross validation
2025-03-29 15:36:13,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:13,483:INFO:Calculating mean and std
2025-03-29 15:36:13,484:INFO:Creating metrics dataframe
2025-03-29 15:36:13,485:INFO:Uploading results into container
2025-03-29 15:36:13,485:INFO:Uploading model into container now
2025-03-29 15:36:13,486:INFO:_master_model_container: 4
2025-03-29 15:36:13,486:INFO:_display_container: 2
2025-03-29 15:36:13,486:INFO:ElasticNet(random_state=1903)
2025-03-29 15:36:13,486:INFO:create_model() successfully completed......................................
2025-03-29 15:36:13,581:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:13,581:INFO:Creating metrics dataframe
2025-03-29 15:36:13,585:INFO:Initializing Least Angle Regression
2025-03-29 15:36:13,585:INFO:Total runtime is 0.09747625986735026 minutes
2025-03-29 15:36:13,587:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:13,587:INFO:Initializing create_model()
2025-03-29 15:36:13,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:13,588:INFO:Checking exceptions
2025-03-29 15:36:13,588:INFO:Importing libraries
2025-03-29 15:36:13,588:INFO:Copying training dataset
2025-03-29 15:36:13,595:INFO:Defining folds
2025-03-29 15:36:13,595:INFO:Declaring metric variables
2025-03-29 15:36:13,597:INFO:Importing untrained model
2025-03-29 15:36:13,599:INFO:Least Angle Regression Imported successfully
2025-03-29 15:36:13,603:INFO:Starting cross validation
2025-03-29 15:36:13,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:13,810:INFO:Calculating mean and std
2025-03-29 15:36:13,811:INFO:Creating metrics dataframe
2025-03-29 15:36:13,812:INFO:Uploading results into container
2025-03-29 15:36:13,812:INFO:Uploading model into container now
2025-03-29 15:36:13,812:INFO:_master_model_container: 5
2025-03-29 15:36:13,813:INFO:_display_container: 2
2025-03-29 15:36:13,813:INFO:Lars(random_state=1903)
2025-03-29 15:36:13,813:INFO:create_model() successfully completed......................................
2025-03-29 15:36:13,909:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:13,909:INFO:Creating metrics dataframe
2025-03-29 15:36:13,913:INFO:Initializing Lasso Least Angle Regression
2025-03-29 15:36:13,913:INFO:Total runtime is 0.1029567281405131 minutes
2025-03-29 15:36:13,915:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:13,915:INFO:Initializing create_model()
2025-03-29 15:36:13,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:13,916:INFO:Checking exceptions
2025-03-29 15:36:13,916:INFO:Importing libraries
2025-03-29 15:36:13,916:INFO:Copying training dataset
2025-03-29 15:36:13,922:INFO:Defining folds
2025-03-29 15:36:13,923:INFO:Declaring metric variables
2025-03-29 15:36:13,925:INFO:Importing untrained model
2025-03-29 15:36:13,927:INFO:Lasso Least Angle Regression Imported successfully
2025-03-29 15:36:13,931:INFO:Starting cross validation
2025-03-29 15:36:13,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:14,134:INFO:Calculating mean and std
2025-03-29 15:36:14,135:INFO:Creating metrics dataframe
2025-03-29 15:36:14,136:INFO:Uploading results into container
2025-03-29 15:36:14,136:INFO:Uploading model into container now
2025-03-29 15:36:14,137:INFO:_master_model_container: 6
2025-03-29 15:36:14,137:INFO:_display_container: 2
2025-03-29 15:36:14,137:INFO:LassoLars(random_state=1903)
2025-03-29 15:36:14,137:INFO:create_model() successfully completed......................................
2025-03-29 15:36:14,233:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:14,233:INFO:Creating metrics dataframe
2025-03-29 15:36:14,238:INFO:Initializing Orthogonal Matching Pursuit
2025-03-29 15:36:14,238:INFO:Total runtime is 0.10837146441141764 minutes
2025-03-29 15:36:14,240:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:14,240:INFO:Initializing create_model()
2025-03-29 15:36:14,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:14,241:INFO:Checking exceptions
2025-03-29 15:36:14,241:INFO:Importing libraries
2025-03-29 15:36:14,241:INFO:Copying training dataset
2025-03-29 15:36:14,248:INFO:Defining folds
2025-03-29 15:36:14,248:INFO:Declaring metric variables
2025-03-29 15:36:14,250:INFO:Importing untrained model
2025-03-29 15:36:14,252:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-29 15:36:14,255:INFO:Starting cross validation
2025-03-29 15:36:14,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:14,472:INFO:Calculating mean and std
2025-03-29 15:36:14,473:INFO:Creating metrics dataframe
2025-03-29 15:36:14,474:INFO:Uploading results into container
2025-03-29 15:36:14,474:INFO:Uploading model into container now
2025-03-29 15:36:14,474:INFO:_master_model_container: 7
2025-03-29 15:36:14,475:INFO:_display_container: 2
2025-03-29 15:36:14,475:INFO:OrthogonalMatchingPursuit()
2025-03-29 15:36:14,475:INFO:create_model() successfully completed......................................
2025-03-29 15:36:14,576:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:14,576:INFO:Creating metrics dataframe
2025-03-29 15:36:14,580:INFO:Initializing Bayesian Ridge
2025-03-29 15:36:14,581:INFO:Total runtime is 0.11407785018285115 minutes
2025-03-29 15:36:14,582:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:14,583:INFO:Initializing create_model()
2025-03-29 15:36:14,583:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:14,583:INFO:Checking exceptions
2025-03-29 15:36:14,583:INFO:Importing libraries
2025-03-29 15:36:14,583:INFO:Copying training dataset
2025-03-29 15:36:14,590:INFO:Defining folds
2025-03-29 15:36:14,590:INFO:Declaring metric variables
2025-03-29 15:36:14,592:INFO:Importing untrained model
2025-03-29 15:36:14,594:INFO:Bayesian Ridge Imported successfully
2025-03-29 15:36:14,598:INFO:Starting cross validation
2025-03-29 15:36:14,599:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:14,846:INFO:Calculating mean and std
2025-03-29 15:36:14,847:INFO:Creating metrics dataframe
2025-03-29 15:36:14,848:INFO:Uploading results into container
2025-03-29 15:36:14,848:INFO:Uploading model into container now
2025-03-29 15:36:14,849:INFO:_master_model_container: 8
2025-03-29 15:36:14,849:INFO:_display_container: 2
2025-03-29 15:36:14,849:INFO:BayesianRidge()
2025-03-29 15:36:14,849:INFO:create_model() successfully completed......................................
2025-03-29 15:36:14,943:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:14,943:INFO:Creating metrics dataframe
2025-03-29 15:36:14,948:INFO:Initializing Passive Aggressive Regressor
2025-03-29 15:36:14,948:INFO:Total runtime is 0.12020165920257567 minutes
2025-03-29 15:36:14,950:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:14,950:INFO:Initializing create_model()
2025-03-29 15:36:14,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:14,950:INFO:Checking exceptions
2025-03-29 15:36:14,950:INFO:Importing libraries
2025-03-29 15:36:14,951:INFO:Copying training dataset
2025-03-29 15:36:14,957:INFO:Defining folds
2025-03-29 15:36:14,957:INFO:Declaring metric variables
2025-03-29 15:36:14,960:INFO:Importing untrained model
2025-03-29 15:36:14,962:INFO:Passive Aggressive Regressor Imported successfully
2025-03-29 15:36:14,966:INFO:Starting cross validation
2025-03-29 15:36:14,967:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:15,329:INFO:Calculating mean and std
2025-03-29 15:36:15,330:INFO:Creating metrics dataframe
2025-03-29 15:36:15,331:INFO:Uploading results into container
2025-03-29 15:36:15,331:INFO:Uploading model into container now
2025-03-29 15:36:15,331:INFO:_master_model_container: 9
2025-03-29 15:36:15,331:INFO:_display_container: 2
2025-03-29 15:36:15,332:INFO:PassiveAggressiveRegressor(random_state=1903)
2025-03-29 15:36:15,332:INFO:create_model() successfully completed......................................
2025-03-29 15:36:15,432:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:15,432:INFO:Creating metrics dataframe
2025-03-29 15:36:15,437:INFO:Initializing Huber Regressor
2025-03-29 15:36:15,437:INFO:Total runtime is 0.12834786574045814 minutes
2025-03-29 15:36:15,439:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:15,439:INFO:Initializing create_model()
2025-03-29 15:36:15,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:15,439:INFO:Checking exceptions
2025-03-29 15:36:15,439:INFO:Importing libraries
2025-03-29 15:36:15,440:INFO:Copying training dataset
2025-03-29 15:36:15,447:INFO:Defining folds
2025-03-29 15:36:15,447:INFO:Declaring metric variables
2025-03-29 15:36:15,449:INFO:Importing untrained model
2025-03-29 15:36:15,451:INFO:Huber Regressor Imported successfully
2025-03-29 15:36:15,454:INFO:Starting cross validation
2025-03-29 15:36:15,456:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:16,769:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:36:16,791:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:36:16,800:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:36:16,818:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:36:16,836:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:36:16,858:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:36:16,860:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:36:16,864:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:36:16,946:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:36:16,954:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:36:16,978:INFO:Calculating mean and std
2025-03-29 15:36:16,979:INFO:Creating metrics dataframe
2025-03-29 15:36:16,980:INFO:Uploading results into container
2025-03-29 15:36:16,980:INFO:Uploading model into container now
2025-03-29 15:36:16,981:INFO:_master_model_container: 10
2025-03-29 15:36:16,981:INFO:_display_container: 2
2025-03-29 15:36:16,981:INFO:HuberRegressor()
2025-03-29 15:36:16,981:INFO:create_model() successfully completed......................................
2025-03-29 15:36:17,077:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:17,077:INFO:Creating metrics dataframe
2025-03-29 15:36:17,082:INFO:Initializing K Neighbors Regressor
2025-03-29 15:36:17,082:INFO:Total runtime is 0.15576021671295165 minutes
2025-03-29 15:36:17,084:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:17,084:INFO:Initializing create_model()
2025-03-29 15:36:17,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:17,084:INFO:Checking exceptions
2025-03-29 15:36:17,084:INFO:Importing libraries
2025-03-29 15:36:17,084:INFO:Copying training dataset
2025-03-29 15:36:17,091:INFO:Defining folds
2025-03-29 15:36:17,091:INFO:Declaring metric variables
2025-03-29 15:36:17,093:INFO:Importing untrained model
2025-03-29 15:36:17,095:INFO:K Neighbors Regressor Imported successfully
2025-03-29 15:36:17,099:INFO:Starting cross validation
2025-03-29 15:36:17,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:17,842:INFO:Calculating mean and std
2025-03-29 15:36:17,843:INFO:Creating metrics dataframe
2025-03-29 15:36:17,844:INFO:Uploading results into container
2025-03-29 15:36:17,844:INFO:Uploading model into container now
2025-03-29 15:36:17,845:INFO:_master_model_container: 11
2025-03-29 15:36:17,845:INFO:_display_container: 2
2025-03-29 15:36:17,845:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-29 15:36:17,845:INFO:create_model() successfully completed......................................
2025-03-29 15:36:17,939:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:17,939:INFO:Creating metrics dataframe
2025-03-29 15:36:17,945:INFO:Initializing Decision Tree Regressor
2025-03-29 15:36:17,945:INFO:Total runtime is 0.17014766931533812 minutes
2025-03-29 15:36:17,947:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:17,947:INFO:Initializing create_model()
2025-03-29 15:36:17,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:17,947:INFO:Checking exceptions
2025-03-29 15:36:17,947:INFO:Importing libraries
2025-03-29 15:36:17,947:INFO:Copying training dataset
2025-03-29 15:36:17,954:INFO:Defining folds
2025-03-29 15:36:17,954:INFO:Declaring metric variables
2025-03-29 15:36:17,957:INFO:Importing untrained model
2025-03-29 15:36:17,960:INFO:Decision Tree Regressor Imported successfully
2025-03-29 15:36:17,964:INFO:Starting cross validation
2025-03-29 15:36:17,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:18,261:INFO:Calculating mean and std
2025-03-29 15:36:18,262:INFO:Creating metrics dataframe
2025-03-29 15:36:18,263:INFO:Uploading results into container
2025-03-29 15:36:18,263:INFO:Uploading model into container now
2025-03-29 15:36:18,264:INFO:_master_model_container: 12
2025-03-29 15:36:18,264:INFO:_display_container: 2
2025-03-29 15:36:18,264:INFO:DecisionTreeRegressor(random_state=1903)
2025-03-29 15:36:18,264:INFO:create_model() successfully completed......................................
2025-03-29 15:36:18,356:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:18,356:INFO:Creating metrics dataframe
2025-03-29 15:36:18,361:INFO:Initializing Random Forest Regressor
2025-03-29 15:36:18,362:INFO:Total runtime is 0.17709629535675048 minutes
2025-03-29 15:36:18,363:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:18,364:INFO:Initializing create_model()
2025-03-29 15:36:18,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:18,364:INFO:Checking exceptions
2025-03-29 15:36:18,364:INFO:Importing libraries
2025-03-29 15:36:18,364:INFO:Copying training dataset
2025-03-29 15:36:18,371:INFO:Defining folds
2025-03-29 15:36:18,371:INFO:Declaring metric variables
2025-03-29 15:36:18,373:INFO:Importing untrained model
2025-03-29 15:36:18,376:INFO:Random Forest Regressor Imported successfully
2025-03-29 15:36:18,379:INFO:Starting cross validation
2025-03-29 15:36:18,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:24,217:INFO:Calculating mean and std
2025-03-29 15:36:24,218:INFO:Creating metrics dataframe
2025-03-29 15:36:24,220:INFO:Uploading results into container
2025-03-29 15:36:24,220:INFO:Uploading model into container now
2025-03-29 15:36:24,221:INFO:_master_model_container: 13
2025-03-29 15:36:24,221:INFO:_display_container: 2
2025-03-29 15:36:24,221:INFO:RandomForestRegressor(n_jobs=-1, random_state=1903)
2025-03-29 15:36:24,221:INFO:create_model() successfully completed......................................
2025-03-29 15:36:24,333:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:24,333:INFO:Creating metrics dataframe
2025-03-29 15:36:24,339:INFO:Initializing Extra Trees Regressor
2025-03-29 15:36:24,339:INFO:Total runtime is 0.27672207752863565 minutes
2025-03-29 15:36:24,341:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:24,341:INFO:Initializing create_model()
2025-03-29 15:36:24,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:24,341:INFO:Checking exceptions
2025-03-29 15:36:24,341:INFO:Importing libraries
2025-03-29 15:36:24,341:INFO:Copying training dataset
2025-03-29 15:36:24,348:INFO:Defining folds
2025-03-29 15:36:24,348:INFO:Declaring metric variables
2025-03-29 15:36:24,350:INFO:Importing untrained model
2025-03-29 15:36:24,352:INFO:Extra Trees Regressor Imported successfully
2025-03-29 15:36:24,357:INFO:Starting cross validation
2025-03-29 15:36:24,358:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:28,119:INFO:Calculating mean and std
2025-03-29 15:36:28,120:INFO:Creating metrics dataframe
2025-03-29 15:36:28,121:INFO:Uploading results into container
2025-03-29 15:36:28,121:INFO:Uploading model into container now
2025-03-29 15:36:28,122:INFO:_master_model_container: 14
2025-03-29 15:36:28,122:INFO:_display_container: 2
2025-03-29 15:36:28,122:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1903)
2025-03-29 15:36:28,123:INFO:create_model() successfully completed......................................
2025-03-29 15:36:28,233:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:28,234:INFO:Creating metrics dataframe
2025-03-29 15:36:28,240:INFO:Initializing AdaBoost Regressor
2025-03-29 15:36:28,240:INFO:Total runtime is 0.3417332092920939 minutes
2025-03-29 15:36:28,242:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:28,242:INFO:Initializing create_model()
2025-03-29 15:36:28,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:28,242:INFO:Checking exceptions
2025-03-29 15:36:28,242:INFO:Importing libraries
2025-03-29 15:36:28,242:INFO:Copying training dataset
2025-03-29 15:36:28,250:INFO:Defining folds
2025-03-29 15:36:28,250:INFO:Declaring metric variables
2025-03-29 15:36:28,253:INFO:Importing untrained model
2025-03-29 15:36:28,255:INFO:AdaBoost Regressor Imported successfully
2025-03-29 15:36:28,259:INFO:Starting cross validation
2025-03-29 15:36:28,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:29,131:INFO:Calculating mean and std
2025-03-29 15:36:29,132:INFO:Creating metrics dataframe
2025-03-29 15:36:29,133:INFO:Uploading results into container
2025-03-29 15:36:29,133:INFO:Uploading model into container now
2025-03-29 15:36:29,133:INFO:_master_model_container: 15
2025-03-29 15:36:29,133:INFO:_display_container: 2
2025-03-29 15:36:29,134:INFO:AdaBoostRegressor(random_state=1903)
2025-03-29 15:36:29,134:INFO:create_model() successfully completed......................................
2025-03-29 15:36:29,235:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:29,235:INFO:Creating metrics dataframe
2025-03-29 15:36:29,242:INFO:Initializing Gradient Boosting Regressor
2025-03-29 15:36:29,242:INFO:Total runtime is 0.3584310173988342 minutes
2025-03-29 15:36:29,244:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:29,245:INFO:Initializing create_model()
2025-03-29 15:36:29,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:29,245:INFO:Checking exceptions
2025-03-29 15:36:29,245:INFO:Importing libraries
2025-03-29 15:36:29,245:INFO:Copying training dataset
2025-03-29 15:36:29,252:INFO:Defining folds
2025-03-29 15:36:29,252:INFO:Declaring metric variables
2025-03-29 15:36:29,254:INFO:Importing untrained model
2025-03-29 15:36:29,257:INFO:Gradient Boosting Regressor Imported successfully
2025-03-29 15:36:29,261:INFO:Starting cross validation
2025-03-29 15:36:29,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:31,123:INFO:Calculating mean and std
2025-03-29 15:36:31,124:INFO:Creating metrics dataframe
2025-03-29 15:36:31,125:INFO:Uploading results into container
2025-03-29 15:36:31,125:INFO:Uploading model into container now
2025-03-29 15:36:31,126:INFO:_master_model_container: 16
2025-03-29 15:36:31,126:INFO:_display_container: 2
2025-03-29 15:36:31,126:INFO:GradientBoostingRegressor(random_state=1903)
2025-03-29 15:36:31,126:INFO:create_model() successfully completed......................................
2025-03-29 15:36:31,223:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:31,223:INFO:Creating metrics dataframe
2025-03-29 15:36:31,229:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 15:36:31,229:INFO:Total runtime is 0.3915572683016459 minutes
2025-03-29 15:36:31,231:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:31,231:INFO:Initializing create_model()
2025-03-29 15:36:31,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:31,231:INFO:Checking exceptions
2025-03-29 15:36:31,232:INFO:Importing libraries
2025-03-29 15:36:31,232:INFO:Copying training dataset
2025-03-29 15:36:31,238:INFO:Defining folds
2025-03-29 15:36:31,238:INFO:Declaring metric variables
2025-03-29 15:36:31,241:INFO:Importing untrained model
2025-03-29 15:36:31,243:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:36:31,247:INFO:Starting cross validation
2025-03-29 15:36:31,248:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:32,023:INFO:Calculating mean and std
2025-03-29 15:36:32,024:INFO:Creating metrics dataframe
2025-03-29 15:36:32,025:INFO:Uploading results into container
2025-03-29 15:36:32,026:INFO:Uploading model into container now
2025-03-29 15:36:32,026:INFO:_master_model_container: 17
2025-03-29 15:36:32,026:INFO:_display_container: 2
2025-03-29 15:36:32,027:INFO:LGBMRegressor(n_jobs=-1, random_state=1903)
2025-03-29 15:36:32,027:INFO:create_model() successfully completed......................................
2025-03-29 15:36:32,142:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:32,142:INFO:Creating metrics dataframe
2025-03-29 15:36:32,148:INFO:Initializing Dummy Regressor
2025-03-29 15:36:32,148:INFO:Total runtime is 0.40687397718429563 minutes
2025-03-29 15:36:32,150:INFO:SubProcess create_model() called ==================================
2025-03-29 15:36:32,150:INFO:Initializing create_model()
2025-03-29 15:36:32,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91A540580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:32,150:INFO:Checking exceptions
2025-03-29 15:36:32,150:INFO:Importing libraries
2025-03-29 15:36:32,150:INFO:Copying training dataset
2025-03-29 15:36:32,157:INFO:Defining folds
2025-03-29 15:36:32,157:INFO:Declaring metric variables
2025-03-29 15:36:32,160:INFO:Importing untrained model
2025-03-29 15:36:32,164:INFO:Dummy Regressor Imported successfully
2025-03-29 15:36:32,169:INFO:Starting cross validation
2025-03-29 15:36:32,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:36:32,363:INFO:Calculating mean and std
2025-03-29 15:36:32,365:INFO:Creating metrics dataframe
2025-03-29 15:36:32,365:INFO:Uploading results into container
2025-03-29 15:36:32,365:INFO:Uploading model into container now
2025-03-29 15:36:32,367:INFO:_master_model_container: 18
2025-03-29 15:36:32,367:INFO:_display_container: 2
2025-03-29 15:36:32,367:INFO:DummyRegressor()
2025-03-29 15:36:32,367:INFO:create_model() successfully completed......................................
2025-03-29 15:36:32,461:INFO:SubProcess create_model() end ==================================
2025-03-29 15:36:32,461:INFO:Creating metrics dataframe
2025-03-29 15:36:32,469:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-29 15:36:32,475:INFO:Initializing create_model()
2025-03-29 15:36:32,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1903), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:36:32,475:INFO:Checking exceptions
2025-03-29 15:36:32,476:INFO:Importing libraries
2025-03-29 15:36:32,476:INFO:Copying training dataset
2025-03-29 15:36:32,482:INFO:Defining folds
2025-03-29 15:36:32,482:INFO:Declaring metric variables
2025-03-29 15:36:32,482:INFO:Importing untrained model
2025-03-29 15:36:32,482:INFO:Declaring custom model
2025-03-29 15:36:32,483:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:36:32,484:INFO:Cross validation set to False
2025-03-29 15:36:32,484:INFO:Fitting Model
2025-03-29 15:36:32,556:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:36:32,558:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.
2025-03-29 15:36:32,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:36:32,559:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:36:32,559:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:36:32,559:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:36:32,559:INFO:[LightGBM] [Info] Start training from score 3257.437704
2025-03-29 15:36:32,601:INFO:LGBMRegressor(n_jobs=-1, random_state=1903)
2025-03-29 15:36:32,601:INFO:create_model() successfully completed......................................
2025-03-29 15:36:32,729:INFO:_master_model_container: 18
2025-03-29 15:36:32,729:INFO:_display_container: 2
2025-03-29 15:36:32,730:INFO:LGBMRegressor(n_jobs=-1, random_state=1903)
2025-03-29 15:36:32,730:INFO:compare_models() successfully completed......................................
2025-03-29 15:36:41,299:INFO:Initializing evaluate_model()
2025-03-29 15:36:41,299:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1903), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-29 15:36:41,308:INFO:Initializing plot_model()
2025-03-29 15:36:41,308:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=1903), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9134A11B0>, system=True)
2025-03-29 15:36:41,309:INFO:Checking exceptions
2025-03-29 15:36:41,312:INFO:Preloading libraries
2025-03-29 15:36:41,314:INFO:Copying training dataset
2025-03-29 15:36:41,315:INFO:Plot type: pipeline
2025-03-29 15:36:41,449:INFO:Visual Rendered Successfully
2025-03-29 15:36:41,549:INFO:plot_model() successfully completed......................................
2025-03-29 15:37:03,886:INFO:PyCaret RegressionExperiment
2025-03-29 15:37:03,886:INFO:Logging name: reg-default-name
2025-03-29 15:37:03,886:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 15:37:03,886:INFO:version 3.3.2
2025-03-29 15:37:03,886:INFO:Initializing setup()
2025-03-29 15:37:03,886:INFO:self.USI: e6af
2025-03-29 15:37:03,886:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 15:37:03,886:INFO:Checking environment
2025-03-29 15:37:03,886:INFO:python_version: 3.10.16
2025-03-29 15:37:03,886:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 15:37:03,886:INFO:machine: AMD64
2025-03-29 15:37:03,886:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 15:37:03,889:INFO:Memory: svmem(total=33411727360, available=15443714048, percent=53.8, used=17968013312, free=15443714048)
2025-03-29 15:37:03,889:INFO:Physical Core: 6
2025-03-29 15:37:03,889:INFO:Logical Core: 12
2025-03-29 15:37:03,890:INFO:Checking libraries
2025-03-29 15:37:03,890:INFO:System:
2025-03-29 15:37:03,890:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 15:37:03,890:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 15:37:03,890:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 15:37:03,890:INFO:PyCaret required dependencies:
2025-03-29 15:37:03,890:INFO:                 pip: 25.0.1
2025-03-29 15:37:03,890:INFO:          setuptools: 75.8.2
2025-03-29 15:37:03,890:INFO:             pycaret: 3.3.2
2025-03-29 15:37:03,890:INFO:             IPython: 8.34.0
2025-03-29 15:37:03,890:INFO:          ipywidgets: 8.1.5
2025-03-29 15:37:03,890:INFO:                tqdm: 4.67.1
2025-03-29 15:37:03,890:INFO:               numpy: 1.26.4
2025-03-29 15:37:03,890:INFO:              pandas: 2.1.4
2025-03-29 15:37:03,890:INFO:              jinja2: 3.1.6
2025-03-29 15:37:03,890:INFO:               scipy: 1.11.4
2025-03-29 15:37:03,890:INFO:              joblib: 1.3.2
2025-03-29 15:37:03,890:INFO:             sklearn: 1.4.2
2025-03-29 15:37:03,890:INFO:                pyod: 2.0.2
2025-03-29 15:37:03,890:INFO:            imblearn: 0.13.0
2025-03-29 15:37:03,890:INFO:   category_encoders: 2.7.0
2025-03-29 15:37:03,890:INFO:            lightgbm: 4.6.0
2025-03-29 15:37:03,890:INFO:               numba: 0.61.0
2025-03-29 15:37:03,890:INFO:            requests: 2.32.3
2025-03-29 15:37:03,890:INFO:          matplotlib: 3.10.1
2025-03-29 15:37:03,890:INFO:          scikitplot: 0.3.7
2025-03-29 15:37:03,890:INFO:         yellowbrick: 1.5
2025-03-29 15:37:03,890:INFO:              plotly: 6.0.1
2025-03-29 15:37:03,890:INFO:    plotly-resampler: Not installed
2025-03-29 15:37:03,890:INFO:             kaleido: 0.2.1
2025-03-29 15:37:03,890:INFO:           schemdraw: 0.15
2025-03-29 15:37:03,890:INFO:         statsmodels: 0.14.4
2025-03-29 15:37:03,890:INFO:              sktime: 0.26.0
2025-03-29 15:37:03,890:INFO:               tbats: 1.1.3
2025-03-29 15:37:03,890:INFO:            pmdarima: 2.0.4
2025-03-29 15:37:03,890:INFO:              psutil: 7.0.0
2025-03-29 15:37:03,890:INFO:          markupsafe: 3.0.2
2025-03-29 15:37:03,890:INFO:             pickle5: Not installed
2025-03-29 15:37:03,890:INFO:         cloudpickle: 3.1.1
2025-03-29 15:37:03,890:INFO:         deprecation: 2.1.0
2025-03-29 15:37:03,890:INFO:              xxhash: 3.5.0
2025-03-29 15:37:03,890:INFO:           wurlitzer: 3.1.1
2025-03-29 15:37:03,890:INFO:PyCaret optional dependencies:
2025-03-29 15:37:03,891:INFO:                shap: Not installed
2025-03-29 15:37:03,891:INFO:           interpret: Not installed
2025-03-29 15:37:03,891:INFO:                umap: 0.5.7
2025-03-29 15:37:03,891:INFO:     ydata_profiling: Not installed
2025-03-29 15:37:03,891:INFO:  explainerdashboard: Not installed
2025-03-29 15:37:03,891:INFO:             autoviz: Not installed
2025-03-29 15:37:03,891:INFO:           fairlearn: Not installed
2025-03-29 15:37:03,891:INFO:          deepchecks: Not installed
2025-03-29 15:37:03,891:INFO:             xgboost: Not installed
2025-03-29 15:37:03,891:INFO:            catboost: Not installed
2025-03-29 15:37:03,891:INFO:              kmodes: Not installed
2025-03-29 15:37:03,891:INFO:             mlxtend: Not installed
2025-03-29 15:37:03,891:INFO:       statsforecast: Not installed
2025-03-29 15:37:03,891:INFO:        tune_sklearn: Not installed
2025-03-29 15:37:03,891:INFO:                 ray: Not installed
2025-03-29 15:37:03,891:INFO:            hyperopt: Not installed
2025-03-29 15:37:03,891:INFO:              optuna: Not installed
2025-03-29 15:37:03,891:INFO:               skopt: Not installed
2025-03-29 15:37:03,891:INFO:              mlflow: 2.21.2
2025-03-29 15:37:03,891:INFO:              gradio: Not installed
2025-03-29 15:37:03,892:INFO:             fastapi: 0.115.12
2025-03-29 15:37:03,892:INFO:             uvicorn: 0.34.0
2025-03-29 15:37:03,892:INFO:              m2cgen: Not installed
2025-03-29 15:37:03,892:INFO:           evidently: Not installed
2025-03-29 15:37:03,892:INFO:               fugue: Not installed
2025-03-29 15:37:03,892:INFO:           streamlit: 1.43.2
2025-03-29 15:37:03,892:INFO:             prophet: Not installed
2025-03-29 15:37:03,892:INFO:None
2025-03-29 15:37:03,892:INFO:Set up data.
2025-03-29 15:37:03,901:INFO:Set up folding strategy.
2025-03-29 15:37:03,901:INFO:Set up train/test split.
2025-03-29 15:37:03,906:INFO:Set up index.
2025-03-29 15:37:03,906:INFO:Assigning column types.
2025-03-29 15:37:03,911:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 15:37:03,911:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:37:03,915:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:37:03,918:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:37:03,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:37:03,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:37:03,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:03,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:03,982:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:37:03,984:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:37:03,987:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,024:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,049:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,050:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 15:37:04,052:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,055:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,091:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,117:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,120:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,123:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,185:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,186:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 15:37:04,192:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,229:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,261:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,298:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,323:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 15:37:04,361:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,449:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,449:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 15:37:04,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,550:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:37:04,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,575:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 15:37:04,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:04,704:INFO:Preparing preprocessing pipeline...
2025-03-29 15:37:04,704:INFO:Set up simple imputation.
2025-03-29 15:37:04,708:INFO:Set up encoding of categorical features.
2025-03-29 15:37:04,708:INFO:Set up column name cleaning.
2025-03-29 15:37:04,795:INFO:Finished creating preprocessing pipeline.
2025-03-29 15:37:04,799:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-29 15:37:04,799:INFO:Creating final display dataframe.
2025-03-29 15:37:05,004:INFO:Setup _display_container:                     Description             Value
0                    Session id              2598
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              e6af
2025-03-29 15:37:05,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:05,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:05,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:05,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:37:05,134:INFO:setup() successfully completed in 1.25s...............
2025-03-29 15:37:28,424:INFO:PyCaret ClassificationExperiment
2025-03-29 15:37:28,424:INFO:Logging name: clf-default-name
2025-03-29 15:37:28,424:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-29 15:37:28,424:INFO:version 3.3.2
2025-03-29 15:37:28,425:INFO:Initializing setup()
2025-03-29 15:37:28,425:INFO:self.USI: d59b
2025-03-29 15:37:28,425:INFO:self._variable_keys: {'fix_imbalance', 'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'is_multiclass'}
2025-03-29 15:37:28,425:INFO:Checking environment
2025-03-29 15:37:28,425:INFO:python_version: 3.10.16
2025-03-29 15:37:28,425:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 15:37:28,425:INFO:machine: AMD64
2025-03-29 15:37:28,425:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 15:37:28,429:INFO:Memory: svmem(total=33411727360, available=15431331840, percent=53.8, used=17980395520, free=15431331840)
2025-03-29 15:37:28,429:INFO:Physical Core: 6
2025-03-29 15:37:28,429:INFO:Logical Core: 12
2025-03-29 15:37:28,429:INFO:Checking libraries
2025-03-29 15:37:28,429:INFO:System:
2025-03-29 15:37:28,430:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 15:37:28,430:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 15:37:28,430:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 15:37:28,430:INFO:PyCaret required dependencies:
2025-03-29 15:37:28,430:INFO:                 pip: 25.0.1
2025-03-29 15:37:28,430:INFO:          setuptools: 75.8.2
2025-03-29 15:37:28,430:INFO:             pycaret: 3.3.2
2025-03-29 15:37:28,430:INFO:             IPython: 8.34.0
2025-03-29 15:37:28,430:INFO:          ipywidgets: 8.1.5
2025-03-29 15:37:28,430:INFO:                tqdm: 4.67.1
2025-03-29 15:37:28,430:INFO:               numpy: 1.26.4
2025-03-29 15:37:28,430:INFO:              pandas: 2.1.4
2025-03-29 15:37:28,430:INFO:              jinja2: 3.1.6
2025-03-29 15:37:28,430:INFO:               scipy: 1.11.4
2025-03-29 15:37:28,430:INFO:              joblib: 1.3.2
2025-03-29 15:37:28,430:INFO:             sklearn: 1.4.2
2025-03-29 15:37:28,430:INFO:                pyod: 2.0.2
2025-03-29 15:37:28,430:INFO:            imblearn: 0.13.0
2025-03-29 15:37:28,430:INFO:   category_encoders: 2.7.0
2025-03-29 15:37:28,430:INFO:            lightgbm: 4.6.0
2025-03-29 15:37:28,430:INFO:               numba: 0.61.0
2025-03-29 15:37:28,430:INFO:            requests: 2.32.3
2025-03-29 15:37:28,430:INFO:          matplotlib: 3.10.1
2025-03-29 15:37:28,430:INFO:          scikitplot: 0.3.7
2025-03-29 15:37:28,430:INFO:         yellowbrick: 1.5
2025-03-29 15:37:28,430:INFO:              plotly: 6.0.1
2025-03-29 15:37:28,430:INFO:    plotly-resampler: Not installed
2025-03-29 15:37:28,430:INFO:             kaleido: 0.2.1
2025-03-29 15:37:28,430:INFO:           schemdraw: 0.15
2025-03-29 15:37:28,430:INFO:         statsmodels: 0.14.4
2025-03-29 15:37:28,430:INFO:              sktime: 0.26.0
2025-03-29 15:37:28,430:INFO:               tbats: 1.1.3
2025-03-29 15:37:28,430:INFO:            pmdarima: 2.0.4
2025-03-29 15:37:28,430:INFO:              psutil: 7.0.0
2025-03-29 15:37:28,430:INFO:          markupsafe: 3.0.2
2025-03-29 15:37:28,430:INFO:             pickle5: Not installed
2025-03-29 15:37:28,430:INFO:         cloudpickle: 3.1.1
2025-03-29 15:37:28,431:INFO:         deprecation: 2.1.0
2025-03-29 15:37:28,431:INFO:              xxhash: 3.5.0
2025-03-29 15:37:28,431:INFO:           wurlitzer: 3.1.1
2025-03-29 15:37:28,431:INFO:PyCaret optional dependencies:
2025-03-29 15:37:28,431:INFO:                shap: Not installed
2025-03-29 15:37:28,431:INFO:           interpret: Not installed
2025-03-29 15:37:28,431:INFO:                umap: 0.5.7
2025-03-29 15:37:28,431:INFO:     ydata_profiling: Not installed
2025-03-29 15:37:28,431:INFO:  explainerdashboard: Not installed
2025-03-29 15:37:28,431:INFO:             autoviz: Not installed
2025-03-29 15:37:28,431:INFO:           fairlearn: Not installed
2025-03-29 15:37:28,431:INFO:          deepchecks: Not installed
2025-03-29 15:37:28,431:INFO:             xgboost: Not installed
2025-03-29 15:37:28,431:INFO:            catboost: Not installed
2025-03-29 15:37:28,431:INFO:              kmodes: Not installed
2025-03-29 15:37:28,431:INFO:             mlxtend: Not installed
2025-03-29 15:37:28,431:INFO:       statsforecast: Not installed
2025-03-29 15:37:28,431:INFO:        tune_sklearn: Not installed
2025-03-29 15:37:28,431:INFO:                 ray: Not installed
2025-03-29 15:37:28,431:INFO:            hyperopt: Not installed
2025-03-29 15:37:28,431:INFO:              optuna: Not installed
2025-03-29 15:37:28,431:INFO:               skopt: Not installed
2025-03-29 15:37:28,431:INFO:              mlflow: 2.21.2
2025-03-29 15:37:28,431:INFO:              gradio: Not installed
2025-03-29 15:37:28,431:INFO:             fastapi: 0.115.12
2025-03-29 15:37:28,431:INFO:             uvicorn: 0.34.0
2025-03-29 15:37:28,431:INFO:              m2cgen: Not installed
2025-03-29 15:37:28,431:INFO:           evidently: Not installed
2025-03-29 15:37:28,431:INFO:               fugue: Not installed
2025-03-29 15:37:28,431:INFO:           streamlit: 1.43.2
2025-03-29 15:37:28,431:INFO:             prophet: Not installed
2025-03-29 15:37:28,431:INFO:None
2025-03-29 15:37:28,431:INFO:Set up data.
2025-03-29 15:37:28,439:INFO:Set up folding strategy.
2025-03-29 15:37:28,439:INFO:Set up train/test split.
2025-03-29 15:38:34,111:INFO:PyCaret RegressionExperiment
2025-03-29 15:38:34,111:INFO:Logging name: reg-default-name
2025-03-29 15:38:34,111:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 15:38:34,111:INFO:version 3.3.2
2025-03-29 15:38:34,111:INFO:Initializing setup()
2025-03-29 15:38:34,111:INFO:self.USI: 3b03
2025-03-29 15:38:34,111:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 15:38:34,111:INFO:Checking environment
2025-03-29 15:38:34,111:INFO:python_version: 3.10.16
2025-03-29 15:38:34,111:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 15:38:34,112:INFO:machine: AMD64
2025-03-29 15:38:34,112:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 15:38:34,116:INFO:Memory: svmem(total=33411727360, available=15250001920, percent=54.4, used=18161725440, free=15250001920)
2025-03-29 15:38:34,116:INFO:Physical Core: 6
2025-03-29 15:38:34,116:INFO:Logical Core: 12
2025-03-29 15:38:34,116:INFO:Checking libraries
2025-03-29 15:38:34,116:INFO:System:
2025-03-29 15:38:34,116:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 15:38:34,116:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 15:38:34,117:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 15:38:34,117:INFO:PyCaret required dependencies:
2025-03-29 15:38:34,117:INFO:                 pip: 25.0.1
2025-03-29 15:38:34,117:INFO:          setuptools: 75.8.2
2025-03-29 15:38:34,117:INFO:             pycaret: 3.3.2
2025-03-29 15:38:34,117:INFO:             IPython: 8.34.0
2025-03-29 15:38:34,117:INFO:          ipywidgets: 8.1.5
2025-03-29 15:38:34,117:INFO:                tqdm: 4.67.1
2025-03-29 15:38:34,117:INFO:               numpy: 1.26.4
2025-03-29 15:38:34,117:INFO:              pandas: 2.1.4
2025-03-29 15:38:34,117:INFO:              jinja2: 3.1.6
2025-03-29 15:38:34,117:INFO:               scipy: 1.11.4
2025-03-29 15:38:34,117:INFO:              joblib: 1.3.2
2025-03-29 15:38:34,117:INFO:             sklearn: 1.4.2
2025-03-29 15:38:34,117:INFO:                pyod: 2.0.2
2025-03-29 15:38:34,117:INFO:            imblearn: 0.13.0
2025-03-29 15:38:34,117:INFO:   category_encoders: 2.7.0
2025-03-29 15:38:34,117:INFO:            lightgbm: 4.6.0
2025-03-29 15:38:34,117:INFO:               numba: 0.61.0
2025-03-29 15:38:34,117:INFO:            requests: 2.32.3
2025-03-29 15:38:34,117:INFO:          matplotlib: 3.10.1
2025-03-29 15:38:34,117:INFO:          scikitplot: 0.3.7
2025-03-29 15:38:34,117:INFO:         yellowbrick: 1.5
2025-03-29 15:38:34,117:INFO:              plotly: 6.0.1
2025-03-29 15:38:34,117:INFO:    plotly-resampler: Not installed
2025-03-29 15:38:34,117:INFO:             kaleido: 0.2.1
2025-03-29 15:38:34,117:INFO:           schemdraw: 0.15
2025-03-29 15:38:34,117:INFO:         statsmodels: 0.14.4
2025-03-29 15:38:34,117:INFO:              sktime: 0.26.0
2025-03-29 15:38:34,117:INFO:               tbats: 1.1.3
2025-03-29 15:38:34,117:INFO:            pmdarima: 2.0.4
2025-03-29 15:38:34,117:INFO:              psutil: 7.0.0
2025-03-29 15:38:34,117:INFO:          markupsafe: 3.0.2
2025-03-29 15:38:34,118:INFO:             pickle5: Not installed
2025-03-29 15:38:34,118:INFO:         cloudpickle: 3.1.1
2025-03-29 15:38:34,118:INFO:         deprecation: 2.1.0
2025-03-29 15:38:34,118:INFO:              xxhash: 3.5.0
2025-03-29 15:38:34,118:INFO:           wurlitzer: 3.1.1
2025-03-29 15:38:34,118:INFO:PyCaret optional dependencies:
2025-03-29 15:38:34,118:INFO:                shap: Not installed
2025-03-29 15:38:34,118:INFO:           interpret: Not installed
2025-03-29 15:38:34,118:INFO:                umap: 0.5.7
2025-03-29 15:38:34,118:INFO:     ydata_profiling: Not installed
2025-03-29 15:38:34,118:INFO:  explainerdashboard: Not installed
2025-03-29 15:38:34,118:INFO:             autoviz: Not installed
2025-03-29 15:38:34,118:INFO:           fairlearn: Not installed
2025-03-29 15:38:34,118:INFO:          deepchecks: Not installed
2025-03-29 15:38:34,118:INFO:             xgboost: Not installed
2025-03-29 15:38:34,118:INFO:            catboost: Not installed
2025-03-29 15:38:34,118:INFO:              kmodes: Not installed
2025-03-29 15:38:34,118:INFO:             mlxtend: Not installed
2025-03-29 15:38:34,118:INFO:       statsforecast: Not installed
2025-03-29 15:38:34,118:INFO:        tune_sklearn: Not installed
2025-03-29 15:38:34,118:INFO:                 ray: Not installed
2025-03-29 15:38:34,118:INFO:            hyperopt: Not installed
2025-03-29 15:38:34,118:INFO:              optuna: Not installed
2025-03-29 15:38:34,118:INFO:               skopt: Not installed
2025-03-29 15:38:34,118:INFO:              mlflow: 2.21.2
2025-03-29 15:38:34,118:INFO:              gradio: Not installed
2025-03-29 15:38:34,118:INFO:             fastapi: 0.115.12
2025-03-29 15:38:34,118:INFO:             uvicorn: 0.34.0
2025-03-29 15:38:34,118:INFO:              m2cgen: Not installed
2025-03-29 15:38:34,118:INFO:           evidently: Not installed
2025-03-29 15:38:34,118:INFO:               fugue: Not installed
2025-03-29 15:38:34,118:INFO:           streamlit: 1.43.2
2025-03-29 15:38:34,118:INFO:             prophet: Not installed
2025-03-29 15:38:34,118:INFO:None
2025-03-29 15:38:34,118:INFO:Set up data.
2025-03-29 15:38:34,127:INFO:Set up folding strategy.
2025-03-29 15:38:34,127:INFO:Set up train/test split.
2025-03-29 15:38:34,132:INFO:Set up index.
2025-03-29 15:38:34,132:INFO:Assigning column types.
2025-03-29 15:38:34,136:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 15:38:34,136:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,139:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,141:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,207:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,209:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,212:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,270:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,271:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 15:38:34,273:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,275:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,340:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,342:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,403:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 15:38:34,408:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,467:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,473:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,534:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 15:38:34,573:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,597:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,639:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,666:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 15:38:34,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:38:34,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,797:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 15:38:34,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:34,935:INFO:Preparing preprocessing pipeline...
2025-03-29 15:38:34,935:INFO:Set up simple imputation.
2025-03-29 15:38:34,940:INFO:Set up encoding of categorical features.
2025-03-29 15:38:34,941:INFO:Set up column name cleaning.
2025-03-29 15:38:35,040:INFO:Finished creating preprocessing pipeline.
2025-03-29 15:38:35,043:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_i...
                                    include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-03-29 15:38:35,043:INFO:Creating final display dataframe.
2025-03-29 15:38:35,263:INFO:Setup _display_container:                     Description             Value
0                    Session id              1667
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              3b03
2025-03-29 15:38:35,332:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:35,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:35,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:35,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:38:35,396:INFO:setup() successfully completed in 1.29s...............
2025-03-29 15:38:45,707:INFO:Initializing evaluate_model()
2025-03-29 15:38:45,708:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-29 15:38:45,716:INFO:Initializing plot_model()
2025-03-29 15:38:45,716:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, system=True)
2025-03-29 15:38:45,716:INFO:Checking exceptions
2025-03-29 15:38:45,720:INFO:Preloading libraries
2025-03-29 15:38:45,722:INFO:Copying training dataset
2025-03-29 15:38:45,722:INFO:Plot type: pipeline
2025-03-29 15:38:45,808:INFO:Visual Rendered Successfully
2025-03-29 15:38:45,928:INFO:plot_model() successfully completed......................................
2025-03-29 15:38:47,623:INFO:Initializing plot_model()
2025-03-29 15:38:47,623:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, system=True)
2025-03-29 15:38:47,623:INFO:Checking exceptions
2025-03-29 15:38:47,627:INFO:Preloading libraries
2025-03-29 15:38:47,641:INFO:Copying training dataset
2025-03-29 15:38:47,641:INFO:Plot type: residuals
2025-03-29 15:38:47,898:INFO:Fitting Model
2025-03-29 15:38:48,659:INFO:Initializing plot_model()
2025-03-29 15:38:48,659:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, system=True)
2025-03-29 15:38:48,659:INFO:Checking exceptions
2025-03-29 15:38:48,662:INFO:Preloading libraries
2025-03-29 15:38:48,665:INFO:Copying training dataset
2025-03-29 15:38:48,665:INFO:Plot type: parameter
2025-03-29 15:38:48,668:INFO:Visual Rendered Successfully
2025-03-29 15:38:48,824:INFO:plot_model() successfully completed......................................
2025-03-29 15:38:49,290:INFO:Initializing plot_model()
2025-03-29 15:38:49,290:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, system=True)
2025-03-29 15:38:49,290:INFO:Checking exceptions
2025-03-29 15:38:49,293:INFO:Preloading libraries
2025-03-29 15:38:49,295:INFO:Copying training dataset
2025-03-29 15:38:49,295:INFO:Plot type: residuals
2025-03-29 15:38:49,525:INFO:Fitting Model
2025-03-29 15:38:50,151:INFO:Initializing plot_model()
2025-03-29 15:38:50,151:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, system=True)
2025-03-29 15:38:50,151:INFO:Checking exceptions
2025-03-29 15:38:50,154:INFO:Preloading libraries
2025-03-29 15:38:50,157:INFO:Copying training dataset
2025-03-29 15:38:50,157:INFO:Plot type: error
2025-03-29 15:38:50,383:INFO:Fitting Model
2025-03-29 15:38:50,383:INFO:Scoring test/hold-out set
2025-03-29 15:38:51,053:INFO:Initializing plot_model()
2025-03-29 15:38:51,053:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, system=True)
2025-03-29 15:38:51,053:INFO:Checking exceptions
2025-03-29 15:38:51,056:INFO:Preloading libraries
2025-03-29 15:38:51,058:INFO:Copying training dataset
2025-03-29 15:38:51,058:INFO:Plot type: cooks
2025-03-29 15:38:51,283:INFO:Fitting Model
2025-03-29 15:38:52,245:INFO:Initializing plot_model()
2025-03-29 15:38:52,245:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, system=True)
2025-03-29 15:38:52,246:INFO:Checking exceptions
2025-03-29 15:38:52,248:INFO:Preloading libraries
2025-03-29 15:38:52,251:INFO:Copying training dataset
2025-03-29 15:38:52,251:INFO:Plot type: rfe
2025-03-29 15:38:52,471:INFO:Fitting Model
2025-03-29 15:38:52,490:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:38:52,490:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:52,490:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:52,490:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:52,490:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:52,491:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:52,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:38:52,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:52,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:52,543:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:52,543:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:52,543:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:52,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:38:52,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:52,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:52,596:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:52,596:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:52,596:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:52,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:38:52,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:52,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:52,653:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:52,653:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:52,653:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:52,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.
2025-03-29 15:38:52,706:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:52,706:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:52,706:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:52,706:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:52,706:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:52,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:38:52,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:52,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:52,760:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:52,760:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:52,760:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:52,812:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:38:52,812:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:52,812:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:52,813:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:52,813:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:52,813:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:52,864:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:38:52,864:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:52,864:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:52,864:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:52,864:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:52,865:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:52,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:38:52,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:52,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:52,916:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:52,916:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:52,916:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:52,976:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000444 seconds.
2025-03-29 15:38:52,976:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:52,976:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:52,976:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:52,976:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:52,976:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,053:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-03-29 15:38:53,053:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,053:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,053:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:53,053:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:53,053:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:38:53,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,131:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:53,131:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:53,131:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,208:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:38:53,208:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,208:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,208:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:38:53,208:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:53,208:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,283:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.
2025-03-29 15:38:53,283:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,283:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,283:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:38:53,284:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:38:53,284:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,363:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:38:53,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,364:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:38:53,364:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:38:53,364:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.
2025-03-29 15:38:53,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,442:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:38:53,443:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:38:53,443:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.
2025-03-29 15:38:53,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,513:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:38:53,513:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:38:53,513:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,577:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000570 seconds.
2025-03-29 15:38:53,577:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,577:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,577:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:38:53,577:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:38:53,578:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-29 15:38:53,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,651:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:38:53,651:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:38:53,651:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.
2025-03-29 15:38:53,727:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,727:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:38:53,727:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:38:53,727:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.
2025-03-29 15:38:53,801:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,801:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,801:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:38:53,801:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:38:53,802:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.
2025-03-29 15:38:53,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,876:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:38:53,876:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:38:53,876:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:53,945:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.
2025-03-29 15:38:53,945:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:53,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:53,945:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:38:53,945:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-29 15:38:53,946:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:54,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.
2025-03-29 15:38:54,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,011:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:38:54,011:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-29 15:38:54,012:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:54,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.
2025-03-29 15:38:54,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,065:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:38:54,065:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-29 15:38:54,065:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:54,105:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.
2025-03-29 15:38:54,105:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,105:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,106:INFO:[LightGBM] [Info] Total Bins 300
2025-03-29 15:38:54,106:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-29 15:38:54,106:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:54,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.
2025-03-29 15:38:54,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,146:INFO:[LightGBM] [Info] Total Bins 255
2025-03-29 15:38:54,146:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 1
2025-03-29 15:38:54,146:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:38:54,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:38:54,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,201:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,202:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:38:54,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,251:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,251:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,251:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:38:54,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,301:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,301:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,301:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:38:54,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,350:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,350:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,350:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,398:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:38:54,398:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,398:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,398:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,398:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,399:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,448:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:38:54,448:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,448:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,448:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,448:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,448:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,496:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:38:54,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,496:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,496:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,496:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:38:54,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,544:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,544:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,544:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,591:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:38:54,591:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,591:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,591:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,591:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,591:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,639:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:38:54,639:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,639:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,639:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,639:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,639:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,686:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:38:54,686:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,686:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,686:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,686:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,686:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,733:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:38:54,733:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,733:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,733:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,733:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,733:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:38:54,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,780:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:38:54,780:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:38:54,780:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,826:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:38:54,826:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,826:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,826:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:38:54,826:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:38:54,826:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:38:54,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,876:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:38:54,876:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:38:54,876:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,929:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.
2025-03-29 15:38:54,929:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,929:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,929:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:38:54,929:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:38:54,929:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:54,978:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:38:54,978:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:54,978:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:54,978:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:38:54,978:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:38:54,978:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,035:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000449 seconds.
2025-03-29 15:38:55,035:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,035:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,035:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:38:55,035:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:38:55,035:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:38:55,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,084:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:38:55,084:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:38:55,084:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:38:55,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,142:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,142:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:38:55,142:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:38:55,142:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:38:55,208:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,208:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,208:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:38:55,208:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:38:55,208:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.
2025-03-29 15:38:55,258:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,258:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:38:55,258:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:38:55,258:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,305:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:38:55,305:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,305:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:38:55,305:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-29 15:38:55,305:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,353:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.
2025-03-29 15:38:55,353:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:38:55,353:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:38:55,353:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-29 15:38:55,353:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,405:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.
2025-03-29 15:38:55,406:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,406:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,406:INFO:[LightGBM] [Info] Total Bins 531
2025-03-29 15:38:55,406:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-29 15:38:55,406:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,450:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000055 seconds.
2025-03-29 15:38:55,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,450:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,450:INFO:[LightGBM] [Info] Total Bins 300
2025-03-29 15:38:55,450:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-29 15:38:55,450:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.
2025-03-29 15:38:55,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,493:INFO:[LightGBM] [Info] Total Bins 255
2025-03-29 15:38:55,493:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 1
2025-03-29 15:38:55,493:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:38:55,548:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:38:55,548:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,549:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,549:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:55,549:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:55,549:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:55,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:38:55,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,603:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:55,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:55,603:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:55,656:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:38:55,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,656:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:55,656:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:55,656:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:55,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:38:55,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,707:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:55,707:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:55,707:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:55,759:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:38:55,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,760:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:55,760:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:55,760:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:55,809:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:38:55,809:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,809:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,809:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:55,809:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:55,809:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:55,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:38:55,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,858:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:55,858:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:55,858:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:55,906:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:38:55,906:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,907:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:55,907:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:55,907:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:55,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:38:55,954:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:55,954:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:55,954:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:55,954:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:55,954:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,001:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:38:56,001:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,001:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:56,001:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:56,001:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,052:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:38:56,052:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,052:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,052:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:56,052:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:56,052:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,101:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:38:56,101:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,101:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,101:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:56,101:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:56,101:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:38:56,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,150:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,150:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:38:56,150:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:56,150:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:38:56,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,200:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:38:56,200:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:38:56,200:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:38:56,253:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,253:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,253:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:38:56,253:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:38:56,253:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,312:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000689 seconds.
2025-03-29 15:38:56,312:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:38:56,312:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:38:56,312:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:38:56,312:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:38:56,364:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,364:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,364:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:38:56,364:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:38:56,364:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-29 15:38:56,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,409:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:38:56,409:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:38:56,409:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:38:56,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,470:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:38:56,470:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:38:56,470:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,521:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.
2025-03-29 15:38:56,521:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,521:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,521:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:38:56,521:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:38:56,521:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,570:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:38:56,570:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,570:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,570:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:38:56,570:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:38:56,570:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,616:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.
2025-03-29 15:38:56,616:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,616:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,616:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:38:56,616:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:38:56,616:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,662:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:38:56,662:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,662:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,662:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:38:56,662:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:38:56,662:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.
2025-03-29 15:38:56,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,707:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:38:56,707:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:38:56,708:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-03-29 15:38:56,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,751:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,751:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:38:56,751:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:38:56,751:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.
2025-03-29 15:38:56,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,792:INFO:[LightGBM] [Info] Total Bins 301
2025-03-29 15:38:56,792:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:38:56,792:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,833:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.
2025-03-29 15:38:56,833:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,833:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,833:INFO:[LightGBM] [Info] Total Bins 255
2025-03-29 15:38:56,833:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-29 15:38:56,834:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:38:56,887:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:38:56,887:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,887:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,887:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:56,887:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:56,887:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:56,970:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:38:56,970:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:56,970:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:56,970:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:56,970:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:56,970:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.
2025-03-29 15:38:57,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,031:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,031:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,031:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:38:57,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,088:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,088:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,088:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:38:57,143:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,143:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,143:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,143:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,143:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:38:57,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,200:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,200:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,200:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,252:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2025-03-29 15:38:57,252:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,252:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,252:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,252:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,252:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,332:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:38:57,333:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,333:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,333:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,333:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,333:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:38:57,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,402:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,402:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,403:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,452:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:38:57,452:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,452:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,452:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,452:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,452:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,506:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:38:57,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,506:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,506:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,507:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,556:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:38:57,556:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,556:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,556:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,556:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,556:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,609:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:38:57,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,609:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:38:57,610:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:57,610:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-03-29 15:38:57,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,665:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:38:57,665:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:38:57,665:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,718:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:38:57,718:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,718:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,718:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:38:57,718:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:38:57,718:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,773:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.
2025-03-29 15:38:57,773:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,773:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,773:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:38:57,773:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:38:57,773:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,830:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-03-29 15:38:57,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,830:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:38:57,831:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:38:57,831:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-29 15:38:57,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,883:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:38:57,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:38:57,883:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,935:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.
2025-03-29 15:38:57,935:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,935:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,935:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:38:57,935:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:38:57,935:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:57,986:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:38:57,986:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:57,986:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:57,986:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:38:57,986:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:38:57,986:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:58,036:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.
2025-03-29 15:38:58,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,036:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:38:58,036:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:38:58,037:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:58,088:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.
2025-03-29 15:38:58,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,088:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:38:58,088:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:38:58,089:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:58,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.
2025-03-29 15:38:58,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,139:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:38:58,139:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:38:58,139:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:58,193:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.
2025-03-29 15:38:58,193:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,193:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,193:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:38:58,193:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:38:58,193:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:58,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000130 seconds.
2025-03-29 15:38:58,252:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,252:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,252:INFO:[LightGBM] [Info] Total Bins 526
2025-03-29 15:38:58,252:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:38:58,252:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:58,317:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.
2025-03-29 15:38:58,318:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,318:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,318:INFO:[LightGBM] [Info] Total Bins 298
2025-03-29 15:38:58,318:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:38:58,318:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:58,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.
2025-03-29 15:38:58,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:38:58,365:INFO:[LightGBM] [Info] Total Bins 255
2025-03-29 15:38:58,365:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-29 15:38:58,365:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:38:58,422:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:38:58,422:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,422:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,422:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,423:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,423:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:58,479:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:38:58,479:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,479:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,479:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,479:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,479:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:58,538:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:38:58,538:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,538:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,538:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,538:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,538:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:58,594:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:38:58,594:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,594:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,594:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,595:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,595:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:58,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:38:58,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,654:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,654:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,654:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:58,709:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:38:58,709:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,709:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,709:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,709:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,709:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:58,761:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:38:58,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,761:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,761:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,762:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:58,818:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.
2025-03-29 15:38:58,818:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,818:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,818:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,818:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,818:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:58,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:38:58,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,873:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,873:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,873:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:58,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:38:58,926:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,926:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,926:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,926:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,926:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:58,978:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:38:58,978:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:58,978:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:58,978:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:58,978:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:58,978:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,030:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:38:59,030:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,030:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,030:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:59,030:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:59,030:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,081:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:38:59,081:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,081:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,081:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:59,081:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:59,081:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:38:59,132:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,132:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:38:59,132:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:38:59,132:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,184:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:38:59,184:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,184:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,184:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:38:59,184:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:38:59,184:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,239:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:38:59,239:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,239:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,239:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:38:59,239:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:38:59,239:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,294:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.
2025-03-29 15:38:59,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,295:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:38:59,295:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:38:59,295:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:38:59,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,351:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:38:59,351:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:38:59,351:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,407:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.
2025-03-29 15:38:59,407:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,407:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,407:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:38:59,407:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:38:59,407:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,460:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:38:59,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,460:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,460:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:38:59,460:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:38:59,460:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,514:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:38:59,514:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,514:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,514:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:38:59,514:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:38:59,514:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:38:59,569:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,569:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,569:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:38:59,569:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:38:59,570:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,623:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-29 15:38:59,623:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,623:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,623:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:38:59,623:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:38:59,623:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,677:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.
2025-03-29 15:38:59,677:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,677:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,677:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:38:59,677:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:38:59,677:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-03-29 15:38:59,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,761:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:38:59,761:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:38:59,761:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000059 seconds.
2025-03-29 15:38:59,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,806:INFO:[LightGBM] [Info] Total Bins 299
2025-03-29 15:38:59,806:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:38:59,806:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.
2025-03-29 15:38:59,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,850:INFO:[LightGBM] [Info] Total Bins 255
2025-03-29 15:38:59,850:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-29 15:38:59,850:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:38:59,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:38:59,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,911:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:38:59,911:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:38:59,911:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:38:59,971:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:38:59,971:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:38:59,971:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:38:59,971:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:38:59,971:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:38:59,971:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:39:00,032:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,032:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,032:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,032:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,032:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,093:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:39:00,093:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,093:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,093:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,093:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,094:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.
2025-03-29 15:39:00,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,155:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,155:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,155:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,229:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:39:00,229:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,229:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,229:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,229:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,229:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:39:00,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,294:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,294:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,294:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,388:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:39:00,388:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,388:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,388:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,388:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,388:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:39:00,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,451:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,451:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,452:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:00,514:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,514:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,514:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,514:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,514:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,574:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:39:00,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,574:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,574:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,575:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,634:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:39:00,634:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,635:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,635:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,635:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,635:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,692:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:00,692:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,692:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,692:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,692:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,692:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,750:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-29 15:39:00,750:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,750:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,750:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:00,750:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:00,750:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,808:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2025-03-29 15:39:00,808:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,808:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,808:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:00,808:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:00,808:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:39:00,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,862:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:00,862:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:00,863:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:39:00,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,916:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:00,916:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:00,916:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:00,969:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:39:00,970:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:00,970:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:00,970:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:00,970:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:00,970:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:01,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.
2025-03-29 15:39:01,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,024:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:01,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:01,024:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:01,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:39:01,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,076:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:01,076:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:01,077:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:01,127:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:39:01,127:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,127:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,127:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:01,128:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:01,128:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:01,179:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000271 seconds.
2025-03-29 15:39:01,179:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,179:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,179:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:01,179:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:01,179:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:01,230:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000598 seconds.
2025-03-29 15:39:01,230:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:39:01,230:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:01,230:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:01,230:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:01,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.
2025-03-29 15:39:01,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,290:INFO:[LightGBM] [Info] Total Bins 531
2025-03-29 15:39:01,290:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:01,290:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:01,342:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.
2025-03-29 15:39:01,343:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,343:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,343:INFO:[LightGBM] [Info] Total Bins 529
2025-03-29 15:39:01,343:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:01,343:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:01,390:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000060 seconds.
2025-03-29 15:39:01,390:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,390:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,390:INFO:[LightGBM] [Info] Total Bins 299
2025-03-29 15:39:01,390:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:01,390:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:01,433:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.
2025-03-29 15:39:01,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,433:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,433:INFO:[LightGBM] [Info] Total Bins 255
2025-03-29 15:39:01,433:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-29 15:39:01,433:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:01,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2025-03-29 15:39:01,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,493:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:01,493:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:01,493:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:01,549:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:39:01,550:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,550:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,550:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:01,550:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:01,550:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:01,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:39:01,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,603:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:01,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:01,603:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:01,661:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:39:01,662:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,662:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,662:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:01,662:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:01,662:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:01,716:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:39:01,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,716:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:01,716:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:01,716:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:01,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:39:01,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,769:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,769:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:01,769:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:01,769:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:01,820:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:39:01,820:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,820:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,820:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:01,820:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:01,821:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:01,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:39:01,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,875:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:01,875:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:01,875:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:01,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:39:01,928:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,928:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,928:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:01,928:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:01,928:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:01,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:39:01,982:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:01,982:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:01,982:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:01,982:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:01,982:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,036:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:02,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,036:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:02,036:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:02,036:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,088:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:39:02,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,088:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:02,088:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:02,089:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,140:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:02,140:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,140:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,140:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:02,140:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:02,141:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:39:02,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,195:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:02,195:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:02,195:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:39:02,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,250:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:02,250:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:02,250:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:39:02,305:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,305:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:02,305:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:02,305:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,357:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:39:02,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,357:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:02,357:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:02,357:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,408:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2025-03-29 15:39:02,408:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,408:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,408:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:02,408:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:02,408:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,462:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:39:02,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,462:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,462:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:02,462:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:02,462:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.
2025-03-29 15:39:02,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,513:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:02,513:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:02,513:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,563:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000716 seconds.
2025-03-29 15:39:02,563:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,563:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,563:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:02,563:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:02,563:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.
2025-03-29 15:39:02,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,614:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:02,614:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:02,614:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.
2025-03-29 15:39:02,667:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,667:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,667:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:02,667:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:02,667:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.
2025-03-29 15:39:02,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,714:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:02,714:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:02,714:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,762:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.
2025-03-29 15:39:02,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,762:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,762:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:02,762:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:02,762:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,804:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.
2025-03-29 15:39:02,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,804:INFO:[LightGBM] [Info] Total Bins 298
2025-03-29 15:39:02,804:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:02,804:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,846:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.
2025-03-29 15:39:02,846:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,846:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,846:INFO:[LightGBM] [Info] Total Bins 255
2025-03-29 15:39:02,847:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-29 15:39:02,847:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:02,903:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:39:02,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,904:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:02,904:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:02,904:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:02,958:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:39:02,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:02,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:02,958:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:02,958:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:02,958:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,013:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000700 seconds.
2025-03-29 15:39:03,014:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,014:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,014:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,014:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,014:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:03,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,068:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,068:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,069:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,122:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:03,122:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,122:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,122:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,122:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,122:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:03,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,176:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,176:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,177:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,232:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:39:03,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,233:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,233:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,233:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,233:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,292:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:03,292:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,292:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,293:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,293:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,293:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,348:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:39:03,348:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,349:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,349:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,349:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,349:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:39:03,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,402:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,402:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,403:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:39:03,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,455:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,455:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,455:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,507:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.
2025-03-29 15:39:03,507:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,507:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,507:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,507:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,507:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:39:03,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,561:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:03,561:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:03,561:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,616:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:39:03,616:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,616:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,616:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:03,616:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:03,616:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,671:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000490 seconds.
2025-03-29 15:39:03,671:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,671:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,671:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:03,671:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:03,672:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:39:03,724:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,724:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,724:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:03,724:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:03,724:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,777:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:39:03,777:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,777:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:03,777:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:03,777:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:39:03,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,832:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:03,832:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:03,832:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-29 15:39:03,888:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,888:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:03,888:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:03,889:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,942:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:39:03,942:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,942:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,942:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:03,942:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:03,942:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:03,998:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:39:03,998:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:03,998:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:03,998:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:03,998:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:03,998:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:04,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.
2025-03-29 15:39:04,057:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,057:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,057:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:04,057:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:04,057:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:04,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:04,110:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,110:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:04,110:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:04,110:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:04,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.
2025-03-29 15:39:04,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,163:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:04,163:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:04,163:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:04,217:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.
2025-03-29 15:39:04,217:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,217:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,217:INFO:[LightGBM] [Info] Total Bins 531
2025-03-29 15:39:04,217:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:04,217:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:04,264:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.
2025-03-29 15:39:04,264:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,264:INFO:[LightGBM] [Info] Total Bins 301
2025-03-29 15:39:04,264:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:04,264:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:04,309:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.
2025-03-29 15:39:04,309:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,310:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,310:INFO:[LightGBM] [Info] Total Bins 255
2025-03-29 15:39:04,310:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-29 15:39:04,310:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:04,371:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.
2025-03-29 15:39:04,372:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,372:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,372:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,372:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,372:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,428:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:39:04,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,428:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,428:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,428:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,428:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:04,482:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,482:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,482:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,482:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,539:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:39:04,539:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,539:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,539:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,539:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,539:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,593:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:04,593:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,593:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,594:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,594:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,594:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,648:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:04,648:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,648:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,648:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,648:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,648:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,704:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000705 seconds.
2025-03-29 15:39:04,704:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:39:04,704:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,704:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,704:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:39:04,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,766:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,766:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,766:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,819:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:39:04,819:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,819:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,819:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,820:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,820:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:39:04,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,873:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,873:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,874:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:04,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,928:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,928:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,928:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:04,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:39:04,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:04,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:04,981:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:04,981:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:04,981:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:39:05,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,033:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:05,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:05,034:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,086:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:39:05,086:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,086:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,086:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:39:05,086:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:05,086:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,138:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:39:05,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,138:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,138:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:05,138:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:05,138:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,189:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:39:05,189:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,189:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,190:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:05,190:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:05,190:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,244:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:39:05,244:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,244:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,244:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:05,244:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:05,244:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,300:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.
2025-03-29 15:39:05,300:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,300:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,300:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:05,300:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:05,300:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-03-29 15:39:05,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,352:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:05,352:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:05,352:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,403:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.
2025-03-29 15:39:05,403:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,403:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,403:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:05,403:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:05,403:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:39:05,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,455:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:05,455:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:05,455:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000127 seconds.
2025-03-29 15:39:05,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,505:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:05,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:05,505:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,555:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.
2025-03-29 15:39:05,555:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,555:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,555:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:05,555:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:05,555:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.
2025-03-29 15:39:05,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,603:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:05,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:05,603:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,653:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-03-29 15:39:05,653:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,653:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:05,653:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:05,653:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,695:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.
2025-03-29 15:39:05,695:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,695:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,695:INFO:[LightGBM] [Info] Total Bins 299
2025-03-29 15:39:05,696:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:05,696:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000031 seconds.
2025-03-29 15:39:05,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,738:INFO:[LightGBM] [Info] Total Bins 255
2025-03-29 15:39:05,738:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-29 15:39:05,738:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:05,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:39:05,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,792:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:05,792:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:05,792:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:05,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:39:05,847:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,847:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,847:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:05,848:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:05,848:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:05,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:39:05,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,901:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:05,901:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:05,901:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:05,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:05,954:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:05,954:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:05,954:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:05,954:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:05,954:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,030:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.
2025-03-29 15:39:06,030:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,030:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,030:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:06,030:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:06,031:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:39:06,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,089:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:06,089:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:06,089:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:06,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,141:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:06,142:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:06,142:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:06,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,196:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,196:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:06,196:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:06,196:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:39:06,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,250:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:06,250:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:06,251:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,310:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:39:06,310:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,310:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,310:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:06,310:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:06,310:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,369:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-03-29 15:39:06,369:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,369:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:06,369:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:06,370:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,421:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:39:06,421:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,421:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,421:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:06,422:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:06,422:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,480:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:39:06,480:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,480:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,480:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:06,480:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:06,480:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,539:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:06,539:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,539:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,539:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:39:06,539:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:06,539:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,591:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.
2025-03-29 15:39:06,591:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,591:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,591:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:39:06,591:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:06,591:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-03-29 15:39:06,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,644:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:06,644:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:06,644:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,716:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.
2025-03-29 15:39:06,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,717:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:06,717:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:06,717:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,787:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000596 seconds.
2025-03-29 15:39:06,787:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,787:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:06,787:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:06,788:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-03-29 15:39:06,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,860:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:06,860:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:06,860:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:06,932:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.
2025-03-29 15:39:06,932:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:06,932:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:06,932:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:06,932:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:06,932:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:07,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.
2025-03-29 15:39:07,004:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,004:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,004:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:07,004:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:07,004:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:07,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.
2025-03-29 15:39:07,073:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,073:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,073:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:07,073:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:07,074:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:07,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:39:07,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,141:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:07,141:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:07,141:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:07,208:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.
2025-03-29 15:39:07,208:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,208:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,208:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:07,208:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:07,208:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:07,281:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.
2025-03-29 15:39:07,281:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,281:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,281:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:07,281:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:07,281:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:07,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000057 seconds.
2025-03-29 15:39:07,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,347:INFO:[LightGBM] [Info] Total Bins 300
2025-03-29 15:39:07,347:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:07,347:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:07,411:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.
2025-03-29 15:39:07,411:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,411:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,411:INFO:[LightGBM] [Info] Total Bins 255
2025-03-29 15:39:07,411:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 1
2025-03-29 15:39:07,411:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:07,491:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:39:07,491:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,491:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,491:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:07,491:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:07,492:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:07,570:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:39:07,570:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,570:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,570:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:07,570:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:07,570:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:07,648:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:07,648:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,648:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,648:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:07,648:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:07,648:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:07,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:39:07,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,721:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,721:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:07,721:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:07,721:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:07,793:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:39:07,793:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,793:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,793:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:07,794:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:07,794:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:07,869:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:39:07,870:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,870:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,870:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:07,870:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:07,870:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:07,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:07,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:07,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:07,944:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:07,944:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:07,945:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:08,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,003:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:08,004:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:08,004:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:08,057:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,057:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,057:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:08,057:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:08,057:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:39:08,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,108:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:08,108:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:08,109:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:08,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,162:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:08,162:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:08,162:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:39:08,215:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,215:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,215:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:08,215:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:08,215:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,267:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:39:08,267:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,267:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,267:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:08,267:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:08,267:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:39:08,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,319:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,319:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:39:08,319:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:39:08,320:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,371:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:39:08,371:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,371:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,371:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:39:08,371:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:39:08,371:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:39:08,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,424:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:08,424:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:39:08,424:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:39:08,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,478:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:08,478:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:39:08,478:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,536:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-03-29 15:39:08,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,537:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,537:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:08,537:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:39:08,537:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,593:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:39:08,594:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,594:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,594:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:08,594:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:39:08,594:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-29 15:39:08,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,654:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:08,654:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:39:08,654:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,712:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:08,712:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,712:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,712:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:08,713:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:39:08,713:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000129 seconds.
2025-03-29 15:39:08,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,769:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,769:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:08,769:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:39:08,769:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,819:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-03-29 15:39:08,819:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,820:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,820:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:08,820:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-29 15:39:08,820:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.
2025-03-29 15:39:08,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,874:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:08,874:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-29 15:39:08,874:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.
2025-03-29 15:39:08,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,930:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:08,930:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-29 15:39:08,930:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:08,976:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000048 seconds.
2025-03-29 15:39:08,976:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:08,976:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:08,976:INFO:[LightGBM] [Info] Total Bins 300
2025-03-29 15:39:08,976:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-29 15:39:08,976:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:09,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:39:09,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,033:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,033:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,093:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:09,093:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,093:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,093:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,093:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,094:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.
2025-03-29 15:39:09,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,154:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,154:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:09,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,213:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,213:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,213:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:39:09,268:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,268:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,268:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,268:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,269:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:39:09,324:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,324:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,324:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,324:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,324:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:39:09,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,379:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,379:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,379:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:39:09,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,436:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,436:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,436:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,490:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:09,490:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,490:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,490:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,490:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,491:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,545:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:09,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,546:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,546:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,546:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,546:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,599:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:09,599:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,599:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,599:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,599:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,599:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:39:09,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,655:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,655:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,655:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,655:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:39:09,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,708:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:09,708:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:09,708:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:39:09,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,760:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:39:09,760:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:39:09,760:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,812:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:39:09,812:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,812:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,813:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:09,813:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:39:09,813:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,867:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:39:09,867:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,867:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,867:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:09,867:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:39:09,867:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,920:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.
2025-03-29 15:39:09,921:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,921:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,921:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:09,921:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:39:09,921:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:09,972:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.
2025-03-29 15:39:09,972:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:09,972:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:09,972:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:09,972:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:39:09,972:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:10,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-29 15:39:10,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,025:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,025:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:10,025:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:39:10,025:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:10,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.
2025-03-29 15:39:10,075:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,075:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,076:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:10,076:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:39:10,076:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:10,126:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:39:10,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,126:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:10,126:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:39:10,127:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:10,177:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.
2025-03-29 15:39:10,178:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,178:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,178:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:10,178:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:39:10,178:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:10,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.
2025-03-29 15:39:10,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,238:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:10,238:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-29 15:39:10,238:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:10,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.
2025-03-29 15:39:10,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,290:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:10,290:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-29 15:39:10,290:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:10,344:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.
2025-03-29 15:39:10,344:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,344:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,344:INFO:[LightGBM] [Info] Total Bins 531
2025-03-29 15:39:10,344:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-29 15:39:10,345:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:10,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.
2025-03-29 15:39:10,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,393:INFO:[LightGBM] [Info] Total Bins 300
2025-03-29 15:39:10,393:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 2
2025-03-29 15:39:10,393:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:10,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:10,456:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,456:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,456:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:10,456:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:10,456:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:10,514:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-03-29 15:39:10,514:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,514:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,514:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:10,514:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:10,515:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:10,571:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:10,571:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,571:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,571:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:10,571:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:10,572:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:10,628:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:10,628:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,628:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,628:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:10,628:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:10,628:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:10,684:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:39:10,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,684:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:10,684:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:10,684:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:10,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:39:10,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,736:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:10,736:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:10,736:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:10,790:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:10,790:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,790:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,790:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:10,790:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:10,790:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:10,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:39:10,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,843:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:10,843:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:10,843:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:10,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:39:10,899:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,899:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:10,899:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:10,899:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:10,953:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:10,953:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:10,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:10,953:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:10,953:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:10,953:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:11,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,007:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:11,007:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:11,007:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,062:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:11,062:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,062:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,063:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:11,063:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:11,063:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:39:11,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,117:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:11,117:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:11,117:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,169:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:11,169:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,169:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,169:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:11,169:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:11,169:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,220:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:39:11,220:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,220:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,220:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:11,220:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:11,220:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:39:11,271:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,271:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,271:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:11,271:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:11,271:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.
2025-03-29 15:39:11,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,323:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:11,323:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:11,324:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:39:11,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,375:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:11,375:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:11,375:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-03-29 15:39:11,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,425:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:11,425:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:11,425:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,476:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:11,476:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,476:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,476:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:11,476:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:11,476:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,528:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:39:11,528:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,528:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,528:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:11,529:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:11,529:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000124 seconds.
2025-03-29 15:39:11,580:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,580:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,580:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:11,580:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:11,580:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,628:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:39:11,628:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,628:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,628:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:11,628:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:11,629:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.
2025-03-29 15:39:11,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,678:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:11,678:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:11,678:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.
2025-03-29 15:39:11,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,728:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:11,728:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:11,728:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.
2025-03-29 15:39:11,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,772:INFO:[LightGBM] [Info] Total Bins 301
2025-03-29 15:39:11,772:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:11,772:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:11,825:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:39:11,825:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,826:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,826:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:11,826:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:11,826:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:11,880:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:39:11,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,880:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:11,880:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:11,881:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:11,936:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:39:11,936:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,936:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,936:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:11,936:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:11,936:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:11,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:39:11,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:11,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:11,990:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:11,990:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:11,990:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,046:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:39:12,046:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,046:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,046:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:12,046:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:12,046:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.
2025-03-29 15:39:12,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,102:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:12,102:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:12,102:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:39:12,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,190:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:12,190:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:12,190:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,244:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:39:12,244:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,244:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,244:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:12,244:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:12,244:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:39:12,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,302:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:12,302:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:12,302:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,354:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:12,354:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,354:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,354:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:12,354:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:12,354:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,405:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:39:12,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,405:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:12,405:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:12,405:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,458:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:39:12,459:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,459:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,459:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:12,459:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:12,459:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:39:12,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,512:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:12,512:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:12,512:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,566:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:39:12,566:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,566:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,566:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:12,566:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:12,566:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,619:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:39:12,619:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,619:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,619:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:12,619:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:12,619:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,675:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:39:12,675:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,675:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:12,676:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:12,676:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:39:12,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,727:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:12,727:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:12,727:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,777:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:39:12,777:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,777:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:12,777:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:12,778:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,828:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:39:12,828:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,828:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,828:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:12,828:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:12,829:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,881:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-03-29 15:39:12,881:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,881:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,881:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:12,881:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:12,881:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.
2025-03-29 15:39:12,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,931:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,931:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:12,931:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:12,931:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:12,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.
2025-03-29 15:39:12,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:12,980:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:12,980:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:12,980:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:12,980:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:13,029:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:39:13,029:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,029:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,029:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:13,030:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:13,030:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:13,077:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000067 seconds.
2025-03-29 15:39:13,077:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,077:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,077:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:13,077:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:13,077:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:13,140:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.
2025-03-29 15:39:13,140:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,140:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,140:INFO:[LightGBM] [Info] Total Bins 526
2025-03-29 15:39:13,140:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:13,140:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:13,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000058 seconds.
2025-03-29 15:39:13,209:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,209:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,209:INFO:[LightGBM] [Info] Total Bins 298
2025-03-29 15:39:13,209:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:13,210:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:13,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000444 seconds.
2025-03-29 15:39:13,271:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,271:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,271:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,271:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,271:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,327:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:39:13,327:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,327:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,327:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,327:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,327:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,383:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:13,383:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,383:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,383:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,383:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,384:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:39:13,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,440:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,440:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,440:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:13,494:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,494:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,494:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,494:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,494:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,548:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:39:13,548:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,548:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,548:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,548:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,548:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:13,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,603:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,604:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,658:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:39:13,658:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,658:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,658:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,658:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,658:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,712:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:13,712:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,712:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,712:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,712:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,712:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,767:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-29 15:39:13,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,767:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,767:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,767:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,768:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,821:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:39:13,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,821:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,821:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,821:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.
2025-03-29 15:39:13,875:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,875:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,875:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,875:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,875:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:13,929:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:39:13,929:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:13,929:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:13,929:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:13,930:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:13,930:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:14,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,012:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:14,012:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:14,012:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,066:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:39:14,067:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,067:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,067:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:14,067:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:14,067:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,119:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2025-03-29 15:39:14,119:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,119:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,119:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:14,119:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:14,119:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,170:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:39:14,170:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,170:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,170:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:14,170:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:14,170:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:39:14,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,263:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:14,263:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:14,263:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-03-29 15:39:14,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,315:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:14,315:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:14,315:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,385:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.
2025-03-29 15:39:14,385:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,385:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,385:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:14,385:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:14,386:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,465:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:39:14,465:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,465:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,465:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:14,465:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:14,466:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:39:14,515:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,515:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,516:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:14,516:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:14,516:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,564:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000453 seconds.
2025-03-29 15:39:14,564:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,564:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,564:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:14,564:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:14,564:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,611:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000066 seconds.
2025-03-29 15:39:14,611:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,611:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,611:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:14,611:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:14,611:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,663:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.
2025-03-29 15:39:14,663:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,663:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,663:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:14,663:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:14,663:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.
2025-03-29 15:39:14,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,708:INFO:[LightGBM] [Info] Total Bins 299
2025-03-29 15:39:14,708:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:14,708:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:14,761:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:14,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,761:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:14,761:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:14,761:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:14,817:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:39:14,817:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,817:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,817:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:14,817:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:14,817:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:14,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.
2025-03-29 15:39:14,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,872:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:14,872:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:14,872:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:14,925:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:14,925:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,925:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,926:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:14,926:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:14,926:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:14,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.
2025-03-29 15:39:14,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:14,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:14,981:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:14,981:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:14,981:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,036:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.
2025-03-29 15:39:15,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,036:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:15,036:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:15,036:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,088:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.
2025-03-29 15:39:15,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,088:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:15,088:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:15,088:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:15,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,141:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:15,141:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:15,141:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:39:15,209:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,209:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,209:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:15,209:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:15,209:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,265:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:39:15,265:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,265:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,266:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:15,266:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:15,266:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.
2025-03-29 15:39:15,321:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,321:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:15,321:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:15,321:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.
2025-03-29 15:39:15,374:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,374:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,374:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:15,375:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:15,375:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:39:15,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,436:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:15,436:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:15,436:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.
2025-03-29 15:39:15,495:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,496:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:15,496:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:15,496:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,556:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:39:15,556:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,556:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,556:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:15,556:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:15,556:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:39:15,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,617:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:15,617:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:15,617:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.
2025-03-29 15:39:15,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,674:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,675:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:15,675:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:15,675:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,733:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:39:15,733:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,733:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,733:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:15,733:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:15,733:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,791:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-03-29 15:39:15,791:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,792:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:15,792:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:15,792:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,845:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:39:15,846:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,846:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,846:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:15,846:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:15,846:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,897:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000453 seconds.
2025-03-29 15:39:15,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,898:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:15,898:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:15,898:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:15,949:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.
2025-03-29 15:39:15,949:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:15,949:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:15,949:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:15,949:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:15,949:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:16,001:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.
2025-03-29 15:39:16,001:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,001:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:16,001:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:16,001:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:16,051:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.
2025-03-29 15:39:16,051:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,051:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,051:INFO:[LightGBM] [Info] Total Bins 531
2025-03-29 15:39:16,051:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:16,051:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:16,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-03-29 15:39:16,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,103:INFO:[LightGBM] [Info] Total Bins 529
2025-03-29 15:39:16,103:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:16,103:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:16,145:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.
2025-03-29 15:39:16,145:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,145:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,145:INFO:[LightGBM] [Info] Total Bins 299
2025-03-29 15:39:16,145:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:16,146:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:16,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:16,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,201:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,201:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-03-29 15:39:16,258:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,259:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,259:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,259:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,344:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
2025-03-29 15:39:16,344:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,344:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,344:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,344:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,344:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,422:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:39:16,422:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,422:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,422:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,422:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,423:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:39:16,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,481:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,481:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,481:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:39:16,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,544:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,544:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,544:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,600:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:39:16,601:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,601:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,601:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,601:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,601:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:39:16,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,655:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,655:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,655:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:39:16,706:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,706:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,706:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,706:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,706:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,759:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:39:16,759:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,759:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,759:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,759:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,760:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,813:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000797 seconds.
2025-03-29 15:39:16,813:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:39:16,813:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,813:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,813:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:16,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,876:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,876:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,876:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,929:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:16,929:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,929:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,929:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:16,929:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:16,930:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:16,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:39:16,982:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:16,982:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:16,982:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:16,982:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:16,982:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,035:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:39:17,035:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,035:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,035:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:17,035:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:17,035:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,085:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.
2025-03-29 15:39:17,085:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,085:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,085:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:17,085:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:17,086:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,135:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.
2025-03-29 15:39:17,135:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,135:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,135:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:17,135:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:17,135:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:39:17,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,187:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:17,187:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:17,187:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:39:17,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,238:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:17,238:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:17,238:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2025-03-29 15:39:17,293:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,293:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:17,293:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:17,294:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:17,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,346:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:17,346:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:17,347:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000112 seconds.
2025-03-29 15:39:17,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,397:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:17,397:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:17,397:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-03-29 15:39:17,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,451:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:17,451:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:17,451:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.
2025-03-29 15:39:17,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,497:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:17,497:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:17,497:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.
2025-03-29 15:39:17,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,547:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:17,547:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:17,547:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,590:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.
2025-03-29 15:39:17,590:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,590:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,590:INFO:[LightGBM] [Info] Total Bins 298
2025-03-29 15:39:17,591:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:17,591:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:17,646:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000977 seconds.
2025-03-29 15:39:17,647:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:39:17,647:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:17,647:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:17,647:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:17,709:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:39:17,709:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,709:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,709:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:17,709:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:17,709:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:17,765:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:39:17,765:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,765:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,765:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:17,765:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:17,765:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:17,819:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:39:17,819:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,819:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,819:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:17,819:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:17,819:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:17,870:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:39:17,870:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,871:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:17,871:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:17,871:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:17,922:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:39:17,922:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,922:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,922:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:17,922:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:17,922:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:17,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:39:17,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:17,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:17,974:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:17,974:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:17,974:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:18,026:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,026:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,026:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:18,026:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:18,026:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,078:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:39:18,078:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,078:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,078:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:18,078:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:18,078:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000590 seconds.
2025-03-29 15:39:18,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,131:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:18,131:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:18,131:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,183:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:39:18,183:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,183:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,183:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:18,183:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:18,183:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:39:18,236:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,236:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,236:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:18,236:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:18,237:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:18,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,290:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:18,290:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:18,290:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,345:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:39:18,345:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,345:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,346:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:18,346:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:18,346:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,400:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.
2025-03-29 15:39:18,400:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,400:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,400:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:18,400:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:18,400:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:39:18,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,455:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:18,455:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:18,455:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:39:18,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,505:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:18,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:18,506:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,560:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:39:18,560:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,560:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:18,560:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:18,560:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,611:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:18,611:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,611:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,611:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:18,611:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:18,611:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,663:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.
2025-03-29 15:39:18,663:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,663:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,664:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:18,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:18,664:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.
2025-03-29 15:39:18,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,714:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:18,714:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:18,714:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,768:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000131 seconds.
2025-03-29 15:39:18,768:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,768:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,768:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:18,768:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:18,768:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,819:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:39:18,819:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,819:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,819:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:18,819:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:18,819:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,875:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.
2025-03-29 15:39:18,875:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,875:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,875:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:18,875:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:18,875:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.
2025-03-29 15:39:18,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,927:INFO:[LightGBM] [Info] Total Bins 531
2025-03-29 15:39:18,927:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:18,927:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:18,975:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.
2025-03-29 15:39:18,975:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:18,975:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:18,975:INFO:[LightGBM] [Info] Total Bins 301
2025-03-29 15:39:18,975:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:18,975:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:19,037:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:39:19,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,037:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,037:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,038:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,096:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:19,096:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,096:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,096:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,096:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,096:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:39:19,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,155:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,155:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,155:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:19,215:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,215:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,215:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,215:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,215:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:19,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,274:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,274:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,275:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,335:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:39:19,336:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,336:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,336:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,336:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,336:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,395:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:39:19,395:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,395:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,395:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,395:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,396:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,458:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:19,458:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,458:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,458:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,458:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,458:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:39:19,515:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,515:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,515:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,515:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,515:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:39:19,573:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,573:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,573:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,573:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,573:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,631:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-29 15:39:19,631:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,631:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,631:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,631:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,631:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,690:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:39:19,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,690:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,690:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,690:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,747:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:39:19,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,747:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:19,747:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:19,747:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,803:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:39:19,803:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,803:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,803:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:39:19,803:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:19,803:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,861:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:39:19,861:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,861:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,861:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:19,861:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:19,861:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,913:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:39:19,913:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,913:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,913:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:19,913:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:19,913:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:19,966:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:39:19,966:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:19,966:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:19,966:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:19,966:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:19,967:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:20,018:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:39:20,018:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,018:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:20,018:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:20,018:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:20,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.
2025-03-29 15:39:20,071:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,071:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,071:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:20,071:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:20,071:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:20,123:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:39:20,123:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,123:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,123:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:20,123:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:20,123:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:20,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:39:20,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,176:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:20,176:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:20,176:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:20,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.
2025-03-29 15:39:20,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,237:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:20,238:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:20,238:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:20,286:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:39:20,287:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,287:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,287:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:20,287:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:20,287:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:20,335:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000066 seconds.
2025-03-29 15:39:20,335:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,335:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,335:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:20,335:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:20,335:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:20,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.
2025-03-29 15:39:20,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,381:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,381:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:20,381:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:20,381:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:20,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000053 seconds.
2025-03-29 15:39:20,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,425:INFO:[LightGBM] [Info] Total Bins 299
2025-03-29 15:39:20,425:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:20,426:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:20,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:39:20,486:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,486:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,486:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:20,486:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:20,486:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:20,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:39:20,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,542:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:20,543:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:20,543:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:20,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:39:20,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,627:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:20,627:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:20,627:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:20,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:39:20,689:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,689:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,689:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:20,689:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:20,689:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:20,743:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:39:20,743:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,743:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,743:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:20,743:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:20,743:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:20,796:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:39:20,796:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,796:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,796:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:20,796:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:20,796:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:20,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:39:20,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,850:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:20,850:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:20,850:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:20,903:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:39:20,903:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,903:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,903:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:20,903:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:20,903:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:20,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:39:20,954:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:20,954:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:20,954:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:20,954:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:20,954:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,005:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:21,005:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,005:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,005:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:21,005:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:21,005:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,057:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:39:21,057:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,057:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,057:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:21,057:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:21,057:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:39:21,110:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,110:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:21,110:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:21,110:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-03-29 15:39:21,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,162:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:21,162:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:21,163:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:39:21,215:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,215:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,215:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:39:21,215:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:21,215:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,266:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:39:21,266:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,266:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,266:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:39:21,266:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:21,267:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,317:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-03-29 15:39:21,318:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,318:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,318:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:21,318:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:21,318:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,368:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:39:21,368:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,368:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,368:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:21,368:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:21,368:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:39:21,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,418:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:21,418:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:21,418:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,468:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-03-29 15:39:21,468:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,468:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,468:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:21,468:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:21,468:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,519:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:39:21,519:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,519:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:21,519:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:21,519:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,568:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.
2025-03-29 15:39:21,568:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,568:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,568:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:21,568:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:21,568:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,616:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.
2025-03-29 15:39:21,616:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,617:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:21,617:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:21,617:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,666:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:39:21,666:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,666:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,667:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:21,667:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:21,667:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,713:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.
2025-03-29 15:39:21,713:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,713:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,713:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:21,713:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:21,713:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.
2025-03-29 15:39:21,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,760:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:21,760:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:21,760:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,804:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000057 seconds.
2025-03-29 15:39:21,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,804:INFO:[LightGBM] [Info] Total Bins 300
2025-03-29 15:39:21,804:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 2
2025-03-29 15:39:21,804:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:21,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:39:21,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,860:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:21,860:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:21,860:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:21,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:39:21,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,915:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,915:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:21,915:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:21,915:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:21,969:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:39:21,969:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:21,969:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:21,969:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:21,969:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:21,969:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:22,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,023:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:22,023:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:22,023:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:22,075:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,075:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,075:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:22,075:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:22,075:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:22,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,131:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:22,131:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:22,131:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:39:22,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,187:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:22,187:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:22,187:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:39:22,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,240:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:22,240:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:22,240:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:22,296:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,296:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,296:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:22,296:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:22,296:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,375:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:39:22,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,375:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:22,376:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:22,376:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,427:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:39:22,427:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,427:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,427:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:22,427:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:22,427:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:39:22,482:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,482:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:22,482:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:22,482:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,536:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:39:22,536:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,536:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,536:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:22,537:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:22,537:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,587:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.
2025-03-29 15:39:22,587:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,587:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,587:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:39:22,587:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:39:22,587:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:39:22,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,637:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:39:22,637:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:39:22,637:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.
2025-03-29 15:39:22,706:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,706:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,706:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:22,706:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:39:22,706:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,777:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000458 seconds.
2025-03-29 15:39:22,777:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,777:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:22,777:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:39:22,778:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,848:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2025-03-29 15:39:22,848:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,848:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,848:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:22,848:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:39:22,849:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:22,918:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,918:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:22,919:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:39:22,919:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:22,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.
2025-03-29 15:39:22,988:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:22,988:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:22,988:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:22,988:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:39:22,988:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:23,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:39:23,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,061:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:23,061:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:39:23,061:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:23,128:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000129 seconds.
2025-03-29 15:39:23,128:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,128:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,128:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:23,128:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:39:23,129:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:23,197:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:39:23,197:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,197:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,197:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:23,197:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-29 15:39:23,197:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:23,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.
2025-03-29 15:39:23,264:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,264:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:23,264:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-29 15:39:23,264:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:23,331:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.
2025-03-29 15:39:23,331:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,331:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,331:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:23,331:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-29 15:39:23,331:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:23,411:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:39:23,411:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,411:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,411:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:23,411:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:23,411:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:23,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:39:23,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,485:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,485:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:23,485:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:23,485:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:23,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:39:23,572:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,572:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:23,572:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:23,573:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:23,662:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:23,662:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,662:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,662:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:23,662:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:23,663:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:23,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-29 15:39:23,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,749:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:23,749:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:23,750:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:23,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:39:23,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,838:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:23,838:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:23,838:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:23,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:39:23,926:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:23,926:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:23,927:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:23,927:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:23,927:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,008:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:39:24,008:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,008:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,008:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:24,008:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:24,008:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:24,073:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,073:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,073:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:24,073:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:24,073:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:39:24,125:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,125:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,125:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:24,125:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:24,125:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,180:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000705 seconds.
2025-03-29 15:39:24,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,180:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:24,180:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:24,181:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,233:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:39:24,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,233:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,233:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:24,233:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:24,233:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:24,287:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,287:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,287:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:24,287:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:24,287:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:39:24,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,338:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:39:24,338:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:39:24,338:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,388:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:39:24,389:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,389:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,389:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:24,389:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:39:24,389:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:39:24,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,439:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:24,439:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:39:24,439:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:39:24,489:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,489:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,489:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:24,489:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:39:24,489:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:24,540:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,540:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,540:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:24,540:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:39:24,541:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:39:24,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,592:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:24,593:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:39:24,593:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:39:24,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,644:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:24,644:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:39:24,644:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,696:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.
2025-03-29 15:39:24,696:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,696:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,696:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:24,696:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:39:24,697:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.
2025-03-29 15:39:24,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,746:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,746:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:24,746:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:39:24,746:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,794:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:39:24,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,794:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:24,794:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-29 15:39:24,794:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.
2025-03-29 15:39:24,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,841:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,841:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:24,841:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-29 15:39:24,842:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,886:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.
2025-03-29 15:39:24,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,886:INFO:[LightGBM] [Info] Total Bins 531
2025-03-29 15:39:24,886:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 3
2025-03-29 15:39:24,886:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:24,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:24,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,940:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:24,940:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:24,941:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:24,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:24,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:24,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:24,994:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:24,994:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:24,994:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,052:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:39:25,052:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,052:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,052:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,052:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,052:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,105:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:39:25,105:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,105:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,105:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,105:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,105:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,158:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:39:25,158:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,158:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,158:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,158:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,158:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,225:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:39:25,225:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,225:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,225:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,225:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,225:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,280:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:39:25,280:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,280:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,280:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,280:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,280:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:39:25,337:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,337:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,337:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,337:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,337:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,389:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:25,389:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,389:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,389:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,389:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,389:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:39:25,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,442:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,442:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,442:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:39:25,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,496:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,496:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,496:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,552:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-03-29 15:39:25,552:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,552:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,552:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,552:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,552:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:39:25,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,604:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:25,604:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:25,604:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,657:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:25,657:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,657:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,657:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:25,657:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:25,657:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,708:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:39:25,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,708:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:25,708:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:25,708:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:39:25,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,760:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:25,760:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:25,760:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:39:25,811:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,811:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,811:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:25,811:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:25,811:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:39:25,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,862:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:25,862:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:25,862:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:39:25,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,911:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:25,912:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:25,912:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:25,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:39:25,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:25,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:25,962:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:25,962:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:25,962:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:26,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:39:26,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,012:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:26,012:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:26,012:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:26,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.
2025-03-29 15:39:26,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,063:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:26,063:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:26,063:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:26,110:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:39:26,111:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,111:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,111:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:26,111:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:26,111:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:26,158:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000066 seconds.
2025-03-29 15:39:26,158:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,158:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,158:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:26,158:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:26,158:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:26,203:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-03-29 15:39:26,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,203:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:26,203:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:26,203:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:26,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:39:26,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,257:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,257:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,258:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,312:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:39:26,312:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,312:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,312:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,312:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,312:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,368:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:39:26,368:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,368:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,368:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,368:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,368:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,427:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:26,427:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,428:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,428:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,428:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,428:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:26,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,487:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,487:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,488:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:39:26,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,542:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,542:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,543:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:26,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,609:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,609:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,609:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-03-29 15:39:26,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,664:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,664:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,718:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:39:26,718:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,718:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,718:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,718:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,718:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:26,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,769:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,769:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,769:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,769:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,820:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:39:26,820:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,820:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,820:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,820:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,820:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:39:26,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,872:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,872:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,872:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,922:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:26,922:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,922:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,922:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:26,922:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:26,922:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:26,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-29 15:39:26,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:26,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:26,973:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:26,973:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:26,973:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:39:27,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,024:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:27,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:27,024:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,074:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:39:27,074:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,075:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,075:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:27,075:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:27,075:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,124:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:39:27,125:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,125:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,125:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:27,125:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:27,125:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:39:27,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,176:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:27,176:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:27,176:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,227:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:27,227:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,227:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,227:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:27,227:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:27,227:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,279:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:39:27,279:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,280:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:27,280:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:27,280:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,330:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.
2025-03-29 15:39:27,330:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,330:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,330:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:27,330:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:27,330:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,379:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-03-29 15:39:27,379:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,379:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,379:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:27,379:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:27,379:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,427:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:39:27,427:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,427:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,427:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:27,427:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:27,427:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.
2025-03-29 15:39:27,475:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,475:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,475:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:27,475:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:27,475:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,520:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.
2025-03-29 15:39:27,520:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,520:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,520:INFO:[LightGBM] [Info] Total Bins 526
2025-03-29 15:39:27,520:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:27,520:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:27,583:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:39:27,583:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,583:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,583:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:27,583:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:27,583:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:27,636:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:27,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,637:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:27,637:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:27,637:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:27,689:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:39:27,689:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,689:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,689:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:27,690:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:27,690:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:27,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:27,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,744:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,744:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:27,745:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:27,745:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:27,798:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.
2025-03-29 15:39:27,798:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,798:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,798:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:27,798:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:27,798:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:27,852:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:39:27,852:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,852:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,852:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:27,852:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:27,853:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:27,905:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:27,905:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,905:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,905:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:27,906:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:27,906:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:27,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:39:27,957:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:27,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:27,957:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:27,958:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:27,958:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,009:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:39:28,009:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,009:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,009:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:28,009:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:28,009:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:28,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,063:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:28,063:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:28,064:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:39:28,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,116:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:28,116:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:28,116:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,169:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:28,169:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,169:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,169:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:28,169:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:28,169:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,220:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:39:28,220:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,220:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,220:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:28,220:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:28,220:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2025-03-29 15:39:28,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,270:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:28,270:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:28,270:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,320:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:39:28,320:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,320:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,321:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:28,321:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:28,321:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,371:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:39:28,371:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,371:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,371:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:28,371:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:28,371:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,419:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:39:28,419:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,419:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,420:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:28,420:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:28,420:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,469:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:39:28,469:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,469:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,469:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:28,469:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:28,469:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,517:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-03-29 15:39:28,517:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,517:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,517:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:28,517:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:28,518:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:39:28,570:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,570:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,570:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:28,570:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:28,570:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,619:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:39:28,619:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,619:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,619:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:28,619:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:28,619:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,669:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:39:28,669:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,669:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,669:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:28,669:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:28,669:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,716:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:39:28,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,716:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:28,716:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:28,716:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,762:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000065 seconds.
2025-03-29 15:39:28,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,762:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,762:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:28,763:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:28,763:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,808:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.
2025-03-29 15:39:28,808:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,808:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,808:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:28,808:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:28,808:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:28,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:39:28,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,862:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:28,862:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:28,862:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:28,917:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:39:28,917:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,917:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,917:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:28,917:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:28,917:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:28,970:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:39:28,970:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:28,970:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:28,970:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:28,970:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:28,970:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:39:29,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,023:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,023:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,023:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:39:29,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,076:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,076:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,076:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,129:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:39:29,129:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,129:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,129:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,129:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,129:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,183:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:39:29,183:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,183:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,183:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,183:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,183:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2025-03-29 15:39:29,236:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,236:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,236:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,236:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,236:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2025-03-29 15:39:29,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,288:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,288:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,288:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,340:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:39:29,340:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,340:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,340:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,340:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,340:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,391:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:39:29,391:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,391:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,391:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,391:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,391:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000287 seconds.
2025-03-29 15:39:29,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,443:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,443:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,443:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,494:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:39:29,494:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,494:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,494:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,495:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,495:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,546:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:39:29,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,546:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,546:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:29,546:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:29,547:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,601:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:39:29,601:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,601:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,601:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:29,601:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:29,601:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:39:29,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,652:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:29,652:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:29,652:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,701:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:39:29,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,701:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:29,701:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:29,701:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.
2025-03-29 15:39:29,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,751:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,751:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:29,751:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:29,751:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,802:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:29,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,802:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:29,802:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:29,802:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,851:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:29,851:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,851:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,851:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:29,851:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:29,851:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.
2025-03-29 15:39:29,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,901:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:29,901:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:29,901:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,950:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.
2025-03-29 15:39:29,950:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,950:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,950:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:29,950:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:29,950:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:29,998:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000767 seconds.
2025-03-29 15:39:29,998:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:29,998:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:29,998:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:29,998:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:29,998:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:30,046:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000072 seconds.
2025-03-29 15:39:30,046:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,046:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,046:INFO:[LightGBM] [Info] Total Bins 531
2025-03-29 15:39:30,046:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:30,046:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:30,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-03-29 15:39:30,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,092:INFO:[LightGBM] [Info] Total Bins 529
2025-03-29 15:39:30,092:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:30,092:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:30,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:30,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,146:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,146:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,146:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:39:30,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,214:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,214:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,214:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:30,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,270:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,270:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,271:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:39:30,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,324:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,324:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,324:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:30,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,377:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,377:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,377:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,378:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,433:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2025-03-29 15:39:30,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,433:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,433:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,434:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,434:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:39:30,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,487:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,487:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,487:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:39:30,540:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,540:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,540:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,540:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,540:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,598:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.
2025-03-29 15:39:30,598:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,598:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,598:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,598:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,598:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:39:30,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,652:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,652:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,653:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:30,704:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,704:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,704:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,704:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,704:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:30,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,755:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,755:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,755:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:39:30,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,806:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:30,806:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:30,806:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,856:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:30,856:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,856:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,856:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:30,856:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:30,856:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,906:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:39:30,906:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,906:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:30,906:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:30,906:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:30,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.
2025-03-29 15:39:30,957:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:30,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:30,957:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:30,957:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:30,957:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:31,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:39:31,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,007:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:31,007:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:31,007:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:31,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:39:31,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,056:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:31,056:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:31,056:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:31,105:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:39:31,105:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,105:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,105:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:31,105:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:31,105:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:31,153:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:31,153:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,153:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,153:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:31,153:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:31,153:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:31,203:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:31,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,203:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:31,203:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:31,203:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:31,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000134 seconds.
2025-03-29 15:39:31,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,250:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:31,250:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:31,251:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:31,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:39:31,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,297:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:31,297:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:31,297:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:31,344:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000067 seconds.
2025-03-29 15:39:31,344:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,344:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,344:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:31,344:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:31,344:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:31,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.
2025-03-29 15:39:31,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,392:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:31,392:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:31,392:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:31,446:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:31,446:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,446:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,446:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,446:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,447:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:31,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:39:31,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,502:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,502:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,502:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:31,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:39:31,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,554:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,555:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:31,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:31,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,609:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,609:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,609:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:31,663:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:39:31,663:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,663:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,663:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,664:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:31,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:39:31,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,717:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,717:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,717:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:31,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:31,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,770:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,770:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,770:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:31,822:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:39:31,822:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,822:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,822:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,822:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,822:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:31,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:39:31,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,873:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,873:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,873:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:31,924:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:39:31,924:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,924:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,924:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,924:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,924:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:31,975:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:39:31,975:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:31,975:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:31,975:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:31,975:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:31,975:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:39:32,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,027:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:32,027:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:32,027:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,078:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:39:32,079:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,079:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,079:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:32,079:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:32,079:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:39:32,132:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,132:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:32,132:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:32,132:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:39:32,186:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,186:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,186:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:32,186:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:32,186:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-29 15:39:32,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,237:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:32,237:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:32,237:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:39:32,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,288:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:32,288:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:32,288:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:39:32,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,338:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:32,338:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:32,338:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,386:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:39:32,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,386:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:32,386:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:32,386:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:39:32,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,436:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:32,436:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:32,436:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.
2025-03-29 15:39:32,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,485:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,485:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:32,485:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:32,510:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.
2025-03-29 15:39:32,569:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,569:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,569:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:32,569:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:32,569:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,619:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.
2025-03-29 15:39:32,619:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,619:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,619:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:32,619:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:32,619:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,668:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.
2025-03-29 15:39:32,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,668:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,668:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:32,668:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:32,669:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.
2025-03-29 15:39:32,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,715:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,715:INFO:[LightGBM] [Info] Total Bins 531
2025-03-29 15:39:32,715:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:32,715:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:32,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:32,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,772:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:32,772:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:32,772:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:32,828:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:39:32,829:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,829:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,829:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:32,829:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:32,829:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:32,885:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:39:32,885:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,885:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,885:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:32,885:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:32,885:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:32,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.
2025-03-29 15:39:32,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:32,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:32,940:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:32,940:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:32,940:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,002:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:39:33,002:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,002:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,002:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:33,002:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:33,002:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:39:33,062:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,062:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,062:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:33,062:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:33,062:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:39:33,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,126:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:33,126:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:33,126:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,184:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:33,184:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,184:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,184:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:33,184:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:33,184:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,243:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-29 15:39:33,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,243:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,243:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:33,243:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:33,243:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:39:33,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,302:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:33,302:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:33,302:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:39:33,360:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,360:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:33,360:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:33,361:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,414:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.
2025-03-29 15:39:33,414:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,414:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,414:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:33,415:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:33,415:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,469:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:39:33,469:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,469:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,469:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:33,469:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:33,469:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,524:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:39:33,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,525:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:39:33,525:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:33,525:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:39:33,580:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,580:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,580:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:33,580:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:33,580:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:39:33,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,638:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:33,638:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:33,638:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,691:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:33,691:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,691:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,691:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:33,691:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:33,692:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,742:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:39:33,743:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,743:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,743:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:33,743:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:33,743:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,794:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:39:33,795:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,795:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,795:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:33,795:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:33,795:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,846:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:39:33,846:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,846:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,846:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:33,846:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:33,846:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-03-29 15:39:33,899:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,899:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:33,899:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:33,899:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:33,950:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.
2025-03-29 15:39:33,950:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:33,950:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:33,950:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:33,950:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:33,951:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:34,001:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:39:34,001:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,002:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,002:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:34,002:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:34,002:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:34,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000080 seconds.
2025-03-29 15:39:34,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,048:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:34,048:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:34,048:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:34,096:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.
2025-03-29 15:39:34,096:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,096:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,096:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:34,096:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:34,096:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:34,152:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:39:34,152:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,152:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,153:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,153:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,153:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:34,209:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,209:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,209:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,209:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,210:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:39:34,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,263:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,263:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,263:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,316:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:39:34,316:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,316:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,316:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,316:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,316:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,369:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:39:34,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,370:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,370:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,370:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,422:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:39:34,422:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,422:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,423:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,423:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,423:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:34,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,474:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,474:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,475:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:39:34,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,526:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,526:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,526:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,589:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:39:34,589:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,589:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,590:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,590:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,590:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:39:34,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,641:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,641:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,641:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,692:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:34,692:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,692:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,692:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,692:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,693:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,745:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:39:34,745:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,745:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,745:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,745:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,745:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,797:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:39:34,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,797:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:34,797:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:34,797:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,852:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:39:34,852:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,852:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,852:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:39:34,852:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:34,852:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,902:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:39:34,902:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,902:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,902:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:39:34,902:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:34,902:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:34,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:34,953:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:34,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:34,953:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:34,953:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:34,953:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:35,002:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:39:35,002:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,002:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,003:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:35,003:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:35,003:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:35,052:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:39:35,053:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,053:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,053:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:35,053:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:35,053:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:35,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:39:35,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,102:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:35,102:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:35,103:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:35,152:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:39:35,152:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,152:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,152:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:35,152:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:35,152:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:35,205:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.
2025-03-29 15:39:35,205:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,205:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,205:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:35,205:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:35,205:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:35,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000126 seconds.
2025-03-29 15:39:35,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,254:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:35,254:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:35,255:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:35,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:39:35,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,303:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:35,303:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:35,303:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:35,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000080 seconds.
2025-03-29 15:39:35,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,351:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:35,351:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:35,352:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:35,399:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.
2025-03-29 15:39:35,399:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,399:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,399:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:35,399:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 3
2025-03-29 15:39:35,399:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:35,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:35,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,457:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:35,457:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:35,457:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:35,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:35,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,513:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:35,513:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:35,513:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:35,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:39:35,569:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,569:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,569:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:35,569:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:35,569:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:35,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:35,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,626:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:35,626:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:35,626:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:35,681:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.
2025-03-29 15:39:35,681:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,681:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,681:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:35,681:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:35,681:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:35,735:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:39:35,735:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,735:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,735:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:35,735:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:35,735:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:35,789:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:39:35,789:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,789:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,789:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:35,789:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:35,789:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:35,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:39:35,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,842:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:35,842:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:35,842:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:35,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:39:35,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,901:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:35,901:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:35,902:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:35,959:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:39:35,959:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:35,959:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:35,959:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:35,959:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:35,959:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,019:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:39:36,019:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,019:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,019:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:36,019:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:36,019:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,077:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:39:36,077:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,077:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,077:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:36,077:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:36,077:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.
2025-03-29 15:39:36,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,132:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:36,132:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:36,132:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:39:36,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,187:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:39:36,187:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:39:36,187:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,244:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:39:36,244:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,244:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,244:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:39:36,244:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:39:36,244:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,298:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:39:36,298:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,298:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,299:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:36,299:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:39:36,299:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,354:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.
2025-03-29 15:39:36,354:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,354:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,355:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:36,355:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:39:36,355:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,406:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:39:36,407:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,407:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,407:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:36,407:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:39:36,407:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,461:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:39:36,461:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,461:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,461:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:36,461:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:39:36,462:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:39:36,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,526:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:36,526:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:39:36,526:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-03-29 15:39:36,581:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,581:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,581:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:36,581:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:39:36,581:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000139 seconds.
2025-03-29 15:39:36,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,645:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:36,645:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:39:36,646:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,696:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:39:36,696:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,696:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,696:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:36,696:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-29 15:39:36,697:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,747:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.
2025-03-29 15:39:36,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,747:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:36,747:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-29 15:39:36,748:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:36,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:36,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,806:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:36,806:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:36,806:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:36,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:39:36,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,862:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:36,862:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:36,862:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:36,917:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:36,917:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,918:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:36,918:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:36,918:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:36,975:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:39:36,975:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:36,975:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:36,975:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:36,975:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:36,975:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,029:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:39:37,029:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,029:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,029:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:37,030:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:37,030:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,083:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:37,083:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,083:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,083:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:37,083:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:37,083:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,138:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:39:37,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,139:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:37,139:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:37,139:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,193:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:37,193:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,193:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,193:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:37,193:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:37,193:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,246:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:37,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,246:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:37,246:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:37,246:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,300:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:37,300:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,300:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,300:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:37,301:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:37,301:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,352:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:39:37,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,352:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:37,353:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:37,353:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,406:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:39:37,406:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,406:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,406:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:37,406:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:37,406:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,460:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:39:37,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,460:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,460:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:37,460:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:37,460:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:39:37,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,513:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:39:37,513:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:39:37,514:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,566:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:39:37,567:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,567:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,567:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:37,567:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:39:37,567:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,619:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:39:37,619:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,619:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,619:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:37,619:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:39:37,619:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,670:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:39:37,670:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,670:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,670:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:37,670:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:39:37,670:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:39:37,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,720:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:37,720:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:39:37,721:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:39:37,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,771:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:37,771:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:39:37,771:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,821:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:39:37,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,821:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:37,821:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:39:37,821:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:39:37,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,871:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:37,871:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:39:37,871:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.
2025-03-29 15:39:37,924:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,924:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,924:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:37,924:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:39:37,924:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:37,972:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
2025-03-29 15:39:37,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:37,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:37,973:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:37,973:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-29 15:39:37,973:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:38,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.
2025-03-29 15:39:38,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,027:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:38,027:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 4
2025-03-29 15:39:38,027:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:38,088:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:38,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,088:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,088:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,088:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,144:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:39:38,144:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,144:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,144:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,144:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,198:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:39:38,198:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,198:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,198:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,198:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,198:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,252:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:39:38,252:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,252:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,252:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,252:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,252:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:39:38,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,304:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,304:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,304:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,359:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:38,359:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,359:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,359:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,359:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,359:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,414:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:39:38,414:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,414:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,414:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,414:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,414:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,468:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:38,469:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,469:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,469:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,469:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,469:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,521:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000452 seconds.
2025-03-29 15:39:38,521:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,521:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,521:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,521:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,521:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,576:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:39:38,576:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,576:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,576:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,576:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,631:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.
2025-03-29 15:39:38,631:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,631:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,631:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,631:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,632:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,697:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-29 15:39:38,697:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,697:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,697:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,697:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:39:38,779:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,779:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,779:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:38,779:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:38,779:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,857:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:39:38,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,857:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:38,857:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:38,857:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:38,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
2025-03-29 15:39:38,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:38,931:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:38,931:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:38,931:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:38,931:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:39,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:39:39,004:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,005:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,005:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:39,005:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:39,005:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:39,080:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.
2025-03-29 15:39:39,080:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,080:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,080:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:39,080:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:39,081:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:39,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:39,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,154:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:39,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:39,154:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:39,223:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:39:39,223:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,223:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,223:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:39,223:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:39,223:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:39,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-03-29 15:39:39,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,303:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:39,303:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:39,303:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:39,380:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.
2025-03-29 15:39:39,380:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,380:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,380:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:39,380:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:39,381:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:39,456:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.
2025-03-29 15:39:39,456:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,456:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,456:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:39,457:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:39,457:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:39,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:39:39,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,526:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:39,526:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:39,526:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:39,595:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000075 seconds.
2025-03-29 15:39:39,595:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,595:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,595:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:39,595:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:39,596:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:39,675:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:39:39,675:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,676:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:39,676:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:39,676:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:39,753:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:39:39,753:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,754:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:39,754:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:39,754:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:39,833:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:39:39,833:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,834:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:39,834:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:39,834:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:39,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:39:39,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,919:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:39,919:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:39,919:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:39,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:39,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:39,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:39,990:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:39,990:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:39,990:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,049:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:39:40,050:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,050:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,050:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:40,050:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:40,050:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:39:40,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,100:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:40,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:40,100:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.
2025-03-29 15:39:40,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,148:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:40,148:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:40,149:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:39:40,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,210:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:40,210:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:40,210:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,261:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:39:40,261:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,261:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,261:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:40,262:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:40,262:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,313:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:40,313:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,313:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,313:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:40,313:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:40,313:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,366:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:39:40,367:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,367:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,367:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:40,367:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:40,367:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,418:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:39:40,418:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,418:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,418:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:40,418:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:40,418:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,468:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:39:40,468:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,469:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,469:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:40,469:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:40,469:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,522:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:39:40,522:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,522:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,522:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:40,522:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:40,522:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,574:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:39:40,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,574:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:40,574:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:40,574:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:39:40,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,628:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,628:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:40,628:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:40,628:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:39:40,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,678:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:40,678:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:40,678:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.
2025-03-29 15:39:40,727:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,727:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:40,727:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:40,727:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,774:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:39:40,774:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,774:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,774:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:40,774:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:40,774:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,820:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.
2025-03-29 15:39:40,820:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,820:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,820:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:40,820:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:40,820:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,867:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.
2025-03-29 15:39:40,867:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,867:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,867:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:40,867:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:40,867:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.
2025-03-29 15:39:40,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,912:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:40,912:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:40,912:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:40,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000065 seconds.
2025-03-29 15:39:40,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:40,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:40,955:INFO:[LightGBM] [Info] Total Bins 528
2025-03-29 15:39:40,955:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:40,955:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:41,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:39:41,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,012:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,012:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,012:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:41,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,063:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,063:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,063:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:41,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,117:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,117:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,117:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,168:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:39:41,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,168:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,168:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,168:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,218:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:41,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,219:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,219:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,219:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,219:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:39:41,268:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,268:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,268:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,268:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,268:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,316:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:41,316:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,316:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,316:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,316:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,316:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,363:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:39:41,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,363:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,363:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,364:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,412:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:39:41,412:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,412:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,412:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,412:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,412:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,459:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:41,459:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,459:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,459:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,459:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,460:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,506:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:41,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,506:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,506:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,506:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-03-29 15:39:41,573:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,573:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,573:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,573:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,573:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,659:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:41,659:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,659:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,659:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:41,659:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:41,659:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,711:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.
2025-03-29 15:39:41,711:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,711:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,711:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:41,711:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:41,712:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,765:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.
2025-03-29 15:39:41,765:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,765:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,765:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:41,765:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:41,765:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,815:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:39:41,815:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,815:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,815:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:41,816:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:41,816:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.
2025-03-29 15:39:41,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,871:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:41,871:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:41,871:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,921:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:39:41,922:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,922:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,922:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:41,922:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:41,922:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:41,971:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:41,971:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:41,971:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:41,971:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:41,971:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:41,971:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:42,018:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-03-29 15:39:42,019:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,019:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,019:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:42,019:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:42,019:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:42,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:39:42,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,065:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:42,065:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:42,065:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:42,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.
2025-03-29 15:39:42,109:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,110:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:42,110:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:42,110:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:42,156:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:39:42,156:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,156:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,156:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:42,156:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:42,156:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:42,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000065 seconds.
2025-03-29 15:39:42,202:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,202:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,202:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:42,202:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:42,202:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:42,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:39:42,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,257:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:42,257:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:42,257:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:39:42,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,311:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,311:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,311:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,363:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:39:42,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,363:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,363:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,363:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,414:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:39:42,415:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,415:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,415:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,415:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,415:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,466:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:42,466:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,466:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,467:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,467:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,467:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,517:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.
2025-03-29 15:39:42,517:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,517:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,517:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,517:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,517:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,569:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000497 seconds.
2025-03-29 15:39:42,569:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:39:42,569:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,569:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,569:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.
2025-03-29 15:39:42,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,625:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,625:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,625:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.
2025-03-29 15:39:42,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,674:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,674:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,674:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,674:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:39:42,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,721:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,721:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,721:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,721:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:39:42,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,771:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,771:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,771:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,819:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.
2025-03-29 15:39:42,819:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,819:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,819:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,819:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,820:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,869:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:39:42,869:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,869:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,869:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,869:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,869:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,928:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:39:42,928:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,928:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,928:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:42,928:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:42,928:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:42,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000820 seconds.
2025-03-29 15:39:42,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:42,980:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:42,980:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:42,980:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:42,982:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:43,046:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:39:43,046:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,046:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,047:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:43,047:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:43,047:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:43,094:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:39:43,094:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,094:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,094:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:43,094:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:43,094:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:43,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:39:43,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,142:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,142:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:43,142:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:43,142:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:43,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.
2025-03-29 15:39:43,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,191:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:43,191:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:43,191:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:43,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.
2025-03-29 15:39:43,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,238:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:43,239:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:43,239:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:43,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:43,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,288:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:43,288:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:43,288:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:43,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.
2025-03-29 15:39:43,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,338:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:43,338:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:43,338:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:43,391:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:39:43,391:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,391:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,391:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:43,391:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:43,391:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:43,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000066 seconds.
2025-03-29 15:39:43,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,442:INFO:[LightGBM] [Info] Total Bins 531
2025-03-29 15:39:43,442:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:43,443:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:43,500:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:39:43,500:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,500:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,500:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:43,500:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:43,501:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:43,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:39:43,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,553:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:43,553:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:43,553:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:43,605:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:43,606:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,606:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,606:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:43,606:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:43,606:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:43,663:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:39:43,663:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,664:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:43,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:43,664:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:43,718:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:39:43,718:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,718:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,718:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:43,718:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:43,719:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:43,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:39:43,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,769:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,769:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:43,769:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:43,769:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:43,820:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:39:43,820:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,820:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,820:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:43,820:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:43,820:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:43,869:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:43,869:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,869:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,869:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:43,869:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:43,869:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:43,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000287 seconds.
2025-03-29 15:39:43,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,916:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:43,916:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:43,916:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:43,965:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:39:43,965:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:43,965:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:43,965:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:43,965:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:43,965:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,016:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:39:44,016:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,016:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,017:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:44,017:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:44,017:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:44,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,068:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:44,068:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:44,068:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:39:44,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,117:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:44,117:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:44,117:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,165:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000719 seconds.
2025-03-29 15:39:44,165:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,165:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:44,165:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:44,165:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:39:44,215:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,215:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,215:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:44,216:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:44,216:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,262:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.
2025-03-29 15:39:44,262:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,262:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,262:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:44,262:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:44,262:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,309:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:39:44,309:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,309:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,309:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:44,309:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:44,309:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,361:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:39:44,361:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,361:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,362:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:44,362:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:44,362:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,408:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:39:44,408:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,408:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,408:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:44,408:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:44,408:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:39:44,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,457:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:44,457:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:44,458:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:39:44,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,505:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:44,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:44,506:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,551:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.
2025-03-29 15:39:44,551:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,551:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,551:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:44,551:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:44,551:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,649:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.
2025-03-29 15:39:44,649:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,649:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,649:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:44,649:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:44,649:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.
2025-03-29 15:39:44,727:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,727:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:44,727:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:44,727:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:44,794:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:44,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,795:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:44,795:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:44,795:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:44,857:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:39:44,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,858:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:44,858:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:44,858:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:44,909:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:39:44,909:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,909:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,909:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:44,909:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:44,909:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:44,966:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-03-29 15:39:44,966:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:44,966:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:44,966:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:44,966:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:44,966:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,017:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:39:45,017:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,017:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,017:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:45,017:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:45,017:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,066:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:39:45,066:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,066:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,066:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:45,066:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:45,066:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,114:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.
2025-03-29 15:39:45,114:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:39:45,114:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:45,114:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:45,114:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,170:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:39:45,170:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,170:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,170:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:45,170:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:45,171:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,218:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:39:45,218:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,218:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,218:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:45,218:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:45,218:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,266:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:39:45,266:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,266:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,266:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:45,266:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:45,266:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:39:45,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,319:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,319:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:45,319:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:45,320:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.
2025-03-29 15:39:45,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,402:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:45,402:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:45,402:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:39:45,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,487:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:45,487:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:45,487:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,539:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:39:45,539:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,539:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,539:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:45,539:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:45,539:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,590:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:39:45,590:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,591:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,591:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:45,591:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:45,591:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,639:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:39:45,639:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,639:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,639:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:45,639:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:45,639:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,690:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:39:45,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,690:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:45,690:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:45,690:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,740:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.
2025-03-29 15:39:45,740:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,740:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,740:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:45,740:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:45,741:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,787:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.
2025-03-29 15:39:45,787:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,787:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:45,787:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:45,787:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:39:45,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,836:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:45,836:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:45,836:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,881:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.
2025-03-29 15:39:45,881:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,881:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,881:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:45,881:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:45,881:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.
2025-03-29 15:39:45,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,927:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:45,927:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:45,927:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:45,970:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:39:45,971:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:45,971:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:45,971:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:45,971:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:45,971:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:46,020:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.
2025-03-29 15:39:46,020:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,020:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,020:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:46,020:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:46,020:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:46,074:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:46,074:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,074:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,074:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,074:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,074:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,124:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:39:46,124:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,124:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,124:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,125:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,125:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,172:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:46,173:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,173:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,173:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,173:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,173:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,222:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:46,222:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,222:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,222:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,222:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,222:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:46,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,270:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,270:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,270:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,318:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:39:46,318:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,318:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,318:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,318:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,318:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,366:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:39:46,366:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,366:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,366:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,366:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,366:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,415:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:39:46,415:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,415:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,415:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,415:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,415:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.
2025-03-29 15:39:46,495:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,495:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,495:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,495:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:39:46,572:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,572:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,572:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,572:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,624:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:46,624:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,625:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,625:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,625:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,681:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.
2025-03-29 15:39:46,681:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,681:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,681:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,681:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,682:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,739:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:46,739:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,739:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,739:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:46,739:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:46,739:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,788:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:39:46,788:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,788:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,788:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:39:46,788:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:46,788:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,835:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:39:46,835:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,836:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:46,836:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:46,836:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.
2025-03-29 15:39:46,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,883:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:46,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:46,883:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,929:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:39:46,929:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,929:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,930:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:46,930:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:46,930:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:46,978:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:39:46,978:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:46,978:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:46,978:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:46,978:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:46,978:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:47,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:39:47,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,027:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:47,027:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:47,027:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:47,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:39:47,073:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,073:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,074:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:47,074:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:47,074:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:47,119:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.
2025-03-29 15:39:47,119:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,119:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,119:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:47,119:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:47,119:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:47,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.
2025-03-29 15:39:47,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,201:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:47,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:47,201:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:47,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-03-29 15:39:47,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,274:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:47,274:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:47,274:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:47,382:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.
2025-03-29 15:39:47,382:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,382:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,382:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:47,382:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:47,382:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:47,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:47,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,474:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:47,474:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:47,474:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:47,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:47,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,554:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:47,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:47,554:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:47,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:47,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,625:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:47,626:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:47,626:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:47,681:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:39:47,681:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,681:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,681:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:47,681:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:47,682:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:47,732:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:47,733:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,733:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,733:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:47,733:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:47,733:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:47,781:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:39:47,781:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,781:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,781:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:47,781:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:47,781:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:47,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:47,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,842:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:47,842:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:47,842:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:47,890:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:39:47,890:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,890:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,890:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:47,890:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:47,890:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:47,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:39:47,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,940:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:47,940:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:47,940:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:47,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:47,988:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:47,988:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:47,988:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:47,988:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:47,988:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,039:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:39:48,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,039:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:48,039:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:48,039:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:48,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,092:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:48,092:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:48,092:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:48,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,139:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:48,139:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:48,139:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,185:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:39:48,185:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,185:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,185:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:39:48,185:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:48,185:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,233:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:39:48,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,233:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,233:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:39:48,233:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:48,233:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,279:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:48,279:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,279:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:48,279:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:48,279:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,325:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:48,325:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,325:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,325:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:48,325:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:48,325:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:39:48,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,370:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:48,370:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:48,370:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,416:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:39:48,416:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,416:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,416:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:48,416:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:48,416:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,461:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:39:48,461:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,461:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,461:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:48,461:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:48,461:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,507:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.
2025-03-29 15:39:48,507:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,507:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,507:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:48,507:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:48,508:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,559:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.
2025-03-29 15:39:48,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,559:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,559:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:48,559:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:48,559:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:39:48,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,604:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:48,604:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:48,604:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,647:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-03-29 15:39:48,648:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,648:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,648:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:48,648:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 4
2025-03-29 15:39:48,648:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:39:48,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:39:48,704:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,704:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,704:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:48,704:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:48,704:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:48,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:48,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,754:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:48,754:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:48,754:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:48,804:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:39:48,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,804:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:48,804:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:48,804:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:48,854:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:48,854:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,854:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,854:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:48,854:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:48,854:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:48,902:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:39:48,902:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,902:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,902:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:48,902:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:48,902:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:48,950:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:39:48,950:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:48,950:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:48,950:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:48,951:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:48,951:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:39:49,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,003:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:49,003:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:49,003:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,053:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:39:49,053:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,053:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,053:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:49,053:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:49,053:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:39:49,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,103:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:49,103:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:49,103:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:39:49,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,157:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:49,157:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:49,157:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,212:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:49,212:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,212:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,213:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:49,213:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:49,213:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,265:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:49,265:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,265:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,265:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:49,265:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:49,265:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,312:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:49,312:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,312:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,312:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:39:49,312:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:49,312:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:39:49,362:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,362:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,362:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:39:49,362:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:39:49,362:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,415:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-03-29 15:39:49,415:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,415:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,415:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:39:49,415:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:39:49,415:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.
2025-03-29 15:39:49,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,472:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,472:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:49,472:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:39:49,472:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,538:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:39:49,539:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,539:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,539:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:49,539:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:39:49,539:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,588:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:39:49,589:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,589:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,589:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:49,589:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:39:49,589:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,636:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.
2025-03-29 15:39:49,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,636:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,636:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:49,636:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:39:49,636:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,685:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:39:49,685:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,685:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,685:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:49,685:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:39:49,685:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,732:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:39:49,732:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,732:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,732:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:49,732:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:39:49,733:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.
2025-03-29 15:39:49,779:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,779:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,779:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:49,779:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:39:49,779:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,824:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:39:49,824:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,824:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,824:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:49,824:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-29 15:39:49,824:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:39:49,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:39:49,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,883:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:49,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:49,883:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:49,938:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:49,938:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,938:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,938:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:49,938:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:49,938:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:49,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:39:49,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:49,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:49,990:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:49,990:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:49,990:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:39:50,038:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,038:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,038:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:50,038:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:50,038:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,086:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:39:50,087:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,087:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,087:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:50,087:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:50,087:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,135:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-29 15:39:50,135:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,135:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,135:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:50,135:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:50,135:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:39:50,186:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,186:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,186:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:50,186:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:50,186:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,235:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:39:50,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,235:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:50,235:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:50,236:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,291:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:50,291:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,291:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,291:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:50,291:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:50,291:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,342:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:39:50,342:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,342:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,342:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:50,342:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:50,342:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000692 seconds.
2025-03-29 15:39:50,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,398:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,398:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:50,398:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:50,398:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:39:50,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,451:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:50,451:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:50,451:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:39:50,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,502:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:39:50,502:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:39:50,502:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,551:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.
2025-03-29 15:39:50,551:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,551:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,551:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:39:50,551:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:39:50,551:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,599:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
2025-03-29 15:39:50,599:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,599:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,600:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:50,600:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:39:50,600:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:39:50,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,654:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:50,654:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:39:50,654:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:39:50,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,703:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:50,703:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:39:50,703:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:39:50,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,751:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,751:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:50,751:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:39:50,752:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,798:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.
2025-03-29 15:39:50,798:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,798:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,798:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:50,798:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:39:50,798:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-03-29 15:39:50,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,858:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:50,858:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:39:50,858:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:50,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.
2025-03-29 15:39:50,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:50,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:50,930:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:50,930:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:39:50,930:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:51,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.
2025-03-29 15:39:51,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,011:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:51,011:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:39:51,011:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:51,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000752 seconds.
2025-03-29 15:39:51,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:39:51,084:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:51,084:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 5
2025-03-29 15:39:51,084:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:39:51,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:39:51,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,168:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,168:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,168:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,229:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:39:51,229:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,229:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,229:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,229:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,229:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,309:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:51,309:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,309:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,309:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,309:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,310:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,382:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-29 15:39:51,382:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,382:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,382:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,382:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,383:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,437:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:51,437:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,437:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,437:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,437:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,438:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,490:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:39:51,490:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,490:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,490:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,490:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,490:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:51,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,543:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,543:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,543:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:39:51,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,597:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,597:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,597:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:39:51,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,650:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,650:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,650:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,701:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:39:51,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,701:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,701:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,701:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,755:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:51,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,755:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,755:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,755:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,810:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:51,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,810:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,810:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,810:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:39:51,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,860:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:51,860:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:51,860:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,914:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:51,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,914:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:51,914:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:51,915:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:51,965:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:39:51,965:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:51,965:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:51,965:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:51,965:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:51,965:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:52,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:39:52,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,012:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:52,013:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:52,013:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:52,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:39:52,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,061:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:52,061:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:52,061:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:52,107:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:39:52,107:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,107:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,107:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:52,107:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:52,107:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:52,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:39:52,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,154:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:52,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:52,154:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:52,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:39:52,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,200:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:52,200:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:52,200:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:52,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.
2025-03-29 15:39:52,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,248:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:52,248:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:52,248:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:52,300:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000122 seconds.
2025-03-29 15:39:52,300:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,300:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,300:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:52,300:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:52,300:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:52,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:39:52,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,346:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:52,346:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:52,346:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:39:52,401:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:52,401:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,401:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,401:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,401:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,401:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,452:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:52,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,453:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,453:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,453:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:39:52,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,502:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,502:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,502:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.
2025-03-29 15:39:52,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,554:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,554:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,609:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:52,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,609:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,609:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,610:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:39:52,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,664:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,665:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.
2025-03-29 15:39:52,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,714:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,714:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,715:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:52,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,772:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,772:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,772:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,823:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:52,823:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,823:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,823:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,823:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,823:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:39:52,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,873:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,873:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,873:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:39:52,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,930:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,931:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,931:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:52,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:39:52,988:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:52,988:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:52,988:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:52,988:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:52,988:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:53,041:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,041:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,041:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:53,041:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:53,041:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,090:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:39:53,090:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,090:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,090:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:53,090:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:53,090:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.
2025-03-29 15:39:53,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,142:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,142:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:53,142:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:53,142:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2025-03-29 15:39:53,194:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,194:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,194:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:53,194:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:53,194:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,269:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-03-29 15:39:53,269:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,269:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,269:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:53,269:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:53,269:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,341:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:39:53,341:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,341:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:53,341:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:53,341:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,429:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:39:53,429:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,431:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,432:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:53,433:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:53,433:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,519:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.
2025-03-29 15:39:53,519:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,519:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:53,519:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:53,519:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.
2025-03-29 15:39:53,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,602:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:53,602:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:53,602:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,682:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.
2025-03-29 15:39:53,682:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,682:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,682:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:53,683:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:53,683:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,768:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-29 15:39:53,768:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,768:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,768:INFO:[LightGBM] [Info] Total Bins 530
2025-03-29 15:39:53,768:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:53,768:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:39:53,851:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.
2025-03-29 15:39:53,852:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,852:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,852:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:53,852:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:53,852:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:53,925:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:39:53,925:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:53,925:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:53,925:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:53,925:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:53,925:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:53,999:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.
2025-03-29 15:39:53,999:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,000:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,000:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,000:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,000:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:54,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,068:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,068:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,069:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,126:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:39:54,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,126:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,126:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,126:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,182:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:39:54,182:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,182:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,182:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,182:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,182:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:39:54,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,240:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,240:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,240:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,294:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:39:54,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,294:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,294:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,294:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,345:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:54,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,346:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,346:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,346:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,398:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:39:54,398:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,398:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,398:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,398:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,398:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,453:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:54,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,453:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,453:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,453:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:39:54,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,509:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,509:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,509:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,509:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,559:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:39:54,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,559:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,559:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:54,559:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:54,559:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,622:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:54,622:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,622:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,622:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:39:54,622:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:54,622:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,675:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:39:54,675:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,675:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:39:54,675:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:54,676:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,747:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000831 seconds.
2025-03-29 15:39:54,747:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:39:54,747:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:54,747:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:54,748:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000490 seconds.
2025-03-29 15:39:54,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,832:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:54,832:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:54,832:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-29 15:39:54,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,904:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:54,904:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:54,904:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:54,974:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-03-29 15:39:54,974:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:54,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:54,974:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:54,974:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:54,974:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:55,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-03-29 15:39:55,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,054:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:55,054:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:55,054:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:55,151:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-29 15:39:55,151:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,151:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,151:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:55,151:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:55,152:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:55,221:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:39:55,221:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,221:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,221:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:55,221:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:55,221:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:55,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.
2025-03-29 15:39:55,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,290:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:55,290:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:55,290:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:39:55,372:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:39:55,372:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,372:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,372:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:55,372:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:55,372:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:55,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:39:55,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,455:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:55,455:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:55,455:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:55,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:39:55,532:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,532:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:55,532:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:55,532:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:55,634:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:39:55,634:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,634:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,634:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:55,634:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:55,634:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:55,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:39:55,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,720:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:55,720:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:55,721:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:55,798:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:39:55,798:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,798:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,799:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:55,799:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:55,799:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:55,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:39:55,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,872:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:55,872:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:55,873:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:55,945:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:39:55,945:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:55,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:55,945:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:55,945:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:55,946:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,017:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.
2025-03-29 15:39:56,017:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,017:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,017:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:56,017:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:56,018:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:39:56,070:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,070:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,070:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:56,070:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:56,070:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,128:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:39:56,128:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,128:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,128:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:56,128:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:56,128:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,185:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:39:56,185:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,185:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,185:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:56,185:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:56,186:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:39:56,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,237:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:56,237:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:56,238:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,283:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.
2025-03-29 15:39:56,284:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,284:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:39:56,284:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:56,284:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,330:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000287 seconds.
2025-03-29 15:39:56,330:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,330:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,330:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:56,330:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:56,330:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:39:56,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,378:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:56,378:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:56,378:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.
2025-03-29 15:39:56,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,425:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:56,425:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:56,425:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:39:56,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,474:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:56,474:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:56,474:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.
2025-03-29 15:39:56,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,526:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:56,526:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:56,526:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,585:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.
2025-03-29 15:39:56,585:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,585:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,585:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:56,585:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:56,585:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.
2025-03-29 15:39:56,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,638:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:56,638:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:56,638:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,689:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-03-29 15:39:56,689:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,689:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,689:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:56,689:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:56,689:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,748:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.
2025-03-29 15:39:56,748:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,748:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,748:INFO:[LightGBM] [Info] Total Bins 533
2025-03-29 15:39:56,748:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:56,748:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:39:56,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:39:56,811:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,811:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,811:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:56,811:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:56,812:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:56,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:39:56,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,862:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:56,862:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:56,862:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:56,936:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:56,936:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,936:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,936:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:56,936:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:56,936:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:56,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:39:56,988:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:56,988:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:56,988:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:56,988:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:56,989:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,039:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:39:57,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,039:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:57,039:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:57,039:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:39:57,090:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,090:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,090:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:57,090:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:57,090:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:57,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,139:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:57,139:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:57,139:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,191:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:39:57,191:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,191:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,191:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:57,191:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:57,191:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,241:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:39:57,241:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,241:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,241:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:57,241:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:57,241:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:39:57,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,289:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:57,289:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:57,289:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,341:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:57,341:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,341:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:57,341:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:57,341:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:57,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,392:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:57,392:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:57,392:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,443:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.
2025-03-29 15:39:57,443:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,443:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,444:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:39:57,444:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:57,444:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2025-03-29 15:39:57,515:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,515:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,515:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:39:57,515:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:57,515:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,590:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:39:57,590:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,590:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,591:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:39:57,591:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:57,591:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,670:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000453 seconds.
2025-03-29 15:39:57,670:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,670:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,670:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:39:57,670:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:57,671:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:39:57,724:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,724:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,724:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:39:57,724:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:57,724:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.
2025-03-29 15:39:57,779:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,779:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,779:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:39:57,779:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:57,780:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.
2025-03-29 15:39:57,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,843:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:39:57,843:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:57,843:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,914:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.
2025-03-29 15:39:57,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,914:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:39:57,914:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:57,915:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:57,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-03-29 15:39:57,983:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:57,983:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:57,983:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:39:57,983:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:57,983:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:58,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000118 seconds.
2025-03-29 15:39:58,038:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,038:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,038:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:39:58,038:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:58,038:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:58,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:39:58,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,088:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:39:58,088:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:58,088:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:39:58,144:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:39:58,144:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,144:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,144:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,144:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000452 seconds.
2025-03-29 15:39:58,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,201:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,201:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:39:58,269:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,269:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,269:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,269:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,269:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:58,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,323:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,324:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,324:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,373:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:39:58,373:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,373:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,373:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,373:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,373:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,423:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:39:58,423:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,423:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,423:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,423:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,423:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:39:58,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,472:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,473:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,473:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,473:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:39:58,527:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,527:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,527:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,527:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,527:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,577:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:39:58,577:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,577:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,577:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,577:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,577:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,624:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:39:58,624:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,624:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,624:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,624:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,624:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,677:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:39:58,677:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,677:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,677:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,677:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,677:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,729:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:39:58,729:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,729:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,729:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,729:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,729:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,778:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:39:58,778:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,778:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,778:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:58,778:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:58,778:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,826:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:39:58,826:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,826:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,826:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:39:58,826:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:58,826:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.
2025-03-29 15:39:58,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,873:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:39:58,873:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:39:58,873:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:39:58,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,919:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:39:58,919:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:39:58,920:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:58,965:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.
2025-03-29 15:39:58,965:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:58,965:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:58,965:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:39:58,965:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:39:58,965:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:59,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-03-29 15:39:59,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,012:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:39:59,012:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:39:59,012:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:59,060:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:39:59,060:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,060:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,060:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:39:59,060:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:39:59,060:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:59,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.
2025-03-29 15:39:59,106:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,106:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,106:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:39:59,106:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:39:59,107:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:59,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.
2025-03-29 15:39:59,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,157:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:39:59,157:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:39:59,157:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:59,203:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.
2025-03-29 15:39:59,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,203:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:39:59,203:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:39:59,204:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:59,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:39:59,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,250:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:39:59,250:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:39:59,250:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:39:59,305:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:39:59,305:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,306:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,306:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,306:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,354:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:39:59,354:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,354:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,354:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,354:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,354:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,406:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:39:59,406:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,406:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,406:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,406:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,406:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,456:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-03-29 15:39:59,456:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,457:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,457:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,457:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:39:59,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,506:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,506:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,506:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:59,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,553:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,554:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.
2025-03-29 15:39:59,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,618:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,618:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,618:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,618:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:39:59,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,676:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,676:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,676:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,732:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000665 seconds.
2025-03-29 15:39:59,732:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,732:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,732:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,732:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,732:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,786:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:39:59,786:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,786:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,786:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,787:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,787:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:39:59,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,842:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,842:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,842:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,897:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:39:59,897:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,897:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,897:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,897:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,897:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,946:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:39:59,946:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,946:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,946:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:39:59,946:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:39:59,947:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:39:59,995:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.
2025-03-29 15:39:59,995:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:39:59,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:39:59,995:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:39:59,995:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:39:59,995:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:00,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:00,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,058:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:00,058:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:00,058:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:00,110:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.
2025-03-29 15:40:00,110:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,110:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:00,110:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:00,110:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:00,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.
2025-03-29 15:40:00,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,163:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:00,163:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:00,163:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:00,247:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.
2025-03-29 15:40:00,247:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,247:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,247:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:00,247:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:00,247:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:00,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:40:00,312:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,312:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,312:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:00,312:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:00,312:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:00,385:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.
2025-03-29 15:40:00,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,386:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:00,386:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:00,386:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:00,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.
2025-03-29 15:40:00,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,451:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:00,451:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:00,451:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:00,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.
2025-03-29 15:40:00,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,526:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:00,526:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:40:00,526:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:00,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.
2025-03-29 15:40:00,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,633:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:00,633:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:40:00,633:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:00,731:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:40:00,731:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,731:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,731:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:00,731:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:00,731:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:00,794:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:40:00,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,794:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:00,794:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:00,794:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:00,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:40:00,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,850:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:00,850:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:00,850:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:00,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:40:00,920:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,920:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,920:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:00,920:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:00,920:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:00,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:40:00,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:00,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:00,973:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:00,973:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:00,973:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.
2025-03-29 15:40:01,026:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,026:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,026:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:01,026:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:01,026:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,081:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:40:01,081:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,081:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,081:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:01,081:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:01,081:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,136:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:40:01,136:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,136:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,136:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:01,136:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:01,136:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:01,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,187:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:01,187:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:01,187:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,235:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:01,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,235:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:01,235:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:01,235:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:40:01,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,288:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:01,288:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:01,288:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000829 seconds.
2025-03-29 15:40:01,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:40:01,341:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:01,341:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:01,341:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:40:01,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,402:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:01,402:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:01,402:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:01,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,452:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:40:01,452:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:01,452:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,500:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:40:01,500:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,500:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,500:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:01,500:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:01,500:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,549:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.
2025-03-29 15:40:01,549:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,549:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,549:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:01,549:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:01,549:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:40:01,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,597:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:01,597:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:01,597:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:40:01,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,645:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:01,645:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:01,645:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,697:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.
2025-03-29 15:40:01,697:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,697:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:01,697:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:01,697:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:01,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,744:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,744:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:01,745:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:01,745:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-03-29 15:40:01,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,792:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:01,792:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:01,792:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,840:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.
2025-03-29 15:40:01,840:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,840:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,840:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:40:01,840:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:40:01,840:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,887:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.
2025-03-29 15:40:01,887:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,888:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:40:01,888:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 5
2025-03-29 15:40:01,888:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:01,946:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:40:01,946:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:01,946:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:01,946:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:01,946:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:01,946:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:40:02,004:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,004:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,004:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,004:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,004:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:40:02,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,055:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,055:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,055:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,055:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:40:02,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,108:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,109:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,109:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:40:02,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,162:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,162:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,163:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,218:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-03-29 15:40:02,218:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,218:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,218:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,218:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,218:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,271:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:02,272:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,272:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,272:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,272:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,272:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:40:02,321:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,321:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,321:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,321:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,385:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:40:02,385:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,385:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,385:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,386:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,386:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,453:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:02,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,453:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,453:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,453:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:40:02,509:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,509:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,509:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,509:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,509:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,586:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.
2025-03-29 15:40:02,586:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,586:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,586:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,586:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,586:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:40:02,667:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,667:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,667:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:02,667:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:02,667:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,723:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:40:02,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,724:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,724:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:40:02,724:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:02,724:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,776:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:40:02,776:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,776:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,776:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:02,776:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:02,776:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,826:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:40:02,826:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,826:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,826:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:02,826:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:02,826:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,875:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:40:02,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,876:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:02,876:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:02,876:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-03-29 15:40:02,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,923:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,923:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:02,923:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:40:02,923:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:02,971:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2025-03-29 15:40:02,971:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:02,971:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:02,971:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:02,971:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:40:02,971:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:03,019:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:40:03,019:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,019:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,019:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:03,019:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:40:03,019:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:03,067:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:40:03,067:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,067:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,067:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:03,068:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:40:03,068:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:03,113:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.
2025-03-29 15:40:03,113:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,113:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,113:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:40:03,113:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:40:03,114:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:03,168:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:40:03,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,169:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,169:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,169:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,169:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,221:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:03,221:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,221:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,221:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,221:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,222:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:40:03,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,274:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,274:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,274:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,326:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:40:03,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,326:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,326:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,326:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:03,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,377:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,377:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,377:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,377:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,448:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:40:03,449:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,449:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,449:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,449:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,449:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,500:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-29 15:40:03,500:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,500:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,500:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,500:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,501:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:40:03,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,554:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,554:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:03,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,604:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,604:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,604:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,658:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:03,658:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,658:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,658:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,658:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,658:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,711:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:40:03,711:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,711:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,711:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,711:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,711:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,764:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:40:03,764:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,764:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,764:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,765:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,765:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,813:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:40:03,813:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,813:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,813:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:03,813:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:03,813:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,866:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:40:03,866:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,866:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,866:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:03,866:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:03,866:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:03,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:40:03,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:03,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:03,940:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:03,940:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:03,940:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:04,017:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:40:04,017:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,017:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,018:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:04,018:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:04,018:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:04,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-29 15:40:04,090:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,090:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,090:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:04,090:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:04,090:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:04,170:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:40:04,171:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,171:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,171:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:04,171:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:40:04,171:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:04,229:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.
2025-03-29 15:40:04,229:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,229:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,229:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:04,229:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:40:04,229:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:04,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:40:04,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,289:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:04,289:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:40:04,289:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:04,349:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.
2025-03-29 15:40:04,349:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,349:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,349:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:40:04,349:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:40:04,350:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:04,438:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000118 seconds.
2025-03-29 15:40:04,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,438:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,438:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:40:04,438:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 6
2025-03-29 15:40:04,438:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:04,514:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:40:04,514:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,514:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,514:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:04,515:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:04,515:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:04,571:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:40:04,571:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,571:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,571:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:04,571:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:04,571:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:04,630:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:04,630:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,630:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,630:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:04,630:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:04,630:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:04,690:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:40:04,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,690:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:04,690:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:04,690:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:04,750:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:40:04,750:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,750:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,750:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:04,750:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:04,750:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:04,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:04,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,807:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:04,807:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:04,807:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:04,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-03-29 15:40:04,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,863:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:04,863:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:04,864:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:04,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000806 seconds.
2025-03-29 15:40:04,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,916:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:04,916:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:04,916:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:04,967:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.
2025-03-29 15:40:04,967:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:04,967:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:04,967:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:04,967:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:04,968:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:40:05,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,023:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:05,023:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:05,023:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,079:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:40:05,079:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,079:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,079:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:05,079:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:05,079:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,138:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:40:05,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,138:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,138:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:05,138:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:05,139:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,192:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:40:05,192:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,192:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,192:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:05,192:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:05,192:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,243:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-03-29 15:40:05,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,244:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,244:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:05,244:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:05,244:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,294:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:40:05,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,294:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:05,294:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:05,295:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,341:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:40:05,342:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,342:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,342:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:05,342:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:05,342:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,410:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-29 15:40:05,411:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,411:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,411:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:05,411:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:05,411:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000591 seconds.
2025-03-29 15:40:05,482:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,482:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:05,482:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:05,482:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.
2025-03-29 15:40:05,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,554:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:05,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:05,554:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,620:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.
2025-03-29 15:40:05,620:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,620:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,620:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:05,620:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:05,620:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:40:05,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,674:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,674:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:05,674:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:05,674:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.
2025-03-29 15:40:05,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,726:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:40:05,727:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:40:05,727:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:05,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:05,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,799:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:05,799:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:05,799:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:05,853:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:40:05,853:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,853:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,853:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:05,853:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:05,853:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:05,906:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:40:05,907:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,907:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,907:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:05,907:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:05,907:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:05,959:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:05,959:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:05,959:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:05,959:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:05,959:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:05,959:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,015:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:40:06,015:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,015:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,015:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:06,015:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:06,016:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,067:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:40:06,067:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,067:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,067:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:06,067:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:06,067:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:40:06,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,117:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:06,117:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:06,117:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,170:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:40:06,170:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,170:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,170:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:06,170:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:06,170:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,222:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:40:06,222:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,222:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,222:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:06,222:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:06,222:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:06,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,274:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:06,274:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:06,274:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,328:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:06,328:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,328:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,328:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:06,328:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:06,328:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:40:06,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,381:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,381:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:06,381:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:06,382:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,430:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:40:06,430:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,430:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,431:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:06,431:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:06,431:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:40:06,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,478:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:06,478:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:06,478:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:40:06,527:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,528:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,528:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:06,528:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:06,528:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,574:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:06,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,575:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:06,575:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:06,575:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.
2025-03-29 15:40:06,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,638:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:06,638:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:06,638:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,690:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:40:06,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,690:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:06,690:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:06,690:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:06,739:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,739:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,739:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:06,739:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:06,739:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:40:06,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,799:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:06,799:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:06,799:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,846:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-03-29 15:40:06,846:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,846:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,846:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:40:06,846:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:06,846:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,890:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-03-29 15:40:06,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,891:INFO:[LightGBM] [Info] Total Bins 532
2025-03-29 15:40:06,891:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:40:06,891:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:06,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:40:06,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:06,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:06,944:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:06,944:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:06,944:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,018:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:40:07,018:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,019:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,019:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,019:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:40:07,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,076:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,076:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,076:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:40:07,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,131:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,131:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,132:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:40:07,186:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,186:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,186:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,186:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,186:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:40:07,236:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,236:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,236:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,236:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,237:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:07,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,288:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,288:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,289:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,340:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:07,340:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,340:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,340:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,340:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,340:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,391:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:07,391:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,391:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,391:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,391:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,391:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,444:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:40:07,444:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,444:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,444:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,444:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,444:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:40:07,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,505:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,505:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:40:07,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,604:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,604:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,605:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,682:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:40:07,683:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,683:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,683:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:07,683:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:07,683:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,768:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:40:07,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,769:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,769:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:07,769:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:07,769:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,844:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:40:07,844:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,844:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,844:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:07,844:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:07,844:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,917:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:40:07,917:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,917:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,917:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:07,917:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:07,917:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:07,986:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.
2025-03-29 15:40:07,986:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:07,986:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:07,986:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:07,986:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:07,986:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:08,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:40:08,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,069:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:08,069:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:08,069:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:08,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:40:08,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,117:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:08,117:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:08,117:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:08,172:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:08,172:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,172:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,172:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:08,172:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:08,172:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:08,230:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-03-29 15:40:08,230:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,230:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,230:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:08,230:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:08,230:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:08,277:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:40:08,277:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,277:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,277:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:08,277:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:40:08,277:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:08,336:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:40:08,336:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,336:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,336:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:08,336:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:08,337:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,390:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:40:08,390:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,390:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,390:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,390:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,390:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,448:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:08,448:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,448:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,448:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,448:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,448:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:40:08,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,502:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,502:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,502:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:40:08,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,553:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,553:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,553:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:40:08,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,604:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,604:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,604:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,657:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:40:08,657:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,657:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,657:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,657:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,657:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:08,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,707:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,707:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,707:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:40:08,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,756:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,756:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,756:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.
2025-03-29 15:40:08,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,807:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,807:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,807:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-03-29 15:40:08,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,858:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,858:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,858:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,912:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:08,912:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,912:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,912:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,912:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,912:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:08,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:40:08,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:08,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:08,962:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:08,963:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:08,963:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:09,015:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000598 seconds.
2025-03-29 15:40:09,015:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,015:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,015:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:09,015:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:09,015:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:09,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:40:09,064:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,064:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,064:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:09,064:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:09,064:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:09,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:09,110:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,110:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:09,110:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:09,110:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:09,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:09,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,155:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:09,155:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:09,155:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:09,223:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:40:09,223:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,223:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,223:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:09,223:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:09,223:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:09,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:40:09,268:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,268:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,268:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:09,268:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:09,269:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:09,313:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:09,313:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,313:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,313:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:40:09,313:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:09,313:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:09,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.
2025-03-29 15:40:09,360:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,360:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:40:09,361:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:09,361:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:09,413:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.
2025-03-29 15:40:09,413:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,413:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,413:INFO:[LightGBM] [Info] Total Bins 535
2025-03-29 15:40:09,413:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:40:09,413:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:09,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.
2025-03-29 15:40:09,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:40:09,472:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:09,472:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:09,472:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:09,530:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:40:09,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,531:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:09,531:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:09,531:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:09,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:40:09,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,602:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:09,602:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:09,603:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:09,672:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:40:09,672:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,672:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,672:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:09,672:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:09,673:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:09,723:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:09,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,723:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:09,723:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:09,723:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:09,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:40:09,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,772:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:09,772:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:09,772:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:09,822:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:09,822:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,822:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,822:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:09,822:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:09,822:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:09,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:40:09,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,871:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:09,871:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:09,871:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:09,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:09,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,919:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:09,919:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:09,919:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:09,971:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:40:09,971:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:09,971:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:09,971:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:09,971:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:09,971:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:40:10,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,021:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:10,021:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:10,021:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:10,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,069:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:10,069:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:10,069:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:40:10,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,117:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:10,117:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:10,117:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:40:10,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,163:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:10,163:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:10,163:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:40:10,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,210:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:10,210:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:10,210:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,256:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:40:10,256:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,256:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,257:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:10,257:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:10,257:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:40:10,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,302:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:10,302:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:10,302:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,347:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-03-29 15:40:10,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,347:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:10,347:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:10,347:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:40:10,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,393:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:10,393:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:10,393:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:10,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,439:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:10,439:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:10,439:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:40:10,484:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,484:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:10,484:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:10,485:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,530:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.
2025-03-29 15:40:10,530:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,530:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,530:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:40:10,530:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:40:10,530:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:10,584:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.
2025-03-29 15:40:10,585:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,585:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,585:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:10,585:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:10,585:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:10,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:10,635:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,635:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,635:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:10,635:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:10,635:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:10,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.
2025-03-29 15:40:10,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,699:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:10,699:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:10,699:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:10,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.
2025-03-29 15:40:10,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,772:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:10,772:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:10,772:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:10,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:40:10,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,843:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:10,843:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:10,843:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:10,917:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:40:10,917:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,918:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:10,918:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:10,918:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:10,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:40:10,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:10,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:10,990:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:10,990:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:10,990:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.
2025-03-29 15:40:11,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,065:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:11,065:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:11,065:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,138:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:40:11,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,138:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,138:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:11,138:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:11,138:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:40:11,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,210:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:11,210:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:11,210:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,284:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:11,284:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,284:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:11,284:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:11,284:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:40:11,355:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,355:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,355:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:11,355:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:11,355:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,428:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:40:11,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,428:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,428:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:11,429:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:11,429:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.
2025-03-29 15:40:11,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,502:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:11,502:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:11,502:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:11,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,574:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:11,574:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:11,574:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,647:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-03-29 15:40:11,647:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,647:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,647:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:11,648:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:11,648:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-03-29 15:40:11,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,722:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,722:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:11,722:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:11,722:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000828 seconds.
2025-03-29 15:40:11,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,799:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:11,799:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:11,800:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.
2025-03-29 15:40:11,882:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,882:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,882:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:11,882:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:11,882:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:11,965:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000847 seconds.
2025-03-29 15:40:11,965:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:11,965:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:11,965:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:11,965:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:11,965:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:12,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:40:12,034:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,034:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,034:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:40:12,034:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:12,034:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:12,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.
2025-03-29 15:40:12,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,103:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:40:12,103:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:40:12,103:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:12,177:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:40:12,177:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,177:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,178:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,178:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,178:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,232:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:40:12,232:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,232:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,232:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,232:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,232:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.
2025-03-29 15:40:12,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,288:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,288:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,288:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:40:12,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,338:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,339:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,339:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:40:12,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,394:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,394:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,394:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,444:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:40:12,444:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,444:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,444:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,444:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,444:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,500:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:40:12,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,501:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,501:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,501:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,551:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:40:12,551:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,551:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,551:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,551:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,551:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:40:12,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,603:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,604:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:40:12,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,665:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,665:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,665:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:12,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,737:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,737:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,737:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,800:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:12,800:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,800:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,800:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,800:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,800:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:40:12,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,850:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:12,850:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:12,850:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.
2025-03-29 15:40:12,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,900:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:12,900:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:12,900:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:12,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:40:12,954:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:12,954:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:12,954:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:12,954:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:12,955:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:13,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:40:13,005:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,005:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,005:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:13,005:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:13,005:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:13,053:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:13,053:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,054:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:13,054:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:13,054:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:13,101:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:40:13,101:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,101:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,101:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:13,102:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:13,102:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:13,149:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000683 seconds.
2025-03-29 15:40:13,149:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,149:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,149:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:13,149:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:13,149:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:13,196:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:40:13,196:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,196:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,197:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:13,197:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:13,197:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:13,243:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:40:13,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,243:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,243:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:13,243:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:13,243:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:13,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.
2025-03-29 15:40:13,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,288:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:13,288:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:40:13,288:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:13,344:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:13,344:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,344:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,344:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,344:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,344:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,395:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:13,395:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,395:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,395:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,395:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,395:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,449:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.
2025-03-29 15:40:13,449:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,449:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,449:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,449:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,449:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,500:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:40:13,500:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,500:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,500:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,500:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,500:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,550:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:13,550:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,550:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,550:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,550:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,550:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,601:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:40:13,601:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,601:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,601:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,601:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,601:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.
2025-03-29 15:40:13,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,654:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,654:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,654:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:40:13,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,703:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,703:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,703:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,753:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:40:13,753:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,753:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,753:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,753:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,753:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,802:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-29 15:40:13,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,803:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,803:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,803:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,803:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,851:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:40:13,852:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,852:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,852:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,852:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,852:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:13,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,901:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,901:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,901:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:13,951:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:40:13,951:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:13,951:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:13,951:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:13,951:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:13,951:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:14,001:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:14,001:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,001:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:40:14,001:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:14,001:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:14,051:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:40:14,051:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,051:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,051:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:14,051:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:14,051:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:14,099:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-03-29 15:40:14,099:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,099:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,100:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:14,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:14,100:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:14,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:40:14,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,147:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:14,147:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:14,147:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:14,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:40:14,194:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,195:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:14,195:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:14,195:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:14,241:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:14,242:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,242:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,242:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:14,242:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:14,242:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:14,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:40:14,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,289:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:14,289:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:14,289:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:14,335:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:40:14,335:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,335:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,335:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:14,335:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:14,335:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:14,383:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.
2025-03-29 15:40:14,383:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,383:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,383:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:40:14,383:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 6
2025-03-29 15:40:14,383:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:14,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:40:14,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,439:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,439:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,439:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:14,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:40:14,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,497:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,497:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,497:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:14,552:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:40:14,552:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,552:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,552:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,552:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,552:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:14,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.
2025-03-29 15:40:14,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,604:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,604:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,605:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:14,659:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:14,659:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,659:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,659:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,659:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,659:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:14,710:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:14,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,710:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,710:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,710:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:14,762:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:40:14,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,762:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,762:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,763:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,763:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:14,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:14,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,815:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,815:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,815:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:14,865:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:40:14,865:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,865:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,865:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,865:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,866:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:14,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:14,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,916:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,916:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,916:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:14,967:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:40:14,967:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:14,967:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:14,967:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:14,967:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:14,967:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,018:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:40:15,018:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,018:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:15,018:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,018:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-29 15:40:15,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,069:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:15,070:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,070:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.
2025-03-29 15:40:15,133:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,133:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,133:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:40:15,133:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:15,133:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,181:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:40:15,181:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,181:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,181:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:15,181:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:15,182:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,231:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:40:15,231:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,231:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,231:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:15,231:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:15,231:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,280:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:15,280:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,280:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,280:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:15,280:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:15,280:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,327:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-03-29 15:40:15,327:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,328:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,328:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:15,328:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:40:15,328:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,376:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.
2025-03-29 15:40:15,376:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,376:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,376:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:15,376:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:40:15,376:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-03-29 15:40:15,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,424:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:15,424:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:40:15,424:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,473:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:40:15,473:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,473:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,473:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:15,473:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:40:15,473:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:15,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:40:15,532:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,532:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:15,532:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,532:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:15,585:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:40:15,585:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,585:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,585:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:15,586:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,586:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:15,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:40:15,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,638:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:15,638:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,639:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:15,691:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:15,691:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,691:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,691:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:15,691:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,691:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:15,742:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:40:15,743:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,743:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,743:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:15,743:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,743:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:15,794:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:40:15,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,794:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:15,794:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,794:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:15,844:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:40:15,844:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,844:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,844:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:15,844:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,844:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:15,897:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:40:15,897:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,897:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,897:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:15,897:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,897:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:15,947:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:40:15,947:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,947:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,947:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:15,947:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,947:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:15,998:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:40:15,998:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:15,998:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:15,998:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:15,998:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:15,998:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:40:16,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,049:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:16,049:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:16,049:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,099:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000645 seconds.
2025-03-29 15:40:16,099:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,099:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,099:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:16,099:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:16,099:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,149:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000723 seconds.
2025-03-29 15:40:16,149:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:40:16,149:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:16,149:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:16,150:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,205:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:40:16,206:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,206:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,206:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:16,206:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:16,206:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:40:16,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,254:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:16,254:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:16,254:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.
2025-03-29 15:40:16,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,303:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:16,303:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:16,303:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:40:16,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,351:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:16,351:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:16,351:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,398:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.
2025-03-29 15:40:16,398:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,398:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,398:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:16,398:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:40:16,398:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,446:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:16,446:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,446:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,446:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:16,446:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:40:16,446:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:40:16,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,493:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:16,493:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:40:16,493:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-03-29 15:40:16,540:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,540:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,540:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:40:16,540:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 7
2025-03-29 15:40:16,540:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:16,622:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:40:16,622:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,622:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,622:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:16,622:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:16,622:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:16,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:40:16,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,678:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:16,678:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:16,678:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:16,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:40:16,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,737:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:16,737:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:16,737:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:16,786:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.
2025-03-29 15:40:16,786:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,786:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,786:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:16,786:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:16,786:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:16,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
2025-03-29 15:40:16,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,842:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:16,842:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:16,843:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:16,896:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:40:16,896:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,896:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,896:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:16,896:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:16,897:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:16,946:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:40:16,946:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,946:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,946:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:16,946:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:16,946:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:16,996:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:40:16,996:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:16,996:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:16,996:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:16,996:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:16,996:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,044:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:40:17,045:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,045:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:17,045:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,045:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,095:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-03-29 15:40:17,095:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,095:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,095:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:17,095:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,095:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,144:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:17,144:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,144:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:17,144:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,144:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:40:17,194:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,194:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,195:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:17,195:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,195:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,245:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:40:17,245:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,245:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,245:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:17,245:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,245:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:40:17,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,296:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:17,296:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:17,296:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:40:17,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,346:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:17,346:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:17,346:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:40:17,418:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,418:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,418:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:17,418:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:17,418:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,467:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:40:17,467:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,467:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,467:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:17,467:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:17,467:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,518:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.
2025-03-29 15:40:17,518:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,518:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,518:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:17,518:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:17,518:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,566:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:17,566:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,566:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,566:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:17,567:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:17,567:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:40:17,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,614:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:17,614:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:17,614:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,662:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:17,662:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,662:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,662:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:17,662:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:17,662:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:17,719:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:40:17,719:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,719:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,719:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:17,719:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,719:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:17,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:17,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,772:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:17,772:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,772:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:17,824:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.
2025-03-29 15:40:17,824:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,824:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,824:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:17,824:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,824:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:17,875:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:40:17,875:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,875:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,876:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:17,876:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,876:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:17,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:40:17,926:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,926:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,927:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:17,927:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,927:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:17,977:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:17,978:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:17,978:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:17,978:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:17,978:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:17,978:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:40:18,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,034:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:18,034:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,034:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,091:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-03-29 15:40:18,091:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,091:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,091:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:18,091:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,091:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,140:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:18,140:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,140:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,140:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:18,140:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,140:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,189:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:40:18,189:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,189:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,189:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:18,189:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,189:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:40:18,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,238:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:18,238:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,238:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:40:18,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,288:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:18,288:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,288:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,335:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:40:18,335:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,335:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,335:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:18,335:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,335:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,385:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:18,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,386:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:18,386:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:18,386:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,435:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:40:18,435:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,435:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,435:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:18,435:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:18,435:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:18,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,485:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,485:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:18,485:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:18,485:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:40:18,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,533:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:18,533:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:18,534:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,585:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:40:18,585:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,585:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,585:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:18,585:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:18,585:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000710 seconds.
2025-03-29 15:40:18,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,633:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:18,633:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:18,633:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,682:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000770 seconds.
2025-03-29 15:40:18,682:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,682:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,682:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:18,682:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:18,682:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,729:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-29 15:40:18,729:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,729:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,729:INFO:[LightGBM] [Info] Total Bins 534
2025-03-29 15:40:18,729:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:18,729:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:18,786:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:18,786:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,786:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,786:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:18,786:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,786:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:18,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:18,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,838:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:18,838:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,838:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:18,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:40:18,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,889:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:18,889:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,889:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:18,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:40:18,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,940:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:18,940:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,940:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:18,991:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:18,991:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:18,991:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:18,991:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:18,991:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:18,992:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,042:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:19,042:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,042:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,042:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:19,042:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:19,042:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,093:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:40:19,093:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,093:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,093:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:19,093:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:19,093:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:19,143:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,143:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,143:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:19,143:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:19,143:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,191:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:19,192:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,192:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,192:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:19,192:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:19,192:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,241:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-03-29 15:40:19,241:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,241:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,241:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:19,241:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:19,241:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:19,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,290:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:19,290:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:19,290:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,336:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:19,336:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,336:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,336:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:19,336:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:19,336:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:40:19,384:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,384:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,385:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:19,385:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:19,385:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,433:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:40:19,434:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,434:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,434:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:19,434:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:19,434:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:19,482:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,482:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:19,482:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:19,482:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,529:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.
2025-03-29 15:40:19,530:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,530:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,530:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:19,530:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:19,530:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,576:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:40:19,577:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,577:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,577:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:19,577:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:19,577:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,623:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-03-29 15:40:19,623:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,623:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,623:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:19,624:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:19,624:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,671:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:40:19,671:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,671:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,671:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:19,671:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:19,671:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:40:19,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,717:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:19,717:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:19,717:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,761:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:40:19,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,761:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:19,761:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:19,762:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:19,816:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:40:19,816:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,816:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,816:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:19,816:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:19,816:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:19,864:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.
2025-03-29 15:40:19,864:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,864:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,864:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:19,865:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:19,865:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:19,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:40:19,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,915:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,915:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:19,915:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:19,915:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:19,963:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:40:19,963:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:19,964:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:19,964:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:19,964:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:19,964:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-03-29 15:40:20,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,012:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:20,012:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:20,012:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-03-29 15:40:20,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,061:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:20,061:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:20,061:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:40:20,109:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,109:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,109:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:20,109:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:20,109:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:40:20,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,157:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:20,158:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:20,158:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:40:20,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,204:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:20,204:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:20,204:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:20,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,251:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:20,251:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:20,251:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,298:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-29 15:40:20,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,299:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:20,299:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:20,299:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,345:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:40:20,345:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,345:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,345:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:20,345:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:20,345:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.
2025-03-29 15:40:20,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,392:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:20,392:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:20,392:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:40:20,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,439:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:20,439:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:20,439:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-29 15:40:20,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,485:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,485:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:20,485:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:20,485:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,530:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:40:20,530:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,530:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,530:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:20,530:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:20,531:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,586:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:40:20,586:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,586:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,586:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:20,586:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:20,587:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,634:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:40:20,634:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,634:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,634:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:20,634:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:20,634:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,682:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:40:20,682:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,682:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,682:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:20,682:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:20,682:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000444 seconds.
2025-03-29 15:40:20,727:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,727:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:40:20,727:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:20,728:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,775:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:20,775:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,775:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,775:INFO:[LightGBM] [Info] Total Bins 537
2025-03-29 15:40:20,775:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:20,776:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:20,831:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:40:20,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,831:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:20,831:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:20,831:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:20,880:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:40:20,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,880:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:20,881:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:20,881:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:20,928:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-29 15:40:20,928:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,928:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,928:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:20,928:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:20,928:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:20,976:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:40:20,976:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:20,976:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:20,976:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:20,976:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:20,976:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:40:21,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,024:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:21,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,024:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:40:21,073:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,073:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,073:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:21,073:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,073:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:40:21,120:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,120:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,120:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:21,120:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,120:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,169:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:40:21,169:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,169:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,169:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:21,169:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,169:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,216:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-03-29 15:40:21,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,216:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,216:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:21,216:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,216:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,262:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:40:21,262:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,262:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,262:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:21,262:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,262:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,308:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:40:21,309:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,309:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,309:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:21,309:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,309:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:21,355:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,355:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,355:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:21,355:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,355:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,401:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:21,401:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,401:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,401:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:21,401:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,402:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:40:21,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,447:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,447:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:21,447:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:21,447:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:40:21,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,496:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:21,496:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:21,496:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,541:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:40:21,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,541:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:21,541:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:21,541:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,586:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:40:21,586:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,587:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,587:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:21,587:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:21,587:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000730 seconds.
2025-03-29 15:40:21,634:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:40:21,634:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:21,634:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:21,634:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,690:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-29 15:40:21,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,690:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:21,690:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:21,691:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.
2025-03-29 15:40:21,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,738:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:21,738:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:21,738:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,786:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:40:21,786:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,786:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,786:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:21,786:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:21,786:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:21,844:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:21,844:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,844:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,844:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:21,844:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,845:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:21,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.
2025-03-29 15:40:21,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,900:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:21,900:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,900:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:21,950:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:40:21,951:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:21,951:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:21,951:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:21,951:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:21,951:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,002:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:40:22,002:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,002:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,002:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,002:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,002:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:40:22,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,054:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,054:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,054:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:22,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,104:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,104:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,104:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:40:22,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,155:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,155:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,155:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,205:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:40:22,205:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,205:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,205:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,205:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,205:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,256:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:40:22,256:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,256:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,256:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,256:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,256:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,306:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:40:22,307:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,307:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,307:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,307:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:40:22,356:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,356:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,356:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,356:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,356:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,405:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:40:22,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,405:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,405:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,405:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:40:22,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,454:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,454:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,454:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:40:22,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,503:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:22,503:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:22,503:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-03-29 15:40:22,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,554:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:22,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:22,554:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:40:22,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,603:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:22,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:22,603:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,653:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:40:22,653:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,653:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:22,653:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:22,653:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:40:22,702:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,702:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,702:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:22,702:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:22,702:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,750:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:40:22,750:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,750:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,750:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:22,750:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:22,750:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000693 seconds.
2025-03-29 15:40:22,800:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,800:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,800:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:22,800:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:22,800:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,848:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:40:22,848:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,848:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,848:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:40:22,848:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:22,849:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:22,906:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:40:22,906:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,906:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,906:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,906:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:22,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:22,957:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:22,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:22,957:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:22,957:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:22,957:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,008:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:23,008:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,008:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,008:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,008:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,009:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:23,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,060:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,060:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,060:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,060:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,111:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:40:23,111:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,111:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,111:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,111:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,111:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,161:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:23,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,161:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,161:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,161:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,161:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:40:23,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,211:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,211:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,211:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,262:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.
2025-03-29 15:40:23,262:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,262:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,262:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,262:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,262:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:23,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,312:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,312:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,312:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,361:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:40:23,361:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,361:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,361:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,361:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,361:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:40:23,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,409:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,409:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,410:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,460:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:40:23,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,460:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,460:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,460:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,460:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-29 15:40:23,515:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,515:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,515:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:23,515:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:23,516:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,591:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-03-29 15:40:23,591:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,591:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,591:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:23,591:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:23,591:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:40:23,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,665:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:23,666:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:23,666:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:40:23,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,736:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:23,736:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:23,736:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,809:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.
2025-03-29 15:40:23,809:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,809:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,809:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:23,809:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:23,809:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.
2025-03-29 15:40:23,882:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,882:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,882:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:23,882:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:23,882:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:23,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-03-29 15:40:23,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:23,952:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:23,952:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:23,952:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:23,953:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:24,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.
2025-03-29 15:40:24,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,024:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:24,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:24,024:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:24,078:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:40:24,078:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,078:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,078:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:24,078:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:24,079:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:24,135:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:24,135:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,135:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,135:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,135:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,135:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:24,186:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,186:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,186:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,186:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,186:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:24,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,237:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,237:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,237:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:40:24,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,288:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,288:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,288:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:24,337:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,337:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,338:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,338:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,338:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,387:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:24,387:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,387:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,387:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,387:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,387:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,438:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.
2025-03-29 15:40:24,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,438:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,438:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,438:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,438:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:24,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,487:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,488:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,488:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:40:24,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,538:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,538:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,538:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,538:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,586:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.
2025-03-29 15:40:24,587:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,587:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,587:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,587:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,587:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,634:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.
2025-03-29 15:40:24,634:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,634:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,634:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,634:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,634:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,684:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:40:24,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,684:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,684:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,684:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,730:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:24,730:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,730:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,730:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:24,730:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:24,730:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,778:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:40:24,778:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,778:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,778:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:40:24,778:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:24,778:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,825:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:24,825:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,825:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,825:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:24,825:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:24,825:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:40:24,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,871:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:24,871:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:24,871:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.
2025-03-29 15:40:24,918:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,918:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:24,918:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:24,918:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:24,965:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:40:24,966:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:24,966:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:24,966:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:24,966:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:24,966:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:25,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:40:25,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,012:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:25,012:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:25,012:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:25,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-03-29 15:40:25,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,061:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:25,061:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:25,061:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:25,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-03-29 15:40:25,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,109:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:25,109:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 7
2025-03-29 15:40:25,109:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:25,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:40:25,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,163:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,163:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,163:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:40:25,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,213:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,214:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,214:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,262:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2025-03-29 15:40:25,262:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,262:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,262:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,262:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,262:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:40:25,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,312:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,312:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,312:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:40:25,360:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,360:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,360:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,360:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,408:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:25,408:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,408:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,408:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,408:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,408:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:25,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,457:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,457:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,457:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.
2025-03-29 15:40:25,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,506:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,506:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,506:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:25,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,554:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,554:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:40:25,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,602:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,602:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,602:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:25,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,652:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,652:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,652:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.
2025-03-29 15:40:25,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,699:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,699:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,699:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:25,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,746:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,746:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:25,746:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:25,746:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.
2025-03-29 15:40:25,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,792:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:40:25,792:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:25,793:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,840:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:40:25,840:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,840:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,840:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:25,840:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:25,840:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,887:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:40:25,887:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,887:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,887:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:25,888:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:25,888:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:25,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,933:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:25,933:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:25,934:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:25,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:40:25,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:25,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:25,979:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:25,979:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:40:25,979:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:26,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.
2025-03-29 15:40:26,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,025:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,025:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:26,025:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:40:26,025:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:26,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:40:26,071:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,071:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,071:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:26,071:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:40:26,071:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:26,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:40:26,125:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,125:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,125:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,125:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,125:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:40:26,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,176:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,176:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,176:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,225:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:40:26,225:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,225:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,225:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,225:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,225:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,273:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:40:26,273:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,273:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,273:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,273:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,273:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.
2025-03-29 15:40:26,321:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,321:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,321:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,321:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,369:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:26,369:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,369:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,369:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,369:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.
2025-03-29 15:40:26,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,417:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,417:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,417:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,464:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:40:26,464:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,464:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,465:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,465:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,465:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:26,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,512:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,512:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,512:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,559:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:26,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,559:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,559:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,559:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,560:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,606:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:40:26,606:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,606:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,606:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,606:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,606:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,655:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:40:26,655:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,655:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,655:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,655:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,655:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:40:26,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,729:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:26,729:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:26,729:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,808:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:26,808:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,808:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,808:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:26,808:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:26,808:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,884:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:40:26,884:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,884:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,884:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:26,884:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:26,885:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:26,963:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:40:26,964:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:26,964:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:26,964:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:26,964:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:26,964:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:27,037:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.
2025-03-29 15:40:27,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,037:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:27,037:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:27,037:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:27,113:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-03-29 15:40:27,113:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,113:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,113:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:27,113:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:40:27,113:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:27,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:40:27,186:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,186:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,186:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:27,187:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:40:27,187:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:27,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:40:27,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,259:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:27,259:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 8
2025-03-29 15:40:27,259:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:27,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:40:27,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,346:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:27,346:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:27,346:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:27,427:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:40:27,427:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,427:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,427:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:27,427:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:27,428:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:27,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:40:27,504:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,504:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,504:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:27,504:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:27,504:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:27,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:40:27,580:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,580:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,580:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:27,580:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:27,580:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:27,657:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:40:27,657:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,657:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,657:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:27,657:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:27,657:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:27,729:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:40:27,729:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,729:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,729:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:27,729:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:27,729:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:27,803:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.
2025-03-29 15:40:27,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,804:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:27,804:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:27,804:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:27,880:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000614 seconds.
2025-03-29 15:40:27,880:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:40:27,880:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:27,880:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:27,881:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:27,967:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:40:27,967:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:27,967:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:27,967:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:27,967:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:27,967:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:40:28,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,024:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:28,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,024:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,079:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:40:28,079:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,079:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,079:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:28,079:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,079:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,133:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:40:28,133:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,133:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,133:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:28,133:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,133:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,184:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:40:28,184:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,184:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,184:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:28,184:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,185:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,235:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.
2025-03-29 15:40:28,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,235:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:28,235:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:28,235:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,286:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:40:28,286:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,286:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,286:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:28,286:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:28,287:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:28,337:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,337:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,337:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:28,337:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:28,337:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,387:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:28,387:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,387:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,387:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:28,387:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:28,387:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,438:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-03-29 15:40:28,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,438:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,438:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:28,438:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:28,438:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:40:28,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,487:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:28,487:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:28,487:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,536:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:40:28,536:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,536:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,536:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:28,536:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:28,537:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:28,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:28,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,597:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:28,598:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,598:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:28,656:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-29 15:40:28,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,656:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:28,656:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,656:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:28,708:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:28,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,709:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:28,709:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,709:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:28,762:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:28,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,762:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,762:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:28,762:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,762:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:28,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000708 seconds.
2025-03-29 15:40:28,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:40:28,816:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:28,816:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,817:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:28,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:28,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,876:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:28,876:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,876:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:28,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:28,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,927:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:28,927:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,927:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:28,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:40:28,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:28,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:28,979:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:28,979:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:28,979:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,030:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:29,030:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,030:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,030:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:29,030:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,030:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,086:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:40:29,086:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,086:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,086:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:29,086:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,086:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:29,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,142:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,142:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:29,142:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,142:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:40:29,194:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,194:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,194:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:29,194:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,194:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,241:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:29,241:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,241:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,241:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:29,241:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,242:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:29,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,289:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:29,289:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:29,289:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,336:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:40:29,336:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,336:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,336:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:29,336:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:29,336:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,382:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:40:29,383:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,383:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,383:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:29,383:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:29,383:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,432:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.
2025-03-29 15:40:29,432:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,432:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,432:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:29,432:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:29,432:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.
2025-03-29 15:40:29,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,478:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:29,478:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:29,479:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:40:29,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,525:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:29,525:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:29,525:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,571:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:40:29,571:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,571:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,571:INFO:[LightGBM] [Info] Total Bins 536
2025-03-29 15:40:29,571:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:29,571:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:29,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:29,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,625:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:29,625:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,625:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:29,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:40:29,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,676:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:29,676:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,676:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:29,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:29,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,726:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:29,726:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,726:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:29,776:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:29,776:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,776:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,777:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:29,777:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,777:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:29,825:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:29,825:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,825:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,825:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:29,826:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,826:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:29,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:40:29,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,874:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:29,874:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,874:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:29,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:29,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,923:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,923:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:29,923:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,924:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:29,971:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:29,971:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:29,971:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:29,971:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:29,972:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:29,972:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,019:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:30,019:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,019:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,019:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:30,019:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:30,020:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,066:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:40:30,066:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,066:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,066:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:30,067:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:30,067:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:30,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,118:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:30,118:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:30,118:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,171:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-03-29 15:40:30,171:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,171:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,171:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:30,171:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:30,171:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,221:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:40:30,221:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,221:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,221:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:30,221:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:30,221:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:40:30,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,274:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:30,274:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:30,275:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:40:30,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,324:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:30,324:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:30,324:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,373:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:40:30,373:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,373:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,373:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:30,373:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:30,374:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,430:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:40:30,430:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,430:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,430:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:30,430:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:30,430:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:30,479:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,479:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,479:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:30,479:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:30,479:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.
2025-03-29 15:40:30,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,526:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:30,526:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:30,526:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,574:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:40:30,575:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,575:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,575:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:30,575:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:30,575:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:30,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
2025-03-29 15:40:30,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,633:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:30,633:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:30,633:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:30,687:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:30,688:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,688:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,688:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:30,688:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:30,688:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:30,739:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:40:30,739:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,739:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,739:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:30,739:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:30,740:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:30,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:30,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,792:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:30,792:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:30,792:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:30,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:40:30,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,842:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:30,842:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:30,843:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:30,893:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:40:30,893:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,893:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,894:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:30,894:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:30,894:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:30,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:40:30,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,944:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:30,944:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:30,944:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:30,995:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:40:30,995:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:30,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:30,995:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:30,995:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:30,995:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,049:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:40:31,049:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,049:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,049:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:31,049:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:31,049:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.
2025-03-29 15:40:31,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,100:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:31,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:31,100:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,153:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.
2025-03-29 15:40:31,153:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,153:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,154:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:31,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:31,154:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.
2025-03-29 15:40:31,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,210:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:31,210:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:31,210:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-03-29 15:40:31,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,259:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:31,259:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:31,259:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,307:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:31,307:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,307:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:31,307:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:31,308:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,357:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-03-29 15:40:31,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,357:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:31,357:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:31,357:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,405:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:40:31,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,405:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:31,405:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:31,405:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,453:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.
2025-03-29 15:40:31,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,453:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:31,453:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:31,453:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:40:31,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,512:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:31,512:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:31,512:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:40:31,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,561:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:31,561:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:31,561:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:40:31,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,609:INFO:[LightGBM] [Info] Total Bins 539
2025-03-29 15:40:31,609:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:31,609:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:31,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:40:31,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,668:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,668:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:31,668:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:31,668:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:31,718:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:40:31,718:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,718:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,718:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:31,718:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:31,718:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:31,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:40:31,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,769:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,769:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:31,769:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:31,769:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:31,820:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:40:31,820:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,820:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,821:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:31,821:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:31,821:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:31,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:40:31,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,874:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:31,874:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:31,875:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:31,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:31,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,927:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:31,927:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:31,927:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:31,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:40:31,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:31,980:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:31,980:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:31,980:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:31,980:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.
2025-03-29 15:40:32,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,033:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:32,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,033:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:32,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,084:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:32,084:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,084:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,134:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:40:32,134:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,134:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,134:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:32,135:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,135:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,189:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:32,189:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,189:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,189:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:32,189:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,189:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,241:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:40:32,241:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,241:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,241:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:32,241:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,242:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,292:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:40:32,292:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,292:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,292:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:32,292:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,292:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,347:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:32,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,347:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:32,347:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:32,347:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:40:32,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,397:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:32,397:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:32,398:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,446:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:40:32,446:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,446:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,446:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:32,446:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:32,446:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,496:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:40:32,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,496:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:32,496:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:32,496:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:40:32,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,544:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:32,544:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:32,544:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:40:32,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,592:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:32,592:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:32,593:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:32,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,642:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:32,642:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:32,642:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:32,698:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:32,698:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,698:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,698:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:32,698:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,699:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:32,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.
2025-03-29 15:40:32,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,749:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:32,749:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,750:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:32,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:40:32,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,802:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:32,802:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,802:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:32,851:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:40:32,851:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,851:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,851:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:32,851:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,852:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:32,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:32,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,901:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:32,901:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,901:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:32,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:40:32,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:32,952:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:32,952:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:32,952:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:32,952:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,002:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:33,002:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,002:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,002:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,003:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,003:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,052:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:40:33,052:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,052:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,052:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,052:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,052:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:40:33,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,102:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,102:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,102:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,151:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:33,152:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,152:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,152:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,152:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,152:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,205:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:33,205:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,205:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,205:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,205:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,205:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,255:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:33,256:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,256:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,256:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,256:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,256:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:40:33,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,303:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,303:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,303:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:40:33,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,350:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:33,350:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:33,350:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,398:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:40:33,398:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,398:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,398:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:33,398:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:33,398:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:40:33,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,447:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,447:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:33,447:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:33,447:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:40:33,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,496:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:33,496:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:33,496:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:40:33,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,543:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:33,543:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:33,544:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:40:33,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,592:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:33,592:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:33,592:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:40:33,642:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,642:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:33,642:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:33,642:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:33,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:33,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,703:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,703:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,703:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:33,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:40:33,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,756:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,756:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,756:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:33,808:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:33,808:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,808:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,809:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,809:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,809:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:33,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:33,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,862:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,862:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,862:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:33,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:40:33,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,915:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,915:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,915:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,915:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:33,967:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:40:33,967:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:33,967:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:33,968:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:33,968:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:33,968:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:34,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,023:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:34,023:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,023:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:40:34,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,076:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:34,076:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,076:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,127:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:34,127:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,127:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,127:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:34,127:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,127:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,178:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:34,178:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,178:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,179:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:34,179:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,179:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,233:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000490 seconds.
2025-03-29 15:40:34,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,233:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,233:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:34,233:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,233:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:34,287:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,287:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,287:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:34,287:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,287:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:34,337:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,337:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,337:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:34,337:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,337:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,386:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:34,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,386:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:34,386:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:34,386:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,435:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:40:34,435:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,435:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,435:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:34,435:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:34,436:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.
2025-03-29 15:40:34,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,485:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,485:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:34,485:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:34,485:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,534:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:40:34,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,534:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:34,535:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:34,535:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,583:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.
2025-03-29 15:40:34,583:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,583:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,583:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:34,583:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:34,584:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,631:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:40:34,631:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,631:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,631:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:34,631:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:34,631:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,681:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:40:34,681:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,681:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,681:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:34,681:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:34,681:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:34,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:40:34,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,737:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:34,737:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,737:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:34,789:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:40:34,789:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,789:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,789:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:34,789:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,789:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:34,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:40:34,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,842:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:34,842:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,842:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:34,892:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:34,892:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,892:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,892:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:34,892:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,893:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:34,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:34,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,945:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:34,945:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,945:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:34,996:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:40:34,996:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:34,996:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:34,996:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:34,996:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:34,996:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:40:35,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,048:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:35,048:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:35,048:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:40:35,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,100:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:35,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:35,100:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:40:35,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,150:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,151:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:35,151:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:35,151:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:40:35,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,200:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:35,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:35,201:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:35,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,254:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:35,254:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:35,254:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,307:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:40:35,307:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,307:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:35,307:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:35,307:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,356:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:40:35,356:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,356:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,356:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:35,356:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:35,356:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,405:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:35,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,405:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:40:35,405:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:35,405:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:40:35,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,454:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:35,454:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:35,454:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,504:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:40:35,504:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,504:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,504:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:35,504:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:35,504:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:35,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,553:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:35,553:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:35,553:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:40:35,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,603:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:35,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:35,603:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:35,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,652:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:35,652:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:35,652:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:40:35,700:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,700:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,700:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:35,700:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 8
2025-03-29 15:40:35,700:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:35,757:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:35,757:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,757:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,757:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:35,757:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:35,757:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:35,810:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:40:35,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,810:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:35,810:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:35,810:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:35,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:40:35,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,863:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:35,863:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:35,863:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:35,914:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:40:35,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,915:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:35,915:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:35,915:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:35,966:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:40:35,967:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:35,967:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:35,967:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:35,967:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:35,967:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,017:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:36,017:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,017:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,017:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:36,018:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,018:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:36,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,069:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:36,069:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,069:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,118:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:36,118:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,118:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,118:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:36,119:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,119:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,169:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:36,169:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,170:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,170:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:36,170:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,170:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,219:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:36,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,219:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,219:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:36,219:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,219:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,275:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:40:36,275:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,275:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,275:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:36,275:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,275:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,330:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:36,330:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,330:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,330:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:36,330:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,330:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-03-29 15:40:36,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:40:36,381:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:36,381:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,381:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:36,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,439:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:40:36,439:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:36,439:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,490:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-03-29 15:40:36,490:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,490:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,490:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:36,490:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:36,490:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-03-29 15:40:36,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,543:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:36,543:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:36,543:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:40:36,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,592:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:36,592:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:36,593:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:40:36,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,644:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:36,644:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:40:36,644:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,697:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:40:36,698:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,698:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,698:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:36,698:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:40:36,698:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:36,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:40:36,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,756:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:36,756:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,756:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:36,828:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:40:36,828:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,828:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,828:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:36,828:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,828:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:36,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:40:36,882:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,882:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,882:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:36,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,883:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:36,942:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:40:36,943:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:36,943:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:36,943:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:36,943:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:36,943:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:37,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,024:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:37,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:37,025:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,115:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.
2025-03-29 15:40:37,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,115:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:37,115:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:37,115:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,192:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:40:37,192:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,192:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,192:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:37,192:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:37,192:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-29 15:40:37,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,270:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:37,271:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:37,271:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:40:37,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,322:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:37,322:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:37,322:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:40:37,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,375:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:37,375:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:37,375:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,438:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:40:37,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,438:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,439:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:37,439:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:37,439:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,519:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-03-29 15:40:37,519:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,519:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:37,519:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:37,519:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,594:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:40:37,594:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,594:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,594:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:37,594:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:37,594:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:40:37,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,678:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:37,678:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:37,678:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,733:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.
2025-03-29 15:40:37,733:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,733:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,733:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:37,733:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:37,734:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000587 seconds.
2025-03-29 15:40:37,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:40:37,783:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:37,783:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:37,783:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:40:37,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,838:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:37,838:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:37,839:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:40:37,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,890:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,890:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:37,890:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:40:37,890:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,937:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:40:37,938:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,938:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,938:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:37,938:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 9
2025-03-29 15:40:37,938:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:37,996:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:37,996:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:37,996:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:37,996:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:37,996:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:37,996:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:40:38,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,048:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,048:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,048:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:40:38,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,100:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,100:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,151:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:40:38,151:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,151:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,151:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,151:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,151:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:40:38,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,202:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,202:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,202:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:40:38,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,251:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,252:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,252:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:38,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,301:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,301:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,301:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,349:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:38,349:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,349:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,349:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,349:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,349:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,396:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:40:38,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,397:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,397:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,397:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,445:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:38,445:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,445:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,445:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,445:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,445:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:38,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,497:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,497:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,497:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,548:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:40:38,548:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,548:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,548:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,548:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,549:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:40:38,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,596:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:38,596:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,596:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,643:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:40:38,643:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,643:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,643:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:38,643:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:38,644:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,692:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:38,692:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,692:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,692:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:38,692:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:38,692:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:40:38,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,738:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:38,739:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:38,739:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,784:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:40:38,784:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,784:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:38,784:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:38,784:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,830:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:40:38,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,830:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:38,830:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:38,830:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,875:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.
2025-03-29 15:40:38,875:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,875:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,875:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:38,876:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:38,876:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:38,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:38,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,930:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:38,930:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,930:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:38,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:40:38,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:38,980:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:38,980:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:38,980:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:38,980:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,034:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:39,034:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,034:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,034:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,034:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,034:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:40:39,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,084:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,084:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,085:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.
2025-03-29 15:40:39,132:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,132:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,132:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,132:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,180:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.
2025-03-29 15:40:39,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,180:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,180:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,180:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,234:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:40:39,234:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,234:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,234:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,234:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,234:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.
2025-03-29 15:40:39,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,285:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,285:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,285:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,285:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,335:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:40:39,335:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,335:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,335:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,335:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,335:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,386:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:39,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,386:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,386:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,386:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,446:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:40:39,446:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,446:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,446:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,446:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,446:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:39,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,501:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,501:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,502:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,550:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:40:39,550:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,550:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,550:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:39,550:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,550:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,601:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:40:39,601:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,601:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,601:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:39,601:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:39,601:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:40:39,651:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,651:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:39,651:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:39,651:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-03-29 15:40:39,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,699:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:39,699:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:39,699:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,747:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:39,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,747:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:39,747:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:39,747:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,796:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:40:39,796:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,796:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,796:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:39,796:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:39,796:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:40:39,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,843:INFO:[LightGBM] [Info] Total Bins 538
2025-03-29 15:40:39,843:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:39,843:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:39,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.
2025-03-29 15:40:39,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,900:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:39,900:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,900:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:39,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:39,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:39,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:39,953:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:39,953:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:39,953:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:40:40,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,003:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,003:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,004:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:40,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,054:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,054:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,055:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:40,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,104:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,104:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,105:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,153:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:40,153:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,154:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,154:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,203:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:40,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,204:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,204:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,204:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:40,253:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,253:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,253:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,253:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,254:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:40,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,303:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,304:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,304:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,352:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:40,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,352:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,352:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,352:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,405:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:40,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,405:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,405:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,405:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,458:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.
2025-03-29 15:40:40,458:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,458:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,458:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,458:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,458:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,506:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:40,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,506:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,506:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,506:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:40,555:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,555:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,555:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:40,555:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:40,555:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:40:40,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,604:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:40,604:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:40,604:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,655:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:40,655:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,655:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,655:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:40,655:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:40,655:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:40:40,702:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,702:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,702:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:40,702:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:40,702:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:40:40,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,749:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:40,749:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:40,749:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,796:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:40:40,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,797:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:40,797:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:40,797:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:40,852:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:40,852:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,852:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,852:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:40,852:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:40,852:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:40,905:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:40:40,905:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,905:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,905:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:40,905:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:40,905:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:40,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:40:40,957:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:40,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:40,957:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:40,957:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:40,957:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,010:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:40:41,010:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,010:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,010:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,010:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,010:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:40:41,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,068:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,068:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,068:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:40:41,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,142:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,142:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,142:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,142:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:40:41,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,211:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,211:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,211:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:40:41,287:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,287:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,287:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,287:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,287:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,356:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:40:41,356:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,356:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,356:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,356:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,356:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,408:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:40:41,408:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,408:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,408:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,408:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,408:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,465:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-29 15:40:41,465:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,465:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,465:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,465:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,465:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,524:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:40:41,524:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,524:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,524:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,524:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,524:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:40:41,573:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,573:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,573:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,573:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,573:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,623:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:40:41,623:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,623:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,623:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:41,623:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:41,623:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,675:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:40:41,675:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,675:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:41,675:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:41,675:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,723:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:41,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,723:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:41,723:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:41,723:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:40:41,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,771:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:41,771:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:41,771:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,818:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.
2025-03-29 15:40:41,818:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,818:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,818:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:41,818:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:41,818:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,866:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.
2025-03-29 15:40:41,866:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,866:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,866:INFO:[LightGBM] [Info] Total Bins 541
2025-03-29 15:40:41,866:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:41,866:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:41,922:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:41,922:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,922:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,922:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:41,922:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:41,922:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:41,974:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:41,974:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:41,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:41,974:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:41,974:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:41,975:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:42,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,025:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,025:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,025:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,025:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:40:42,073:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,073:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,074:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,074:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,074:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,122:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:40:42,122:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,122:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,122:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,122:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,122:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,171:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:40:42,171:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,171:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,171:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,171:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,171:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,222:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:42,222:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,222:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,222:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,222:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,222:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,272:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:42,273:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,273:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,273:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,273:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,273:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,320:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:42,320:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,321:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,321:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,321:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,369:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:40:42,369:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,369:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,369:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,369:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,421:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:40:42,421:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,421:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,421:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,421:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,422:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,491:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:40:42,491:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,491:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,491:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,491:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,491:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,546:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:42,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,547:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:42,547:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:42,547:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,598:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:40:42,598:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,598:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,598:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:42,598:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:42,598:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-03-29 15:40:42,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,652:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:42,652:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:42,653:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.
2025-03-29 15:40:42,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,721:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,721:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:42,721:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:42,721:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:42,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,792:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:42,792:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:42,792:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.
2025-03-29 15:40:42,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,862:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:42,862:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:42,862:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:42,934:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000577 seconds.
2025-03-29 15:40:42,934:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:42,934:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:42,934:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:42,934:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:42,934:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:43,015:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:40:43,015:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,015:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,015:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,015:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,015:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:40:43,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,092:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,092:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,092:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,168:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:40:43,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,168:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,168:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,168:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,243:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:40:43,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,243:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,243:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,243:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,243:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:40:43,321:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,321:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,321:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,321:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:40:43,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,394:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,394:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,394:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:43,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,472:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,472:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,472:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,472:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,550:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.
2025-03-29 15:40:43,550:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,550:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,550:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,550:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,550:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.
2025-03-29 15:40:43,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,625:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,626:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,626:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,701:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.
2025-03-29 15:40:43,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,701:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,701:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,701:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,777:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-29 15:40:43,777:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,777:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,777:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,778:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,856:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:40:43,856:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,856:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,856:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,856:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,856:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,925:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-29 15:40:43,925:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,925:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,925:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:43,925:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:43,926:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:43,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:40:43,988:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:43,988:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:43,989:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:43,989:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:43,989:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:44,039:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:40:44,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,039:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:44,039:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:44,039:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:44,088:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:40:44,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,088:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:44,088:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:44,089:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:44,159:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:40:44,159:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,159:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,159:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:44,159:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:44,159:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:44,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:44,209:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,209:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,209:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:44,209:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:44,209:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:44,261:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:40:44,261:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,261:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,261:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:44,261:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:44,261:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:44,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:44,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,323:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,323:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,323:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,379:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:40:44,379:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,379:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,379:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,379:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,379:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:44,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,436:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,436:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,436:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:40:44,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,488:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,488:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,489:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2025-03-29 15:40:44,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,541:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,541:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,541:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:40:44,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,593:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,593:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,593:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:40:44,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,650:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,650:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,650:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:44,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,707:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,707:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,707:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,758:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:40:44,758:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,758:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,758:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,758:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,758:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,809:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:44,809:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,809:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,810:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,810:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,810:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,864:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:44,864:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,864:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,864:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,864:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,865:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:44,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,919:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,920:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,920:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:44,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:40:44,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:44,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:44,973:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:44,973:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:44,973:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:45,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:40:45,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,024:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:45,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:45,024:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:45,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:40:45,073:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,073:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,073:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:45,073:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:45,073:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:45,121:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000458 seconds.
2025-03-29 15:40:45,122:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,122:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,122:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:45,122:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:45,122:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:45,172:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:40:45,173:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,173:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,173:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:45,173:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:45,173:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:45,223:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:40:45,223:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,223:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,223:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:45,223:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:45,223:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:45,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:40:45,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,270:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:45,270:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:45,270:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:45,324:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:40:45,324:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,324:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,324:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,324:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,324:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,372:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:40:45,372:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,372:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,372:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,373:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,373:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,421:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:45,421:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,421:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,421:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,421:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,422:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:40:45,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,470:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,471:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,471:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,519:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:40:45,519:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,519:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,519:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,519:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,591:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:45,591:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,591:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,591:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,591:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,591:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:40:45,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,644:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,644:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,644:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,701:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:40:45,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,701:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,701:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,701:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:40:45,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,755:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,755:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,755:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,805:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:40:45,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,806:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,806:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,806:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-03-29 15:40:45,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,862:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,862:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,862:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:40:45,924:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,924:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,924:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,924:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,924:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:45,974:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:40:45,974:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:45,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:45,974:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:45,974:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:45,974:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:46,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:46,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,024:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:40:46,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:46,024:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:46,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:46,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,076:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:46,076:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:46,076:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:46,126:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-03-29 15:40:46,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,126:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:46,126:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:46,127:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:46,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-03-29 15:40:46,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,211:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:46,211:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:46,211:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:46,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:40:46,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,285:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,285:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:46,285:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:46,285:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:46,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000920 seconds.
2025-03-29 15:40:46,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,370:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:46,370:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 9
2025-03-29 15:40:46,370:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:46,459:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-03-29 15:40:46,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,460:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,460:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:46,460:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:46,460:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:46,536:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:40:46,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,537:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,537:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:46,537:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:46,537:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:46,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:40:46,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,627:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:46,627:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:46,627:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:46,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:40:46,688:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,688:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,688:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:46,688:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:46,688:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:46,742:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:40:46,742:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,742:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,742:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:46,742:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:46,743:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:46,803:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.
2025-03-29 15:40:46,803:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,803:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,803:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:46,803:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:46,804:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:46,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:40:46,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,878:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,878:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:46,878:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:46,878:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:46,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:46,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:46,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:46,955:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:46,955:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:46,955:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,043:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:40:47,044:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,044:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,044:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:47,044:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,044:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,123:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.
2025-03-29 15:40:47,123:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,123:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,123:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:47,123:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,123:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,206:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:40:47,206:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,206:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,206:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:47,206:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,206:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,279:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:40:47,279:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,279:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:47,279:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,279:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,331:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:40:47,331:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,331:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,331:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:47,331:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,331:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,389:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:40:47,389:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,389:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,389:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:40:47,389:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:47,390:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,466:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.
2025-03-29 15:40:47,467:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,467:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,467:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:47,467:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:47,467:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-03-29 15:40:47,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,525:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:47,525:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:47,526:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,588:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:40:47,588:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,588:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,588:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:47,588:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:47,588:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.
2025-03-29 15:40:47,642:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,642:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:47,642:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:40:47,642:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:47,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:40:47,702:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,702:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,702:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:47,702:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,702:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:47,752:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-03-29 15:40:47,752:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,752:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,752:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:47,752:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,752:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:47,802:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:40:47,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,802:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:47,802:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,802:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:47,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:40:47,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,850:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:47,850:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,850:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:47,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:40:47,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,902:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:47,902:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,902:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:47,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-03-29 15:40:47,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:47,952:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:47,953:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:47,953:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:47,953:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-03-29 15:40:48,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,012:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:48,012:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:48,012:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:40:48,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,065:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:48,065:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:48,065:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:40:48,120:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,120:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,120:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:48,120:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:48,120:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,177:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:48,178:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,178:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,178:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:48,178:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:48,178:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,246:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:40:48,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,246:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:48,246:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:48,247:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:40:48,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,302:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:48,302:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:48,303:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:48,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,351:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:48,351:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:48,351:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:40:48,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,397:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:48,397:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:48,397:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,443:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:40:48,444:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,444:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,444:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:48,444:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:48,444:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,490:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:48,490:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,490:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,490:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:48,491:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:48,491:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,541:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:40:48,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,541:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:48,541:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:48,541:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:48,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,592:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:48,593:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 10
2025-03-29 15:40:48,593:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:48,653:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:48,653:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,653:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:48,653:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:48,653:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:48,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:48,704:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,704:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,704:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:48,704:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:48,704:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:48,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:40:48,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,757:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:48,757:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:48,757:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:48,820:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:40:48,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,821:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:48,821:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:48,821:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:48,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:48,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,878:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,878:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:48,878:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:48,878:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:48,941:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.
2025-03-29 15:40:48,941:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,941:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,941:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:48,941:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:48,941:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:48,998:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:40:48,998:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:48,998:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:48,998:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:48,998:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:48,998:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,050:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:40:49,050:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,050:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,050:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:49,050:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:49,050:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,105:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:40:49,105:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,105:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,105:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:49,105:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:49,105:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:49,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,154:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:49,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:49,154:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:40:49,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,207:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:49,207:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:49,207:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,262:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:40:49,262:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,263:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:49,263:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:49,263:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,314:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:49,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,315:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:49,315:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:49,315:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,369:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:40:49,369:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,369:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:49,369:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:49,369:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,420:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:40:49,420:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,420:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,420:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:49,421:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:49,421:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:49,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,513:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:49,513:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:49,513:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.
2025-03-29 15:40:49,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,597:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:49,598:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:49,598:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-03-29 15:40:49,689:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,689:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,689:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:49,689:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:49,689:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:49,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
2025-03-29 15:40:49,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,772:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:49,772:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:49,772:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:49,855:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:40:49,855:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,855:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,855:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:49,855:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:49,855:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:49,932:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:40:49,932:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:49,932:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:49,932:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:49,932:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:49,932:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:40:50,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,006:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:50,006:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,006:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,062:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:40:50,062:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,062:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,062:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:50,062:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,062:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,118:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:40:50,118:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,118:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,118:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:50,118:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,118:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,172:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:40:50,172:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,172:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,172:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:50,172:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,172:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,224:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:40:50,224:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,224:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,225:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:50,225:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,225:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:40:50,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,274:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:50,274:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,274:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,325:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:50,325:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,325:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,325:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:50,325:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,326:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:50,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,377:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,377:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:50,377:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,377:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,431:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:40:50,431:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,431:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,431:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:50,431:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,431:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.
2025-03-29 15:40:50,484:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,484:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:50,484:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,485:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,534:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:40:50,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,534:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:50,534:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:50,534:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,584:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.
2025-03-29 15:40:50,584:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,584:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,584:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:50,584:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:50,585:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,630:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:40:50,630:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,630:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,630:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:50,631:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:50,631:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,681:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:40:50,681:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,681:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,681:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:50,681:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:50,681:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.
2025-03-29 15:40:50,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,727:INFO:[LightGBM] [Info] Total Bins 540
2025-03-29 15:40:50,727:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:50,727:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:40:50,783:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:40:50,783:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,783:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,783:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:50,783:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,783:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:50,834:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:40:50,834:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,834:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:50,834:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,834:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:50,884:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.
2025-03-29 15:40:50,884:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,884:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,884:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:50,884:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,885:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:50,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:40:50,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,933:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:50,933:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,933:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:50,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:40:50,983:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:50,983:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:50,983:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:50,983:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:50,983:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,042:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:40:51,042:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,042:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,042:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:51,042:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:51,043:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,094:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:40:51,094:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,094:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,094:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:51,094:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:51,094:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:51,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,147:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:51,147:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:51,147:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:40:51,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,201:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:51,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:51,201:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.
2025-03-29 15:40:51,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,251:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:51,251:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:51,251:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,306:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:40:51,306:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,306:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,306:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:51,306:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:51,306:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:51,358:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,358:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,358:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:51,358:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:51,358:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,408:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:40:51,408:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,408:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,408:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:51,408:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:51,408:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:40:51,475:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,475:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,475:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:51,475:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:51,475:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,548:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-03-29 15:40:51,548:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,548:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,548:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:51,548:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:51,548:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:51,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,626:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:51,626:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:51,626:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-03-29 15:40:51,702:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,702:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,702:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:51,702:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:51,702:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-03-29 15:40:51,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,767:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,767:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:51,767:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:51,767:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:40:51,824:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:51,824:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,824:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,824:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:51,824:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:51,825:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:51,891:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.
2025-03-29 15:40:51,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,891:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:51,891:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:51,891:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:51,958:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:40:51,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:51,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:51,958:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:51,958:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:51,958:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,020:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:40:52,020:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,020:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,020:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,020:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,021:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:40:52,075:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,075:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,075:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,075:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,075:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,127:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:40:52,127:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,127:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,127:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,127:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,127:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,178:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.
2025-03-29 15:40:52,179:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,179:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,179:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,179:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,179:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,229:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:40:52,229:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,229:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,229:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,229:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,229:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,282:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000288 seconds.
2025-03-29 15:40:52,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,283:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,283:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,283:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,332:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:52,332:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,332:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,332:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,332:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,332:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,386:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:40:52,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,387:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,387:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,387:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,387:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,444:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.
2025-03-29 15:40:52,444:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,444:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,444:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,444:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,444:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,492:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:40:52,492:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,492:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,492:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,492:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,492:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,539:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:40:52,539:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,539:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,539:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:52,539:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:52,540:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,586:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000277 seconds.
2025-03-29 15:40:52,586:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,586:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,586:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:52,586:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:52,586:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,639:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:40:52,639:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,639:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,639:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:52,639:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:52,639:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,687:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:40:52,687:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,687:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,688:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:52,688:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:52,688:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-03-29 15:40:52,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,736:INFO:[LightGBM] [Info] Total Bins 543
2025-03-29 15:40:52,736:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:52,736:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:40:52,793:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:52,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,794:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:52,794:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:52,794:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:52,846:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:40:52,846:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,846:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,846:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:52,846:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:52,846:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:52,897:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:52,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,898:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:52,898:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:52,898:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:52,948:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:40:52,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,948:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:52,948:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:52,948:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:52,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:40:52,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:52,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:52,997:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:52,997:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:52,997:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,045:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:53,045:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,045:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:53,045:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:53,046:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-29 15:40:53,120:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,120:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,120:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:53,120:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:53,120:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:53,177:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,177:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,177:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:53,177:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:53,177:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,229:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:53,229:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,230:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,230:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:53,230:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:53,230:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.
2025-03-29 15:40:53,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,285:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,285:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:53,285:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:53,286:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,340:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:40:53,340:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,341:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:53,341:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:53,341:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:40:53,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,393:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:53,393:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:53,393:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,441:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:40:53,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,442:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:53,442:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:53,442:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:40:53,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,493:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:53,493:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:53,493:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,583:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:40:53,583:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,583:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,583:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:53,583:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:53,584:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.
2025-03-29 15:40:53,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,665:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:53,666:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:53,666:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,778:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.
2025-03-29 15:40:53,778:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,778:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,778:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:53,778:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:53,779:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:53,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000622 seconds.
2025-03-29 15:40:53,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:53,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:53,883:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:53,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:53,883:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:40:54,000:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2025-03-29 15:40:54,000:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,000:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,001:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,001:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,001:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,086:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.
2025-03-29 15:40:54,086:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,086:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,086:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,086:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,087:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,170:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:54,170:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,171:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,171:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,171:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,171:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,224:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:54,224:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,224:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,224:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,224:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,224:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,275:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:40:54,275:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,275:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,275:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,275:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,276:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,332:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:40:54,333:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,333:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,333:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,333:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,333:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:40:54,384:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,385:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,385:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,385:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,385:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,437:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:40:54,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,438:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,438:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,438:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,438:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,489:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:40:54,489:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,489:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,489:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,489:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,489:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:40:54,540:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,540:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,540:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,541:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,541:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,594:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:40:54,594:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,594:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,594:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,594:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,595:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000713 seconds.
2025-03-29 15:40:54,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,650:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,650:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,650:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:40:54,704:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,704:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,705:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:54,705:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:54,705:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:40:54,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,782:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:40:54,782:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:54,782:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.
2025-03-29 15:40:54,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,858:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:54,858:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:54,858:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,938:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:40:54,938:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,938:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,938:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:54,938:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:54,938:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:54,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.
2025-03-29 15:40:54,989:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:54,989:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:54,989:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:54,989:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:54,989:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:55,036:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:40:55,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,036:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:40:55,036:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:55,036:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:40:55,095:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:40:55,095:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,095:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,095:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,095:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,095:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:55,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,147:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,147:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,147:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-03-29 15:40:55,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,201:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,201:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,252:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:55,252:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,252:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,252:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,252:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,252:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:55,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,301:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,301:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,301:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:40:55,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,350:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,350:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,350:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,399:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:40:55,399:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,399:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,399:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,400:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,400:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,449:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:40:55,449:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,449:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,449:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,450:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,450:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,500:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-03-29 15:40:55,500:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,500:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,500:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,501:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,501:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,550:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000681 seconds.
2025-03-29 15:40:55,550:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,550:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,550:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,550:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,550:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.
2025-03-29 15:40:55,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,603:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,603:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,656:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:40:55,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,656:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,656:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,656:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:40:55,704:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,704:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,704:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:40:55,704:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:55,704:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:40:55,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,751:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,751:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:55,751:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:55,751:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.
2025-03-29 15:40:55,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,807:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:55,807:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:55,807:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:40:55,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,872:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:55,872:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:55,872:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,920:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:40:55,921:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,921:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,921:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:55,921:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:55,921:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:55,967:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:40:55,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:55,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:55,968:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:55,968:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:55,968:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:40:56,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:40:56,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,023:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,024:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:40:56,073:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,073:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,074:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,074:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,074:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,122:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:40:56,122:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,122:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,122:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,122:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,123:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,172:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:40:56,172:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,172:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,172:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,172:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,172:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,225:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:40:56,225:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,225:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,226:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,226:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,226:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,275:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:56,275:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,275:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,275:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,276:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,276:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,327:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:56,327:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,327:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,327:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,327:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,327:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:56,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,378:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,378:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,378:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,426:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:40:56,426:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,426:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,426:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,426:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,426:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,479:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-03-29 15:40:56,479:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,479:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,479:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,479:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,479:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:56,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,531:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,532:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,532:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,583:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:56,583:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,583:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,583:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,583:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,583:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,630:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:40:56,630:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,630:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,630:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:40:56,630:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:56,630:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:56,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,678:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:40:56,678:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:56,678:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,725:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:40:56,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,725:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:40:56,726:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:56,726:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.
2025-03-29 15:40:56,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,771:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:40:56,771:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:56,771:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,817:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000642 seconds.
2025-03-29 15:40:56,817:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,817:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,817:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:56,817:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:56,817:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:56,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,863:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:40:56,863:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 10
2025-03-29 15:40:56,863:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:40:56,937:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:40:56,937:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,937:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,937:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:56,937:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:56,937:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:56,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:40:56,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:56,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:56,990:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:56,990:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:56,990:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,043:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:40:57,043:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,043:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,043:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,043:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,043:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:57,106:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,106:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,106:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,106:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,106:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:40:57,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,154:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,154:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:40:57,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,205:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,205:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,205:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:40:57,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,257:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,257:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,257:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,306:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:57,306:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,306:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,306:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,306:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,307:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:40:57,355:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,355:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,355:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,355:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,356:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,403:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:40:57,403:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,403:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,403:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,403:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,404:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:57,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,454:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,454:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,454:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:40:57,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,505:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,505:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,551:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:57,551:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,551:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,551:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:40:57,551:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,552:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,598:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:40:57,599:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,599:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,599:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:40:57,599:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:57,599:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,646:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:40:57,646:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,646:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,646:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:57,646:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:57,646:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,692:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:40:57,692:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,692:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,692:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:57,692:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:57,692:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:40:57,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,738:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:57,738:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:57,738:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:40:57,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:40:57,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,792:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:57,792:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,793:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:57,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:40:57,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,841:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,841:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:57,841:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,841:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:57,890:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:40:57,890:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,890:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,890:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:57,890:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,890:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:57,961:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:40:57,961:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:57,961:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:57,961:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:57,961:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:57,961:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:40:58,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,027:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:58,027:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:58,027:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:40:58,087:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,087:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,087:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:58,087:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:58,087:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:40:58,137:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,137:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,137:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:58,137:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:58,137:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:40:58,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,187:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:58,187:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:58,188:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:40:58,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,237:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:58,237:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:58,237:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:58,287:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,287:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,287:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:58,287:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:58,287:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:40:58,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,338:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:58,338:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:58,338:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,387:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:40:58,387:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,387:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,388:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:58,388:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:58,388:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,437:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:40:58,437:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,437:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,437:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:40:58,437:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:40:58,437:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:40:58,486:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,486:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,486:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:40:58,486:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:40:58,487:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,538:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:40:58,538:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,538:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,538:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:40:58,539:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:40:58,539:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,591:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:40:58,591:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,591:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,591:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:40:58,591:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:40:58,591:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,639:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2025-03-29 15:40:58,639:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,639:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,639:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:40:58,639:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 11
2025-03-29 15:40:58,639:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:40:58,716:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.
2025-03-29 15:40:58,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,716:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:58,716:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:58,716:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:58,791:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-29 15:40:58,791:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,792:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:58,792:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:58,792:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:58,865:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-03-29 15:40:58,865:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,865:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,865:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:58,865:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:58,866:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:58,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:40:58,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:58,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:58,940:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:58,940:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:58,940:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-03-29 15:40:59,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,012:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:59,012:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:59,012:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,088:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:40:59,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,088:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:59,088:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:59,088:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,160:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:40:59,160:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,160:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,160:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:59,160:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:59,160:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,232:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.
2025-03-29 15:40:59,232:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,232:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,232:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:59,233:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:59,233:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:40:59,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,304:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:59,304:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:59,304:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:40:59,374:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,374:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,374:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:59,374:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:59,375:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:40:59,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,447:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,447:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:59,447:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:59,447:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,520:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:40:59,521:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,521:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,521:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:59,521:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:59,521:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,590:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:40:59,590:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,590:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,590:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:40:59,590:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:59,590:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,663:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:40:59,663:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,664:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:40:59,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:40:59,664:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:40:59,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,739:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:40:59,739:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:40:59,739:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,812:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:40:59,812:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,812:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,812:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:40:59,812:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:40:59,813:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,880:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.
2025-03-29 15:40:59,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,880:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:40:59,880:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:40:59,881:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:40:59,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:40:59,953:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:40:59,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:40:59,953:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:40:59,953:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:40:59,953:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:41:00,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,003:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,003:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,003:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,064:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:00,064:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,064:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,064:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,064:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,064:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,115:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:00,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,115:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,115:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,115:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,165:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:41:00,165:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,165:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,165:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,166:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:00,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,214:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,214:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,214:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:00,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,264:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,264:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,264:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,314:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:00,314:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,314:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,314:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,314:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,314:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:00,362:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,362:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,363:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,363:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,363:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:00,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,409:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,409:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,410:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:41:00,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,457:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,457:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,457:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,510:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:00,510:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,510:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,510:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,510:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,510:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,560:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:00,560:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,560:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:00,560:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,561:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,612:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:41:00,612:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,612:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,612:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:00,613:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:00,613:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,670:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:00,670:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,670:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,671:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:41:00,671:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:00,671:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:41:00,729:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,729:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,729:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:41:00,729:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:00,729:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.
2025-03-29 15:41:00,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,780:INFO:[LightGBM] [Info] Total Bins 542
2025-03-29 15:41:00,780:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:41:00,780:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:00,837:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:00,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,838:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:00,838:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,838:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:00,891:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:00,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,891:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:00,891:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,891:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:00,942:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:00,942:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,942:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,942:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:00,942:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,943:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:00,995:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:41:00,995:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:00,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:00,995:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:00,995:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:00,996:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:01,047:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,047:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,048:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:01,048:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:01,048:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:41:01,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,100:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:01,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:01,101:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,151:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.
2025-03-29 15:41:01,151:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,151:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,151:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:01,151:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:01,151:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,202:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:01,202:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,202:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,202:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:01,202:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:01,202:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:01,253:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,253:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,253:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:01,253:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:01,253:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:41:01,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,302:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:01,302:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:01,302:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.
2025-03-29 15:41:01,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,351:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:01,351:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:01,351:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,399:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:01,399:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,399:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,399:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:01,399:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:01,400:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,448:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:41:01,448:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,448:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,448:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:01,448:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:01,448:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:41:01,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,497:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:41:01,497:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:01,497:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,548:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:41:01,548:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,548:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,548:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:41:01,548:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:01,548:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,598:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:41:01,598:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,598:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,598:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:01,598:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:01,598:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,643:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:41:01,643:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,643:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,643:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:41:01,643:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:41:01,643:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:01,696:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:01,697:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,697:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:01,697:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:01,697:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:01,745:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:41:01,745:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,745:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,745:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:01,745:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:01,745:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:01,793:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:41:01,793:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,793:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,793:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:01,793:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:01,793:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:01,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:41:01,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,842:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:01,842:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:01,843:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:01,891:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:41:01,892:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,892:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,892:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:01,892:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:01,892:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:01,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:01,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,940:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:01,940:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:01,940:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:01,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:41:01,988:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:01,988:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:01,988:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:01,988:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:01,989:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,037:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:41:02,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,037:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:02,037:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:02,037:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.
2025-03-29 15:41:02,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,084:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:02,084:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:02,084:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:41:02,132:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,132:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:02,132:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:02,132:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,178:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:41:02,178:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,178:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,178:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:02,178:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:02,178:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,225:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:41:02,225:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,225:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,225:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:02,225:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:02,225:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,276:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:41:02,276:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,276:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,276:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:02,276:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:02,276:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,328:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:41:02,328:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,328:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,328:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:02,328:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:02,328:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,382:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:41:02,382:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,382:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,382:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:41:02,382:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:02,383:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,437:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:41:02,437:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,437:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,437:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:41:02,437:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:02,437:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:41:02,486:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,486:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,486:INFO:[LightGBM] [Info] Total Bins 545
2025-03-29 15:41:02,486:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:41:02,487:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:02,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:02,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,542:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:02,542:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:02,543:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:02,595:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:41:02,595:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,595:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,595:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:02,595:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:02,595:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:02,646:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:02,646:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,646:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,646:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:02,646:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:02,647:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:02,697:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:02,697:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,697:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:02,697:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:02,697:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:02,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:02,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,747:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:02,747:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:02,747:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:02,796:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:02,796:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,796:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,796:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:02,796:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:02,796:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:02,845:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:02,845:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,845:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,845:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:02,845:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:02,845:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:02,892:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:02,893:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,893:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,893:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:02,893:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:02,893:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:02,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:02,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,939:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:02,939:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:02,939:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:02,987:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:02,987:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:02,987:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:02,987:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:02,987:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:02,987:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:03,035:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:41:03,035:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,035:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,036:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:03,036:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,036:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:03,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.
2025-03-29 15:41:03,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,084:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:03,084:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,084:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:03,133:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:03,133:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,133:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,133:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:03,133:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,133:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:03,179:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:03,179:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,179:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,179:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:03,179:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:03,180:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:03,229:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:41:03,229:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,229:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,229:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:03,229:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:03,229:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:03,278:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:41:03,278:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,278:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,278:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:41:03,278:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:03,278:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:03,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:41:03,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,323:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:41:03,323:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:41:03,323:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:03,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:41:03,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,378:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,378:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,378:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,426:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:03,426:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,426:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,426:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,426:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,426:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:41:03,475:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,475:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,476:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,476:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,476:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:41:03,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,525:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,525:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,525:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,575:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:41:03,575:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,575:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,575:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,575:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,575:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,624:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:41:03,624:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,624:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,624:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,624:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,624:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:03,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,677:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,677:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,677:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,725:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:41:03,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,725:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,725:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,725:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:03,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,772:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,772:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,772:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,819:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:41:03,820:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,820:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,820:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,820:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,820:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,866:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:03,866:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,866:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,866:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,867:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,867:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,914:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:03,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,914:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,914:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,914:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:03,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:03,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:03,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:03,963:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:03,963:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:03,963:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:04,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:41:04,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,011:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:04,011:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:04,011:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:04,060:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:41:04,060:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,060:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,060:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:04,060:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:04,060:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:04,111:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:41:04,111:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,111:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,111:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:41:04,111:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:04,111:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:04,156:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:41:04,156:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,156:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,156:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:41:04,156:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:41:04,156:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:04,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:04,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,211:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,211:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,211:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,260:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:04,260:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,260:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,260:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,260:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,260:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,310:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:04,310:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,310:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,310:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,310:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,310:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:04,358:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,358:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,358:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,358:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,358:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,407:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:04,407:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,407:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,407:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,407:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,407:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:41:04,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,455:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,456:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,456:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:04,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,503:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,503:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,503:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,551:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:41:04,551:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,551:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,551:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,551:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,551:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,599:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:04,599:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,599:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,599:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,599:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,599:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,646:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:41:04,646:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,646:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,646:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,646:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,646:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:04,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,693:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,693:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,693:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,740:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:04,740:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,740:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,740:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,740:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,741:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,787:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:04,787:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,787:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:04,787:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:04,788:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,835:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:41:04,835:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,835:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,835:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:41:04,835:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:04,835:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,884:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:04,884:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,884:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,884:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:41:04,884:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:04,884:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000710 seconds.
2025-03-29 15:41:04,934:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,934:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,934:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:41:04,934:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:04,934:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:04,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:41:04,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:04,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:04,979:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:04,979:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:41:04,979:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:05,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:05,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,033:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,033:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,082:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:41:05,082:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,082:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,082:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,082:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,082:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:05,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,139:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,139:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,139:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,191:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:05,191:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,191:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,191:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,191:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,191:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,243:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:05,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,243:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,243:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,243:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,243:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:05,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,295:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,295:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,295:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:05,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,346:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,346:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,346:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:05,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,397:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,397:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,397:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:05,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,448:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,448:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,448:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,448:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:05,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,497:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,497:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,497:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:05,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,547:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,547:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,547:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:05,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,597:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,597:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,597:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,647:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:05,647:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,647:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,647:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:05,647:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:05,647:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,696:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:05,696:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,696:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,696:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:41:05,696:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:05,696:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,747:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:05,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,747:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:41:05,747:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:05,747:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,798:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000449 seconds.
2025-03-29 15:41:05,798:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,798:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,798:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:41:05,798:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:05,799:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,846:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:41:05,846:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,846:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,846:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:41:05,846:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 11
2025-03-29 15:41:05,846:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:05,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:05,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,904:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:05,904:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:05,904:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:05,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:05,954:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:05,954:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:05,955:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:05,955:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:05,955:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,005:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:06,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,006:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,006:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,006:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,057:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:41:06,057:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,057:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,057:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,057:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,057:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,107:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:41:06,107:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,107:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,107:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,107:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,107:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,158:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:41:06,158:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,158:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,158:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,158:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,158:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:41:06,209:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,209:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,209:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,209:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,209:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,256:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:06,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,257:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,257:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,257:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:06,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,304:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,304:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,304:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2025-03-29 15:41:06,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,351:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,351:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,351:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:06,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,397:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,397:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,398:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:06,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,447:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,448:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,448:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,448:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:06,495:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,495:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:06,495:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,496:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:41:06,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,542:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:41:06,542:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:41:06,542:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-03-29 15:41:06,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,592:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:41:06,592:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:41:06,592:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:41:06,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,641:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:06,641:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:41:06,641:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:06,695:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:06,696:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,696:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,696:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:06,696:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,696:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:06,745:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:06,745:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,745:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,745:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:06,745:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,745:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:06,793:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:06,793:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,793:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,793:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:06,793:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,793:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:06,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:06,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,842:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:06,842:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,842:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:06,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:06,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,890:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:06,890:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,890:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:06,946:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:41:06,946:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,947:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,947:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:06,947:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,947:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:06,999:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:41:06,999:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:06,999:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:06,999:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:06,999:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:06,999:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:07,046:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:07,046:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,046:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,046:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:07,046:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:07,046:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:07,094:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:41:07,094:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,094:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,094:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:07,094:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:07,095:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:07,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:07,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,154:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:07,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:07,154:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:07,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:07,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,201:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:07,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:07,201:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:07,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:07,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,249:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:07,249:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:07,249:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:07,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:07,296:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,296:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,296:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:07,296:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:07,296:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:07,341:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:41:07,342:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,342:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,342:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:41:07,342:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:41:07,342:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:07,390:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:41:07,390:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,390:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,391:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:07,391:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:41:07,391:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:07,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:41:07,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,439:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:41:07,439:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 12
2025-03-29 15:41:07,439:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:07,494:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:41:07,494:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,494:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,494:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,494:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,494:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:07,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:41:07,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,543:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,543:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,543:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:07,591:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:07,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,592:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,592:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,592:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:07,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:07,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,641:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,642:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,642:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:07,689:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:07,689:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,690:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,690:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,690:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:07,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:41:07,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,738:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,738:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,738:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:07,786:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:07,786:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,786:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,786:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,786:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,786:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:07,834:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:41:07,834:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,834:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,834:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,834:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:07,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:07,882:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,882:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,883:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,883:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:07,929:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:41:07,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,930:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,930:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,930:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:07,976:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:07,976:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:07,976:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:07,976:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:07,976:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:07,976:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:08,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:41:08,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,024:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:08,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,024:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:08,070:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:08,070:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,070:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,070:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:08,070:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,070:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:08,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2025-03-29 15:41:08,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,117:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:41:08,117:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:08,117:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:08,165:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:41:08,165:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,165:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:08,165:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:08,165:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:08,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-03-29 15:41:08,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,211:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:41:08,211:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:08,211:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:08,264:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:08,264:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,264:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,264:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,264:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,313:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:08,314:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,314:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,314:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,314:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,314:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:41:08,362:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,362:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,362:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,363:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,363:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,411:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:08,411:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,411:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,411:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,411:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,411:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,459:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:08,459:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,460:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,460:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,460:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,460:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.
2025-03-29 15:41:08,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,508:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,508:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,508:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,555:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.
2025-03-29 15:41:08,555:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,555:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,555:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,555:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,555:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:41:08,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,603:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,603:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,655:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:41:08,655:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,655:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,655:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,655:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,655:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:41:08,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,703:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,703:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,703:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,750:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:08,750:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,750:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,750:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,750:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,750:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,797:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:08,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,797:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,797:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,797:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,844:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:08,844:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,844:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,844:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:08,844:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:08,845:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,891:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:41:08,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,891:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:08,891:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:08,891:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,937:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:41:08,937:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,937:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,937:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:41:08,937:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:08,937:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:08,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:41:08,982:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:08,982:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:08,982:INFO:[LightGBM] [Info] Total Bins 544
2025-03-29 15:41:08,982:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:08,982:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:09,036:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:41:09,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,036:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,036:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,036:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,085:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:09,085:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,085:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,085:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,085:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,086:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,135:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.
2025-03-29 15:41:09,135:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,135:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,135:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,135:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,135:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,184:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:41:09,184:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,184:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,184:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,184:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,184:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,232:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:41:09,232:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,232:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,232:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,233:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,233:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,281:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:41:09,281:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,281:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,281:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,281:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,281:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,328:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:41:09,328:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,328:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,328:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,328:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,329:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,375:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:09,376:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,376:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,376:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,376:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,376:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,422:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:09,423:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,423:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,423:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,423:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,423:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,469:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:09,469:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,469:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,469:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,469:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,469:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,518:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:09,519:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,519:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,519:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,519:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:09,569:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,569:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,569:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,569:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,569:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,620:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:41:09,620:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,620:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,620:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,620:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,620:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,669:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.
2025-03-29 15:41:09,669:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,669:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,669:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:41:09,669:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:09,669:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,715:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:41:09,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,716:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:41:09,716:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:09,716:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,761:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:09,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,761:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:09,761:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:09,761:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:09,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:09,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,814:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:09,814:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:09,814:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:09,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.
2025-03-29 15:41:09,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,863:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:09,863:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:09,863:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:09,912:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:09,913:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,913:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,913:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:09,913:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:09,913:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:09,961:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:41:09,961:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:09,961:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:09,961:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:09,961:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:09,961:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:10,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,012:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:10,012:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:10,012:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:41:10,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,063:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:10,063:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:10,063:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,113:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:41:10,113:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,113:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,113:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:10,113:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:10,113:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:41:10,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,163:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:10,163:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:10,163:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.
2025-03-29 15:41:10,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,211:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:10,211:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:10,211:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:41:10,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,258:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:10,258:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:10,258:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,305:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-03-29 15:41:10,305:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,305:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:10,305:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:10,305:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:41:10,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,351:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:10,351:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:10,352:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,399:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.
2025-03-29 15:41:10,399:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,399:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,399:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:10,399:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:10,399:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,448:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.
2025-03-29 15:41:10,448:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,448:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,448:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:10,448:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:10,448:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:41:10,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,497:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:41:10,497:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:10,497:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:41:10,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,544:INFO:[LightGBM] [Info] Total Bins 547
2025-03-29 15:41:10,544:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:10,544:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:10,600:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:41:10,601:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,601:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,601:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:10,601:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:10,601:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:10,653:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:41:10,653:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,653:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:10,653:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:10,654:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:10,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:10,704:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,704:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,704:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:10,704:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:10,704:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:10,755:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:41:10,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,755:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:10,755:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:10,755:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:10,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:41:10,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,806:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:10,806:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:10,806:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:10,856:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:10,856:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,856:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,856:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:10,856:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:10,856:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:10,906:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:10,906:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,906:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:10,906:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:10,906:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:10,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:10,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:10,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:10,956:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:10,956:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:10,956:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:11,005:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:11,005:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,005:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,005:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:11,005:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,005:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:11,053:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:41:11,053:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,053:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,053:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:11,053:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,053:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:11,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:11,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,102:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:11,102:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,102:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:11,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:11,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,150:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,150:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:11,150:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,150:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:11,198:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:11,198:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,198:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,198:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:11,199:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,199:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:11,247:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:11,247:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,247:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,247:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:11,247:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:11,247:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:11,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:41:11,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,297:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:11,297:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:11,297:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:11,344:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:41:11,344:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,344:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,344:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:41:11,344:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:11,344:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:11,400:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:41:11,400:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,400:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,400:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,400:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,400:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000574 seconds.
2025-03-29 15:41:11,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,451:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,451:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,452:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:11,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,503:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,503:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,503:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:11,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,554:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,554:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,605:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:41:11,606:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,606:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,606:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,606:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,606:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,657:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.
2025-03-29 15:41:11,657:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,657:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,657:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,657:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,657:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:11,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,707:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,707:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,707:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:11,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,756:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,757:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,757:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:11,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,807:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,807:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,807:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,854:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:11,854:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,854:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,854:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,854:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,854:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,902:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:11,902:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,902:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,902:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,902:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,902:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,949:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:11,950:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,950:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,950:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,950:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,950:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:11,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:11,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:11,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:11,997:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:11,997:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:11,997:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:12,043:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:41:12,043:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,043:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,044:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:12,044:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:12,044:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:12,092:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.
2025-03-29 15:41:12,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:41:12,092:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:12,092:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:12,092:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:12,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:41:12,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,147:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:41:12,147:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:12,147:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:12,203:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:41:12,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,203:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,204:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,204:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.
2025-03-29 15:41:12,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,254:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,254:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,254:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:41:12,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,304:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,304:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,304:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,354:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:12,354:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,354:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,354:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,354:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,354:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,404:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:12,404:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,405:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,405:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,405:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-03-29 15:41:12,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,455:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,455:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,455:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:12,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,506:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,506:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,506:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,558:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:41:12,558:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,558:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,558:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,558:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:41:12,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,608:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,608:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,608:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,659:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:41:12,659:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,659:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,659:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,659:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,659:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,709:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:41:12,709:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,709:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,709:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,709:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,709:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,758:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:12,758:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,758:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,758:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,758:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,758:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:41:12,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,807:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:12,807:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:12,807:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,856:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:41:12,856:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,856:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,856:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:41:12,856:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:12,856:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:12,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,904:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:41:12,904:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:12,904:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:12,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:41:12,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:12,952:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:12,953:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:41:12,953:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:12,953:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:13,010:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:41:13,010:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,010:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,010:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,010:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,010:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:13,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,062:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,062:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,062:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,062:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,114:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:41:13,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,115:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,115:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,115:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000684 seconds.
2025-03-29 15:41:13,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,167:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,167:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,168:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,218:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000607 seconds.
2025-03-29 15:41:13,218:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,218:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,218:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,218:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,219:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,269:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:13,269:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,269:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,269:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,269:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,269:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:13,321:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,321:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,321:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,321:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,371:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:13,371:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,371:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,371:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,371:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,371:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,421:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:13,421:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,421:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,421:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,421:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,421:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:41:13,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,470:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,470:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,470:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,521:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:13,522:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,522:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,522:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,522:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,522:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:41:13,572:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,572:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,572:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,572:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,621:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:13,621:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,621:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,621:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:13,621:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:13,621:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,694:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:41:13,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,694:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:41:13,694:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:13,694:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:13,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,744:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,744:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:41:13,744:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:13,744:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:13,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,792:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:41:13,792:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 12
2025-03-29 15:41:13,792:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:13,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:41:13,847:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,847:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,847:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:13,847:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:13,847:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:13,896:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:13,896:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,896:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,896:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:13,896:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:13,896:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:13,945:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:41:13,945:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,945:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:13,945:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:13,945:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:13,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:41:13,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:13,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:13,994:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:13,994:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:13,994:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,043:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:14,043:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,043:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,043:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:14,043:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,044:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:41:14,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,092:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:14,092:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,092:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,140:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:41:14,140:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,140:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,140:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:14,140:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,141:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,188:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:41:14,188:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,188:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,188:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:14,188:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,188:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:41:14,236:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,236:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,236:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:14,236:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,236:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,282:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:14,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,282:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:14,283:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,283:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,330:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:14,330:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,330:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,330:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:14,331:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,331:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:14,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,377:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,377:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:14,377:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,378:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:14,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,424:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:14,424:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,424:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,471:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:41:14,471:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,471:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,471:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:41:14,471:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:41:14,471:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,518:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:41:14,518:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,518:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,518:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:41:14,518:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:41:14,518:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:14,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:14,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,574:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:14,574:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,574:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:14,623:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:14,623:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,623:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,623:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:14,623:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,623:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:14,673:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:41:14,673:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,673:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,673:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:14,674:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,674:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:14,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:41:14,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,746:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,746:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:14,746:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,747:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:14,821:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:41:14,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,822:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:14,822:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,822:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:14,895:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:41:14,895:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,895:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,895:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:14,896:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,896:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:14,969:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:41:14,969:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:14,969:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:14,969:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:14,969:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:14,970:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:15,043:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.
2025-03-29 15:41:15,044:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,044:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,044:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:15,044:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:15,044:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:15,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-03-29 15:41:15,120:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,120:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,120:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:15,120:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:15,120:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:15,192:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:41:15,192:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,192:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,192:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:15,192:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:15,192:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:15,265:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:41:15,265:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,265:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,265:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:15,265:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:15,265:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:15,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:41:15,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,338:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:15,338:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:15,338:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:15,410:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.
2025-03-29 15:41:15,410:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,410:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,410:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:15,410:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:15,410:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:15,483:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:41:15,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,483:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,483:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:41:15,483:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:41:15,484:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:15,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:41:15,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,553:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:15,553:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 13
2025-03-29 15:41:15,554:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:15,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:41:15,635:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,635:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,635:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:15,635:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:15,635:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:15,710:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-03-29 15:41:15,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,710:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:15,710:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:15,710:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:15,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000603 seconds.
2025-03-29 15:41:15,784:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:41:15,784:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:15,784:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:15,784:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:15,865:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:41:15,865:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,865:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,866:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:15,866:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:15,866:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:15,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:41:15,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:15,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:15,939:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:15,939:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:15,940:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:16,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,003:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:16,004:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,004:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:41:16,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,054:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:16,054:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,054:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:16,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,104:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:16,104:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,104:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,151:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:16,151:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,152:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,152:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:16,152:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,152:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,198:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:41:16,199:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,199:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,199:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:16,199:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,199:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,255:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
2025-03-29 15:41:16,255:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,255:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,255:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:16,255:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,256:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:16,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,311:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:16,311:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,311:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,357:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-03-29 15:41:16,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,358:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,358:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:16,358:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,358:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,404:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.
2025-03-29 15:41:16,404:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,404:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,404:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:41:16,404:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:16,404:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:41:16,452:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,452:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,452:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:16,452:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:16,452:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:16,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:16,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,505:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:16,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,506:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:16,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:16,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,554:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:16,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,554:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:16,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-29 15:41:16,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,604:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:16,604:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,604:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:16,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:16,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,654:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:16,654:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,654:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:16,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:16,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,703:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:16,703:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,704:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:16,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.
2025-03-29 15:41:16,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,751:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,751:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:16,751:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,751:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:16,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:41:16,801:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,801:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,801:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:16,801:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,801:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:16,849:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:16,849:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,849:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,849:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:16,849:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,849:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:16,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:41:16,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,904:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:16,904:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,904:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:16,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:41:16,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:16,952:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:16,952:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:16,952:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:16,953:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:17,014:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:17,014:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,014:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,014:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:17,014:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,015:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:17,066:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:17,066:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,066:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,066:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:17,066:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,066:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:17,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:41:17,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,116:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:17,116:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,116:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:17,180:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:41:17,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,180:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:17,180:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:17,180:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:17,231:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:17,231:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,231:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,232:INFO:[LightGBM] [Info] Total Bins 546
2025-03-29 15:41:17,232:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:17,232:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:17,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:41:17,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,289:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,289:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,289:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,340:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:17,340:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,341:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,341:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,341:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:17,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,394:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,394:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,394:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,446:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:17,446:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,446:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,446:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,446:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,446:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,500:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:41:17,500:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,500:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,500:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,500:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,500:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,552:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:41:17,552:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,552:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,552:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,552:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,552:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.
2025-03-29 15:41:17,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,604:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,605:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,605:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,657:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:41:17,657:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,657:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,658:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,658:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,658:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,708:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:17,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,708:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,709:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,709:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,759:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:41:17,759:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,759:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,759:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,759:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,759:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,810:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:17,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,811:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,811:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,811:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,811:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,861:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:17,861:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,861:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,861:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,861:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,861:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,912:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:41:17,912:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,912:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,912:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:17,913:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:17,913:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:17,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:41:17,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:17,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:17,962:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:41:17,962:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:17,962:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:18,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:41:18,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,011:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:41:18,011:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:18,011:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:18,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.
2025-03-29 15:41:18,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,068:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:18,068:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:18,068:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,119:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
2025-03-29 15:41:18,119:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,119:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,119:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,119:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,119:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,172:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:41:18,172:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,172:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,173:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,173:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,173:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,225:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:41:18,225:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,225:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,225:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,225:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,225:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,276:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:41:18,276:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,276:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,276:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,276:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,276:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,326:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:41:18,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,326:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,326:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,326:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,376:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:18,376:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,376:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,376:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,377:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,377:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,429:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:18,429:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,429:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,429:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,429:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,429:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:41:18,482:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,482:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,482:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,482:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,534:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:41:18,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,534:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,534:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,534:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,585:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:41:18,585:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,585:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,585:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,585:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,585:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:41:18,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,639:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,639:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,639:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,689:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:41:18,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,690:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,690:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,690:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,742:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.
2025-03-29 15:41:18,742:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,742:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,742:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:18,742:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:18,742:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,793:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:18,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,794:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 15:41:18,794:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:18,794:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:18,851:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:41:18,851:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,851:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,852:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:18,852:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:18,852:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:18,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:18,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,904:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:18,904:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:18,904:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:18,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:41:18,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:18,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:18,956:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:18,956:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:18,956:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:41:19,007:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,007:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,007:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:19,007:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,007:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,057:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:41:19,057:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,057:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,057:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:19,058:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,058:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,110:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:41:19,110:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,110:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:19,110:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,110:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,161:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:41:19,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,161:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,162:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:19,162:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,162:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:41:19,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,213:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:19,213:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,213:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,267:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:41:19,267:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,267:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,267:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:19,267:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,267:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:41:19,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,322:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:19,322:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,322:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,376:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:41:19,376:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,376:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,376:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:19,376:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,376:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,432:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:19,432:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,432:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,432:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:19,432:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,432:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:19,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,487:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:19,488:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,488:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,541:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:41:19,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,541:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:19,541:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:19,542:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:19,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,592:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:19,592:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:19,592:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:19,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:41:19,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,650:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:19,650:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,651:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:19,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:19,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,720:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:19,720:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,720:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:19,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:41:19,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,771:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:19,771:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,771:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:19,823:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:41:19,824:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,824:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,824:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:19,824:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,824:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:19,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:41:19,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,874:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:19,874:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,874:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:19,925:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:19,925:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,925:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,925:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:19,925:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,925:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:19,976:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:19,976:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:19,976:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:19,976:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:19,976:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:19,976:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:20,028:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:20,028:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,028:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,028:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,028:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,028:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:20,080:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:41:20,080:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,080:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,080:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,080:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,080:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:20,130:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:20,130:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,131:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,131:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,131:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:20,181:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:20,181:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,181:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,182:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,182:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,182:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:20,231:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:20,232:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,232:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,232:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,232:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,232:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:20,284:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:41:20,284:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,284:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,284:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,284:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:20,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:20,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,350:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:20,350:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:20,350:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:20,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:41:20,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,402:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:20,402:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:20,402:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:20,463:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:20,463:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,463:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,463:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,463:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,463:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:20,516:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:20,516:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,516:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,516:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,516:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,516:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:20,586:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:20,586:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,586:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,586:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,586:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,586:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:20,643:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:41:20,643:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,643:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,643:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,643:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,643:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:20,695:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:20,696:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,696:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,696:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,696:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,696:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:20,748:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:20,748:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,748:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,749:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,749:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,749:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:20,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:20,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,807:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,807:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,807:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:20,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:20,861:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,861:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,861:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,861:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,861:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:20,910:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:41:20,910:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,910:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,910:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,910:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,910:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:20,959:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:20,959:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:20,959:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:20,960:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:20,960:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:20,960:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:21,009:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:21,009:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,009:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,009:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:21,009:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,010:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:21,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.
2025-03-29 15:41:21,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,062:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:21,062:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,062:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:21,114:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:41:21,114:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,114:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,115:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:21,115:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,115:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:21,164:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.
2025-03-29 15:41:21,165:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,165:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:41:21,165:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:21,165:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:21,216:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:41:21,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,216:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,216:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:41:21,216:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:21,216:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:21,273:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.
2025-03-29 15:41:21,273:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,273:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,273:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,273:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,273:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,330:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:21,330:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,330:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,330:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,330:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,330:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,385:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.
2025-03-29 15:41:21,385:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,385:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,385:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,385:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,385:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:41:21,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,439:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,439:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,439:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,492:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:41:21,492:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,492:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,493:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,493:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,493:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:21,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,544:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,544:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,544:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,595:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:21,595:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,595:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,595:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,595:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,595:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,647:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:21,647:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,647:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,647:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,647:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,647:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,700:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:41:21,700:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,700:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,700:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,700:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,700:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,753:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:41:21,753:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,753:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,754:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,754:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,754:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,805:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:21,805:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,805:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,805:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,805:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,805:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,856:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:41:21,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,857:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,857:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,857:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,908:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:41:21,908:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,908:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,908:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:21,908:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:21,908:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:21,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:41:21,957:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:21,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:21,957:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:41:21,958:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:21,958:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:22,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:22,007:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,007:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,007:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:41:22,007:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 13
2025-03-29 15:41:22,007:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:22,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:22,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,065:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,065:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,065:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:22,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,117:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,117:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,117:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,169:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:22,169:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,169:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,169:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,169:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,169:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,220:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.
2025-03-29 15:41:22,220:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,220:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,220:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,220:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,221:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,271:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:41:22,271:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,271:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,271:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,271:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,271:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:41:22,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,323:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,323:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,323:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,373:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:22,374:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,374:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,374:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,374:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,374:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:22,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,425:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,425:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,425:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:22,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,475:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,475:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,475:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,475:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,523:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:41:22,523:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,523:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,523:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,523:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,523:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:22,572:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,572:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,572:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,572:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,622:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:22,622:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,622:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,622:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,622:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,623:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,673:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:22,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,674:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,674:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:22,674:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,674:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,723:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:41:22,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,723:INFO:[LightGBM] [Info] Total Bins 555
2025-03-29 15:41:22,723:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:41:22,723:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:22,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:41:22,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,780:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:22,780:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,780:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:22,835:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:22,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,837:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:22,837:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,837:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:22,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:22,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,889:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:22,889:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,889:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:22,941:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:41:22,941:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,941:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,941:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:22,941:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,941:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:22,991:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:22,991:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:22,991:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:22,992:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:22,992:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:22,992:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:23,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:23,041:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,041:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,041:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:23,041:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:23,041:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:23,091:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:41:23,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,092:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:23,092:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:23,092:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:23,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:41:23,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,141:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:23,141:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:23,141:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:23,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:41:23,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,190:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:23,190:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:23,190:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:23,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:41:23,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,240:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:23,240:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:23,241:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:23,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:41:23,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,290:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:23,290:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:23,290:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:23,340:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:41:23,340:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,340:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,341:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:23,341:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:23,341:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:23,390:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:41:23,390:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,390:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,390:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:23,390:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:23,391:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:23,441:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:41:23,441:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,441:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,441:INFO:[LightGBM] [Info] Total Bins 553
2025-03-29 15:41:23,441:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 14
2025-03-29 15:41:23,441:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:23,499:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.
2025-03-29 15:41:23,499:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,499:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,499:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:23,499:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:23,499:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:23,578:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:41:23,578:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,578:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,578:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:23,578:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:23,579:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:23,657:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.
2025-03-29 15:41:23,658:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,658:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,658:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:23,658:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:23,658:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:23,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:41:23,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,744:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,744:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:23,744:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:23,744:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:23,823:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:41:23,823:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,823:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,823:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:23,824:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:23,824:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:23,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.
2025-03-29 15:41:23,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,902:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,902:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:23,902:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:23,902:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:23,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:23,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:23,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:23,979:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:23,979:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:23,979:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:24,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.
2025-03-29 15:41:24,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,056:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:24,056:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,056:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:24,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.
2025-03-29 15:41:24,109:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,109:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,109:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:24,109:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,109:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:24,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:24,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,162:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:24,162:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,162:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:24,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:24,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,214:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:24,214:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,214:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:24,266:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:41:24,266:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,266:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,266:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:24,266:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,266:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:24,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:24,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,322:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:24,322:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,322:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:24,371:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:41:24,371:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,371:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,371:INFO:[LightGBM] [Info] Total Bins 550
2025-03-29 15:41:24,372:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:24,372:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:24,428:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:41:24,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,428:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,428:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,428:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,428:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,480:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:24,480:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,480:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,480:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,480:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,480:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:41:24,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,531:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,531:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,531:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,584:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:24,584:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,584:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,584:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,584:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,584:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,636:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:41:24,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,636:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,636:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,636:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,636:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:41:24,689:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,689:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,689:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,689:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,689:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,739:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.
2025-03-29 15:41:24,740:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,740:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,740:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,740:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,740:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:41:24,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,793:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,793:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,793:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,793:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,848:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:24,848:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,848:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,848:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,848:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,848:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,897:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:41:24,897:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,897:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,897:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,897:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,898:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,946:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:24,946:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,946:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,946:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,946:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,946:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:24,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:24,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:24,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:24,997:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:24,997:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:24,997:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:25,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:41:25,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,048:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:25,048:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,048:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:25,097:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:41:25,097:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,097:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,097:INFO:[LightGBM] [Info] Total Bins 548
2025-03-29 15:41:25,097:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:25,097:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:25,152:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:25,152:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,152:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,152:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,152:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,152:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:41:25,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,200:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,200:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,200:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,249:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:25,249:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,249:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,249:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,249:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,249:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:41:25,298:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,298:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,298:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,298:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,298:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,347:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:25,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,347:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,347:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,347:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,395:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:41:25,395:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,395:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,395:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,395:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,395:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,445:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:25,445:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,445:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,445:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,445:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,445:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,494:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:25,494:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,494:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,494:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,494:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,494:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:25,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,544:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,544:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,544:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,595:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:41:25,595:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,595:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,595:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,595:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,595:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:25,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,645:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,645:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,645:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,695:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.
2025-03-29 15:41:25,695:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,695:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,695:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,695:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,695:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:25,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,744:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,744:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,744:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,744:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,794:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000726 seconds.
2025-03-29 15:41:25,794:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:41:25,794:INFO:[LightGBM] [Info] Total Bins 552
2025-03-29 15:41:25,794:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:25,794:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:25,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:41:25,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,858:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:25,858:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:25,858:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:25,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:41:25,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,911:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:25,911:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:25,911:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:25,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:41:25,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:25,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:25,962:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:25,962:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:25,962:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,013:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:41:26,013:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,013:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,013:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,013:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,013:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:41:26,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,065:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,065:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,065:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:41:26,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,116:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,116:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,117:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:41:26,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,168:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,168:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,168:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,219:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:41:26,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,219:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,219:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,219:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,219:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:26,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,270:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,270:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,270:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:41:26,321:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,321:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,321:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,321:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:26,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,370:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,371:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,371:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,420:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:41:26,420:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,420:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,420:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,420:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,420:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.
2025-03-29 15:41:26,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,470:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,470:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,470:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,518:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-03-29 15:41:26,518:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,518:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,519:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:26,519:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:26,519:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:26,577:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:41:26,577:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,578:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,578:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:26,578:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:26,578:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:26,631:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.
2025-03-29 15:41:26,631:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,631:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,631:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:26,631:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:26,631:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:26,683:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:26,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,684:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:26,684:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:26,684:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:26,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:26,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,736:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:26,736:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:26,736:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:26,787:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.
2025-03-29 15:41:26,787:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,787:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:26,787:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:26,787:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:26,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:26,839:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,839:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,839:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:26,839:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:26,839:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:26,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:26,888:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,889:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:26,889:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:26,889:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:26,938:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:26,938:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,938:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,938:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:26,938:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:26,938:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:26,986:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:41:26,986:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:26,986:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:26,986:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:26,986:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:26,986:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:27,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:41:27,034:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,034:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,034:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:27,034:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,034:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:27,093:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:27,093:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,093:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,093:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:27,093:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,093:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:27,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.
2025-03-29 15:41:27,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,139:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:27,139:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,139:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:27,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:27,186:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,186:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,187:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:27,187:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,187:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:27,249:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:41:27,249:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,249:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,249:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:27,249:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:27,249:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:27,307:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:27,307:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,307:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,307:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,307:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:27,360:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,360:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,360:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,360:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,411:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:27,411:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,411:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,411:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,411:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,411:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,461:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:27,461:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,461:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,461:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,461:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,462:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:41:27,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,512:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,512:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,512:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:41:27,572:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,572:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,572:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,572:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:41:27,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,650:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,651:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,651:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,705:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:41:27,705:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,706:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,706:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,706:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,706:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,755:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:27,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,755:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,755:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,755:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,804:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:27,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,804:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,804:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,804:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,854:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:41:27,854:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,854:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,854:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,854:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,854:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:27,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,904:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,904:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,905:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:27,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-03-29 15:41:27,954:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:27,954:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:27,954:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:27,954:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:27,954:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:28,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:41:28,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,003:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:28,003:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:28,003:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:28,060:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.
2025-03-29 15:41:28,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,061:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,061:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,061:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,111:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:41:28,112:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,112:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,112:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,112:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,112:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,161:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:28,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,161:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,161:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,162:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,162:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:41:28,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,211:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,211:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,211:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:41:28,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,259:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,259:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,259:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,308:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:28,308:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,308:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,308:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,308:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,308:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,359:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:41:28,359:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,359:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,359:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,359:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,359:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,408:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:41:28,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,409:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,409:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,409:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,462:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:28,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,462:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,462:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,462:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,462:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:41:28,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,513:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,513:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,513:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:41:28,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,561:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,561:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,561:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,609:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-03-29 15:41:28,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,609:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,609:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,609:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:28,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,664:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:28,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,664:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,712:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:41:28,712:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,713:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,713:INFO:[LightGBM] [Info] Total Bins 554
2025-03-29 15:41:28,713:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:28,713:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:28,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:28,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,771:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:28,771:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,771:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:28,822:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:28,822:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,822:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,822:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:28,822:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,822:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:28,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:28,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,874:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:28,874:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,874:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:28,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:28,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,927:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:28,927:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,927:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:28,977:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:41:28,977:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:28,977:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:28,977:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:28,977:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:28,977:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:29,026:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:29,026:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,026:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,026:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:29,027:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:29,027:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:29,074:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:29,074:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,074:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,074:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:29,074:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:29,074:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:29,123:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:29,123:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,123:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,123:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:29,123:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:29,123:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:29,171:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:41:29,171:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,171:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,171:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:29,171:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:29,171:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:29,219:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:29,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,219:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,219:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:29,219:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:29,219:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:29,266:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:29,266:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,267:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,267:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:29,267:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:29,267:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:29,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:29,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,315:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:29,315:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:29,315:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:29,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:29,364:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,364:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,364:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:29,364:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:29,364:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:29,411:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:41:29,411:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,411:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,412:INFO:[LightGBM] [Info] Total Bins 556
2025-03-29 15:41:29,412:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:29,412:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:29,468:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.
2025-03-29 15:41:29,468:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,468:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,468:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,468:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,468:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:29,518:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.
2025-03-29 15:41:29,518:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,518:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,518:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,518:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,518:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:29,567:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:41:29,567:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,567:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,567:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,567:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,567:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:29,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.
2025-03-29 15:41:29,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,618:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,618:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,618:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:29,670:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:41:29,670:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,670:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,670:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,670:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,670:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:29,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:41:29,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,720:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,720:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,720:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:29,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:41:29,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,770:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,770:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,770:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:29,819:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:29,819:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,819:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,819:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,819:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,819:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:29,867:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:29,867:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,867:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,867:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,867:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,867:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:29,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:29,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,916:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,916:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,916:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:29,963:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:29,963:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:29,963:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:29,963:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:29,963:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:29,964:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:30,010:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:30,010:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,010:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,010:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:30,010:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,011:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:30,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:30,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,058:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:30,058:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,058:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:30,113:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:30,113:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,113:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,113:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,113:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,114:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:30,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,162:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,162:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,163:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:30,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,211:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,211:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,211:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:30,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,259:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,259:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,259:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,308:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:30,308:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,308:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,308:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,308:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,308:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,356:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:30,356:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,357:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,357:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,357:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,404:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:41:30,404:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,404:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,404:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,404:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,404:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,452:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.
2025-03-29 15:41:30,452:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,452:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,452:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,452:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,452:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,499:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:41:30,499:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,499:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,499:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,499:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,499:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,545:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:41:30,545:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,546:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,546:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,546:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,546:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:30,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,592:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,592:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,592:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,639:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:41:30,639:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,639:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,639:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,639:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,639:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,687:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.
2025-03-29 15:41:30,687:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,687:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,687:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:30,687:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:30,687:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:30,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:41:30,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,769:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,769:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:30,769:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:30,770:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:30,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:41:30,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,843:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:30,843:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:30,843:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:30,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.
2025-03-29 15:41:30,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,916:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:30,916:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:30,916:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:30,989:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:41:30,989:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:30,989:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:30,989:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:30,989:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:30,989:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:31,066:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:41:31,066:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,066:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,066:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:31,066:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,066:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:31,138:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:41:31,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,138:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,138:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:31,138:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,139:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:31,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:41:31,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,210:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:31,210:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,211:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:31,284:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:41:31,284:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,285:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:31,285:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,285:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:31,356:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:41:31,356:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,356:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,357:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:31,357:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,357:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:31,430:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000444 seconds.
2025-03-29 15:41:31,430:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,430:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,430:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:31,430:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,430:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:31,500:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:41:31,500:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,500:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,500:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:31,500:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,500:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:31,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-29 15:41:31,573:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,573:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,573:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:31,573:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,573:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:31,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:41:31,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,645:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:31,645:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,646:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:31,725:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:31,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,725:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:31,725:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,725:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:31,798:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:41:31,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,799:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:31,799:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,799:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:31,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:31,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,877:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:31,877:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,877:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:31,949:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:41:31,949:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:31,949:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:31,949:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:31,949:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:31,950:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:32,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:41:32,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,003:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:32,003:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,003:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:32,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:41:32,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,072:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:32,072:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,073:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:32,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:41:32,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,146:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:32,146:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,147:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:32,218:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:41:32,218:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,218:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,218:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:32,219:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,219:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:32,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.
2025-03-29 15:41:32,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,290:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:32,290:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,291:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:32,373:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.
2025-03-29 15:41:32,373:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,373:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,373:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:32,373:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,373:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:32,453:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:41:32,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,453:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:32,453:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,453:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:32,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.
2025-03-29 15:41:32,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,533:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:32,533:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,533:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:32,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:41:32,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,608:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:32,608:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,608:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:32,691:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:41:32,691:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,691:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,691:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:32,692:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,692:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:32,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:41:32,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,766:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:32,766:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,766:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:32,839:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:41:32,839:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,839:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,840:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:32,840:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,840:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:32,913:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:41:32,913:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,913:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,913:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:32,913:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,913:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:32,987:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:41:32,987:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:32,987:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:32,987:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:32,987:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:32,987:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:33,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:33,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,059:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:33,059:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:33,059:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:33,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-03-29 15:41:33,137:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,137:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,137:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:33,137:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:33,138:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:33,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.
2025-03-29 15:41:33,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,211:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:33,211:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:33,211:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:33,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:41:33,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,285:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,285:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:33,285:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:33,285:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:33,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:41:33,358:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,358:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,358:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:33,358:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:33,358:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:33,432:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.
2025-03-29 15:41:33,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,433:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,433:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:33,433:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:33,433:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:33,510:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-03-29 15:41:33,510:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,510:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,510:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:33,510:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:33,511:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:33,585:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:41:33,585:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,585:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,585:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:33,585:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:33,585:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:33,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:33,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,664:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:33,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:33,664:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:33,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-03-29 15:41:33,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,738:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:33,738:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:33,739:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:33,813:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:41:33,813:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,813:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,813:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:33,813:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:33,813:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:33,886:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:41:33,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,886:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:33,886:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:33,886:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:33,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:41:33,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:33,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:33,962:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:33,962:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:33,962:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:34,035:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.
2025-03-29 15:41:34,035:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,035:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,035:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:34,035:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:34,036:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:34,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:41:34,106:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,106:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,106:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:34,106:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:34,106:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:34,179:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:41:34,179:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,179:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,179:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:34,179:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:34,179:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:34,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:41:34,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,250:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:34,250:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:34,251:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:34,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:41:34,321:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,321:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:34,321:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:34,322:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:34,372:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.
2025-03-29 15:41:34,372:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,372:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,372:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:34,372:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:34,372:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:34,421:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:34,421:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,421:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,421:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:34,421:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:34,421:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:34,467:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-03-29 15:41:34,467:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,467:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,467:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:34,467:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:34,467:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:34,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:34,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,525:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:34,525:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:34,525:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:34,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:41:34,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,603:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:34,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:34,603:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:34,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:34,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,664:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:34,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:34,665:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:34,713:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:34,713:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,713:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,713:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:34,713:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:34,713:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:34,761:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:41:34,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,761:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:34,761:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:34,761:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:34,808:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:41:34,808:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,808:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,808:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:34,808:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:34,808:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:34,855:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:34,855:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,855:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,855:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:34,855:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:34,855:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:34,902:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:41:34,903:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,903:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,903:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:34,903:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:34,903:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:34,950:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:34,951:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,951:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,951:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:34,951:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:34,951:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:34,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:34,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:34,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:34,997:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:34,997:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:34,997:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:35,044:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:35,044:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,044:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,044:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:35,044:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,044:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:35,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.
2025-03-29 15:41:35,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,093:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:35,093:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,093:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:35,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:41:35,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,139:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:35,139:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,139:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:35,193:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:35,193:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,193:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,193:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,193:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,193:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,241:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:35,241:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,241:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,241:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,241:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,242:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:35,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,290:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,290:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,290:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,339:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:41:35,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,339:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,339:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,339:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,387:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:41:35,387:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,387:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,387:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,387:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,387:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:41:35,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,436:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,436:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,436:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,483:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:35,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,483:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,483:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,484:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,484:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:35,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,531:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,531:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,531:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,578:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:41:35,578:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,578:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,578:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,578:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,578:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.
2025-03-29 15:41:35,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,625:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,625:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,625:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,673:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:35,673:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,673:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,673:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,673:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,673:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:35,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,721:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,721:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,721:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.
2025-03-29 15:41:35,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,769:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,769:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,769:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,769:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:35,822:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:41:35,822:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,822:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,822:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,822:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,823:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:35,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:35,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,871:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,871:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,871:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:35,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:41:35,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,920:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,920:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,920:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,920:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:35,976:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:41:35,976:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:35,976:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:35,976:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:35,976:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:35,976:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:36,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:36,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,024:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:36,024:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,024:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:36,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:41:36,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,072:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:36,072:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,072:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:36,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-03-29 15:41:36,120:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,120:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,120:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:36,120:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,120:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:36,168:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:41:36,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,168:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:36,168:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,168:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:36,216:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:41:36,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,216:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,216:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:36,216:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,216:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:36,265:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:41:36,265:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,265:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,265:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:36,265:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,265:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:36,312:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:36,312:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,312:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,312:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:36,312:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,312:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:36,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:36,359:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,359:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,359:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:36,359:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,359:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:36,405:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:36,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,405:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:36,405:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,405:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:36,458:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:41:36,459:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,459:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,459:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,459:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,459:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:41:36,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,508:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,508:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,508:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,558:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:41:36,558:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,558:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,558:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,558:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:36,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,607:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,607:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,608:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,608:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,657:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:36,657:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,657:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,657:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,657:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,657:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:41:36,706:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,706:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,706:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,706:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,706:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,753:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:41:36,753:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,753:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,753:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,753:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,753:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:36,801:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,801:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,801:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,801:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,801:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,848:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:41:36,848:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,848:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,848:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,848:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,848:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,895:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:41:36,895:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,895:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,896:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,896:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,896:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,943:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:36,943:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,943:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,943:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,943:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,943:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:36,992:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:41:36,992:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:36,992:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:36,992:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:36,992:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:36,992:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:37,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:41:37,038:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,038:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,038:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:37,038:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:37,039:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:37,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:41:37,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,102:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,102:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,102:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:37,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,155:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,155:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,155:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,203:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:37,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,204:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,204:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,204:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,264:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:37,264:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,264:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,264:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,264:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,313:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:41:37,313:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,313:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,313:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,313:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,313:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:41:37,362:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,362:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,362:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,362:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,362:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:41:37,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,409:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,410:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,410:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,459:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-03-29 15:41:37,459:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,459:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,459:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,459:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,459:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,507:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:37,507:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,507:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,507:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,507:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,507:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:37,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,554:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,555:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:41:37,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,603:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,603:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,603:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:41:37,651:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,651:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:37,651:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,651:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:37,705:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:37,705:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,705:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,705:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:37,705:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,705:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:37,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.
2025-03-29 15:41:37,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,754:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:37,754:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,754:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:37,802:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:41:37,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,802:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:37,802:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,803:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:37,851:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:37,851:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,851:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,851:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:37,851:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,851:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:37,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:37,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,900:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:37,900:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,900:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:37,948:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:37,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,948:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:37,948:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,948:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:37,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:41:37,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:37,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:37,997:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:37,997:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:37,997:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:38,044:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:41:38,044:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,044:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,044:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:38,045:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:38,045:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:38,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:38,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,092:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:38,092:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:38,092:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:38,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:41:38,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,141:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:38,141:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:38,141:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:38,189:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:41:38,189:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,189:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,189:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:38,189:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:38,189:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:38,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:38,236:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,236:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,236:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:38,236:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:38,236:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:38,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:41:38,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,289:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,289:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,290:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:38,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,338:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,338:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,338:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,387:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:41:38,387:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,387:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,387:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,387:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,387:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:38,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,436:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,436:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,437:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:41:38,484:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,484:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,485:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,485:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:38,532:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,533:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,533:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,533:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,581:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:41:38,581:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,581:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,582:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,582:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,582:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,630:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:38,630:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,630:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,630:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,630:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,630:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:38,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,679:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,679:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,679:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:41:38,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,726:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,726:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,726:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:38,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,773:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,773:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,773:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,819:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:38,819:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,819:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,819:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:38,820:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,820:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:38,877:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:41:38,877:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,877:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,877:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:38,877:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,877:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:38,971:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-29 15:41:38,972:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:38,972:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:38,972:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:38,972:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:38,973:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:39,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,031:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:39,031:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,031:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,079:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:39,079:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,079:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,079:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:39,079:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,079:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,128:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:39,128:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,128:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,128:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:39,128:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,128:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:39,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,176:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:39,176:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,176:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,225:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:39,225:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,225:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,225:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:39,225:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,225:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,273:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:41:39,273:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,273:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,273:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:39,273:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,273:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,320:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:39,320:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,320:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,320:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:39,320:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,320:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,368:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:39,368:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,368:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,368:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:39,368:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,368:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,416:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:39,416:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,416:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,416:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:39,416:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,416:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,463:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:39,463:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,463:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,463:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:39,463:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,464:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:39,519:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-03-29 15:41:39,519:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,519:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:39,519:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,519:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:39,567:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:39,567:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,567:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,567:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:39,567:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,567:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:39,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:41:39,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,617:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:39,617:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,617:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:39,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:39,667:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,667:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,667:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:39,667:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,667:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:39,715:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:39,715:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,715:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,715:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:39,715:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,715:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:39,764:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:41:39,764:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,764:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,765:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:39,765:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,765:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:39,812:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:41:39,812:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,812:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,812:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:39,812:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,812:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:39,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:39,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,860:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:39,860:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,860:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:39,908:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:39,908:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,908:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,908:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:39,908:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,908:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:39,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:41:39,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:39,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:39,955:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:39,955:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:39,955:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:40,002:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:41:40,002:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,002:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,002:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:40,002:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:40,002:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:40,049:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:40,049:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,049:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,050:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:40,050:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:40,050:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:40,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:40,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,104:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:40,104:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:40,104:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,152:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.
2025-03-29 15:41:40,153:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,153:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,153:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,153:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,153:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:41:40,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,201:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,201:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:41:40,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,250:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,250:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,250:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,299:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:41:40,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,299:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,299:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,299:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:41:40,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,347:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,347:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,347:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:41:40,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,394:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,394:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,394:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,441:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:40,441:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,441:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,441:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,441:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,442:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:41:40,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,488:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,488:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,489:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,536:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:40,536:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,536:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,536:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,536:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,536:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,584:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:41:40,584:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,584:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,584:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,584:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,584:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,632:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:40,632:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,632:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,632:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:40,632:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:40,632:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:40,687:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:41:40,687:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,687:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,687:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:40,687:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:40,687:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:40,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.
2025-03-29 15:41:40,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,736:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:40,736:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:40,736:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:40,784:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:40,784:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,784:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:40,784:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:40,785:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:40,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:41:40,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,832:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:40,832:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:40,832:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:40,880:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:41:40,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,880:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:40,880:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:40,880:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:40,928:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:41:40,928:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,928:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,928:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:40,928:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:40,928:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:40,975:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:40,976:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:40,976:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:40,976:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:40,976:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:40,976:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:41,022:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:41:41,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,023:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:41,023:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,023:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:41,070:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:41:41,070:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,071:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,071:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:41,071:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,071:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:41,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:41,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,118:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,118:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:41,118:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,118:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:41,164:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:41:41,165:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,165:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:41,165:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,165:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:41,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:41,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,211:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:41,211:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,211:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:41,265:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:41:41,266:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,266:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,266:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,266:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,266:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:41:41,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,315:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,315:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,315:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,363:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:41,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,364:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,364:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,364:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,412:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:41:41,412:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,413:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,413:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,413:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,413:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,461:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:41:41,461:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,461:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,461:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,461:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,461:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:41,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,509:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,509:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,509:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,560:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:41:41,560:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,560:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,560:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,560:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:41,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,615:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,615:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,615:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,615:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:41:41,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,668:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,668:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,668:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,668:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:41:41,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,720:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,720:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,720:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:41,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,771:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,771:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,771:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,821:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:41,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,821:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,821:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,821:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:41,879:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:41:41,879:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,879:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,879:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,879:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,879:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:41,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:41,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,931:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,931:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,931:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:41,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:41,982:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:41,982:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:41,982:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:41,982:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:41,982:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:42,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:41:42,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,033:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:42,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,033:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:42,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:42,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,084:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:42,085:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,085:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:42,136:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:42,136:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,136:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,136:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:42,136:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,137:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:42,188:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:41:42,188:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,188:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,188:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:42,188:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,188:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:42,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:41:42,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,238:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:42,238:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,238:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:42,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:42,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,288:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:42,288:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,288:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:42,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:42,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,338:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:42,338:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,338:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:42,387:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:42,387:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,387:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,387:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:42,387:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,387:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:42,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-03-29 15:41:42,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,436:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:42,436:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,436:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:42,492:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:41:42,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,493:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:42,493:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,493:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:42,545:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:42,545:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,545:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,545:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:42,545:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,545:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:42,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:41:42,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,597:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:42,598:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,598:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:42,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:41:42,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,650:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:42,650:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,650:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:42,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:41:42,702:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,702:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,702:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:42,702:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,702:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:42,753:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:41:42,753:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,753:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,753:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:42,753:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,754:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:42,803:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:42,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,804:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:42,804:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,804:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:42,855:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-03-29 15:41:42,855:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,855:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,855:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:42,855:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,855:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:42,905:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:42,905:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,905:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,905:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:42,905:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,905:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:42,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:41:42,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:42,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:42,955:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:42,955:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:42,955:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:43,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:41:43,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,006:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:43,006:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:43,006:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:43,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:43,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,056:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:43,056:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:43,056:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:43,115:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:43,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,115:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,115:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,115:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:41:43,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,167:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,167:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,167:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,219:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.
2025-03-29 15:41:43,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,219:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,219:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,219:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,220:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,271:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:43,271:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,271:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,271:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,272:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,272:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:41:43,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,322:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,322:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,322:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:43,374:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,374:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,374:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,374:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,374:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:43,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,425:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,425:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,425:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:43,475:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,475:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,475:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,475:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,475:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:41:43,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,525:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,525:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,525:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,575:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:43,575:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,575:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,575:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,575:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,575:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:41:43,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,625:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:43,625:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,626:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:43,684:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:41:43,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,684:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:43,684:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,684:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:43,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:43,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,736:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:43,737:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,737:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:43,788:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:43,788:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,788:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,789:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:43,789:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,789:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:43,839:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:43,839:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,839:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,839:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:43,839:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,839:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:43,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:41:43,890:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,890:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,890:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:43,890:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,890:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:43,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:41:43,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,940:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:43,940:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,941:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:43,992:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:41:43,992:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:43,992:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:43,992:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:43,992:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:43,992:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:44,043:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:41:44,043:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,043:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,043:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:44,043:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:44,044:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:44,095:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:41:44,095:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,095:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,095:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:44,095:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:44,095:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:44,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:44,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,147:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:44,147:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:44,147:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:44,199:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:41:44,199:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,199:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,199:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:44,199:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:44,199:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:44,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:41:44,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,257:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,257:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,258:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:44,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,311:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,311:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,311:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,366:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:41:44,366:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,366:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,366:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,366:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,367:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,420:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:44,420:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,420:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,420:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,420:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,420:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,473:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:41:44,473:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,473:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,473:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,473:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,473:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:41:44,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,526:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,526:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,526:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,578:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.
2025-03-29 15:41:44,578:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,578:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,578:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,578:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,578:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,631:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:41:44,631:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,631:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,631:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,631:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,631:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,683:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:41:44,683:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,683:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,683:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,684:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,684:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,732:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:44,733:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,733:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,733:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,733:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,733:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:44,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,783:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:44,783:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,783:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:44,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:41:44,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,841:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,841:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:44,841:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,841:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:44,894:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-03-29 15:41:44,894:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,894:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,894:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:44,895:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,895:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:44,947:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:44,947:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,947:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,947:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:44,947:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,947:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:44,998:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:41:44,998:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:44,999:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:44,999:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:44,999:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:44,999:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:45,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:45,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,048:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:45,048:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,048:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:45,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:41:45,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,100:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:45,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,100:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:45,151:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:45,151:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,151:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,151:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:45,151:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,152:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:45,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-03-29 15:41:45,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,201:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:45,201:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,202:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:45,252:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:41:45,252:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,252:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,252:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:45,252:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,253:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:45,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:41:45,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,302:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:45,302:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,303:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:45,352:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:41:45,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,352:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:45,352:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,352:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:45,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-03-29 15:41:45,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,409:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,409:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,410:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,460:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:45,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,460:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,460:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,460:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,460:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:41:45,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,512:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,512:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,512:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,563:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:41:45,563:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,563:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,563:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,563:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,564:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:41:45,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,614:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,614:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,614:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:41:45,666:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,666:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,666:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,666:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,666:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,715:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:45,715:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,715:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,715:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,715:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,715:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,765:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:41:45,765:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,765:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,765:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,765:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,765:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:45,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,814:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,814:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,814:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:41:45,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,863:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,863:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,863:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:45,912:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,912:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,912:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,912:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,912:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:45,969:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.
2025-03-29 15:41:45,970:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:45,970:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:45,970:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:45,970:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:45,970:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:41:46,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,023:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:46,023:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:46,023:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:46,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,076:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:46,076:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:46,076:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,129:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-29 15:41:46,129:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,129:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,129:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:46,129:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:46,129:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,179:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:41:46,179:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,179:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,180:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:46,180:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:46,180:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,231:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.
2025-03-29 15:41:46,231:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,231:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,231:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:46,231:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:46,231:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,282:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.
2025-03-29 15:41:46,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,282:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:46,282:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:46,282:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,331:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.
2025-03-29 15:41:46,331:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,331:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,331:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:46,331:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:46,331:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,380:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.
2025-03-29 15:41:46,380:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,380:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,380:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:46,381:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:46,381:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,431:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:41:46,431:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,431:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,431:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:46,431:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:46,431:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.
2025-03-29 15:41:46,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,481:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:46,481:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:46,481:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:46,541:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:41:46,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,542:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:46,542:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:46,542:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:46,594:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:41:46,594:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,594:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,594:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:46,595:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:46,595:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:46,649:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:46,649:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,649:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,649:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:46,649:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:46,649:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:46,715:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-03-29 15:41:46,715:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,715:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,715:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:46,715:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:46,716:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:46,791:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:41:46,791:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,791:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,791:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:46,791:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:46,792:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:46,865:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:46,865:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,865:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,865:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:46,865:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:46,866:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:46,938:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:41:46,938:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:46,938:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:46,938:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:46,938:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:46,938:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:47,009:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:47,009:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,009:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,009:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:47,009:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,009:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:47,085:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-03-29 15:41:47,085:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,085:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,085:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:47,085:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,085:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:47,164:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:41:47,164:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,164:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,165:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:47,165:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,165:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:47,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:41:47,236:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,237:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:47,237:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,237:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:47,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:41:47,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,323:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:47,323:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,323:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:47,404:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-03-29 15:41:47,404:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,404:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,404:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:47,404:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,404:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:47,479:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:47,479:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,480:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,480:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:47,480:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,480:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:47,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:47,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,554:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:47,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,554:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:47,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:47,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,626:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:47,626:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,626:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:47,701:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:47,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,701:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:47,701:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,701:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:47,775:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:47,775:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,775:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,775:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:47,775:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,775:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:47,853:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:41:47,853:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,853:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,853:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:47,853:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,853:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:47,928:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.
2025-03-29 15:41:47,929:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:47,929:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:47,929:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:47,929:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:47,929:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:48,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:41:48,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,003:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,003:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,003:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:48,057:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:41:48,057:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,057:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,057:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,057:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,057:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:48,121:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:48,121:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,121:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,121:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,121:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,121:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,177:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:41:48,177:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,178:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,178:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,178:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,178:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,230:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:48,230:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,230:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,230:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,230:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,230:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,282:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:41:48,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,282:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,282:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,282:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,332:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:41:48,332:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,332:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,332:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,332:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,333:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,382:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:41:48,382:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,383:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,383:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,383:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,383:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,433:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:41:48,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,433:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,433:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,434:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,434:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,483:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:48,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,483:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,483:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,483:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,484:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,534:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:41:48,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,534:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,534:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,534:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.
2025-03-29 15:41:48,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,610:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,610:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,610:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,610:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,686:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:48,686:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,686:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,686:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:48,687:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,687:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:48,747:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:48,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,747:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:48,747:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,747:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:48,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.
2025-03-29 15:41:48,801:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,801:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,801:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:48,801:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,801:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:48,854:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:41:48,854:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,854:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,854:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:48,854:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,855:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:48,906:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:48,906:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,906:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:48,906:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,906:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:48,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:41:48,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:48,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:48,956:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:48,956:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:48,956:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:49,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:41:49,007:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,007:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,007:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:49,007:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:49,008:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:49,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:49,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,057:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:49,057:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:49,057:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:49,107:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:41:49,107:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,107:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,107:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:49,107:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:49,108:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:49,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:49,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,157:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:49,158:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:49,158:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:49,208:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.
2025-03-29 15:41:49,208:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,208:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,208:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:49,208:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:49,208:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:49,256:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:49,256:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,256:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,256:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:49,256:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:49,256:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:49,312:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:41:49,313:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,313:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,313:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:49,313:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,313:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:49,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:49,364:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,364:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,364:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:49,364:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,364:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:49,415:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.
2025-03-29 15:41:49,415:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,415:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,415:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:49,415:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,416:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:49,465:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:49,465:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,465:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,465:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:49,465:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,465:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:49,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:49,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,513:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:49,513:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,513:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:49,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:49,562:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,562:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,562:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:49,562:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,562:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:49,624:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-29 15:41:49,624:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,624:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,624:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:49,624:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,624:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:49,681:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:41:49,682:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,682:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,682:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:49,682:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,682:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:49,732:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:49,733:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,733:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,733:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:49,733:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,733:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:49,785:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:49,785:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,785:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,785:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:49,785:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,785:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:49,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:49,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,841:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,841:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:49,841:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,842:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:49,892:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:41:49,893:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,893:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,893:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:49,893:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,893:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:49,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:41:49,945:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,945:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:49,945:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,945:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:49,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:49,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:49,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:49,994:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:49,994:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:49,995:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:50,044:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:50,044:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,044:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,044:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:50,044:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:50,044:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:50,093:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-03-29 15:41:50,094:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,094:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,094:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:50,094:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:50,094:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:50,144:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:41:50,144:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,144:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:50,144:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:50,144:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:50,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:50,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,195:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:50,195:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:50,195:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:50,245:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:50,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,246:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:50,246:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:50,246:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:50,294:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:41:50,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,294:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:50,294:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:50,294:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:50,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:50,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,350:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:50,350:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,350:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:50,400:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:50,400:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,400:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,400:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:50,400:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,400:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:50,448:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:50,449:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,449:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,449:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:50,449:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,449:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:50,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-03-29 15:41:50,498:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,498:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,498:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:50,498:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,498:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:50,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.
2025-03-29 15:41:50,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,547:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:50,547:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,547:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:50,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:50,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,596:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:50,596:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,596:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:50,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-03-29 15:41:50,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,645:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:50,645:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,645:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:50,694:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:50,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,694:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:50,694:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,694:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:50,747:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:50,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,747:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:50,747:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,747:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:50,797:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:41:50,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,797:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:50,797:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,797:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:50,853:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.
2025-03-29 15:41:50,853:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,853:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,853:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:50,853:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,853:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:50,903:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.
2025-03-29 15:41:50,903:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,903:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,903:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:50,903:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,903:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:50,953:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000616 seconds.
2025-03-29 15:41:50,953:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:50,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:50,953:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:50,953:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:50,953:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:51,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:51,004:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,004:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,004:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:51,004:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,004:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:51,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-03-29 15:41:51,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,055:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,055:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:51,055:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,055:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:51,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.
2025-03-29 15:41:51,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,104:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:51,104:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,104:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:51,152:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:51,152:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,152:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,152:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:51,152:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,152:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:51,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:41:51,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,200:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:51,200:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,200:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:51,247:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:51,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,248:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:51,248:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,248:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:51,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:51,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,297:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:51,297:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,297:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:51,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 15:41:51,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,351:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,351:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,351:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:51,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:41:51,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,403:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,403:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,403:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:51,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:51,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,454:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,454:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,454:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:51,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:51,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,505:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,505:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:51,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:41:51,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,554:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,554:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:51,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:41:51,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,604:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,604:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,604:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:51,655:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-03-29 15:41:51,655:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,655:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,655:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,655:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,655:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:51,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:51,704:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,704:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,704:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,704:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,705:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:51,755:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:51,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,755:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,755:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,755:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:51,804:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:51,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,804:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,804:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,804:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:51,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:51,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,858:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:51,858:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:51,858:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:51,907:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:51,907:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,907:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,907:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:51,908:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:51,908:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:51,958:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:41:51,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:51,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:51,958:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:51,959:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:51,959:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:52,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.
2025-03-29 15:41:52,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,011:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:52,011:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:52,011:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:52,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:41:52,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,059:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:52,059:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:52,059:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:52,110:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:41:52,110:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,110:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:52,110:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:52,110:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:52,161:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:41:52,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,161:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,161:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:52,161:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:52,161:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:52,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:41:52,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,213:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:52,213:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:52,213:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:52,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:41:52,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,263:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:52,263:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:52,263:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:52,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:52,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,315:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:52,315:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:52,315:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:52,371:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:41:52,371:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,371:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,371:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:52,371:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,371:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:52,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:52,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,425:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:52,425:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,426:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:52,476:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-03-29 15:41:52,476:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,476:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,476:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:52,476:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,476:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:52,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:52,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,526:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:52,526:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,526:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:52,575:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:41:52,575:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,575:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,575:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:52,575:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,575:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:52,624:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:52,624:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,624:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,624:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:52,624:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,624:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:52,673:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:52,673:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,673:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,673:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:52,673:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,673:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:52,719:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.
2025-03-29 15:41:52,719:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,720:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:52,720:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,720:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:52,767:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:41:52,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,768:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,768:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:52,768:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,768:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:52,815:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:52,816:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,816:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,816:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:52,816:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,816:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:52,870:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000727 seconds.
2025-03-29 15:41:52,870:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,870:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,870:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:52,870:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,870:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:52,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:52,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,919:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:52,919:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,919:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:52,969:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000449 seconds.
2025-03-29 15:41:52,969:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:52,969:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:52,969:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:52,969:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:52,969:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:53,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:41:53,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,021:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,021:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,021:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:53,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:53,071:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,071:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,071:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,071:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,071:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:53,121:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-29 15:41:53,121:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,121:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,121:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,121:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,121:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:53,170:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:53,171:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,171:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,171:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,171:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,171:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:53,220:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:41:53,220:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,220:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,220:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,220:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,220:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:53,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:53,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,271:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,271:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,271:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:53,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:53,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,319:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,319:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,319:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,320:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:53,375:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:41:53,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,375:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,375:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,375:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:53,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:41:53,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,425:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,425:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,425:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:53,473:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:53,473:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,474:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,474:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,474:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:53,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:41:53,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,544:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,544:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,544:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:53,620:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.
2025-03-29 15:41:53,620:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,620:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,620:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,620:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,620:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:53,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:53,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,693:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,693:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,693:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:53,768:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:41:53,768:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,768:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,768:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,768:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,768:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:53,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-03-29 15:41:53,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,842:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,842:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,842:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:53,910:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:53,910:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,910:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,910:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,910:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,910:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:53,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:41:53,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:53,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:53,973:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:53,973:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:53,973:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:54,039:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:41:54,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,039:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:54,039:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:54,039:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:54,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:54,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,092:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:54,092:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:54,092:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:54,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:54,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,147:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:54,147:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:54,147:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:54,199:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:54,199:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,199:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,199:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:54,199:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:54,200:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:54,252:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:54,252:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,252:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,252:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:54,252:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:54,252:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:54,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:41:54,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,303:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:54,303:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:54,303:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:54,354:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:41:54,355:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,355:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,355:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:54,355:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:54,355:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:54,406:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:41:54,407:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,407:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,407:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:54,407:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:54,407:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:54,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:54,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,457:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:54,457:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:54,458:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:54,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:54,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,508:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:54,508:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:54,508:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:54,567:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:41:54,567:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,567:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,567:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:54,567:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:54,568:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:54,623:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:54,623:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,623:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,623:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:54,623:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:54,623:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:54,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:41:54,677:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,677:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,677:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:54,677:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:54,677:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:54,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:54,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,728:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:54,728:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:54,728:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:54,778:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:41:54,778:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,778:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,778:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:54,778:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:54,779:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:54,829:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-29 15:41:54,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,830:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:54,830:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:54,830:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:54,880:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:41:54,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,880:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:54,880:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:54,880:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:54,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:54,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,930:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:54,930:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:54,930:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:54,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:41:54,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:54,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:54,979:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:54,979:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:54,980:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:55,037:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:55,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,037:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:55,037:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:55,037:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:55,090:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-03-29 15:41:55,090:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,091:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,091:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:55,091:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:55,091:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:55,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:41:55,143:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,143:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,143:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:55,144:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:55,144:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:55,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-03-29 15:41:55,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,196:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:55,196:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:55,196:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:55,246:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:41:55,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,246:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:55,246:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:55,247:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:55,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-03-29 15:41:55,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,297:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:55,297:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:55,298:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:55,349:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:41:55,349:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,349:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,349:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:55,349:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:55,349:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:55,399:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:55,399:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,399:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,399:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:55,399:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:55,399:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:55,448:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:55,448:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,448:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,449:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:55,449:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:55,449:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:55,504:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-03-29 15:41:55,504:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,504:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,504:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:55,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:55,505:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:55,559:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:41:55,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,559:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,559:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:55,559:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:55,560:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:55,613:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:55,613:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,613:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,613:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:55,613:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:55,613:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:55,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:41:55,666:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,666:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,666:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:55,666:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:55,666:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:55,718:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:41:55,718:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,718:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,718:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:55,718:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:55,718:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:55,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:55,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,771:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:55,771:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:55,771:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:55,822:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:55,823:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,823:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,823:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:55,823:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:55,823:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:55,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:55,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,874:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:55,874:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:55,874:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:55,922:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:55,922:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,922:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,922:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:55,923:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:55,923:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:41:55,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-03-29 15:41:55,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:55,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:55,979:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:55,979:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:55,979:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:56,030:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:56,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,031:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:56,031:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,031:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:56,083:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:56,083:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,083:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,083:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:56,083:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,083:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:56,135:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:56,135:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,135:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,135:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:56,136:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,136:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:56,188:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:56,188:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,188:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,188:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:56,188:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,188:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:56,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:56,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,240:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:56,240:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,241:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:56,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:41:56,293:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,293:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:56,293:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,293:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:56,344:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2025-03-29 15:41:56,344:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,344:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,344:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:56,344:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,344:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:56,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:56,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,395:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:41:56,395:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,395:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:41:56,452:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:56,452:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,452:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,452:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:56,452:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,452:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:56,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:56,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,505:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:56,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,505:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:56,557:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:41:56,557:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,557:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,557:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:56,557:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,558:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:56,613:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:56,613:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,614:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:56,614:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,614:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:56,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:56,667:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,667:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,667:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:56,667:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,667:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:56,718:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:56,718:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,718:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,718:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:56,718:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,719:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:56,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:41:56,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,769:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,769:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:56,769:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,770:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:56,821:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:41:56,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,821:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:56,821:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,821:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:56,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:41:56,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,872:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:56,872:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,873:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:41:56,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:41:56,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,930:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:41:56,930:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:56,930:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:56,985:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:41:56,985:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:56,985:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:56,985:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:56,985:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:56,985:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:57,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:41:57,038:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,038:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,038:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:57,038:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:57,038:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:57,090:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.
2025-03-29 15:41:57,090:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,090:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,090:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:57,090:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:57,090:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:57,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:57,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,141:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:57,141:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:57,141:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:57,203:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:41:57,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,203:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:57,203:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:57,203:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:57,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:41:57,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,251:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:57,251:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:57,251:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:57,299:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.
2025-03-29 15:41:57,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,299:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:57,299:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:57,299:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:57,361:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:41:57,361:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,361:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,361:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:41:57,361:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:41:57,361:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:41:57,415:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:57,415:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,415:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,415:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:57,415:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,415:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:57,464:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:41:57,464:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,464:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,464:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:57,464:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,465:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:57,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:41:57,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,512:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:57,512:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,512:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:57,560:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.
2025-03-29 15:41:57,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,561:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:57,561:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,561:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:57,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:41:57,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,610:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,610:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:57,610:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,610:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:57,660:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:57,660:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,660:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,660:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:57,660:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,660:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:57,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:41:57,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,707:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:57,707:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,707:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:57,755:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:41:57,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,755:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:57,755:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,755:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:57,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:57,801:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,801:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,801:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:41:57,801:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,801:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:41:57,856:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:41:57,856:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,856:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,856:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:57,857:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,857:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:57,906:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:41:57,906:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,906:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:57,906:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,906:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:57,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:57,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:57,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:57,956:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:57,956:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:57,956:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:58,014:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:41:58,014:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,014:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,014:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,014:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,014:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:58,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:58,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,063:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,063:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,063:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:58,111:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:41:58,111:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,111:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,111:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,112:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,112:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:58,160:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.
2025-03-29 15:41:58,160:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,160:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,160:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,160:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,160:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:58,208:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-03-29 15:41:58,208:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,208:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,208:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,208:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,208:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:58,256:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:58,256:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,256:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,256:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,256:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,256:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:41:58,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:41:58,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,311:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,311:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,312:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:58,359:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:41:58,359:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,360:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,360:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,360:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:58,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:41:58,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,409:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,409:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,409:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:58,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:41:58,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,457:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,458:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,458:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:58,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:41:58,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,505:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,505:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:58,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:41:58,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,554:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,554:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,554:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:58,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:58,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,602:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,602:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,603:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:58,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000784 seconds.
2025-03-29 15:41:58,653:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:41:58,653:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,653:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,653:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:58,708:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:41:58,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,708:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:41:58,708:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,709:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:41:58,762:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:41:58,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,762:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,762:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:58,762:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,762:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:58,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:58,811:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,811:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,811:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:58,811:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,811:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:58,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:41:58,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,860:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:58,860:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,860:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:58,909:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:41:58,909:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,909:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,909:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:58,909:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,909:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:58,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:41:58,957:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:58,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:58,957:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:58,957:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:58,957:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:59,005:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:41:59,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,006:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:59,006:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:59,006:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:59,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:41:59,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,054:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:59,054:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:59,054:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:59,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:41:59,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,102:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:59,102:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:59,102:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:59,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:41:59,151:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,151:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,151:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:41:59,151:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:41:59,151:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:41:59,206:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:41:59,206:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,206:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,206:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:59,206:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,206:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:59,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:41:59,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,254:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:59,254:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,255:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:59,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.
2025-03-29 15:41:59,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,303:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:59,303:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,304:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:59,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:59,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,352:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:59,352:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,352:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:59,401:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:59,401:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,401:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,401:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:59,401:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,401:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:59,450:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:41:59,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,450:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,450:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:59,450:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,450:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:59,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:41:59,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,501:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:59,501:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,501:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:59,552:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:41:59,552:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,552:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,552:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:41:59,552:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,552:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:41:59,609:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:41:59,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,609:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:59,609:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,609:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:59,661:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:41:59,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,661:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:59,661:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,661:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:59,710:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:41:59,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,710:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:59,710:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,710:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:59,759:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:41:59,759:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,759:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,759:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:59,759:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,759:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:59,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:41:59,811:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,811:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,811:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:59,811:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,811:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:59,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:41:59,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,860:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:59,860:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,860:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:59,913:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:41:59,913:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,913:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,913:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:59,913:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,913:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:41:59,964:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:41:59,964:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:41:59,964:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:41:59,964:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:41:59,964:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:41:59,964:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:00,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:42:00,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,025:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:00,025:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,025:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:00,081:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:42:00,082:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,082:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,082:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:00,082:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,082:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:00,138:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:42:00,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,138:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,139:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:00,139:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,139:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:00,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:42:00,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,190:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:00,190:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,190:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:00,242:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:42:00,242:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,242:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,242:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:00,242:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,242:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:00,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:42:00,293:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,293:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:00,293:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,293:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:00,345:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:42:00,345:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,345:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,345:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:00,345:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,345:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:00,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:42:00,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,397:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:00,397:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,397:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:00,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:42:00,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,455:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:00,455:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,455:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:00,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:42:00,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,508:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:00,508:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,508:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:00,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:42:00,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,561:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:00,561:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,561:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:00,613:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:42:00,613:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,613:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,613:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:00,613:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,613:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:00,668:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:42:00,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,668:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,668:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:00,668:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,668:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:00,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:42:00,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,721:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,722:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:00,722:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,722:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:00,776:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:42:00,776:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,776:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,776:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:00,776:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,777:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:00,831:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:42:00,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,831:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:00,831:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,831:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:00,891:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:42:00,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,891:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:00,891:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,891:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:00,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:42:00,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:00,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:00,962:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:00,962:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:00,963:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:01,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-03-29 15:42:01,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,039:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:01,039:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:01,039:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:01,114:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:42:01,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,115:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:01,115:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:01,115:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:01,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.
2025-03-29 15:42:01,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,187:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:01,188:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:01,188:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:01,260:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2025-03-29 15:42:01,260:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,260:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,260:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:01,260:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:01,260:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:01,331:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:42:01,331:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,331:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,331:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:01,331:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:01,331:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:01,404:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:42:01,404:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,404:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,404:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:01,404:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:01,405:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:01,464:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:42:01,464:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,464:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,464:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:01,464:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:01,464:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:01,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.
2025-03-29 15:42:01,515:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,515:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,515:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:01,515:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:01,516:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:01,568:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.
2025-03-29 15:42:01,568:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,568:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,568:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:01,568:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:01,568:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:01,621:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.
2025-03-29 15:42:01,621:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,621:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,621:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:01,621:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:01,621:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:01,675:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.
2025-03-29 15:42:01,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,676:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:01,676:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:01,676:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:01,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000280 seconds.
2025-03-29 15:42:01,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,726:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:01,726:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:01,726:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:01,775:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.
2025-03-29 15:42:01,775:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,775:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,775:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:01,775:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:01,776:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:01,826:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:42:01,826:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,826:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,826:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:01,826:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:01,826:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:01,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:42:01,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,883:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:01,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:01,884:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:01,937:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:42:01,937:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,937:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,937:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:01,938:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:01,938:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:01,989:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:42:01,989:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:01,989:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:01,989:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:01,989:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:01,989:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:02,039:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:42:02,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,039:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:02,039:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,039:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:02,091:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:42:02,091:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,091:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,091:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:02,091:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,091:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:02,145:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:42:02,145:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,145:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,145:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:02,145:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,145:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:02,196:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:02,196:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,196:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,196:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:02,196:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,197:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:02,247:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:42:02,247:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,247:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,247:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:02,247:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,247:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:02,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.
2025-03-29 15:42:02,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,304:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:02,304:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,304:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:02,361:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:02,361:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,361:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,361:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:02,361:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,361:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:02,445:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.
2025-03-29 15:42:02,445:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:42:02,445:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:02,445:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,446:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:02,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-29 15:42:02,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,534:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:02,534:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,534:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:02,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.
2025-03-29 15:42:02,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,638:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:02,638:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,638:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:02,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.
2025-03-29 15:42:02,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,746:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,746:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:02,746:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,746:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:02,833:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:42:02,833:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,833:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,833:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:02,833:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,833:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:02,914:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:42:02,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:02,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:02,914:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:02,914:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:02,914:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:03,000:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-03-29 15:42:03,000:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,000:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,000:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:03,000:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,000:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:03,079:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:42:03,080:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,080:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,080:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:03,080:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,080:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:03,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:42:03,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,157:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:03,157:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,157:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:03,232:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-03-29 15:42:03,232:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,232:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,232:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:03,233:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,233:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:03,308:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:42:03,308:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,308:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,308:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:03,308:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,308:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:03,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:42:03,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,382:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,382:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:03,382:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,382:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:03,458:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:42:03,458:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,458:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,458:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:03,458:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,458:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:03,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:42:03,532:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,533:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:03,533:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,533:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:03,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-03-29 15:42:03,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,617:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:03,617:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,617:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:03,695:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.
2025-03-29 15:42:03,695:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,695:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,695:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:03,695:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,696:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:03,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-03-29 15:42:03,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,771:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:03,771:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,771:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:03,844:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-03-29 15:42:03,844:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,844:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,844:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:03,844:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,845:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:03,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-03-29 15:42:03,918:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:03,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:03,918:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:03,918:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:03,918:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:04,026:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-03-29 15:42:04,026:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,026:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,027:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:04,027:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:04,027:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:04,097:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:42:04,098:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,098:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,098:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:04,098:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:04,098:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:04,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:42:04,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,163:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:04,164:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:04,164:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:04,233:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:42:04,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,233:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,233:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:04,233:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,234:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:04,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-03-29 15:42:04,296:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,296:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,296:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:04,296:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,296:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:04,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:42:04,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,352:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:04,352:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,352:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:04,413:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:42:04,413:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,413:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,413:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:04,413:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,413:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:04,471:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.
2025-03-29 15:42:04,471:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,471:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,471:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:04,471:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,471:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:04,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:04,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,525:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:04,525:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,525:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:04,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:42:04,580:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,580:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,580:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:04,580:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,580:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:04,656:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.
2025-03-29 15:42:04,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,656:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:04,656:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,656:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:04,710:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:42:04,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,710:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:04,710:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,710:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:04,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:42:04,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,763:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:04,763:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,763:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:04,831:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:42:04,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,831:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:04,831:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,831:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:04,884:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-29 15:42:04,885:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,885:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,885:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:04,885:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,885:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:04,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:42:04,941:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,941:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,941:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:04,941:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,941:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:04,993:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:42:04,993:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:04,993:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:04,994:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:04,994:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:04,994:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:05,049:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:42:05,049:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,050:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,050:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:05,050:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,050:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:05,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:42:05,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,100:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:05,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,100:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:05,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:42:05,158:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,158:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,158:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:05,158:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,158:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:05,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:42:05,209:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,209:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,209:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:05,209:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,209:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:05,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:42:05,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,259:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:05,259:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,259:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:05,307:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:42:05,307:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,308:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:05,308:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,308:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:05,354:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-03-29 15:42:05,354:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,354:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,355:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:05,355:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,355:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:05,408:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:42:05,408:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,408:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,408:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:05,408:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,408:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:05,458:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:42:05,458:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,458:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,458:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:05,458:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,458:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:05,506:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:42:05,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,506:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:05,506:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,507:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:05,556:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:42:05,556:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,556:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,556:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:05,556:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,556:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:05,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:42:05,611:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,611:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,611:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:05,611:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,611:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:05,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:42:05,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,665:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:05,665:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,665:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:05,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:42:05,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,714:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:05,714:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,714:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:05,773:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:05,773:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,773:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,773:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:05,773:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,773:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:05,824:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:42:05,824:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,824:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,824:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:05,824:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,824:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:05,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:42:05,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,876:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:05,876:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,876:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:05,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:42:05,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,927:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:05,927:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,928:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:05,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:42:05,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:05,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:05,979:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:05,979:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:05,979:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:06,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:42:06,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,033:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:06,033:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,033:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:06,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:42:06,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,084:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:06,084:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,084:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:06,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:42:06,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,139:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:06,139:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,139:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:06,189:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:42:06,189:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,189:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,189:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:06,189:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:06,189:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:06,239:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.
2025-03-29 15:42:06,239:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,239:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,239:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:06,239:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:06,239:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:06,292:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:42:06,293:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,293:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:06,293:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:06,293:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:06,343:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-03-29 15:42:06,343:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,343:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,343:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:06,343:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:06,344:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:06,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:42:06,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,393:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:06,393:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:06,393:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:06,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.
2025-03-29 15:42:06,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,442:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:06,443:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:06,443:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:06,504:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:42:06,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,505:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:06,505:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,505:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:06,559:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.
2025-03-29 15:42:06,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,559:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,559:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:06,559:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,559:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:06,611:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:06,611:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,611:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,611:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:06,611:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,611:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:06,662:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:42:06,663:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,663:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,663:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:06,663:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,663:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:06,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:42:06,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,714:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:06,714:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,714:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:06,764:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:42:06,764:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,764:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,764:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:06,764:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,764:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:06,816:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:42:06,816:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,816:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,816:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:06,816:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,816:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:06,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:42:06,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,873:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:06,874:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,874:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:06,925:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:42:06,925:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:06,925:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:06,925:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:06,925:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:06,925:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:07,002:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-29 15:42:07,002:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,002:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,002:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,002:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,002:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:07,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:42:07,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,058:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,058:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,058:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:07,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:42:07,109:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,109:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,109:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,109:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,110:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:07,165:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:42:07,165:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,165:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,165:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,165:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:07,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-03-29 15:42:07,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,213:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,213:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,213:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:07,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:42:07,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,289:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,289:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,289:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:07,339:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:42:07,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,339:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,339:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,339:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:07,404:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:42:07,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,405:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,405:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,405:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:07,453:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-03-29 15:42:07,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,454:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,454:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,454:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:07,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:07,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,502:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,502:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,502:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:07,551:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:42:07,551:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,551:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,551:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,551:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,551:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:07,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:42:07,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,604:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:07,604:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,604:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:07,666:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:42:07,666:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,666:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,666:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:07,666:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,666:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:07,723:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.
2025-03-29 15:42:07,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,724:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:07,724:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,724:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:07,777:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:42:07,777:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,777:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:07,777:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,777:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:07,830:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:42:07,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,830:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:07,830:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,830:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:07,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:42:07,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,883:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:07,883:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,883:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:07,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:42:07,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,933:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:07,933:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,933:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:07,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:42:07,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:07,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:07,981:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:07,981:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:07,981:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:08,037:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:42:08,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,037:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:08,037:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,037:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:08,086:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:42:08,086:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,086:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,086:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:08,086:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,086:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:08,136:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000633 seconds.
2025-03-29 15:42:08,136:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,136:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,136:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:08,136:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,136:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:08,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:42:08,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,187:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:08,187:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,187:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:08,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:42:08,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,238:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:08,238:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,238:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:08,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.
2025-03-29 15:42:08,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,290:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:08,290:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,290:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:08,348:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:42:08,348:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,348:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,349:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:08,349:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,349:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:08,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:42:08,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,402:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:08,402:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,403:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:08,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:42:08,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,457:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:08,457:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,457:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:08,510:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.
2025-03-29 15:42:08,510:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,510:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,510:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:08,510:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,510:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:08,562:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2025-03-29 15:42:08,562:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,562:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,562:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:08,562:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,562:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:08,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:42:08,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,614:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:08,614:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:08,614:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:08,673:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:42:08,673:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,673:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,674:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:08,674:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:08,674:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:08,727:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.
2025-03-29 15:42:08,727:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:42:08,727:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:08,727:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:08,727:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:08,788:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:42:08,788:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,788:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,788:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:08,788:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:08,788:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:08,840:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:42:08,840:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,840:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,840:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:08,840:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:08,841:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:08,894:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:42:08,894:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,894:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,894:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:08,894:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:08,894:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:08,948:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:42:08,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:08,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:08,948:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:08,948:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:08,948:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:09,015:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:42:09,015:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,015:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,015:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:09,015:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,016:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:09,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.
2025-03-29 15:42:09,075:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,075:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,075:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:09,075:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,075:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:09,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2025-03-29 15:42:09,132:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,132:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:09,132:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,132:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:09,191:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-03-29 15:42:09,191:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,191:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,191:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:09,191:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,191:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:09,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:42:09,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,251:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:09,251:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,251:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:09,308:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.
2025-03-29 15:42:09,308:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,308:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,308:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:09,308:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,308:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:09,371:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.
2025-03-29 15:42:09,371:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,371:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,371:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:09,371:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,371:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:09,430:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:42:09,430:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,430:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,430:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:09,430:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,431:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:09,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.
2025-03-29 15:42:09,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,489:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:09,489:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,489:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:09,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:42:09,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,542:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:09,542:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,542:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:09,620:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000683 seconds.
2025-03-29 15:42:09,620:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,620:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,620:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:09,620:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,620:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:09,673:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:42:09,673:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,673:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,673:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:09,673:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,673:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:09,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2025-03-29 15:42:09,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,728:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:09,728:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:09,728:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:09,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:42:09,779:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,779:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,779:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:09,779:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:09,779:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:09,827:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:42:09,827:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,827:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,827:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:09,828:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:09,828:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:09,881:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2025-03-29 15:42:09,881:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,881:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,881:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:09,881:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:09,881:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:09,937:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-03-29 15:42:09,937:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,937:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,937:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:09,937:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:09,937:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:09,992:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:42:09,992:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:09,992:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:09,992:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:09,992:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:09,993:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:10,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:42:10,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,048:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:10,048:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,048:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:10,095:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-03-29 15:42:10,095:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,096:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,096:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:10,096:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,096:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:10,145:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.
2025-03-29 15:42:10,145:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,145:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,145:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:10,145:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,145:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:10,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:42:10,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,195:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:10,195:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,195:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:10,242:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:42:10,242:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,242:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,242:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:10,242:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,242:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:10,332:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:42:10,332:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,332:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,332:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:10,332:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,333:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:10,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.
2025-03-29 15:42:10,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,392:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,392:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,392:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:10,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:42:10,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,447:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,447:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,447:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,447:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:10,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:42:10,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,502:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,502:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,502:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:10,560:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:42:10,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,561:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,561:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,561:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:10,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.
2025-03-29 15:42:10,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,614:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,614:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,614:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:10,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:42:10,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,664:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,664:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:10,719:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-03-29 15:42:10,719:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,719:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,719:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,719:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,719:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:10,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-29 15:42:10,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,770:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,770:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,771:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:10,826:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:10,826:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,826:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,826:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,826:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,826:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:10,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:42:10,879:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,879:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,879:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,879:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,879:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:10,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:42:10,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,933:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,933:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,933:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:10,986:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:42:10,986:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:10,986:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:10,986:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:10,986:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:10,987:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:11,046:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.
2025-03-29 15:42:11,047:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,047:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,047:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:11,047:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:11,047:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:11,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:42:11,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,102:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:11,102:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:11,102:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:11,156:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-03-29 15:42:11,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,157:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:11,157:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:11,157:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:11,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-03-29 15:42:11,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,210:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:11,210:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:11,211:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:11,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.
2025-03-29 15:42:11,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,263:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:11,263:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:11,264:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:11,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:42:11,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,319:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,319:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:11,319:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:11,319:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:11,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:42:11,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,378:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:11,378:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:11,378:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:11,430:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:42:11,430:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,430:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,430:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:11,430:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:11,430:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:11,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:42:11,482:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,482:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:11,482:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:11,482:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:11,541:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:42:11,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,542:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:11,542:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:11,542:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:11,593:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:42:11,593:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,593:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,593:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:11,593:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:11,593:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:11,655:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-29 15:42:11,655:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,655:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,655:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:11,655:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:11,655:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:11,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-03-29 15:42:11,704:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,704:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,704:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:11,704:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:11,704:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:11,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-03-29 15:42:11,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,755:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:11,755:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:11,755:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:11,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000621 seconds.
2025-03-29 15:42:11,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:42:11,804:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:11,804:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:11,805:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:11,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:11,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,864:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:11,864:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:11,864:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:11,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:42:11,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,924:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,924:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:11,924:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:11,924:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:11,978:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:42:11,978:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:11,978:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:11,978:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:11,978:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:11,978:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:12,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:42:12,032:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,032:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,032:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:12,032:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,033:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:12,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:42:12,087:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,087:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,087:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:12,087:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,087:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:12,140:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:42:12,140:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,140:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,140:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:12,140:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,140:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:12,197:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.
2025-03-29 15:42:12,197:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,197:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,197:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:12,197:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,197:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:12,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:42:12,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,250:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:12,251:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,251:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:12,306:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:42:12,306:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,306:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,306:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:12,306:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,306:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:12,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:42:12,358:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,358:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,358:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:12,359:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,359:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:12,412:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:42:12,412:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,412:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,412:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:12,412:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,413:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:12,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:42:12,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,472:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,472:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:12,472:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,472:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:12,528:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-29 15:42:12,528:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,528:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,529:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:12,529:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,529:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:12,581:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:42:12,581:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,582:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,582:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:12,582:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,582:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:12,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-03-29 15:42:12,635:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,635:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,635:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:12,635:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,635:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:12,690:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:42:12,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,690:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:12,690:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,690:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:12,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.
2025-03-29 15:42:12,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,749:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:12,749:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:12,749:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:12,803:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.
2025-03-29 15:42:12,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,804:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:12,804:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:12,804:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:12,857:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.
2025-03-29 15:42:12,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,857:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:12,857:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:12,857:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:12,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:42:12,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,915:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,915:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:12,915:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:12,916:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:12,968:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-03-29 15:42:12,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:12,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:12,968:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:12,968:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:12,969:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:13,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2025-03-29 15:42:13,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,025:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,025:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:13,025:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,026:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:13,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.
2025-03-29 15:42:13,075:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,075:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,076:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:13,076:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,076:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:13,126:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:42:13,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,126:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:13,126:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,126:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:13,175:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:42:13,175:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,175:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,175:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:13,175:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,176:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:13,224:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:42:13,224:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,224:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,224:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:13,224:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,224:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:13,278:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:42:13,278:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,278:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,278:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:13,278:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,279:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:13,328:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:42:13,328:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,328:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,328:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:13,328:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,328:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:13,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:42:13,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,378:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:13,378:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,378:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:13,427:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-03-29 15:42:13,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,428:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,428:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:13,428:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,428:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:13,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:42:13,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,478:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:13,478:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,478:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:13,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.
2025-03-29 15:42:13,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,534:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:13,534:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,534:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:13,583:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2025-03-29 15:42:13,583:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,583:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,584:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:13,584:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,584:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:13,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:42:13,635:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,635:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,635:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:13,635:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,635:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:13,687:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-03-29 15:42:13,687:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,687:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,687:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:13,687:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,687:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:13,741:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-03-29 15:42:13,741:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,741:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,741:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:13,741:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,741:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:13,797:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-03-29 15:42:13,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,797:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:13,797:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,797:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:13,849:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:42:13,849:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,849:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,849:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:13,849:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,849:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:13,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:42:13,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,900:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:13,900:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,900:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:13,950:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:42:13,951:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:13,951:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:13,951:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:13,951:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:13,951:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:14,000:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-03-29 15:42:14,000:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,001:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:14,001:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,001:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:14,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.
2025-03-29 15:42:14,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,058:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:14,058:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:14,058:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:14,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:14,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,108:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:14,108:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:14,108:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:14,159:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-03-29 15:42:14,159:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,159:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,159:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:14,159:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:14,159:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:14,208:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-03-29 15:42:14,208:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,208:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,208:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:14,208:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:14,208:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:14,264:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-03-29 15:42:14,264:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,264:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:14,264:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:14,264:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:14,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.
2025-03-29 15:42:14,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,315:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:14,315:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:14,315:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:14,366:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:42:14,366:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,366:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,366:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:14,366:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:14,366:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:14,415:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-03-29 15:42:14,415:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,415:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,415:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:14,415:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:14,415:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:14,471:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:42:14,471:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,471:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,471:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:14,471:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,471:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:14,521:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.
2025-03-29 15:42:14,521:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,521:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,521:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:14,521:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,521:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:14,571:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-03-29 15:42:14,571:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,571:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,571:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:14,571:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,571:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:14,620:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2025-03-29 15:42:14,620:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,620:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,620:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:14,620:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,620:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:14,677:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-03-29 15:42:14,677:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,677:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,677:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:14,677:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,677:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:14,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:42:14,727:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,727:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:14,727:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,727:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:14,777:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:42:14,777:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,777:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:14,777:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,777:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:14,829:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-03-29 15:42:14,829:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,829:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,829:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:14,829:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,829:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:14,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:42:14,884:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,884:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,884:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:14,884:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,884:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:14,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:42:14,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,933:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:14,933:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,933:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:14,986:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:42:14,987:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:14,987:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:14,987:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:14,987:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:14,987:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:15,039:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:42:15,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,039:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:15,039:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,040:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:15,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:42:15,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,100:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:15,100:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,100:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:15,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:42:15,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,155:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:15,155:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:15,156:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:15,206:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-03-29 15:42:15,206:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,206:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,206:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:15,206:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:15,206:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:15,256:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:42:15,256:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,256:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,256:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:15,256:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:15,256:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:15,313:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-03-29 15:42:15,313:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,313:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,313:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:15,313:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,313:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:15,365:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.
2025-03-29 15:42:15,365:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,365:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,365:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:15,365:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,365:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:15,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:42:15,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,417:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:15,417:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,417:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:15,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-03-29 15:42:15,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,472:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,472:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:15,472:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,473:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:15,530:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-03-29 15:42:15,530:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,530:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,530:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:15,530:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,531:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:15,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-03-29 15:42:15,583:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,583:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,583:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:15,583:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,583:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:15,634:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-03-29 15:42:15,634:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,634:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,634:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:15,634:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,634:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:15,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:42:15,688:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,688:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,688:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:15,688:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,688:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:15,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.
2025-03-29 15:42:15,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,752:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,752:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:15,752:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,752:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:15,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-03-29 15:42:15,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,807:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:15,807:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,807:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:15,861:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:42:15,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,862:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:15,862:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,862:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:15,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:42:15,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,911:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:15,911:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,911:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:15,966:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-29 15:42:15,966:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:15,966:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:15,966:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:15,966:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:15,966:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:16,017:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-03-29 15:42:16,018:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,018:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:16,018:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,018:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:16,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:42:16,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,068:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:16,068:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,068:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:16,119:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2025-03-29 15:42:16,119:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,119:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,119:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:16,119:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,119:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:16,185:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:42:16,185:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,185:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,185:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:16,185:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:16,186:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:16,242:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-03-29 15:42:16,242:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,242:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,242:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:16,242:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:16,242:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:16,298:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:42:16,298:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,298:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,298:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:16,298:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:16,298:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:16,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.
2025-03-29 15:42:16,362:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,362:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,362:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:16,362:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:16,362:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:16,422:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.
2025-03-29 15:42:16,422:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,422:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,422:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:16,422:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:16,422:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:16,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.
2025-03-29 15:42:16,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,478:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:16,478:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:16,478:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:16,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:42:16,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,538:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,538:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:16,538:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,538:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:16,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:42:16,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,597:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:16,597:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,598:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:16,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:42:16,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,652:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:16,652:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,652:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:16,713:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:42:16,713:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,713:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,713:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:16,713:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,713:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:16,767:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-03-29 15:42:16,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,767:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,768:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:16,768:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,768:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:16,823:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.
2025-03-29 15:42:16,823:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,823:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,823:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:16,823:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,823:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:16,884:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-03-29 15:42:16,884:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,884:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,884:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:16,884:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,885:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:16,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.
2025-03-29 15:42:16,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,939:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:16,939:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,939:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:16,992:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:16,992:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:16,992:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:16,992:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:16,992:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:16,992:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:17,050:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-03-29 15:42:17,050:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,050:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,050:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:17,050:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,050:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:17,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.
2025-03-29 15:42:17,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,102:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:17,102:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:17,102:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:17,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:42:17,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,154:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:17,154:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:17,154:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:17,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-03-29 15:42:17,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,214:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:17,214:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,214:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:17,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000622 seconds.
2025-03-29 15:42:17,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,270:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:17,270:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,271:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:17,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:42:17,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,339:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:17,339:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,339:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:17,412:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000629 seconds.
2025-03-29 15:42:17,412:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-29 15:42:17,412:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:17,412:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,413:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:17,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:42:17,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,483:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,483:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:17,483:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,483:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:17,555:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-03-29 15:42:17,555:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,555:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,555:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:17,556:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,556:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:17,613:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:42:17,613:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,613:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,613:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:17,613:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,613:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:17,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:17,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,664:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:17,664:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,664:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:17,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.
2025-03-29 15:42:17,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,717:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:17,717:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,717:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:17,775:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-03-29 15:42:17,775:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,775:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,775:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:17,775:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,775:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:17,828:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.
2025-03-29 15:42:17,828:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,828:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,829:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:17,829:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,829:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:17,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-03-29 15:42:17,882:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,882:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,882:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:17,882:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:17,882:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:17,942:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-29 15:42:17,942:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,942:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,942:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:17,942:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:17,942:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:17,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-03-29 15:42:17,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:17,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:17,997:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:17,997:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:17,997:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:18,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.
2025-03-29 15:42:18,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,055:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,055:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:18,056:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:18,056:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:18,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.
2025-03-29 15:42:18,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,108:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:18,108:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:18,108:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:18,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2025-03-29 15:42:18,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,164:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:18,164:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,164:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:18,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-03-29 15:42:18,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,213:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:18,213:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,213:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:18,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:42:18,268:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,268:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,268:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:18,268:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,268:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:18,318:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-03-29 15:42:18,318:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,318:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,318:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:18,318:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,318:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:18,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-03-29 15:42:18,374:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,374:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,374:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:18,374:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,374:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:18,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-03-29 15:42:18,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,424:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:18,424:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,424:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:18,483:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-03-29 15:42:18,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,483:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,483:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:18,483:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,483:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:18,552:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-03-29 15:42:18,552:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,552:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,552:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:18,552:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 14
2025-03-29 15:42:18,552:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:18,619:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-03-29 15:42:18,619:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,619:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,619:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:18,619:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,619:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:18,673:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-03-29 15:42:18,673:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,673:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,673:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:18,674:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,674:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:18,752:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:42:18,752:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,752:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,752:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:18,753:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,753:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:18,830:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:42:18,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,830:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:18,830:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,830:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:18,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-03-29 15:42:18,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,915:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,915:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:18,915:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,915:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:18,991:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-03-29 15:42:18,991:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:18,991:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:18,991:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:18,991:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:18,991:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:19,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:42:19,075:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,076:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:19,076:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:19,076:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:19,151:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:42:19,151:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,151:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,151:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:19,151:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:19,152:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:19,234:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:42:19,234:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,234:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,234:INFO:[LightGBM] [Info] Total Bins 564
2025-03-29 15:42:19,234:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:19,234:INFO:[LightGBM] [Info] Start training from score 3251.550927
2025-03-29 15:42:19,316:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-03-29 15:42:19,316:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,316:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,316:INFO:[LightGBM] [Info] Total Bins 561
2025-03-29 15:42:19,316:INFO:[LightGBM] [Info] Number of data points in the train set: 30367, number of used features: 15
2025-03-29 15:42:19,316:INFO:[LightGBM] [Info] Start training from score 3246.877564
2025-03-29 15:42:19,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-03-29 15:42:19,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,394:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:19,394:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:19,394:INFO:[LightGBM] [Info] Start training from score 3257.837395
2025-03-29 15:42:19,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-03-29 15:42:19,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,478:INFO:[LightGBM] [Info] Total Bins 557
2025-03-29 15:42:19,478:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:19,478:INFO:[LightGBM] [Info] Start training from score 3257.776805
2025-03-29 15:42:19,562:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2025-03-29 15:42:19,562:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,562:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,562:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:19,562:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:19,562:INFO:[LightGBM] [Info] Start training from score 3250.623815
2025-03-29 15:42:19,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-03-29 15:42:19,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,644:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:42:19,644:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:19,645:INFO:[LightGBM] [Info] Start training from score 3253.088811
2025-03-29 15:42:19,725:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-03-29 15:42:19,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,725:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 15:42:19,725:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:19,725:INFO:[LightGBM] [Info] Start training from score 3252.954722
2025-03-29 15:42:19,805:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-03-29 15:42:19,805:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,805:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,805:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:19,805:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:19,805:INFO:[LightGBM] [Info] Start training from score 3248.962954
2025-03-29 15:42:19,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-03-29 15:42:19,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,889:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:19,889:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:19,889:INFO:[LightGBM] [Info] Start training from score 3244.335155
2025-03-29 15:42:19,971:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-03-29 15:42:19,972:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:19,972:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:19,972:INFO:[LightGBM] [Info] Total Bins 558
2025-03-29 15:42:19,972:INFO:[LightGBM] [Info] Number of data points in the train set: 30368, number of used features: 15
2025-03-29 15:42:19,972:INFO:[LightGBM] [Info] Start training from score 3253.187763
2025-03-29 15:42:20,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2025-03-29 15:42:20,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,031:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,031:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,031:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,085:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.
2025-03-29 15:42:20,085:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,085:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,085:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,085:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,085:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.
2025-03-29 15:42:20,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,142:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,142:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,142:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,142:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,196:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2025-03-29 15:42:20,196:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,196:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,196:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,196:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,196:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,249:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2025-03-29 15:42:20,249:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,249:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,249:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,250:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,250:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-03-29 15:42:20,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,304:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,304:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,304:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,359:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-03-29 15:42:20,359:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,359:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,359:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,359:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,359:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,411:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-29 15:42:20,411:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,411:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,411:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,412:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,412:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,463:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-29 15:42:20,463:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,463:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,463:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,463:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,463:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-03-29 15:42:20,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,512:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,512:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,512:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,571:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-03-29 15:42:20,571:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,571:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,572:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,572:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,572:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,623:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.
2025-03-29 15:42:20,623:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,623:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,624:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,624:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,624:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,679:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.
2025-03-29 15:42:20,680:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:20,680:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:20,680:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:20,680:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:20,680:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:20,825:INFO:Visual Rendered Successfully
2025-03-29 15:42:20,978:INFO:plot_model() successfully completed......................................
2025-03-29 15:42:20,985:INFO:Initializing tune_model()
2025-03-29 15:42:20,985:INFO:tune_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>)
2025-03-29 15:42:20,985:INFO:Checking exceptions
2025-03-29 15:42:20,997:INFO:Copying training dataset
2025-03-29 15:42:21,002:INFO:Checking base model
2025-03-29 15:42:21,002:INFO:Base model : Light Gradient Boosting Machine
2025-03-29 15:42:21,004:INFO:Declaring metric variables
2025-03-29 15:42:21,006:INFO:Defining Hyperparameters
2025-03-29 15:42:21,153:INFO:Tuning with n_jobs=-1
2025-03-29 15:42:21,153:INFO:Initializing RandomizedSearchCV
2025-03-29 15:42:33,282:INFO:Initializing plot_model()
2025-03-29 15:42:33,283:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, system=True)
2025-03-29 15:42:33,283:INFO:Checking exceptions
2025-03-29 15:42:33,286:INFO:Preloading libraries
2025-03-29 15:42:33,289:INFO:Copying training dataset
2025-03-29 15:42:33,289:INFO:Plot type: pipeline
2025-03-29 15:42:33,366:INFO:Visual Rendered Successfully
2025-03-29 15:42:33,530:INFO:plot_model() successfully completed......................................
2025-03-29 15:42:34,694:INFO:Initializing tune_model()
2025-03-29 15:42:34,694:INFO:tune_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>)
2025-03-29 15:42:34,694:INFO:Checking exceptions
2025-03-29 15:42:34,708:INFO:Copying training dataset
2025-03-29 15:42:34,714:INFO:Checking base model
2025-03-29 15:42:34,714:INFO:Base model : Light Gradient Boosting Machine
2025-03-29 15:42:34,717:INFO:Declaring metric variables
2025-03-29 15:42:34,719:INFO:Defining Hyperparameters
2025-03-29 15:42:34,879:INFO:Tuning with n_jobs=-1
2025-03-29 15:42:34,880:INFO:Initializing RandomizedSearchCV
2025-03-29 15:42:53,805:INFO:best_params: {'actual_estimator__reg_lambda': 1, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 60, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 100, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.7}
2025-03-29 15:42:53,806:INFO:Hyperparameter search completed
2025-03-29 15:42:53,806:INFO:SubProcess create_model() called ==================================
2025-03-29 15:42:53,807:INFO:Initializing create_model()
2025-03-29 15:42:53,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9201ACA60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1, 'reg_alpha': 2, 'num_leaves': 60, 'n_estimators': 160, 'min_split_gain': 0.5, 'min_child_samples': 100, 'learning_rate': 0.05, 'feature_fraction': 0.6, 'bagging_freq': 4, 'bagging_fraction': 0.7})
2025-03-29 15:42:53,807:INFO:Checking exceptions
2025-03-29 15:42:53,807:INFO:Importing libraries
2025-03-29 15:42:53,807:INFO:Copying training dataset
2025-03-29 15:42:53,818:INFO:Defining folds
2025-03-29 15:42:53,818:INFO:Declaring metric variables
2025-03-29 15:42:53,821:INFO:Importing untrained model
2025-03-29 15:42:53,821:INFO:Declaring custom model
2025-03-29 15:42:53,823:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:42:53,829:INFO:Starting cross validation
2025-03-29 15:42:53,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:42:55,888:INFO:Calculating mean and std
2025-03-29 15:42:55,889:INFO:Creating metrics dataframe
2025-03-29 15:42:55,891:INFO:Finalizing model
2025-03-29 15:42:55,989:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-03-29 15:42:55,989:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-03-29 15:42:55,990:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2025-03-29 15:42:56,002:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:42:56,003:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-03-29 15:42:56,003:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-03-29 15:42:56,003:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2025-03-29 15:42:56,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.
2025-03-29 15:42:56,005:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:56,005:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:56,005:INFO:[LightGBM] [Info] Total Bins 551
2025-03-29 15:42:56,005:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 13
2025-03-29 15:42:56,005:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:56,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 15:42:56,179:INFO:Uploading results into container
2025-03-29 15:42:56,180:INFO:Uploading model into container now
2025-03-29 15:42:56,180:INFO:_master_model_container: 1
2025-03-29 15:42:56,180:INFO:_display_container: 2
2025-03-29 15:42:56,181:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=4, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
              importance_type='split', learning_rate=0.05, max_depth=-1,
              min_child_samples=100, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=160, n_jobs=-1, num_leaves=60, objective=None,
              random_state=1903, reg_alpha=2, reg_lambda=1, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 15:42:56,181:INFO:create_model() successfully completed......................................
2025-03-29 15:42:56,361:INFO:SubProcess create_model() end ==================================
2025-03-29 15:42:56,361:INFO:choose_better activated
2025-03-29 15:42:56,363:INFO:SubProcess create_model() called ==================================
2025-03-29 15:42:56,364:INFO:Initializing create_model()
2025-03-29 15:42:56,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91A0D1330>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:42:56,364:INFO:Checking exceptions
2025-03-29 15:42:56,366:INFO:Importing libraries
2025-03-29 15:42:56,366:INFO:Copying training dataset
2025-03-29 15:42:56,373:INFO:Defining folds
2025-03-29 15:42:56,373:INFO:Declaring metric variables
2025-03-29 15:42:56,373:INFO:Importing untrained model
2025-03-29 15:42:56,373:INFO:Declaring custom model
2025-03-29 15:42:56,374:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:42:56,374:INFO:Starting cross validation
2025-03-29 15:42:56,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:42:57,162:INFO:Calculating mean and std
2025-03-29 15:42:57,162:INFO:Creating metrics dataframe
2025-03-29 15:42:57,164:INFO:Finalizing model
2025-03-29 15:42:57,281:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:42:57,283:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.
2025-03-29 15:42:57,283:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:42:57,283:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:42:57,283:INFO:[LightGBM] [Info] Total Bins 562
2025-03-29 15:42:57,283:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:42:57,283:INFO:[LightGBM] [Info] Start training from score 3251.719608
2025-03-29 15:42:57,346:INFO:Uploading results into container
2025-03-29 15:42:57,346:INFO:Uploading model into container now
2025-03-29 15:42:57,347:INFO:_master_model_container: 2
2025-03-29 15:42:57,347:INFO:_display_container: 3
2025-03-29 15:42:57,347:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 15:42:57,347:INFO:create_model() successfully completed......................................
2025-03-29 15:42:57,541:INFO:SubProcess create_model() end ==================================
2025-03-29 15:42:57,542:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.2162
2025-03-29 15:42:57,542:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=4, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
              importance_type='split', learning_rate=0.05, max_depth=-1,
              min_child_samples=100, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=160, n_jobs=-1, num_leaves=60, objective=None,
              random_state=1903, reg_alpha=2, reg_lambda=1, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.2114
2025-03-29 15:42:57,543:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-03-29 15:42:57,543:INFO:choose_better completed
2025-03-29 15:42:57,543:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-29 15:42:57,549:INFO:_master_model_container: 2
2025-03-29 15:42:57,549:INFO:_display_container: 2
2025-03-29 15:42:57,549:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=1903, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 15:42:57,550:INFO:tune_model() successfully completed......................................
2025-03-29 15:47:30,804:INFO:PyCaret RegressionExperiment
2025-03-29 15:47:30,805:INFO:Logging name: reg-default-name
2025-03-29 15:47:30,805:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 15:47:30,805:INFO:version 3.3.2
2025-03-29 15:47:30,805:INFO:Initializing setup()
2025-03-29 15:47:30,805:INFO:self.USI: a911
2025-03-29 15:47:30,805:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 15:47:30,805:INFO:Checking environment
2025-03-29 15:47:30,806:INFO:python_version: 3.10.16
2025-03-29 15:47:30,806:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 15:47:30,806:INFO:machine: AMD64
2025-03-29 15:47:30,806:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 15:47:30,810:INFO:Memory: svmem(total=33411727360, available=14866223104, percent=55.5, used=18545504256, free=14866223104)
2025-03-29 15:47:30,810:INFO:Physical Core: 6
2025-03-29 15:47:30,810:INFO:Logical Core: 12
2025-03-29 15:47:30,810:INFO:Checking libraries
2025-03-29 15:47:30,810:INFO:System:
2025-03-29 15:47:30,810:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 15:47:30,810:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 15:47:30,810:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 15:47:30,810:INFO:PyCaret required dependencies:
2025-03-29 15:47:30,811:INFO:                 pip: 25.0.1
2025-03-29 15:47:30,811:INFO:          setuptools: 75.8.2
2025-03-29 15:47:30,811:INFO:             pycaret: 3.3.2
2025-03-29 15:47:30,811:INFO:             IPython: 8.34.0
2025-03-29 15:47:30,811:INFO:          ipywidgets: 8.1.5
2025-03-29 15:47:30,811:INFO:                tqdm: 4.67.1
2025-03-29 15:47:30,811:INFO:               numpy: 1.26.4
2025-03-29 15:47:30,811:INFO:              pandas: 2.1.4
2025-03-29 15:47:30,811:INFO:              jinja2: 3.1.6
2025-03-29 15:47:30,811:INFO:               scipy: 1.11.4
2025-03-29 15:47:30,811:INFO:              joblib: 1.3.2
2025-03-29 15:47:30,811:INFO:             sklearn: 1.4.2
2025-03-29 15:47:30,811:INFO:                pyod: 2.0.2
2025-03-29 15:47:30,811:INFO:            imblearn: 0.13.0
2025-03-29 15:47:30,811:INFO:   category_encoders: 2.7.0
2025-03-29 15:47:30,811:INFO:            lightgbm: 4.6.0
2025-03-29 15:47:30,811:INFO:               numba: 0.61.0
2025-03-29 15:47:30,811:INFO:            requests: 2.32.3
2025-03-29 15:47:30,811:INFO:          matplotlib: 3.10.1
2025-03-29 15:47:30,811:INFO:          scikitplot: 0.3.7
2025-03-29 15:47:30,811:INFO:         yellowbrick: 1.5
2025-03-29 15:47:30,811:INFO:              plotly: 6.0.1
2025-03-29 15:47:30,811:INFO:    plotly-resampler: Not installed
2025-03-29 15:47:30,811:INFO:             kaleido: 0.2.1
2025-03-29 15:47:30,811:INFO:           schemdraw: 0.15
2025-03-29 15:47:30,811:INFO:         statsmodels: 0.14.4
2025-03-29 15:47:30,811:INFO:              sktime: 0.26.0
2025-03-29 15:47:30,811:INFO:               tbats: 1.1.3
2025-03-29 15:47:30,811:INFO:            pmdarima: 2.0.4
2025-03-29 15:47:30,811:INFO:              psutil: 7.0.0
2025-03-29 15:47:30,811:INFO:          markupsafe: 3.0.2
2025-03-29 15:47:30,811:INFO:             pickle5: Not installed
2025-03-29 15:47:30,811:INFO:         cloudpickle: 3.1.1
2025-03-29 15:47:30,811:INFO:         deprecation: 2.1.0
2025-03-29 15:47:30,811:INFO:              xxhash: 3.5.0
2025-03-29 15:47:30,811:INFO:           wurlitzer: 3.1.1
2025-03-29 15:47:30,811:INFO:PyCaret optional dependencies:
2025-03-29 15:47:30,811:INFO:                shap: Not installed
2025-03-29 15:47:30,811:INFO:           interpret: Not installed
2025-03-29 15:47:30,811:INFO:                umap: 0.5.7
2025-03-29 15:47:30,811:INFO:     ydata_profiling: Not installed
2025-03-29 15:47:30,811:INFO:  explainerdashboard: Not installed
2025-03-29 15:47:30,811:INFO:             autoviz: Not installed
2025-03-29 15:47:30,811:INFO:           fairlearn: Not installed
2025-03-29 15:47:30,811:INFO:          deepchecks: Not installed
2025-03-29 15:47:30,812:INFO:             xgboost: Not installed
2025-03-29 15:47:30,812:INFO:            catboost: Not installed
2025-03-29 15:47:30,812:INFO:              kmodes: Not installed
2025-03-29 15:47:30,812:INFO:             mlxtend: Not installed
2025-03-29 15:47:30,812:INFO:       statsforecast: Not installed
2025-03-29 15:47:30,812:INFO:        tune_sklearn: Not installed
2025-03-29 15:47:30,812:INFO:                 ray: Not installed
2025-03-29 15:47:30,812:INFO:            hyperopt: Not installed
2025-03-29 15:47:30,812:INFO:              optuna: Not installed
2025-03-29 15:47:30,812:INFO:               skopt: Not installed
2025-03-29 15:47:30,812:INFO:              mlflow: 2.21.2
2025-03-29 15:47:30,812:INFO:              gradio: Not installed
2025-03-29 15:47:30,812:INFO:             fastapi: 0.115.12
2025-03-29 15:47:30,812:INFO:             uvicorn: 0.34.0
2025-03-29 15:47:30,812:INFO:              m2cgen: Not installed
2025-03-29 15:47:30,812:INFO:           evidently: Not installed
2025-03-29 15:47:30,812:INFO:               fugue: Not installed
2025-03-29 15:47:30,812:INFO:           streamlit: 1.43.2
2025-03-29 15:47:30,812:INFO:             prophet: Not installed
2025-03-29 15:47:30,812:INFO:None
2025-03-29 15:47:30,812:INFO:Set up data.
2025-03-29 15:47:30,820:INFO:Set up folding strategy.
2025-03-29 15:47:30,820:INFO:Set up train/test split.
2025-03-29 15:47:30,825:INFO:Set up index.
2025-03-29 15:47:30,826:INFO:Assigning column types.
2025-03-29 15:47:30,830:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 15:47:30,830:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,833:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,836:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,873:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,903:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:30,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:30,904:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,907:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,909:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,947:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,974:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:30,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:30,975:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 15:47:30,978:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:47:30,980:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,018:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,048:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,051:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,120:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 15:47:31,125:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,172:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,205:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,270:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 15:47:31,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,403:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,403:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 15:47:31,443:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 15:47:31,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,532:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 15:47:31,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:31,665:INFO:Preparing preprocessing pipeline...
2025-03-29 15:47:31,666:INFO:Set up simple imputation.
2025-03-29 15:47:31,669:INFO:Set up encoding of categorical features.
2025-03-29 15:47:31,669:INFO:Set up column name cleaning.
2025-03-29 15:47:31,755:INFO:Finished creating preprocessing pipeline.
2025-03-29 15:47:31,758:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_i...
                                    include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-03-29 15:47:31,758:INFO:Creating final display dataframe.
2025-03-29 15:47:31,960:INFO:Setup _display_container:                     Description             Value
0                    Session id              7428
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              a911
2025-03-29 15:47:32,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:32,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:32,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:32,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 15:47:32,097:INFO:setup() successfully completed in 1.29s...............
2025-03-29 15:47:48,044:INFO:Initializing get_config()
2025-03-29 15:47:48,045:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, variable=X_train)
2025-03-29 15:47:48,045:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-03-29 15:47:48,046:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-03-29 15:47:48,052:INFO:Variable:  returned as       holiday        temp  rain_1h  snow_1h  clouds_all weather_main  \
39231     NaN  277.079987      0.0      0.0           1        Clear   
9949      NaN  271.640015      0.0      0.0          90       Clouds   
30257     NaN  275.209991      0.0      0.0          90         Rain   
41059     NaN  263.010010      0.0      0.0           1        Clear   
4943      NaN  280.010010      0.0      0.0          90       Clouds   
...       ...         ...      ...      ...         ...          ...   
3417      NaN  268.369995      0.0      0.0          90         Haze   
37070     NaN  297.079987      0.0      0.0          20       Clouds   
38098     NaN  284.890015      0.0      0.0           1        Clear   
31541     NaN  289.750000      0.0      0.0          40       Clouds   
26130     NaN  299.630005      0.0      0.0          20       Clouds   

       Rush Hour  
39231          0  
9949           0  
30257          0  
41059          0  
4943           1  
...          ...  
3417           0  
37070          0  
38098          0  
31541          0  
26130          1  

[33742 rows x 7 columns]
2025-03-29 15:47:48,052:INFO:get_config() successfully completed......................................
2025-03-29 15:47:57,188:INFO:Initializing get_config()
2025-03-29 15:47:57,189:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, variable=X_train)
2025-03-29 15:47:57,189:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-03-29 15:47:57,189:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-03-29 15:47:57,195:INFO:Variable:  returned as       holiday        temp  rain_1h  snow_1h  clouds_all weather_main  \
39231     NaN  277.079987      0.0      0.0           1        Clear   
9949      NaN  271.640015      0.0      0.0          90       Clouds   
30257     NaN  275.209991      0.0      0.0          90         Rain   
41059     NaN  263.010010      0.0      0.0           1        Clear   
4943      NaN  280.010010      0.0      0.0          90       Clouds   
...       ...         ...      ...      ...         ...          ...   
3417      NaN  268.369995      0.0      0.0          90         Haze   
37070     NaN  297.079987      0.0      0.0          20       Clouds   
38098     NaN  284.890015      0.0      0.0           1        Clear   
31541     NaN  289.750000      0.0      0.0          40       Clouds   
26130     NaN  299.630005      0.0      0.0          20       Clouds   

       Rush Hour  
39231          0  
9949           0  
30257          0  
41059          0  
4943           1  
...          ...  
3417           0  
37070          0  
38098          0  
31541          0  
26130          1  

[33742 rows x 7 columns]
2025-03-29 15:47:57,195:INFO:get_config() successfully completed......................................
2025-03-29 15:48:43,557:INFO:Initializing compare_models()
2025-03-29 15:48:43,557:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-29 15:48:43,557:INFO:Checking exceptions
2025-03-29 15:48:43,560:INFO:Preparing display monitor
2025-03-29 15:48:43,575:INFO:Initializing Linear Regression
2025-03-29 15:48:43,575:INFO:Total runtime is 0.0 minutes
2025-03-29 15:48:43,577:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:43,577:INFO:Initializing create_model()
2025-03-29 15:48:43,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:43,577:INFO:Checking exceptions
2025-03-29 15:48:43,578:INFO:Importing libraries
2025-03-29 15:48:43,578:INFO:Copying training dataset
2025-03-29 15:48:43,584:INFO:Defining folds
2025-03-29 15:48:43,585:INFO:Declaring metric variables
2025-03-29 15:48:43,587:INFO:Importing untrained model
2025-03-29 15:48:43,589:INFO:Linear Regression Imported successfully
2025-03-29 15:48:43,593:INFO:Starting cross validation
2025-03-29 15:48:43,594:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:46,386:INFO:Calculating mean and std
2025-03-29 15:48:46,387:INFO:Creating metrics dataframe
2025-03-29 15:48:46,389:INFO:Uploading results into container
2025-03-29 15:48:46,390:INFO:Uploading model into container now
2025-03-29 15:48:46,390:INFO:_master_model_container: 1
2025-03-29 15:48:46,390:INFO:_display_container: 2
2025-03-29 15:48:46,391:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-03-29 15:48:46,391:INFO:create_model() successfully completed......................................
2025-03-29 15:48:46,566:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:46,566:INFO:Creating metrics dataframe
2025-03-29 15:48:46,570:INFO:Initializing Lasso Regression
2025-03-29 15:48:46,570:INFO:Total runtime is 0.049907374382019046 minutes
2025-03-29 15:48:46,572:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:46,572:INFO:Initializing create_model()
2025-03-29 15:48:46,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:46,572:INFO:Checking exceptions
2025-03-29 15:48:46,572:INFO:Importing libraries
2025-03-29 15:48:46,572:INFO:Copying training dataset
2025-03-29 15:48:46,579:INFO:Defining folds
2025-03-29 15:48:46,579:INFO:Declaring metric variables
2025-03-29 15:48:46,581:INFO:Importing untrained model
2025-03-29 15:48:46,583:INFO:Lasso Regression Imported successfully
2025-03-29 15:48:46,588:INFO:Starting cross validation
2025-03-29 15:48:46,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:48,284:INFO:Calculating mean and std
2025-03-29 15:48:48,285:INFO:Creating metrics dataframe
2025-03-29 15:48:48,286:INFO:Uploading results into container
2025-03-29 15:48:48,287:INFO:Uploading model into container now
2025-03-29 15:48:48,287:INFO:_master_model_container: 2
2025-03-29 15:48:48,287:INFO:_display_container: 2
2025-03-29 15:48:48,287:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=7428, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-03-29 15:48:48,287:INFO:create_model() successfully completed......................................
2025-03-29 15:48:48,441:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:48,441:INFO:Creating metrics dataframe
2025-03-29 15:48:48,445:INFO:Initializing Ridge Regression
2025-03-29 15:48:48,445:INFO:Total runtime is 0.08116438388824462 minutes
2025-03-29 15:48:48,447:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:48,447:INFO:Initializing create_model()
2025-03-29 15:48:48,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:48,447:INFO:Checking exceptions
2025-03-29 15:48:48,447:INFO:Importing libraries
2025-03-29 15:48:48,447:INFO:Copying training dataset
2025-03-29 15:48:48,455:INFO:Defining folds
2025-03-29 15:48:48,455:INFO:Declaring metric variables
2025-03-29 15:48:48,457:INFO:Importing untrained model
2025-03-29 15:48:48,459:INFO:Ridge Regression Imported successfully
2025-03-29 15:48:48,463:INFO:Starting cross validation
2025-03-29 15:48:48,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:48,682:INFO:Calculating mean and std
2025-03-29 15:48:48,683:INFO:Creating metrics dataframe
2025-03-29 15:48:48,684:INFO:Uploading results into container
2025-03-29 15:48:48,684:INFO:Uploading model into container now
2025-03-29 15:48:48,685:INFO:_master_model_container: 3
2025-03-29 15:48:48,685:INFO:_display_container: 2
2025-03-29 15:48:48,685:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=7428, solver='auto', tol=0.0001)
2025-03-29 15:48:48,686:INFO:create_model() successfully completed......................................
2025-03-29 15:48:48,831:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:48,831:INFO:Creating metrics dataframe
2025-03-29 15:48:48,835:INFO:Initializing Elastic Net
2025-03-29 15:48:48,835:INFO:Total runtime is 0.08765798807144165 minutes
2025-03-29 15:48:48,837:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:48,838:INFO:Initializing create_model()
2025-03-29 15:48:48,838:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:48,838:INFO:Checking exceptions
2025-03-29 15:48:48,838:INFO:Importing libraries
2025-03-29 15:48:48,838:INFO:Copying training dataset
2025-03-29 15:48:48,845:INFO:Defining folds
2025-03-29 15:48:48,845:INFO:Declaring metric variables
2025-03-29 15:48:48,847:INFO:Importing untrained model
2025-03-29 15:48:48,849:INFO:Elastic Net Imported successfully
2025-03-29 15:48:48,853:INFO:Starting cross validation
2025-03-29 15:48:48,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:49,069:INFO:Calculating mean and std
2025-03-29 15:48:49,070:INFO:Creating metrics dataframe
2025-03-29 15:48:49,072:INFO:Uploading results into container
2025-03-29 15:48:49,072:INFO:Uploading model into container now
2025-03-29 15:48:49,073:INFO:_master_model_container: 4
2025-03-29 15:48:49,073:INFO:_display_container: 2
2025-03-29 15:48:49,073:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=7428,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-03-29 15:48:49,073:INFO:create_model() successfully completed......................................
2025-03-29 15:48:49,225:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:49,225:INFO:Creating metrics dataframe
2025-03-29 15:48:49,230:INFO:Initializing Least Angle Regression
2025-03-29 15:48:49,230:INFO:Total runtime is 0.09425056378046671 minutes
2025-03-29 15:48:49,232:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:49,232:INFO:Initializing create_model()
2025-03-29 15:48:49,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:49,232:INFO:Checking exceptions
2025-03-29 15:48:49,232:INFO:Importing libraries
2025-03-29 15:48:49,232:INFO:Copying training dataset
2025-03-29 15:48:49,239:INFO:Defining folds
2025-03-29 15:48:49,240:INFO:Declaring metric variables
2025-03-29 15:48:49,242:INFO:Importing untrained model
2025-03-29 15:48:49,244:INFO:Least Angle Regression Imported successfully
2025-03-29 15:48:49,248:INFO:Starting cross validation
2025-03-29 15:48:49,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:49,457:INFO:Calculating mean and std
2025-03-29 15:48:49,458:INFO:Creating metrics dataframe
2025-03-29 15:48:49,459:INFO:Uploading results into container
2025-03-29 15:48:49,459:INFO:Uploading model into container now
2025-03-29 15:48:49,459:INFO:_master_model_container: 5
2025-03-29 15:48:49,460:INFO:_display_container: 2
2025-03-29 15:48:49,460:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=7428,
     verbose=False)
2025-03-29 15:48:49,460:INFO:create_model() successfully completed......................................
2025-03-29 15:48:49,619:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:49,619:INFO:Creating metrics dataframe
2025-03-29 15:48:49,624:INFO:Initializing Lasso Least Angle Regression
2025-03-29 15:48:49,624:INFO:Total runtime is 0.10080402294794719 minutes
2025-03-29 15:48:49,626:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:49,626:INFO:Initializing create_model()
2025-03-29 15:48:49,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:49,626:INFO:Checking exceptions
2025-03-29 15:48:49,626:INFO:Importing libraries
2025-03-29 15:48:49,626:INFO:Copying training dataset
2025-03-29 15:48:49,633:INFO:Defining folds
2025-03-29 15:48:49,633:INFO:Declaring metric variables
2025-03-29 15:48:49,636:INFO:Importing untrained model
2025-03-29 15:48:49,638:INFO:Lasso Least Angle Regression Imported successfully
2025-03-29 15:48:49,642:INFO:Starting cross validation
2025-03-29 15:48:49,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:49,850:INFO:Calculating mean and std
2025-03-29 15:48:49,851:INFO:Creating metrics dataframe
2025-03-29 15:48:49,852:INFO:Uploading results into container
2025-03-29 15:48:49,853:INFO:Uploading model into container now
2025-03-29 15:48:49,853:INFO:_master_model_container: 6
2025-03-29 15:48:49,853:INFO:_display_container: 2
2025-03-29 15:48:49,853:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=7428, verbose=False)
2025-03-29 15:48:49,854:INFO:create_model() successfully completed......................................
2025-03-29 15:48:50,010:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:50,010:INFO:Creating metrics dataframe
2025-03-29 15:48:50,015:INFO:Initializing Orthogonal Matching Pursuit
2025-03-29 15:48:50,015:INFO:Total runtime is 0.10731775363286336 minutes
2025-03-29 15:48:50,017:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:50,017:INFO:Initializing create_model()
2025-03-29 15:48:50,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:50,017:INFO:Checking exceptions
2025-03-29 15:48:50,017:INFO:Importing libraries
2025-03-29 15:48:50,017:INFO:Copying training dataset
2025-03-29 15:48:50,024:INFO:Defining folds
2025-03-29 15:48:50,024:INFO:Declaring metric variables
2025-03-29 15:48:50,026:INFO:Importing untrained model
2025-03-29 15:48:50,029:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-29 15:48:50,032:INFO:Starting cross validation
2025-03-29 15:48:50,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:50,241:INFO:Calculating mean and std
2025-03-29 15:48:50,242:INFO:Creating metrics dataframe
2025-03-29 15:48:50,243:INFO:Uploading results into container
2025-03-29 15:48:50,243:INFO:Uploading model into container now
2025-03-29 15:48:50,243:INFO:_master_model_container: 7
2025-03-29 15:48:50,243:INFO:_display_container: 2
2025-03-29 15:48:50,244:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-03-29 15:48:50,244:INFO:create_model() successfully completed......................................
2025-03-29 15:48:50,390:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:50,391:INFO:Creating metrics dataframe
2025-03-29 15:48:50,395:INFO:Initializing Bayesian Ridge
2025-03-29 15:48:50,396:INFO:Total runtime is 0.11368347406387329 minutes
2025-03-29 15:48:50,397:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:50,398:INFO:Initializing create_model()
2025-03-29 15:48:50,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:50,398:INFO:Checking exceptions
2025-03-29 15:48:50,398:INFO:Importing libraries
2025-03-29 15:48:50,398:INFO:Copying training dataset
2025-03-29 15:48:50,405:INFO:Defining folds
2025-03-29 15:48:50,405:INFO:Declaring metric variables
2025-03-29 15:48:50,407:INFO:Importing untrained model
2025-03-29 15:48:50,409:INFO:Bayesian Ridge Imported successfully
2025-03-29 15:48:50,413:INFO:Starting cross validation
2025-03-29 15:48:50,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:50,664:INFO:Calculating mean and std
2025-03-29 15:48:50,665:INFO:Creating metrics dataframe
2025-03-29 15:48:50,666:INFO:Uploading results into container
2025-03-29 15:48:50,666:INFO:Uploading model into container now
2025-03-29 15:48:50,666:INFO:_master_model_container: 8
2025-03-29 15:48:50,667:INFO:_display_container: 2
2025-03-29 15:48:50,667:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-03-29 15:48:50,667:INFO:create_model() successfully completed......................................
2025-03-29 15:48:50,813:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:50,813:INFO:Creating metrics dataframe
2025-03-29 15:48:50,818:INFO:Initializing Passive Aggressive Regressor
2025-03-29 15:48:50,819:INFO:Total runtime is 0.12073255777359009 minutes
2025-03-29 15:48:50,821:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:50,821:INFO:Initializing create_model()
2025-03-29 15:48:50,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:50,821:INFO:Checking exceptions
2025-03-29 15:48:50,821:INFO:Importing libraries
2025-03-29 15:48:50,821:INFO:Copying training dataset
2025-03-29 15:48:50,828:INFO:Defining folds
2025-03-29 15:48:50,829:INFO:Declaring metric variables
2025-03-29 15:48:50,831:INFO:Importing untrained model
2025-03-29 15:48:50,833:INFO:Passive Aggressive Regressor Imported successfully
2025-03-29 15:48:50,837:INFO:Starting cross validation
2025-03-29 15:48:50,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:51,195:INFO:Calculating mean and std
2025-03-29 15:48:51,196:INFO:Creating metrics dataframe
2025-03-29 15:48:51,197:INFO:Uploading results into container
2025-03-29 15:48:51,197:INFO:Uploading model into container now
2025-03-29 15:48:51,197:INFO:_master_model_container: 9
2025-03-29 15:48:51,198:INFO:_display_container: 2
2025-03-29 15:48:51,198:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=7428, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 15:48:51,198:INFO:create_model() successfully completed......................................
2025-03-29 15:48:51,344:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:51,344:INFO:Creating metrics dataframe
2025-03-29 15:48:51,349:INFO:Initializing Huber Regressor
2025-03-29 15:48:51,349:INFO:Total runtime is 0.12955764532089234 minutes
2025-03-29 15:48:51,351:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:51,351:INFO:Initializing create_model()
2025-03-29 15:48:51,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:51,352:INFO:Checking exceptions
2025-03-29 15:48:51,352:INFO:Importing libraries
2025-03-29 15:48:51,352:INFO:Copying training dataset
2025-03-29 15:48:51,359:INFO:Defining folds
2025-03-29 15:48:51,359:INFO:Declaring metric variables
2025-03-29 15:48:51,361:INFO:Importing untrained model
2025-03-29 15:48:51,363:INFO:Huber Regressor Imported successfully
2025-03-29 15:48:51,366:INFO:Starting cross validation
2025-03-29 15:48:51,368:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:52,709:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:48:52,736:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:48:52,747:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:48:52,759:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:48:52,761:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:48:52,779:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:48:52,780:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:48:52,804:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:48:52,884:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:48:52,905:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 15:48:52,926:INFO:Calculating mean and std
2025-03-29 15:48:52,927:INFO:Creating metrics dataframe
2025-03-29 15:48:52,928:INFO:Uploading results into container
2025-03-29 15:48:52,928:INFO:Uploading model into container now
2025-03-29 15:48:52,929:INFO:_master_model_container: 10
2025-03-29 15:48:52,929:INFO:_display_container: 2
2025-03-29 15:48:52,929:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-03-29 15:48:52,929:INFO:create_model() successfully completed......................................
2025-03-29 15:48:53,079:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:53,079:INFO:Creating metrics dataframe
2025-03-29 15:48:53,085:INFO:Initializing K Neighbors Regressor
2025-03-29 15:48:53,085:INFO:Total runtime is 0.15850044886271158 minutes
2025-03-29 15:48:53,087:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:53,088:INFO:Initializing create_model()
2025-03-29 15:48:53,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:53,088:INFO:Checking exceptions
2025-03-29 15:48:53,088:INFO:Importing libraries
2025-03-29 15:48:53,088:INFO:Copying training dataset
2025-03-29 15:48:53,094:INFO:Defining folds
2025-03-29 15:48:53,095:INFO:Declaring metric variables
2025-03-29 15:48:53,097:INFO:Importing untrained model
2025-03-29 15:48:53,100:INFO:K Neighbors Regressor Imported successfully
2025-03-29 15:48:53,106:INFO:Starting cross validation
2025-03-29 15:48:53,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:53,942:INFO:Calculating mean and std
2025-03-29 15:48:53,943:INFO:Creating metrics dataframe
2025-03-29 15:48:53,944:INFO:Uploading results into container
2025-03-29 15:48:53,944:INFO:Uploading model into container now
2025-03-29 15:48:53,945:INFO:_master_model_container: 11
2025-03-29 15:48:53,945:INFO:_display_container: 2
2025-03-29 15:48:53,945:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-03-29 15:48:53,946:INFO:create_model() successfully completed......................................
2025-03-29 15:48:54,106:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:54,106:INFO:Creating metrics dataframe
2025-03-29 15:48:54,111:INFO:Initializing Decision Tree Regressor
2025-03-29 15:48:54,111:INFO:Total runtime is 0.17559321324030558 minutes
2025-03-29 15:48:54,113:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:54,114:INFO:Initializing create_model()
2025-03-29 15:48:54,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:54,114:INFO:Checking exceptions
2025-03-29 15:48:54,114:INFO:Importing libraries
2025-03-29 15:48:54,114:INFO:Copying training dataset
2025-03-29 15:48:54,121:INFO:Defining folds
2025-03-29 15:48:54,121:INFO:Declaring metric variables
2025-03-29 15:48:54,124:INFO:Importing untrained model
2025-03-29 15:48:54,126:INFO:Decision Tree Regressor Imported successfully
2025-03-29 15:48:54,130:INFO:Starting cross validation
2025-03-29 15:48:54,131:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:48:54,436:INFO:Calculating mean and std
2025-03-29 15:48:54,437:INFO:Creating metrics dataframe
2025-03-29 15:48:54,438:INFO:Uploading results into container
2025-03-29 15:48:54,438:INFO:Uploading model into container now
2025-03-29 15:48:54,438:INFO:_master_model_container: 12
2025-03-29 15:48:54,438:INFO:_display_container: 2
2025-03-29 15:48:54,439:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=7428, splitter='best')
2025-03-29 15:48:54,439:INFO:create_model() successfully completed......................................
2025-03-29 15:48:54,588:INFO:SubProcess create_model() end ==================================
2025-03-29 15:48:54,588:INFO:Creating metrics dataframe
2025-03-29 15:48:54,593:INFO:Initializing Random Forest Regressor
2025-03-29 15:48:54,594:INFO:Total runtime is 0.1836459438006083 minutes
2025-03-29 15:48:54,596:INFO:SubProcess create_model() called ==================================
2025-03-29 15:48:54,596:INFO:Initializing create_model()
2025-03-29 15:48:54,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:48:54,596:INFO:Checking exceptions
2025-03-29 15:48:54,596:INFO:Importing libraries
2025-03-29 15:48:54,596:INFO:Copying training dataset
2025-03-29 15:48:54,603:INFO:Defining folds
2025-03-29 15:48:54,603:INFO:Declaring metric variables
2025-03-29 15:48:54,605:INFO:Importing untrained model
2025-03-29 15:48:54,607:INFO:Random Forest Regressor Imported successfully
2025-03-29 15:48:54,611:INFO:Starting cross validation
2025-03-29 15:48:54,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:49:00,450:INFO:Calculating mean and std
2025-03-29 15:49:00,452:INFO:Creating metrics dataframe
2025-03-29 15:49:00,454:INFO:Uploading results into container
2025-03-29 15:49:00,454:INFO:Uploading model into container now
2025-03-29 15:49:00,455:INFO:_master_model_container: 13
2025-03-29 15:49:00,455:INFO:_display_container: 2
2025-03-29 15:49:00,455:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=7428, verbose=0, warm_start=False)
2025-03-29 15:49:00,455:INFO:create_model() successfully completed......................................
2025-03-29 15:49:00,653:INFO:SubProcess create_model() end ==================================
2025-03-29 15:49:00,653:INFO:Creating metrics dataframe
2025-03-29 15:49:00,663:INFO:Initializing Extra Trees Regressor
2025-03-29 15:49:00,663:INFO:Total runtime is 0.2847987174987793 minutes
2025-03-29 15:49:00,665:INFO:SubProcess create_model() called ==================================
2025-03-29 15:49:00,665:INFO:Initializing create_model()
2025-03-29 15:49:00,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:49:00,666:INFO:Checking exceptions
2025-03-29 15:49:00,666:INFO:Importing libraries
2025-03-29 15:49:00,666:INFO:Copying training dataset
2025-03-29 15:49:00,674:INFO:Defining folds
2025-03-29 15:49:00,674:INFO:Declaring metric variables
2025-03-29 15:49:00,676:INFO:Importing untrained model
2025-03-29 15:49:00,679:INFO:Extra Trees Regressor Imported successfully
2025-03-29 15:49:00,683:INFO:Starting cross validation
2025-03-29 15:49:00,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:49:04,518:INFO:Calculating mean and std
2025-03-29 15:49:04,519:INFO:Creating metrics dataframe
2025-03-29 15:49:04,521:INFO:Uploading results into container
2025-03-29 15:49:04,521:INFO:Uploading model into container now
2025-03-29 15:49:04,522:INFO:_master_model_container: 14
2025-03-29 15:49:04,522:INFO:_display_container: 2
2025-03-29 15:49:04,522:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=7428, verbose=0, warm_start=False)
2025-03-29 15:49:04,522:INFO:create_model() successfully completed......................................
2025-03-29 15:49:04,701:INFO:SubProcess create_model() end ==================================
2025-03-29 15:49:04,701:INFO:Creating metrics dataframe
2025-03-29 15:49:04,708:INFO:Initializing AdaBoost Regressor
2025-03-29 15:49:04,708:INFO:Total runtime is 0.352212655544281 minutes
2025-03-29 15:49:04,710:INFO:SubProcess create_model() called ==================================
2025-03-29 15:49:04,710:INFO:Initializing create_model()
2025-03-29 15:49:04,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:49:04,710:INFO:Checking exceptions
2025-03-29 15:49:04,710:INFO:Importing libraries
2025-03-29 15:49:04,710:INFO:Copying training dataset
2025-03-29 15:49:04,718:INFO:Defining folds
2025-03-29 15:49:04,718:INFO:Declaring metric variables
2025-03-29 15:49:04,721:INFO:Importing untrained model
2025-03-29 15:49:04,723:INFO:AdaBoost Regressor Imported successfully
2025-03-29 15:49:04,727:INFO:Starting cross validation
2025-03-29 15:49:04,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:49:05,618:INFO:Calculating mean and std
2025-03-29 15:49:05,619:INFO:Creating metrics dataframe
2025-03-29 15:49:05,620:INFO:Uploading results into container
2025-03-29 15:49:05,620:INFO:Uploading model into container now
2025-03-29 15:49:05,620:INFO:_master_model_container: 15
2025-03-29 15:49:05,620:INFO:_display_container: 2
2025-03-29 15:49:05,621:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=7428)
2025-03-29 15:49:05,621:INFO:create_model() successfully completed......................................
2025-03-29 15:49:05,774:INFO:SubProcess create_model() end ==================================
2025-03-29 15:49:05,774:INFO:Creating metrics dataframe
2025-03-29 15:49:05,780:INFO:Initializing Gradient Boosting Regressor
2025-03-29 15:49:05,780:INFO:Total runtime is 0.37007295290629066 minutes
2025-03-29 15:49:05,782:INFO:SubProcess create_model() called ==================================
2025-03-29 15:49:05,782:INFO:Initializing create_model()
2025-03-29 15:49:05,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:49:05,782:INFO:Checking exceptions
2025-03-29 15:49:05,782:INFO:Importing libraries
2025-03-29 15:49:05,782:INFO:Copying training dataset
2025-03-29 15:49:05,790:INFO:Defining folds
2025-03-29 15:49:05,790:INFO:Declaring metric variables
2025-03-29 15:49:05,793:INFO:Importing untrained model
2025-03-29 15:49:05,795:INFO:Gradient Boosting Regressor Imported successfully
2025-03-29 15:49:05,799:INFO:Starting cross validation
2025-03-29 15:49:05,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:49:07,669:INFO:Calculating mean and std
2025-03-29 15:49:07,670:INFO:Creating metrics dataframe
2025-03-29 15:49:07,671:INFO:Uploading results into container
2025-03-29 15:49:07,672:INFO:Uploading model into container now
2025-03-29 15:49:07,672:INFO:_master_model_container: 16
2025-03-29 15:49:07,672:INFO:_display_container: 2
2025-03-29 15:49:07,673:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=7428, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-29 15:49:07,673:INFO:create_model() successfully completed......................................
2025-03-29 15:49:07,828:INFO:SubProcess create_model() end ==================================
2025-03-29 15:49:07,828:INFO:Creating metrics dataframe
2025-03-29 15:49:07,835:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 15:49:07,835:INFO:Total runtime is 0.4043192823727925 minutes
2025-03-29 15:49:07,837:INFO:SubProcess create_model() called ==================================
2025-03-29 15:49:07,838:INFO:Initializing create_model()
2025-03-29 15:49:07,838:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:49:07,838:INFO:Checking exceptions
2025-03-29 15:49:07,838:INFO:Importing libraries
2025-03-29 15:49:07,838:INFO:Copying training dataset
2025-03-29 15:49:07,845:INFO:Defining folds
2025-03-29 15:49:07,845:INFO:Declaring metric variables
2025-03-29 15:49:07,848:INFO:Importing untrained model
2025-03-29 15:49:07,850:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:49:07,854:INFO:Starting cross validation
2025-03-29 15:49:07,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:49:08,630:INFO:Calculating mean and std
2025-03-29 15:49:08,631:INFO:Creating metrics dataframe
2025-03-29 15:49:08,633:INFO:Uploading results into container
2025-03-29 15:49:08,633:INFO:Uploading model into container now
2025-03-29 15:49:08,633:INFO:_master_model_container: 17
2025-03-29 15:49:08,634:INFO:_display_container: 2
2025-03-29 15:49:08,634:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=7428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 15:49:08,634:INFO:create_model() successfully completed......................................
2025-03-29 15:49:08,812:INFO:SubProcess create_model() end ==================================
2025-03-29 15:49:08,812:INFO:Creating metrics dataframe
2025-03-29 15:49:08,818:INFO:Initializing Dummy Regressor
2025-03-29 15:49:08,818:INFO:Total runtime is 0.42070459524790443 minutes
2025-03-29 15:49:08,820:INFO:SubProcess create_model() called ==================================
2025-03-29 15:49:08,821:INFO:Initializing create_model()
2025-03-29 15:49:08,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91D105F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:49:08,821:INFO:Checking exceptions
2025-03-29 15:49:08,821:INFO:Importing libraries
2025-03-29 15:49:08,821:INFO:Copying training dataset
2025-03-29 15:49:08,828:INFO:Defining folds
2025-03-29 15:49:08,828:INFO:Declaring metric variables
2025-03-29 15:49:08,830:INFO:Importing untrained model
2025-03-29 15:49:08,832:INFO:Dummy Regressor Imported successfully
2025-03-29 15:49:08,836:INFO:Starting cross validation
2025-03-29 15:49:08,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 15:49:09,033:INFO:Calculating mean and std
2025-03-29 15:49:09,035:INFO:Creating metrics dataframe
2025-03-29 15:49:09,037:INFO:Uploading results into container
2025-03-29 15:49:09,037:INFO:Uploading model into container now
2025-03-29 15:49:09,038:INFO:_master_model_container: 18
2025-03-29 15:49:09,038:INFO:_display_container: 2
2025-03-29 15:49:09,038:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-03-29 15:49:09,038:INFO:create_model() successfully completed......................................
2025-03-29 15:49:09,191:INFO:SubProcess create_model() end ==================================
2025-03-29 15:49:09,191:INFO:Creating metrics dataframe
2025-03-29 15:49:09,198:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-29 15:49:09,203:INFO:Initializing create_model()
2025-03-29 15:49:09,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F5A8550>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=7428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 15:49:09,203:INFO:Checking exceptions
2025-03-29 15:49:09,204:INFO:Importing libraries
2025-03-29 15:49:09,204:INFO:Copying training dataset
2025-03-29 15:49:09,210:INFO:Defining folds
2025-03-29 15:49:09,211:INFO:Declaring metric variables
2025-03-29 15:49:09,211:INFO:Importing untrained model
2025-03-29 15:49:09,211:INFO:Declaring custom model
2025-03-29 15:49:09,211:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 15:49:09,212:INFO:Cross validation set to False
2025-03-29 15:49:09,212:INFO:Fitting Model
2025-03-29 15:49:09,288:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 15:49:09,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-03-29 15:49:09,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 15:49:09,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 15:49:09,290:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 15:49:09,290:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 15:49:09,290:INFO:[LightGBM] [Info] Start training from score 3257.550056
2025-03-29 15:49:09,332:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=7428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 15:49:09,332:INFO:create_model() successfully completed......................................
2025-03-29 15:49:09,518:INFO:_master_model_container: 18
2025-03-29 15:49:09,518:INFO:_display_container: 2
2025-03-29 15:49:09,519:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=7428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 15:49:09,519:INFO:compare_models() successfully completed......................................
2025-03-29 16:00:23,249:INFO:PyCaret RegressionExperiment
2025-03-29 16:00:23,250:INFO:Logging name: reg-default-name
2025-03-29 16:00:23,250:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 16:00:23,250:INFO:version 3.3.2
2025-03-29 16:00:23,250:INFO:Initializing setup()
2025-03-29 16:00:23,250:INFO:self.USI: e578
2025-03-29 16:00:23,250:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 16:00:23,250:INFO:Checking environment
2025-03-29 16:00:23,250:INFO:python_version: 3.10.16
2025-03-29 16:00:23,250:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:00:23,250:INFO:machine: AMD64
2025-03-29 16:00:23,250:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:00:23,254:INFO:Memory: svmem(total=33411727360, available=16381071360, percent=51.0, used=17030656000, free=16381071360)
2025-03-29 16:00:23,254:INFO:Physical Core: 6
2025-03-29 16:00:23,255:INFO:Logical Core: 12
2025-03-29 16:00:23,255:INFO:Checking libraries
2025-03-29 16:00:23,255:INFO:System:
2025-03-29 16:00:23,255:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:00:23,255:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:00:23,255:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:00:23,255:INFO:PyCaret required dependencies:
2025-03-29 16:00:23,255:INFO:                 pip: 25.0.1
2025-03-29 16:00:23,255:INFO:          setuptools: 75.8.2
2025-03-29 16:00:23,255:INFO:             pycaret: 3.3.2
2025-03-29 16:00:23,255:INFO:             IPython: 8.34.0
2025-03-29 16:00:23,255:INFO:          ipywidgets: 8.1.5
2025-03-29 16:00:23,255:INFO:                tqdm: 4.67.1
2025-03-29 16:00:23,255:INFO:               numpy: 1.26.4
2025-03-29 16:00:23,255:INFO:              pandas: 2.1.4
2025-03-29 16:00:23,255:INFO:              jinja2: 3.1.6
2025-03-29 16:00:23,255:INFO:               scipy: 1.11.4
2025-03-29 16:00:23,255:INFO:              joblib: 1.3.2
2025-03-29 16:00:23,255:INFO:             sklearn: 1.4.2
2025-03-29 16:00:23,255:INFO:                pyod: 2.0.2
2025-03-29 16:00:23,255:INFO:            imblearn: 0.13.0
2025-03-29 16:00:23,255:INFO:   category_encoders: 2.7.0
2025-03-29 16:00:23,255:INFO:            lightgbm: 4.6.0
2025-03-29 16:00:23,255:INFO:               numba: 0.61.0
2025-03-29 16:00:23,255:INFO:            requests: 2.32.3
2025-03-29 16:00:23,255:INFO:          matplotlib: 3.10.1
2025-03-29 16:00:23,255:INFO:          scikitplot: 0.3.7
2025-03-29 16:00:23,255:INFO:         yellowbrick: 1.5
2025-03-29 16:00:23,255:INFO:              plotly: 6.0.1
2025-03-29 16:00:23,255:INFO:    plotly-resampler: Not installed
2025-03-29 16:00:23,255:INFO:             kaleido: 0.2.1
2025-03-29 16:00:23,255:INFO:           schemdraw: 0.15
2025-03-29 16:00:23,255:INFO:         statsmodels: 0.14.4
2025-03-29 16:00:23,255:INFO:              sktime: 0.26.0
2025-03-29 16:00:23,255:INFO:               tbats: 1.1.3
2025-03-29 16:00:23,255:INFO:            pmdarima: 2.0.4
2025-03-29 16:00:23,255:INFO:              psutil: 7.0.0
2025-03-29 16:00:23,255:INFO:          markupsafe: 3.0.2
2025-03-29 16:00:23,255:INFO:             pickle5: Not installed
2025-03-29 16:00:23,256:INFO:         cloudpickle: 3.1.1
2025-03-29 16:00:23,256:INFO:         deprecation: 2.1.0
2025-03-29 16:00:23,256:INFO:              xxhash: 3.5.0
2025-03-29 16:00:23,256:INFO:           wurlitzer: 3.1.1
2025-03-29 16:00:23,256:INFO:PyCaret optional dependencies:
2025-03-29 16:00:23,256:INFO:                shap: Not installed
2025-03-29 16:00:23,256:INFO:           interpret: Not installed
2025-03-29 16:00:23,256:INFO:                umap: 0.5.7
2025-03-29 16:00:23,256:INFO:     ydata_profiling: Not installed
2025-03-29 16:00:23,256:INFO:  explainerdashboard: Not installed
2025-03-29 16:00:23,256:INFO:             autoviz: Not installed
2025-03-29 16:00:23,256:INFO:           fairlearn: Not installed
2025-03-29 16:00:23,256:INFO:          deepchecks: Not installed
2025-03-29 16:00:23,256:INFO:             xgboost: Not installed
2025-03-29 16:00:23,256:INFO:            catboost: Not installed
2025-03-29 16:00:23,256:INFO:              kmodes: Not installed
2025-03-29 16:00:23,256:INFO:             mlxtend: Not installed
2025-03-29 16:00:23,256:INFO:       statsforecast: Not installed
2025-03-29 16:00:23,256:INFO:        tune_sklearn: Not installed
2025-03-29 16:00:23,256:INFO:                 ray: Not installed
2025-03-29 16:00:23,256:INFO:            hyperopt: Not installed
2025-03-29 16:00:23,256:INFO:              optuna: Not installed
2025-03-29 16:00:23,256:INFO:               skopt: Not installed
2025-03-29 16:00:23,256:INFO:              mlflow: 2.21.2
2025-03-29 16:00:23,256:INFO:              gradio: Not installed
2025-03-29 16:00:23,256:INFO:             fastapi: 0.115.12
2025-03-29 16:00:23,256:INFO:             uvicorn: 0.34.0
2025-03-29 16:00:23,256:INFO:              m2cgen: Not installed
2025-03-29 16:00:23,256:INFO:           evidently: Not installed
2025-03-29 16:00:23,256:INFO:               fugue: Not installed
2025-03-29 16:00:23,256:INFO:           streamlit: 1.43.2
2025-03-29 16:00:23,256:INFO:             prophet: Not installed
2025-03-29 16:00:23,256:INFO:None
2025-03-29 16:00:23,256:INFO:Set up data.
2025-03-29 16:00:23,264:INFO:Set up folding strategy.
2025-03-29 16:00:23,265:INFO:Set up train/test split.
2025-03-29 16:00:23,269:INFO:Set up index.
2025-03-29 16:00:23,270:INFO:Assigning column types.
2025-03-29 16:00:23,274:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 16:00:23,274:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,277:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,280:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,319:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,348:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,351:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,354:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,426:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,427:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 16:00:23,430:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,433:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,473:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,501:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,505:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,507:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,547:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,574:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 16:00:23,580:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,644:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,649:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,686:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,711:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,712:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 16:00:23,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,778:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,819:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,845:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 16:00:23,886:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:00:23,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:23,984:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 16:00:24,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:24,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:24,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:24,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:24,127:INFO:Preparing preprocessing pipeline...
2025-03-29 16:00:24,127:INFO:Set up simple imputation.
2025-03-29 16:00:24,130:INFO:Set up encoding of categorical features.
2025-03-29 16:00:24,130:INFO:Set up feature normalization.
2025-03-29 16:00:24,131:INFO:Set up column name cleaning.
2025-03-29 16:00:24,246:INFO:Finished creating preprocessing pipeline.
2025-03-29 16:00:24,250:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_i...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-03-29 16:00:24,250:INFO:Creating final display dataframe.
2025-03-29 16:00:24,491:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              e578
2025-03-29 16:00:24,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:24,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:24,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:24,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:00:24,630:INFO:setup() successfully completed in 1.38s...............
2025-03-29 16:00:26,759:INFO:Initializing get_config()
2025-03-29 16:00:26,759:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, variable=X_train)
2025-03-29 16:00:26,760:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-03-29 16:00:26,760:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-03-29 16:00:26,766:INFO:Variable:  returned as       holiday        temp  rain_1h  snow_1h  clouds_all weather_main  \
5068      NaN  271.880005      0.0      0.0          90         Mist   
8455      NaN  290.549988      0.0      0.0          90       Clouds   
34864     NaN  284.339996      0.0      0.0           1        Clear   
1526      NaN  264.839996      0.0      0.0          40       Clouds   
6499      NaN  286.989990      0.0      0.0          90      Drizzle   
...       ...         ...      ...      ...         ...          ...   
7763      NaN  305.880005      0.0      0.0           0        Clear   
15377     NaN  298.799988      0.0      0.0          44       Clouds   
17730     NaN  282.170013      0.0      0.0           1         Mist   
28030     NaN  280.420013      0.0      0.0           1        Clear   
15725     NaN  290.320007      0.0      0.0           1        Clear   

       Rush Hour  
5068           0  
8455           0  
34864          0  
1526           0  
6499           0  
...          ...  
7763           0  
15377          0  
17730          0  
28030          0  
15725          0  

[33742 rows x 7 columns]
2025-03-29 16:00:26,766:INFO:get_config() successfully completed......................................
2025-03-29 16:00:28,004:INFO:Initializing compare_models()
2025-03-29 16:00:28,004:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-29 16:00:28,004:INFO:Checking exceptions
2025-03-29 16:00:28,008:INFO:Preparing display monitor
2025-03-29 16:00:28,022:INFO:Initializing Linear Regression
2025-03-29 16:00:28,023:INFO:Total runtime is 1.6649564107259113e-05 minutes
2025-03-29 16:00:28,025:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:28,025:INFO:Initializing create_model()
2025-03-29 16:00:28,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:28,025:INFO:Checking exceptions
2025-03-29 16:00:28,025:INFO:Importing libraries
2025-03-29 16:00:28,025:INFO:Copying training dataset
2025-03-29 16:00:28,032:INFO:Defining folds
2025-03-29 16:00:28,032:INFO:Declaring metric variables
2025-03-29 16:00:28,034:INFO:Importing untrained model
2025-03-29 16:00:28,037:INFO:Linear Regression Imported successfully
2025-03-29 16:00:28,042:INFO:Starting cross validation
2025-03-29 16:00:28,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:30,996:INFO:Calculating mean and std
2025-03-29 16:00:30,998:INFO:Creating metrics dataframe
2025-03-29 16:00:31,000:INFO:Uploading results into container
2025-03-29 16:00:31,000:INFO:Uploading model into container now
2025-03-29 16:00:31,000:INFO:_master_model_container: 1
2025-03-29 16:00:31,001:INFO:_display_container: 2
2025-03-29 16:00:31,001:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-03-29 16:00:31,001:INFO:create_model() successfully completed......................................
2025-03-29 16:00:31,188:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:31,188:INFO:Creating metrics dataframe
2025-03-29 16:00:31,191:INFO:Initializing Lasso Regression
2025-03-29 16:00:31,192:INFO:Total runtime is 0.05281692345937093 minutes
2025-03-29 16:00:31,194:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:31,194:INFO:Initializing create_model()
2025-03-29 16:00:31,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:31,194:INFO:Checking exceptions
2025-03-29 16:00:31,194:INFO:Importing libraries
2025-03-29 16:00:31,194:INFO:Copying training dataset
2025-03-29 16:00:31,202:INFO:Defining folds
2025-03-29 16:00:31,202:INFO:Declaring metric variables
2025-03-29 16:00:31,204:INFO:Importing untrained model
2025-03-29 16:00:31,207:INFO:Lasso Regression Imported successfully
2025-03-29 16:00:31,210:INFO:Starting cross validation
2025-03-29 16:00:31,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:32,980:INFO:Calculating mean and std
2025-03-29 16:00:32,981:INFO:Creating metrics dataframe
2025-03-29 16:00:32,983:INFO:Uploading results into container
2025-03-29 16:00:32,983:INFO:Uploading model into container now
2025-03-29 16:00:32,983:INFO:_master_model_container: 2
2025-03-29 16:00:32,984:INFO:_display_container: 2
2025-03-29 16:00:32,984:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-03-29 16:00:32,984:INFO:create_model() successfully completed......................................
2025-03-29 16:00:33,143:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:33,143:INFO:Creating metrics dataframe
2025-03-29 16:00:33,148:INFO:Initializing Ridge Regression
2025-03-29 16:00:33,148:INFO:Total runtime is 0.0854223648707072 minutes
2025-03-29 16:00:33,150:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:33,150:INFO:Initializing create_model()
2025-03-29 16:00:33,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:33,150:INFO:Checking exceptions
2025-03-29 16:00:33,150:INFO:Importing libraries
2025-03-29 16:00:33,150:INFO:Copying training dataset
2025-03-29 16:00:33,157:INFO:Defining folds
2025-03-29 16:00:33,158:INFO:Declaring metric variables
2025-03-29 16:00:33,160:INFO:Importing untrained model
2025-03-29 16:00:33,162:INFO:Ridge Regression Imported successfully
2025-03-29 16:00:33,165:INFO:Starting cross validation
2025-03-29 16:00:33,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:33,423:INFO:Calculating mean and std
2025-03-29 16:00:33,424:INFO:Creating metrics dataframe
2025-03-29 16:00:33,426:INFO:Uploading results into container
2025-03-29 16:00:33,426:INFO:Uploading model into container now
2025-03-29 16:00:33,426:INFO:_master_model_container: 3
2025-03-29 16:00:33,427:INFO:_display_container: 2
2025-03-29 16:00:33,427:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-03-29 16:00:33,427:INFO:create_model() successfully completed......................................
2025-03-29 16:00:33,591:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:33,591:INFO:Creating metrics dataframe
2025-03-29 16:00:33,596:INFO:Initializing Elastic Net
2025-03-29 16:00:33,596:INFO:Total runtime is 0.09289907614390056 minutes
2025-03-29 16:00:33,598:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:33,598:INFO:Initializing create_model()
2025-03-29 16:00:33,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:33,599:INFO:Checking exceptions
2025-03-29 16:00:33,599:INFO:Importing libraries
2025-03-29 16:00:33,599:INFO:Copying training dataset
2025-03-29 16:00:33,605:INFO:Defining folds
2025-03-29 16:00:33,606:INFO:Declaring metric variables
2025-03-29 16:00:33,608:INFO:Importing untrained model
2025-03-29 16:00:33,611:INFO:Elastic Net Imported successfully
2025-03-29 16:00:33,614:INFO:Starting cross validation
2025-03-29 16:00:33,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:33,890:INFO:Calculating mean and std
2025-03-29 16:00:33,891:INFO:Creating metrics dataframe
2025-03-29 16:00:33,892:INFO:Uploading results into container
2025-03-29 16:00:33,893:INFO:Uploading model into container now
2025-03-29 16:00:33,893:INFO:_master_model_container: 4
2025-03-29 16:00:33,893:INFO:_display_container: 2
2025-03-29 16:00:33,893:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-03-29 16:00:33,893:INFO:create_model() successfully completed......................................
2025-03-29 16:00:34,056:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:34,056:INFO:Creating metrics dataframe
2025-03-29 16:00:34,061:INFO:Initializing Least Angle Regression
2025-03-29 16:00:34,061:INFO:Total runtime is 0.10064073006312052 minutes
2025-03-29 16:00:34,063:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:34,063:INFO:Initializing create_model()
2025-03-29 16:00:34,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:34,063:INFO:Checking exceptions
2025-03-29 16:00:34,063:INFO:Importing libraries
2025-03-29 16:00:34,063:INFO:Copying training dataset
2025-03-29 16:00:34,070:INFO:Defining folds
2025-03-29 16:00:34,070:INFO:Declaring metric variables
2025-03-29 16:00:34,073:INFO:Importing untrained model
2025-03-29 16:00:34,075:INFO:Least Angle Regression Imported successfully
2025-03-29 16:00:34,079:INFO:Starting cross validation
2025-03-29 16:00:34,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:34,350:INFO:Calculating mean and std
2025-03-29 16:00:34,351:INFO:Creating metrics dataframe
2025-03-29 16:00:34,352:INFO:Uploading results into container
2025-03-29 16:00:34,352:INFO:Uploading model into container now
2025-03-29 16:00:34,353:INFO:_master_model_container: 5
2025-03-29 16:00:34,353:INFO:_display_container: 2
2025-03-29 16:00:34,353:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-03-29 16:00:34,353:INFO:create_model() successfully completed......................................
2025-03-29 16:00:34,508:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:34,508:INFO:Creating metrics dataframe
2025-03-29 16:00:34,514:INFO:Initializing Lasso Least Angle Regression
2025-03-29 16:00:34,514:INFO:Total runtime is 0.10819162925084432 minutes
2025-03-29 16:00:34,516:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:34,516:INFO:Initializing create_model()
2025-03-29 16:00:34,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:34,516:INFO:Checking exceptions
2025-03-29 16:00:34,516:INFO:Importing libraries
2025-03-29 16:00:34,516:INFO:Copying training dataset
2025-03-29 16:00:34,524:INFO:Defining folds
2025-03-29 16:00:34,524:INFO:Declaring metric variables
2025-03-29 16:00:34,527:INFO:Importing untrained model
2025-03-29 16:00:34,529:INFO:Lasso Least Angle Regression Imported successfully
2025-03-29 16:00:34,533:INFO:Starting cross validation
2025-03-29 16:00:34,534:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:34,798:INFO:Calculating mean and std
2025-03-29 16:00:34,799:INFO:Creating metrics dataframe
2025-03-29 16:00:34,801:INFO:Uploading results into container
2025-03-29 16:00:34,801:INFO:Uploading model into container now
2025-03-29 16:00:34,802:INFO:_master_model_container: 6
2025-03-29 16:00:34,802:INFO:_display_container: 2
2025-03-29 16:00:34,802:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-03-29 16:00:34,802:INFO:create_model() successfully completed......................................
2025-03-29 16:00:34,963:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:34,964:INFO:Creating metrics dataframe
2025-03-29 16:00:34,969:INFO:Initializing Orthogonal Matching Pursuit
2025-03-29 16:00:34,969:INFO:Total runtime is 0.11577353477478027 minutes
2025-03-29 16:00:34,971:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:34,971:INFO:Initializing create_model()
2025-03-29 16:00:34,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:34,971:INFO:Checking exceptions
2025-03-29 16:00:34,971:INFO:Importing libraries
2025-03-29 16:00:34,971:INFO:Copying training dataset
2025-03-29 16:00:34,978:INFO:Defining folds
2025-03-29 16:00:34,978:INFO:Declaring metric variables
2025-03-29 16:00:34,981:INFO:Importing untrained model
2025-03-29 16:00:34,983:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-29 16:00:34,988:INFO:Starting cross validation
2025-03-29 16:00:34,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:35,251:INFO:Calculating mean and std
2025-03-29 16:00:35,252:INFO:Creating metrics dataframe
2025-03-29 16:00:35,254:INFO:Uploading results into container
2025-03-29 16:00:35,254:INFO:Uploading model into container now
2025-03-29 16:00:35,255:INFO:_master_model_container: 7
2025-03-29 16:00:35,255:INFO:_display_container: 2
2025-03-29 16:00:35,255:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-03-29 16:00:35,255:INFO:create_model() successfully completed......................................
2025-03-29 16:00:35,414:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:35,414:INFO:Creating metrics dataframe
2025-03-29 16:00:35,419:INFO:Initializing Bayesian Ridge
2025-03-29 16:00:35,420:INFO:Total runtime is 0.12329616546630859 minutes
2025-03-29 16:00:35,422:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:35,422:INFO:Initializing create_model()
2025-03-29 16:00:35,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:35,422:INFO:Checking exceptions
2025-03-29 16:00:35,422:INFO:Importing libraries
2025-03-29 16:00:35,422:INFO:Copying training dataset
2025-03-29 16:00:35,429:INFO:Defining folds
2025-03-29 16:00:35,429:INFO:Declaring metric variables
2025-03-29 16:00:35,432:INFO:Importing untrained model
2025-03-29 16:00:35,434:INFO:Bayesian Ridge Imported successfully
2025-03-29 16:00:35,438:INFO:Starting cross validation
2025-03-29 16:00:35,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:35,741:INFO:Calculating mean and std
2025-03-29 16:00:35,742:INFO:Creating metrics dataframe
2025-03-29 16:00:35,743:INFO:Uploading results into container
2025-03-29 16:00:35,744:INFO:Uploading model into container now
2025-03-29 16:00:35,744:INFO:_master_model_container: 8
2025-03-29 16:00:35,744:INFO:_display_container: 2
2025-03-29 16:00:35,744:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-03-29 16:00:35,745:INFO:create_model() successfully completed......................................
2025-03-29 16:00:35,915:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:35,915:INFO:Creating metrics dataframe
2025-03-29 16:00:35,920:INFO:Initializing Passive Aggressive Regressor
2025-03-29 16:00:35,920:INFO:Total runtime is 0.13162811994552612 minutes
2025-03-29 16:00:35,922:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:35,923:INFO:Initializing create_model()
2025-03-29 16:00:35,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:35,923:INFO:Checking exceptions
2025-03-29 16:00:35,923:INFO:Importing libraries
2025-03-29 16:00:35,923:INFO:Copying training dataset
2025-03-29 16:00:35,930:INFO:Defining folds
2025-03-29 16:00:35,930:INFO:Declaring metric variables
2025-03-29 16:00:35,932:INFO:Importing untrained model
2025-03-29 16:00:35,934:INFO:Passive Aggressive Regressor Imported successfully
2025-03-29 16:00:35,938:INFO:Starting cross validation
2025-03-29 16:00:35,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:36,281:INFO:Calculating mean and std
2025-03-29 16:00:36,281:INFO:Creating metrics dataframe
2025-03-29 16:00:36,283:INFO:Uploading results into container
2025-03-29 16:00:36,283:INFO:Uploading model into container now
2025-03-29 16:00:36,283:INFO:_master_model_container: 9
2025-03-29 16:00:36,283:INFO:_display_container: 2
2025-03-29 16:00:36,284:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:00:36,284:INFO:create_model() successfully completed......................................
2025-03-29 16:00:36,441:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:36,441:INFO:Creating metrics dataframe
2025-03-29 16:00:36,447:INFO:Initializing Huber Regressor
2025-03-29 16:00:36,447:INFO:Total runtime is 0.1404046058654785 minutes
2025-03-29 16:00:36,449:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:36,449:INFO:Initializing create_model()
2025-03-29 16:00:36,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:36,449:INFO:Checking exceptions
2025-03-29 16:00:36,449:INFO:Importing libraries
2025-03-29 16:00:36,449:INFO:Copying training dataset
2025-03-29 16:00:36,456:INFO:Defining folds
2025-03-29 16:00:36,456:INFO:Declaring metric variables
2025-03-29 16:00:36,458:INFO:Importing untrained model
2025-03-29 16:00:36,460:INFO:Huber Regressor Imported successfully
2025-03-29 16:00:36,464:INFO:Starting cross validation
2025-03-29 16:00:36,465:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:36,959:INFO:Calculating mean and std
2025-03-29 16:00:36,960:INFO:Creating metrics dataframe
2025-03-29 16:00:36,961:INFO:Uploading results into container
2025-03-29 16:00:36,961:INFO:Uploading model into container now
2025-03-29 16:00:36,961:INFO:_master_model_container: 10
2025-03-29 16:00:36,962:INFO:_display_container: 2
2025-03-29 16:00:36,962:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-03-29 16:00:36,962:INFO:create_model() successfully completed......................................
2025-03-29 16:00:37,121:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:37,121:INFO:Creating metrics dataframe
2025-03-29 16:00:37,127:INFO:Initializing K Neighbors Regressor
2025-03-29 16:00:37,127:INFO:Total runtime is 0.15174298683802287 minutes
2025-03-29 16:00:37,129:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:37,129:INFO:Initializing create_model()
2025-03-29 16:00:37,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:37,129:INFO:Checking exceptions
2025-03-29 16:00:37,129:INFO:Importing libraries
2025-03-29 16:00:37,129:INFO:Copying training dataset
2025-03-29 16:00:37,136:INFO:Defining folds
2025-03-29 16:00:37,136:INFO:Declaring metric variables
2025-03-29 16:00:37,139:INFO:Importing untrained model
2025-03-29 16:00:37,141:INFO:K Neighbors Regressor Imported successfully
2025-03-29 16:00:37,145:INFO:Starting cross validation
2025-03-29 16:00:37,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:37,977:INFO:Calculating mean and std
2025-03-29 16:00:37,978:INFO:Creating metrics dataframe
2025-03-29 16:00:37,979:INFO:Uploading results into container
2025-03-29 16:00:37,979:INFO:Uploading model into container now
2025-03-29 16:00:37,980:INFO:_master_model_container: 11
2025-03-29 16:00:37,980:INFO:_display_container: 2
2025-03-29 16:00:37,980:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-03-29 16:00:37,980:INFO:create_model() successfully completed......................................
2025-03-29 16:00:38,140:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:38,140:INFO:Creating metrics dataframe
2025-03-29 16:00:38,146:INFO:Initializing Decision Tree Regressor
2025-03-29 16:00:38,146:INFO:Total runtime is 0.16873023907343546 minutes
2025-03-29 16:00:38,148:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:38,149:INFO:Initializing create_model()
2025-03-29 16:00:38,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:38,149:INFO:Checking exceptions
2025-03-29 16:00:38,149:INFO:Importing libraries
2025-03-29 16:00:38,149:INFO:Copying training dataset
2025-03-29 16:00:38,156:INFO:Defining folds
2025-03-29 16:00:38,156:INFO:Declaring metric variables
2025-03-29 16:00:38,158:INFO:Importing untrained model
2025-03-29 16:00:38,160:INFO:Decision Tree Regressor Imported successfully
2025-03-29 16:00:38,164:INFO:Starting cross validation
2025-03-29 16:00:38,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:38,525:INFO:Calculating mean and std
2025-03-29 16:00:38,526:INFO:Creating metrics dataframe
2025-03-29 16:00:38,527:INFO:Uploading results into container
2025-03-29 16:00:38,528:INFO:Uploading model into container now
2025-03-29 16:00:38,528:INFO:_master_model_container: 12
2025-03-29 16:00:38,528:INFO:_display_container: 2
2025-03-29 16:00:38,528:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-03-29 16:00:38,528:INFO:create_model() successfully completed......................................
2025-03-29 16:00:38,685:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:38,686:INFO:Creating metrics dataframe
2025-03-29 16:00:38,692:INFO:Initializing Random Forest Regressor
2025-03-29 16:00:38,692:INFO:Total runtime is 0.17782761653264362 minutes
2025-03-29 16:00:38,694:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:38,694:INFO:Initializing create_model()
2025-03-29 16:00:38,694:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:38,694:INFO:Checking exceptions
2025-03-29 16:00:38,694:INFO:Importing libraries
2025-03-29 16:00:38,694:INFO:Copying training dataset
2025-03-29 16:00:38,701:INFO:Defining folds
2025-03-29 16:00:38,701:INFO:Declaring metric variables
2025-03-29 16:00:38,704:INFO:Importing untrained model
2025-03-29 16:00:38,706:INFO:Random Forest Regressor Imported successfully
2025-03-29 16:00:38,710:INFO:Starting cross validation
2025-03-29 16:00:38,711:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:44,760:INFO:Calculating mean and std
2025-03-29 16:00:44,761:INFO:Creating metrics dataframe
2025-03-29 16:00:44,762:INFO:Uploading results into container
2025-03-29 16:00:44,763:INFO:Uploading model into container now
2025-03-29 16:00:44,763:INFO:_master_model_container: 13
2025-03-29 16:00:44,763:INFO:_display_container: 2
2025-03-29 16:00:44,764:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-03-29 16:00:44,764:INFO:create_model() successfully completed......................................
2025-03-29 16:00:44,969:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:44,969:INFO:Creating metrics dataframe
2025-03-29 16:00:44,977:INFO:Initializing Extra Trees Regressor
2025-03-29 16:00:44,977:INFO:Total runtime is 0.28258073727289834 minutes
2025-03-29 16:00:44,979:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:44,980:INFO:Initializing create_model()
2025-03-29 16:00:44,980:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:44,980:INFO:Checking exceptions
2025-03-29 16:00:44,980:INFO:Importing libraries
2025-03-29 16:00:44,980:INFO:Copying training dataset
2025-03-29 16:00:44,988:INFO:Defining folds
2025-03-29 16:00:44,988:INFO:Declaring metric variables
2025-03-29 16:00:44,991:INFO:Importing untrained model
2025-03-29 16:00:44,993:INFO:Extra Trees Regressor Imported successfully
2025-03-29 16:00:44,997:INFO:Starting cross validation
2025-03-29 16:00:44,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:48,940:INFO:Calculating mean and std
2025-03-29 16:00:48,941:INFO:Creating metrics dataframe
2025-03-29 16:00:48,942:INFO:Uploading results into container
2025-03-29 16:00:48,943:INFO:Uploading model into container now
2025-03-29 16:00:48,943:INFO:_master_model_container: 14
2025-03-29 16:00:48,943:INFO:_display_container: 2
2025-03-29 16:00:48,943:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-03-29 16:00:48,944:INFO:create_model() successfully completed......................................
2025-03-29 16:00:49,138:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:49,138:INFO:Creating metrics dataframe
2025-03-29 16:00:49,146:INFO:Initializing AdaBoost Regressor
2025-03-29 16:00:49,146:INFO:Total runtime is 0.35206187963485713 minutes
2025-03-29 16:00:49,148:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:49,148:INFO:Initializing create_model()
2025-03-29 16:00:49,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:49,148:INFO:Checking exceptions
2025-03-29 16:00:49,148:INFO:Importing libraries
2025-03-29 16:00:49,148:INFO:Copying training dataset
2025-03-29 16:00:49,158:INFO:Defining folds
2025-03-29 16:00:49,158:INFO:Declaring metric variables
2025-03-29 16:00:49,160:INFO:Importing untrained model
2025-03-29 16:00:49,163:INFO:AdaBoost Regressor Imported successfully
2025-03-29 16:00:49,166:INFO:Starting cross validation
2025-03-29 16:00:49,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:50,057:INFO:Calculating mean and std
2025-03-29 16:00:50,058:INFO:Creating metrics dataframe
2025-03-29 16:00:50,059:INFO:Uploading results into container
2025-03-29 16:00:50,060:INFO:Uploading model into container now
2025-03-29 16:00:50,060:INFO:_master_model_container: 15
2025-03-29 16:00:50,060:INFO:_display_container: 2
2025-03-29 16:00:50,060:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-03-29 16:00:50,060:INFO:create_model() successfully completed......................................
2025-03-29 16:00:50,218:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:50,218:INFO:Creating metrics dataframe
2025-03-29 16:00:50,225:INFO:Initializing Gradient Boosting Regressor
2025-03-29 16:00:50,225:INFO:Total runtime is 0.3700400034586588 minutes
2025-03-29 16:00:50,227:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:50,227:INFO:Initializing create_model()
2025-03-29 16:00:50,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:50,227:INFO:Checking exceptions
2025-03-29 16:00:50,227:INFO:Importing libraries
2025-03-29 16:00:50,227:INFO:Copying training dataset
2025-03-29 16:00:50,234:INFO:Defining folds
2025-03-29 16:00:50,234:INFO:Declaring metric variables
2025-03-29 16:00:50,236:INFO:Importing untrained model
2025-03-29 16:00:50,238:INFO:Gradient Boosting Regressor Imported successfully
2025-03-29 16:00:50,242:INFO:Starting cross validation
2025-03-29 16:00:50,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:52,207:INFO:Calculating mean and std
2025-03-29 16:00:52,208:INFO:Creating metrics dataframe
2025-03-29 16:00:52,209:INFO:Uploading results into container
2025-03-29 16:00:52,209:INFO:Uploading model into container now
2025-03-29 16:00:52,209:INFO:_master_model_container: 16
2025-03-29 16:00:52,209:INFO:_display_container: 2
2025-03-29 16:00:52,210:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-29 16:00:52,210:INFO:create_model() successfully completed......................................
2025-03-29 16:00:52,368:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:52,368:INFO:Creating metrics dataframe
2025-03-29 16:00:52,375:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 16:00:52,375:INFO:Total runtime is 0.4058767914772033 minutes
2025-03-29 16:00:52,378:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:52,378:INFO:Initializing create_model()
2025-03-29 16:00:52,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:52,378:INFO:Checking exceptions
2025-03-29 16:00:52,378:INFO:Importing libraries
2025-03-29 16:00:52,378:INFO:Copying training dataset
2025-03-29 16:00:52,385:INFO:Defining folds
2025-03-29 16:00:52,385:INFO:Declaring metric variables
2025-03-29 16:00:52,387:INFO:Importing untrained model
2025-03-29 16:00:52,390:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:00:52,394:INFO:Starting cross validation
2025-03-29 16:00:52,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:53,329:INFO:Calculating mean and std
2025-03-29 16:00:53,330:INFO:Creating metrics dataframe
2025-03-29 16:00:53,331:INFO:Uploading results into container
2025-03-29 16:00:53,332:INFO:Uploading model into container now
2025-03-29 16:00:53,332:INFO:_master_model_container: 17
2025-03-29 16:00:53,332:INFO:_display_container: 2
2025-03-29 16:00:53,333:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:00:53,333:INFO:create_model() successfully completed......................................
2025-03-29 16:00:53,531:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:53,531:INFO:Creating metrics dataframe
2025-03-29 16:00:53,538:INFO:Initializing Dummy Regressor
2025-03-29 16:00:53,538:INFO:Total runtime is 0.42525912523269643 minutes
2025-03-29 16:00:53,540:INFO:SubProcess create_model() called ==================================
2025-03-29 16:00:53,540:INFO:Initializing create_model()
2025-03-29 16:00:53,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F045FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:53,541:INFO:Checking exceptions
2025-03-29 16:00:53,541:INFO:Importing libraries
2025-03-29 16:00:53,541:INFO:Copying training dataset
2025-03-29 16:00:53,547:INFO:Defining folds
2025-03-29 16:00:53,548:INFO:Declaring metric variables
2025-03-29 16:00:53,550:INFO:Importing untrained model
2025-03-29 16:00:53,552:INFO:Dummy Regressor Imported successfully
2025-03-29 16:00:53,555:INFO:Starting cross validation
2025-03-29 16:00:53,557:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:00:53,807:INFO:Calculating mean and std
2025-03-29 16:00:53,808:INFO:Creating metrics dataframe
2025-03-29 16:00:53,809:INFO:Uploading results into container
2025-03-29 16:00:53,810:INFO:Uploading model into container now
2025-03-29 16:00:53,810:INFO:_master_model_container: 18
2025-03-29 16:00:53,810:INFO:_display_container: 2
2025-03-29 16:00:53,810:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-03-29 16:00:53,810:INFO:create_model() successfully completed......................................
2025-03-29 16:00:53,972:INFO:SubProcess create_model() end ==================================
2025-03-29 16:00:53,972:INFO:Creating metrics dataframe
2025-03-29 16:00:53,980:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-29 16:00:53,985:INFO:Initializing create_model()
2025-03-29 16:00:53,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91ECAEF50>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:00:53,985:INFO:Checking exceptions
2025-03-29 16:00:53,987:INFO:Importing libraries
2025-03-29 16:00:53,987:INFO:Copying training dataset
2025-03-29 16:00:53,994:INFO:Defining folds
2025-03-29 16:00:53,995:INFO:Declaring metric variables
2025-03-29 16:00:53,995:INFO:Importing untrained model
2025-03-29 16:00:53,995:INFO:Declaring custom model
2025-03-29 16:00:53,996:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:00:53,997:INFO:Cross validation set to False
2025-03-29 16:00:53,997:INFO:Fitting Model
2025-03-29 16:00:54,102:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:00:54,105:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000972 seconds.
2025-03-29 16:00:54,106:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:00:54,106:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:00:54,106:INFO:[LightGBM] [Info] Total Bins 575
2025-03-29 16:00:54,106:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 16:00:54,106:INFO:[LightGBM] [Info] Start training from score 3248.074833
2025-03-29 16:00:54,187:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:00:54,188:INFO:create_model() successfully completed......................................
2025-03-29 16:00:54,388:INFO:_master_model_container: 18
2025-03-29 16:00:54,388:INFO:_display_container: 2
2025-03-29 16:00:54,388:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:00:54,389:INFO:compare_models() successfully completed......................................
2025-03-29 16:04:56,733:INFO:PyCaret RegressionExperiment
2025-03-29 16:04:56,734:INFO:Logging name: reg-default-name
2025-03-29 16:04:56,734:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 16:04:56,734:INFO:version 3.3.2
2025-03-29 16:04:56,734:INFO:Initializing setup()
2025-03-29 16:04:56,734:INFO:self.USI: b39e
2025-03-29 16:04:56,734:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 16:04:56,735:INFO:Checking environment
2025-03-29 16:04:56,735:INFO:python_version: 3.10.16
2025-03-29 16:04:56,735:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:04:56,735:INFO:machine: AMD64
2025-03-29 16:04:56,735:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:04:56,740:INFO:Memory: svmem(total=33411727360, available=16854421504, percent=49.6, used=16557305856, free=16854421504)
2025-03-29 16:04:56,740:INFO:Physical Core: 6
2025-03-29 16:04:56,740:INFO:Logical Core: 12
2025-03-29 16:04:56,740:INFO:Checking libraries
2025-03-29 16:04:56,741:INFO:System:
2025-03-29 16:04:56,741:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:04:56,741:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:04:56,741:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:04:56,741:INFO:PyCaret required dependencies:
2025-03-29 16:04:56,741:INFO:                 pip: 25.0.1
2025-03-29 16:04:56,741:INFO:          setuptools: 75.8.2
2025-03-29 16:04:56,741:INFO:             pycaret: 3.3.2
2025-03-29 16:04:56,741:INFO:             IPython: 8.34.0
2025-03-29 16:04:56,741:INFO:          ipywidgets: 8.1.5
2025-03-29 16:04:56,741:INFO:                tqdm: 4.67.1
2025-03-29 16:04:56,741:INFO:               numpy: 1.26.4
2025-03-29 16:04:56,741:INFO:              pandas: 2.1.4
2025-03-29 16:04:56,741:INFO:              jinja2: 3.1.6
2025-03-29 16:04:56,741:INFO:               scipy: 1.11.4
2025-03-29 16:04:56,741:INFO:              joblib: 1.3.2
2025-03-29 16:04:56,741:INFO:             sklearn: 1.4.2
2025-03-29 16:04:56,741:INFO:                pyod: 2.0.2
2025-03-29 16:04:56,741:INFO:            imblearn: 0.13.0
2025-03-29 16:04:56,741:INFO:   category_encoders: 2.7.0
2025-03-29 16:04:56,741:INFO:            lightgbm: 4.6.0
2025-03-29 16:04:56,741:INFO:               numba: 0.61.0
2025-03-29 16:04:56,741:INFO:            requests: 2.32.3
2025-03-29 16:04:56,741:INFO:          matplotlib: 3.10.1
2025-03-29 16:04:56,741:INFO:          scikitplot: 0.3.7
2025-03-29 16:04:56,741:INFO:         yellowbrick: 1.5
2025-03-29 16:04:56,741:INFO:              plotly: 6.0.1
2025-03-29 16:04:56,741:INFO:    plotly-resampler: Not installed
2025-03-29 16:04:56,741:INFO:             kaleido: 0.2.1
2025-03-29 16:04:56,741:INFO:           schemdraw: 0.15
2025-03-29 16:04:56,741:INFO:         statsmodels: 0.14.4
2025-03-29 16:04:56,741:INFO:              sktime: 0.26.0
2025-03-29 16:04:56,741:INFO:               tbats: 1.1.3
2025-03-29 16:04:56,741:INFO:            pmdarima: 2.0.4
2025-03-29 16:04:56,741:INFO:              psutil: 7.0.0
2025-03-29 16:04:56,741:INFO:          markupsafe: 3.0.2
2025-03-29 16:04:56,741:INFO:             pickle5: Not installed
2025-03-29 16:04:56,741:INFO:         cloudpickle: 3.1.1
2025-03-29 16:04:56,741:INFO:         deprecation: 2.1.0
2025-03-29 16:04:56,741:INFO:              xxhash: 3.5.0
2025-03-29 16:04:56,741:INFO:           wurlitzer: 3.1.1
2025-03-29 16:04:56,741:INFO:PyCaret optional dependencies:
2025-03-29 16:04:56,741:INFO:                shap: Not installed
2025-03-29 16:04:56,741:INFO:           interpret: Not installed
2025-03-29 16:04:56,741:INFO:                umap: 0.5.7
2025-03-29 16:04:56,742:INFO:     ydata_profiling: Not installed
2025-03-29 16:04:56,742:INFO:  explainerdashboard: Not installed
2025-03-29 16:04:56,742:INFO:             autoviz: Not installed
2025-03-29 16:04:56,742:INFO:           fairlearn: Not installed
2025-03-29 16:04:56,742:INFO:          deepchecks: Not installed
2025-03-29 16:04:56,742:INFO:             xgboost: Not installed
2025-03-29 16:04:56,742:INFO:            catboost: Not installed
2025-03-29 16:04:56,742:INFO:              kmodes: Not installed
2025-03-29 16:04:56,742:INFO:             mlxtend: Not installed
2025-03-29 16:04:56,742:INFO:       statsforecast: Not installed
2025-03-29 16:04:56,742:INFO:        tune_sklearn: Not installed
2025-03-29 16:04:56,742:INFO:                 ray: Not installed
2025-03-29 16:04:56,742:INFO:            hyperopt: Not installed
2025-03-29 16:04:56,742:INFO:              optuna: Not installed
2025-03-29 16:04:56,742:INFO:               skopt: Not installed
2025-03-29 16:04:56,742:INFO:              mlflow: 2.21.2
2025-03-29 16:04:56,742:INFO:              gradio: Not installed
2025-03-29 16:04:56,742:INFO:             fastapi: 0.115.12
2025-03-29 16:04:56,742:INFO:             uvicorn: 0.34.0
2025-03-29 16:04:56,742:INFO:              m2cgen: Not installed
2025-03-29 16:04:56,742:INFO:           evidently: Not installed
2025-03-29 16:04:56,742:INFO:               fugue: Not installed
2025-03-29 16:04:56,742:INFO:           streamlit: 1.43.2
2025-03-29 16:04:56,742:INFO:             prophet: Not installed
2025-03-29 16:04:56,742:INFO:None
2025-03-29 16:04:56,742:INFO:Set up data.
2025-03-29 16:04:56,751:INFO:Set up folding strategy.
2025-03-29 16:04:56,751:INFO:Set up train/test split.
2025-03-29 16:04:56,757:INFO:Set up index.
2025-03-29 16:04:56,758:INFO:Assigning column types.
2025-03-29 16:04:56,762:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 16:04:56,762:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,764:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,768:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:56,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:56,832:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,835:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,838:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:56,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:56,903:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 16:04:56,905:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,908:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:56,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:56,976:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:04:56,978:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,014:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,041:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 16:04:57,046:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,085:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,118:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,162:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,191:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,191:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 16:04:57,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,300:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,326:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 16:04:57,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:04:57,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,460:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 16:04:57,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:57,597:INFO:Preparing preprocessing pipeline...
2025-03-29 16:04:57,597:INFO:Set up simple imputation.
2025-03-29 16:04:57,601:INFO:Set up encoding of categorical features.
2025-03-29 16:04:57,601:INFO:Set up feature normalization.
2025-03-29 16:04:57,602:INFO:Set up column name cleaning.
2025-03-29 16:04:57,714:INFO:Finished creating preprocessing pipeline.
2025-03-29 16:04:57,718:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour',
                                             'holiday_binary'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-03-29 16:04:57,718:INFO:Creating final display dataframe.
2025-03-29 16:04:57,973:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 9)
4        Transformed data shape       (48204, 29)
5   Transformed train set shape       (33742, 29)
6    Transformed test set shape       (14462, 29)
7              Numeric features                 6
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              b39e
2025-03-29 16:04:58,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:58,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:58,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:58,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:04:58,109:INFO:setup() successfully completed in 1.38s...............
2025-03-29 16:05:00,636:INFO:Initializing compare_models()
2025-03-29 16:05:00,637:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-29 16:05:00,637:INFO:Checking exceptions
2025-03-29 16:05:00,640:INFO:Preparing display monitor
2025-03-29 16:05:00,653:INFO:Initializing Linear Regression
2025-03-29 16:05:00,653:INFO:Total runtime is 0.0 minutes
2025-03-29 16:05:00,656:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:00,656:INFO:Initializing create_model()
2025-03-29 16:05:00,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:00,656:INFO:Checking exceptions
2025-03-29 16:05:00,656:INFO:Importing libraries
2025-03-29 16:05:00,656:INFO:Copying training dataset
2025-03-29 16:05:00,664:INFO:Defining folds
2025-03-29 16:05:00,664:INFO:Declaring metric variables
2025-03-29 16:05:00,666:INFO:Importing untrained model
2025-03-29 16:05:00,669:INFO:Linear Regression Imported successfully
2025-03-29 16:05:00,672:INFO:Starting cross validation
2025-03-29 16:05:00,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:00,988:INFO:Calculating mean and std
2025-03-29 16:05:00,988:INFO:Creating metrics dataframe
2025-03-29 16:05:00,990:INFO:Uploading results into container
2025-03-29 16:05:00,990:INFO:Uploading model into container now
2025-03-29 16:05:00,991:INFO:_master_model_container: 1
2025-03-29 16:05:00,991:INFO:_display_container: 2
2025-03-29 16:05:00,991:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-03-29 16:05:00,991:INFO:create_model() successfully completed......................................
2025-03-29 16:05:01,159:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:01,159:INFO:Creating metrics dataframe
2025-03-29 16:05:01,163:INFO:Initializing Lasso Regression
2025-03-29 16:05:01,163:INFO:Total runtime is 0.008499987920125325 minutes
2025-03-29 16:05:01,165:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:01,165:INFO:Initializing create_model()
2025-03-29 16:05:01,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:01,165:INFO:Checking exceptions
2025-03-29 16:05:01,165:INFO:Importing libraries
2025-03-29 16:05:01,165:INFO:Copying training dataset
2025-03-29 16:05:01,173:INFO:Defining folds
2025-03-29 16:05:01,173:INFO:Declaring metric variables
2025-03-29 16:05:01,175:INFO:Importing untrained model
2025-03-29 16:05:01,177:INFO:Lasso Regression Imported successfully
2025-03-29 16:05:01,180:INFO:Starting cross validation
2025-03-29 16:05:01,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:01,529:INFO:Calculating mean and std
2025-03-29 16:05:01,529:INFO:Creating metrics dataframe
2025-03-29 16:05:01,530:INFO:Uploading results into container
2025-03-29 16:05:01,531:INFO:Uploading model into container now
2025-03-29 16:05:01,531:INFO:_master_model_container: 2
2025-03-29 16:05:01,531:INFO:_display_container: 2
2025-03-29 16:05:01,531:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-03-29 16:05:01,531:INFO:create_model() successfully completed......................................
2025-03-29 16:05:01,696:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:01,696:INFO:Creating metrics dataframe
2025-03-29 16:05:01,701:INFO:Initializing Ridge Regression
2025-03-29 16:05:01,701:INFO:Total runtime is 0.017466668287913004 minutes
2025-03-29 16:05:01,703:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:01,703:INFO:Initializing create_model()
2025-03-29 16:05:01,703:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:01,703:INFO:Checking exceptions
2025-03-29 16:05:01,704:INFO:Importing libraries
2025-03-29 16:05:01,704:INFO:Copying training dataset
2025-03-29 16:05:01,711:INFO:Defining folds
2025-03-29 16:05:01,711:INFO:Declaring metric variables
2025-03-29 16:05:01,713:INFO:Importing untrained model
2025-03-29 16:05:01,716:INFO:Ridge Regression Imported successfully
2025-03-29 16:05:01,720:INFO:Starting cross validation
2025-03-29 16:05:01,721:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:01,995:INFO:Calculating mean and std
2025-03-29 16:05:01,996:INFO:Creating metrics dataframe
2025-03-29 16:05:01,997:INFO:Uploading results into container
2025-03-29 16:05:01,997:INFO:Uploading model into container now
2025-03-29 16:05:01,998:INFO:_master_model_container: 3
2025-03-29 16:05:01,998:INFO:_display_container: 2
2025-03-29 16:05:01,998:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-03-29 16:05:01,998:INFO:create_model() successfully completed......................................
2025-03-29 16:05:02,159:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:02,159:INFO:Creating metrics dataframe
2025-03-29 16:05:02,163:INFO:Initializing Elastic Net
2025-03-29 16:05:02,164:INFO:Total runtime is 0.02518330415089925 minutes
2025-03-29 16:05:02,166:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:02,166:INFO:Initializing create_model()
2025-03-29 16:05:02,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:02,166:INFO:Checking exceptions
2025-03-29 16:05:02,166:INFO:Importing libraries
2025-03-29 16:05:02,166:INFO:Copying training dataset
2025-03-29 16:05:02,173:INFO:Defining folds
2025-03-29 16:05:02,174:INFO:Declaring metric variables
2025-03-29 16:05:02,176:INFO:Importing untrained model
2025-03-29 16:05:02,178:INFO:Elastic Net Imported successfully
2025-03-29 16:05:02,181:INFO:Starting cross validation
2025-03-29 16:05:02,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:02,479:INFO:Calculating mean and std
2025-03-29 16:05:02,480:INFO:Creating metrics dataframe
2025-03-29 16:05:02,481:INFO:Uploading results into container
2025-03-29 16:05:02,482:INFO:Uploading model into container now
2025-03-29 16:05:02,482:INFO:_master_model_container: 4
2025-03-29 16:05:02,482:INFO:_display_container: 2
2025-03-29 16:05:02,483:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-03-29 16:05:02,483:INFO:create_model() successfully completed......................................
2025-03-29 16:05:02,657:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:02,657:INFO:Creating metrics dataframe
2025-03-29 16:05:02,662:INFO:Initializing Least Angle Regression
2025-03-29 16:05:02,662:INFO:Total runtime is 0.03348331848780314 minutes
2025-03-29 16:05:02,664:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:02,664:INFO:Initializing create_model()
2025-03-29 16:05:02,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:02,664:INFO:Checking exceptions
2025-03-29 16:05:02,664:INFO:Importing libraries
2025-03-29 16:05:02,664:INFO:Copying training dataset
2025-03-29 16:05:02,672:INFO:Defining folds
2025-03-29 16:05:02,672:INFO:Declaring metric variables
2025-03-29 16:05:02,675:INFO:Importing untrained model
2025-03-29 16:05:02,677:INFO:Least Angle Regression Imported successfully
2025-03-29 16:05:02,680:INFO:Starting cross validation
2025-03-29 16:05:02,682:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:02,957:INFO:Calculating mean and std
2025-03-29 16:05:02,958:INFO:Creating metrics dataframe
2025-03-29 16:05:02,959:INFO:Uploading results into container
2025-03-29 16:05:02,959:INFO:Uploading model into container now
2025-03-29 16:05:02,959:INFO:_master_model_container: 5
2025-03-29 16:05:02,959:INFO:_display_container: 2
2025-03-29 16:05:02,960:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-03-29 16:05:02,960:INFO:create_model() successfully completed......................................
2025-03-29 16:05:03,118:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:03,118:INFO:Creating metrics dataframe
2025-03-29 16:05:03,123:INFO:Initializing Lasso Least Angle Regression
2025-03-29 16:05:03,123:INFO:Total runtime is 0.041166635354359944 minutes
2025-03-29 16:05:03,125:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:03,125:INFO:Initializing create_model()
2025-03-29 16:05:03,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:03,125:INFO:Checking exceptions
2025-03-29 16:05:03,125:INFO:Importing libraries
2025-03-29 16:05:03,125:INFO:Copying training dataset
2025-03-29 16:05:03,133:INFO:Defining folds
2025-03-29 16:05:03,133:INFO:Declaring metric variables
2025-03-29 16:05:03,135:INFO:Importing untrained model
2025-03-29 16:05:03,137:INFO:Lasso Least Angle Regression Imported successfully
2025-03-29 16:05:03,140:INFO:Starting cross validation
2025-03-29 16:05:03,141:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:03,422:INFO:Calculating mean and std
2025-03-29 16:05:03,423:INFO:Creating metrics dataframe
2025-03-29 16:05:03,424:INFO:Uploading results into container
2025-03-29 16:05:03,424:INFO:Uploading model into container now
2025-03-29 16:05:03,425:INFO:_master_model_container: 6
2025-03-29 16:05:03,425:INFO:_display_container: 2
2025-03-29 16:05:03,425:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-03-29 16:05:03,425:INFO:create_model() successfully completed......................................
2025-03-29 16:05:03,584:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:03,584:INFO:Creating metrics dataframe
2025-03-29 16:05:03,588:INFO:Initializing Orthogonal Matching Pursuit
2025-03-29 16:05:03,588:INFO:Total runtime is 0.04891666173934937 minutes
2025-03-29 16:05:03,590:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:03,590:INFO:Initializing create_model()
2025-03-29 16:05:03,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:03,591:INFO:Checking exceptions
2025-03-29 16:05:03,591:INFO:Importing libraries
2025-03-29 16:05:03,591:INFO:Copying training dataset
2025-03-29 16:05:03,598:INFO:Defining folds
2025-03-29 16:05:03,598:INFO:Declaring metric variables
2025-03-29 16:05:03,601:INFO:Importing untrained model
2025-03-29 16:05:03,605:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-29 16:05:03,609:INFO:Starting cross validation
2025-03-29 16:05:03,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:03,873:INFO:Calculating mean and std
2025-03-29 16:05:03,874:INFO:Creating metrics dataframe
2025-03-29 16:05:03,875:INFO:Uploading results into container
2025-03-29 16:05:03,875:INFO:Uploading model into container now
2025-03-29 16:05:03,876:INFO:_master_model_container: 7
2025-03-29 16:05:03,876:INFO:_display_container: 2
2025-03-29 16:05:03,876:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-03-29 16:05:03,876:INFO:create_model() successfully completed......................................
2025-03-29 16:05:04,042:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:04,042:INFO:Creating metrics dataframe
2025-03-29 16:05:04,047:INFO:Initializing Bayesian Ridge
2025-03-29 16:05:04,047:INFO:Total runtime is 0.056566834449768066 minutes
2025-03-29 16:05:04,050:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:04,050:INFO:Initializing create_model()
2025-03-29 16:05:04,050:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:04,050:INFO:Checking exceptions
2025-03-29 16:05:04,050:INFO:Importing libraries
2025-03-29 16:05:04,050:INFO:Copying training dataset
2025-03-29 16:05:04,057:INFO:Defining folds
2025-03-29 16:05:04,058:INFO:Declaring metric variables
2025-03-29 16:05:04,060:INFO:Importing untrained model
2025-03-29 16:05:04,062:INFO:Bayesian Ridge Imported successfully
2025-03-29 16:05:04,065:INFO:Starting cross validation
2025-03-29 16:05:04,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:04,381:INFO:Calculating mean and std
2025-03-29 16:05:04,382:INFO:Creating metrics dataframe
2025-03-29 16:05:04,384:INFO:Uploading results into container
2025-03-29 16:05:04,384:INFO:Uploading model into container now
2025-03-29 16:05:04,385:INFO:_master_model_container: 8
2025-03-29 16:05:04,385:INFO:_display_container: 2
2025-03-29 16:05:04,385:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-03-29 16:05:04,385:INFO:create_model() successfully completed......................................
2025-03-29 16:05:04,547:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:04,547:INFO:Creating metrics dataframe
2025-03-29 16:05:04,553:INFO:Initializing Passive Aggressive Regressor
2025-03-29 16:05:04,553:INFO:Total runtime is 0.06499999364217122 minutes
2025-03-29 16:05:04,555:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:04,555:INFO:Initializing create_model()
2025-03-29 16:05:04,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:04,555:INFO:Checking exceptions
2025-03-29 16:05:04,555:INFO:Importing libraries
2025-03-29 16:05:04,555:INFO:Copying training dataset
2025-03-29 16:05:04,563:INFO:Defining folds
2025-03-29 16:05:04,563:INFO:Declaring metric variables
2025-03-29 16:05:04,565:INFO:Importing untrained model
2025-03-29 16:05:04,568:INFO:Passive Aggressive Regressor Imported successfully
2025-03-29 16:05:04,571:INFO:Starting cross validation
2025-03-29 16:05:04,573:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:04,937:INFO:Calculating mean and std
2025-03-29 16:05:04,938:INFO:Creating metrics dataframe
2025-03-29 16:05:04,939:INFO:Uploading results into container
2025-03-29 16:05:04,939:INFO:Uploading model into container now
2025-03-29 16:05:04,940:INFO:_master_model_container: 9
2025-03-29 16:05:04,940:INFO:_display_container: 2
2025-03-29 16:05:04,940:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:05:04,940:INFO:create_model() successfully completed......................................
2025-03-29 16:05:05,099:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:05,099:INFO:Creating metrics dataframe
2025-03-29 16:05:05,105:INFO:Initializing Huber Regressor
2025-03-29 16:05:05,105:INFO:Total runtime is 0.07419999043146769 minutes
2025-03-29 16:05:05,107:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:05,107:INFO:Initializing create_model()
2025-03-29 16:05:05,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:05,107:INFO:Checking exceptions
2025-03-29 16:05:05,107:INFO:Importing libraries
2025-03-29 16:05:05,107:INFO:Copying training dataset
2025-03-29 16:05:05,115:INFO:Defining folds
2025-03-29 16:05:05,115:INFO:Declaring metric variables
2025-03-29 16:05:05,117:INFO:Importing untrained model
2025-03-29 16:05:05,119:INFO:Huber Regressor Imported successfully
2025-03-29 16:05:05,123:INFO:Starting cross validation
2025-03-29 16:05:05,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:05,696:INFO:Calculating mean and std
2025-03-29 16:05:05,697:INFO:Creating metrics dataframe
2025-03-29 16:05:05,698:INFO:Uploading results into container
2025-03-29 16:05:05,699:INFO:Uploading model into container now
2025-03-29 16:05:05,699:INFO:_master_model_container: 10
2025-03-29 16:05:05,699:INFO:_display_container: 2
2025-03-29 16:05:05,699:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-03-29 16:05:05,700:INFO:create_model() successfully completed......................................
2025-03-29 16:05:05,859:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:05,859:INFO:Creating metrics dataframe
2025-03-29 16:05:05,864:INFO:Initializing K Neighbors Regressor
2025-03-29 16:05:05,864:INFO:Total runtime is 0.08685160875320434 minutes
2025-03-29 16:05:05,867:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:05,867:INFO:Initializing create_model()
2025-03-29 16:05:05,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:05,867:INFO:Checking exceptions
2025-03-29 16:05:05,867:INFO:Importing libraries
2025-03-29 16:05:05,867:INFO:Copying training dataset
2025-03-29 16:05:05,874:INFO:Defining folds
2025-03-29 16:05:05,874:INFO:Declaring metric variables
2025-03-29 16:05:05,876:INFO:Importing untrained model
2025-03-29 16:05:05,879:INFO:K Neighbors Regressor Imported successfully
2025-03-29 16:05:05,882:INFO:Starting cross validation
2025-03-29 16:05:05,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:06,668:INFO:Calculating mean and std
2025-03-29 16:05:06,669:INFO:Creating metrics dataframe
2025-03-29 16:05:06,670:INFO:Uploading results into container
2025-03-29 16:05:06,670:INFO:Uploading model into container now
2025-03-29 16:05:06,671:INFO:_master_model_container: 11
2025-03-29 16:05:06,671:INFO:_display_container: 2
2025-03-29 16:05:06,671:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-03-29 16:05:06,671:INFO:create_model() successfully completed......................................
2025-03-29 16:05:06,836:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:06,836:INFO:Creating metrics dataframe
2025-03-29 16:05:06,841:INFO:Initializing Decision Tree Regressor
2025-03-29 16:05:06,842:INFO:Total runtime is 0.10315165917078653 minutes
2025-03-29 16:05:06,844:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:06,844:INFO:Initializing create_model()
2025-03-29 16:05:06,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:06,844:INFO:Checking exceptions
2025-03-29 16:05:06,844:INFO:Importing libraries
2025-03-29 16:05:06,844:INFO:Copying training dataset
2025-03-29 16:05:06,852:INFO:Defining folds
2025-03-29 16:05:06,853:INFO:Declaring metric variables
2025-03-29 16:05:06,855:INFO:Importing untrained model
2025-03-29 16:05:06,857:INFO:Decision Tree Regressor Imported successfully
2025-03-29 16:05:06,861:INFO:Starting cross validation
2025-03-29 16:05:06,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:07,229:INFO:Calculating mean and std
2025-03-29 16:05:07,230:INFO:Creating metrics dataframe
2025-03-29 16:05:07,231:INFO:Uploading results into container
2025-03-29 16:05:07,232:INFO:Uploading model into container now
2025-03-29 16:05:07,232:INFO:_master_model_container: 12
2025-03-29 16:05:07,232:INFO:_display_container: 2
2025-03-29 16:05:07,233:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-03-29 16:05:07,233:INFO:create_model() successfully completed......................................
2025-03-29 16:05:07,395:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:07,395:INFO:Creating metrics dataframe
2025-03-29 16:05:07,401:INFO:Initializing Random Forest Regressor
2025-03-29 16:05:07,401:INFO:Total runtime is 0.11246830622355142 minutes
2025-03-29 16:05:07,403:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:07,403:INFO:Initializing create_model()
2025-03-29 16:05:07,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:07,403:INFO:Checking exceptions
2025-03-29 16:05:07,403:INFO:Importing libraries
2025-03-29 16:05:07,403:INFO:Copying training dataset
2025-03-29 16:05:07,411:INFO:Defining folds
2025-03-29 16:05:07,411:INFO:Declaring metric variables
2025-03-29 16:05:07,414:INFO:Importing untrained model
2025-03-29 16:05:07,416:INFO:Random Forest Regressor Imported successfully
2025-03-29 16:05:07,420:INFO:Starting cross validation
2025-03-29 16:05:07,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:13,804:INFO:Calculating mean and std
2025-03-29 16:05:13,805:INFO:Creating metrics dataframe
2025-03-29 16:05:13,807:INFO:Uploading results into container
2025-03-29 16:05:13,807:INFO:Uploading model into container now
2025-03-29 16:05:13,808:INFO:_master_model_container: 13
2025-03-29 16:05:13,808:INFO:_display_container: 2
2025-03-29 16:05:13,808:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-03-29 16:05:13,808:INFO:create_model() successfully completed......................................
2025-03-29 16:05:14,001:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:14,001:INFO:Creating metrics dataframe
2025-03-29 16:05:14,008:INFO:Initializing Extra Trees Regressor
2025-03-29 16:05:14,008:INFO:Total runtime is 0.22258102099100746 minutes
2025-03-29 16:05:14,011:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:14,011:INFO:Initializing create_model()
2025-03-29 16:05:14,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:14,012:INFO:Checking exceptions
2025-03-29 16:05:14,012:INFO:Importing libraries
2025-03-29 16:05:14,012:INFO:Copying training dataset
2025-03-29 16:05:14,021:INFO:Defining folds
2025-03-29 16:05:14,022:INFO:Declaring metric variables
2025-03-29 16:05:14,025:INFO:Importing untrained model
2025-03-29 16:05:14,029:INFO:Extra Trees Regressor Imported successfully
2025-03-29 16:05:14,036:INFO:Starting cross validation
2025-03-29 16:05:14,038:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:18,199:INFO:Calculating mean and std
2025-03-29 16:05:18,200:INFO:Creating metrics dataframe
2025-03-29 16:05:18,202:INFO:Uploading results into container
2025-03-29 16:05:18,202:INFO:Uploading model into container now
2025-03-29 16:05:18,202:INFO:_master_model_container: 14
2025-03-29 16:05:18,203:INFO:_display_container: 2
2025-03-29 16:05:18,203:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-03-29 16:05:18,203:INFO:create_model() successfully completed......................................
2025-03-29 16:05:18,379:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:18,379:INFO:Creating metrics dataframe
2025-03-29 16:05:18,386:INFO:Initializing AdaBoost Regressor
2025-03-29 16:05:18,386:INFO:Total runtime is 0.29554771184921264 minutes
2025-03-29 16:05:18,388:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:18,388:INFO:Initializing create_model()
2025-03-29 16:05:18,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:18,388:INFO:Checking exceptions
2025-03-29 16:05:18,388:INFO:Importing libraries
2025-03-29 16:05:18,388:INFO:Copying training dataset
2025-03-29 16:05:18,397:INFO:Defining folds
2025-03-29 16:05:18,397:INFO:Declaring metric variables
2025-03-29 16:05:18,401:INFO:Importing untrained model
2025-03-29 16:05:18,403:INFO:AdaBoost Regressor Imported successfully
2025-03-29 16:05:18,408:INFO:Starting cross validation
2025-03-29 16:05:18,410:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:19,426:INFO:Calculating mean and std
2025-03-29 16:05:19,427:INFO:Creating metrics dataframe
2025-03-29 16:05:19,429:INFO:Uploading results into container
2025-03-29 16:05:19,429:INFO:Uploading model into container now
2025-03-29 16:05:19,429:INFO:_master_model_container: 15
2025-03-29 16:05:19,430:INFO:_display_container: 2
2025-03-29 16:05:19,430:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-03-29 16:05:19,430:INFO:create_model() successfully completed......................................
2025-03-29 16:05:19,595:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:19,595:INFO:Creating metrics dataframe
2025-03-29 16:05:19,602:INFO:Initializing Gradient Boosting Regressor
2025-03-29 16:05:19,602:INFO:Total runtime is 0.31581435998280843 minutes
2025-03-29 16:05:19,604:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:19,605:INFO:Initializing create_model()
2025-03-29 16:05:19,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:19,605:INFO:Checking exceptions
2025-03-29 16:05:19,605:INFO:Importing libraries
2025-03-29 16:05:19,605:INFO:Copying training dataset
2025-03-29 16:05:19,613:INFO:Defining folds
2025-03-29 16:05:19,613:INFO:Declaring metric variables
2025-03-29 16:05:19,616:INFO:Importing untrained model
2025-03-29 16:05:19,619:INFO:Gradient Boosting Regressor Imported successfully
2025-03-29 16:05:19,623:INFO:Starting cross validation
2025-03-29 16:05:19,625:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:21,671:INFO:Calculating mean and std
2025-03-29 16:05:21,672:INFO:Creating metrics dataframe
2025-03-29 16:05:21,673:INFO:Uploading results into container
2025-03-29 16:05:21,673:INFO:Uploading model into container now
2025-03-29 16:05:21,673:INFO:_master_model_container: 16
2025-03-29 16:05:21,674:INFO:_display_container: 2
2025-03-29 16:05:21,674:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-29 16:05:21,674:INFO:create_model() successfully completed......................................
2025-03-29 16:05:21,829:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:21,829:INFO:Creating metrics dataframe
2025-03-29 16:05:21,836:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 16:05:21,836:INFO:Total runtime is 0.3530554374059041 minutes
2025-03-29 16:05:21,838:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:21,839:INFO:Initializing create_model()
2025-03-29 16:05:21,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:21,839:INFO:Checking exceptions
2025-03-29 16:05:21,839:INFO:Importing libraries
2025-03-29 16:05:21,839:INFO:Copying training dataset
2025-03-29 16:05:21,846:INFO:Defining folds
2025-03-29 16:05:21,846:INFO:Declaring metric variables
2025-03-29 16:05:21,849:INFO:Importing untrained model
2025-03-29 16:05:21,852:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:05:21,856:INFO:Starting cross validation
2025-03-29 16:05:21,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:22,699:INFO:Calculating mean and std
2025-03-29 16:05:22,700:INFO:Creating metrics dataframe
2025-03-29 16:05:22,701:INFO:Uploading results into container
2025-03-29 16:05:22,702:INFO:Uploading model into container now
2025-03-29 16:05:22,702:INFO:_master_model_container: 17
2025-03-29 16:05:22,702:INFO:_display_container: 2
2025-03-29 16:05:22,703:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:05:22,703:INFO:create_model() successfully completed......................................
2025-03-29 16:05:22,880:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:22,880:INFO:Creating metrics dataframe
2025-03-29 16:05:22,888:INFO:Initializing Dummy Regressor
2025-03-29 16:05:22,889:INFO:Total runtime is 0.37060545285542806 minutes
2025-03-29 16:05:22,891:INFO:SubProcess create_model() called ==================================
2025-03-29 16:05:22,891:INFO:Initializing create_model()
2025-03-29 16:05:22,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E922BB6200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:22,891:INFO:Checking exceptions
2025-03-29 16:05:22,891:INFO:Importing libraries
2025-03-29 16:05:22,891:INFO:Copying training dataset
2025-03-29 16:05:22,899:INFO:Defining folds
2025-03-29 16:05:22,899:INFO:Declaring metric variables
2025-03-29 16:05:22,902:INFO:Importing untrained model
2025-03-29 16:05:22,904:INFO:Dummy Regressor Imported successfully
2025-03-29 16:05:22,908:INFO:Starting cross validation
2025-03-29 16:05:22,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:05:23,167:INFO:Calculating mean and std
2025-03-29 16:05:23,168:INFO:Creating metrics dataframe
2025-03-29 16:05:23,169:INFO:Uploading results into container
2025-03-29 16:05:23,169:INFO:Uploading model into container now
2025-03-29 16:05:23,169:INFO:_master_model_container: 18
2025-03-29 16:05:23,169:INFO:_display_container: 2
2025-03-29 16:05:23,170:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-03-29 16:05:23,170:INFO:create_model() successfully completed......................................
2025-03-29 16:05:23,321:INFO:SubProcess create_model() end ==================================
2025-03-29 16:05:23,321:INFO:Creating metrics dataframe
2025-03-29 16:05:23,328:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-29 16:05:23,335:INFO:Initializing create_model()
2025-03-29 16:05:23,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E91F650340>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:05:23,335:INFO:Checking exceptions
2025-03-29 16:05:23,336:INFO:Importing libraries
2025-03-29 16:05:23,336:INFO:Copying training dataset
2025-03-29 16:05:23,343:INFO:Defining folds
2025-03-29 16:05:23,343:INFO:Declaring metric variables
2025-03-29 16:05:23,343:INFO:Importing untrained model
2025-03-29 16:05:23,343:INFO:Declaring custom model
2025-03-29 16:05:23,344:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:05:23,345:INFO:Cross validation set to False
2025-03-29 16:05:23,345:INFO:Fitting Model
2025-03-29 16:05:23,441:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:05:23,443:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.
2025-03-29 16:05:23,443:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:05:23,443:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:05:23,443:INFO:[LightGBM] [Info] Total Bins 578
2025-03-29 16:05:23,443:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 16
2025-03-29 16:05:23,444:INFO:[LightGBM] [Info] Start training from score 3248.074833
2025-03-29 16:05:23,488:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:05:23,488:INFO:create_model() successfully completed......................................
2025-03-29 16:05:23,678:INFO:_master_model_container: 18
2025-03-29 16:05:23,678:INFO:_display_container: 2
2025-03-29 16:05:23,679:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:05:23,679:INFO:compare_models() successfully completed......................................
2025-03-29 16:06:10,703:INFO:PyCaret RegressionExperiment
2025-03-29 16:06:10,704:INFO:Logging name: reg-default-name
2025-03-29 16:06:10,704:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 16:06:10,704:INFO:version 3.3.2
2025-03-29 16:06:10,704:INFO:Initializing setup()
2025-03-29 16:06:10,704:INFO:self.USI: 26d2
2025-03-29 16:06:10,704:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 16:06:10,704:INFO:Checking environment
2025-03-29 16:06:10,704:INFO:python_version: 3.10.16
2025-03-29 16:06:10,704:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:06:10,705:INFO:machine: AMD64
2025-03-29 16:06:10,705:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:06:10,709:INFO:Memory: svmem(total=33411727360, available=17001394176, percent=49.1, used=16410333184, free=17001394176)
2025-03-29 16:06:10,709:INFO:Physical Core: 6
2025-03-29 16:06:10,709:INFO:Logical Core: 12
2025-03-29 16:06:10,709:INFO:Checking libraries
2025-03-29 16:06:10,709:INFO:System:
2025-03-29 16:06:10,709:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:06:10,709:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:06:10,709:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:06:10,709:INFO:PyCaret required dependencies:
2025-03-29 16:06:10,709:INFO:                 pip: 25.0.1
2025-03-29 16:06:10,709:INFO:          setuptools: 75.8.2
2025-03-29 16:06:10,709:INFO:             pycaret: 3.3.2
2025-03-29 16:06:10,709:INFO:             IPython: 8.34.0
2025-03-29 16:06:10,709:INFO:          ipywidgets: 8.1.5
2025-03-29 16:06:10,709:INFO:                tqdm: 4.67.1
2025-03-29 16:06:10,709:INFO:               numpy: 1.26.4
2025-03-29 16:06:10,709:INFO:              pandas: 2.1.4
2025-03-29 16:06:10,709:INFO:              jinja2: 3.1.6
2025-03-29 16:06:10,709:INFO:               scipy: 1.11.4
2025-03-29 16:06:10,709:INFO:              joblib: 1.3.2
2025-03-29 16:06:10,709:INFO:             sklearn: 1.4.2
2025-03-29 16:06:10,709:INFO:                pyod: 2.0.2
2025-03-29 16:06:10,709:INFO:            imblearn: 0.13.0
2025-03-29 16:06:10,709:INFO:   category_encoders: 2.7.0
2025-03-29 16:06:10,709:INFO:            lightgbm: 4.6.0
2025-03-29 16:06:10,709:INFO:               numba: 0.61.0
2025-03-29 16:06:10,709:INFO:            requests: 2.32.3
2025-03-29 16:06:10,709:INFO:          matplotlib: 3.10.1
2025-03-29 16:06:10,709:INFO:          scikitplot: 0.3.7
2025-03-29 16:06:10,709:INFO:         yellowbrick: 1.5
2025-03-29 16:06:10,709:INFO:              plotly: 6.0.1
2025-03-29 16:06:10,709:INFO:    plotly-resampler: Not installed
2025-03-29 16:06:10,710:INFO:             kaleido: 0.2.1
2025-03-29 16:06:10,710:INFO:           schemdraw: 0.15
2025-03-29 16:06:10,710:INFO:         statsmodels: 0.14.4
2025-03-29 16:06:10,710:INFO:              sktime: 0.26.0
2025-03-29 16:06:10,710:INFO:               tbats: 1.1.3
2025-03-29 16:06:10,710:INFO:            pmdarima: 2.0.4
2025-03-29 16:06:10,710:INFO:              psutil: 7.0.0
2025-03-29 16:06:10,710:INFO:          markupsafe: 3.0.2
2025-03-29 16:06:10,710:INFO:             pickle5: Not installed
2025-03-29 16:06:10,710:INFO:         cloudpickle: 3.1.1
2025-03-29 16:06:10,710:INFO:         deprecation: 2.1.0
2025-03-29 16:06:10,710:INFO:              xxhash: 3.5.0
2025-03-29 16:06:10,710:INFO:           wurlitzer: 3.1.1
2025-03-29 16:06:10,710:INFO:PyCaret optional dependencies:
2025-03-29 16:06:10,710:INFO:                shap: Not installed
2025-03-29 16:06:10,710:INFO:           interpret: Not installed
2025-03-29 16:06:10,710:INFO:                umap: 0.5.7
2025-03-29 16:06:10,710:INFO:     ydata_profiling: Not installed
2025-03-29 16:06:10,710:INFO:  explainerdashboard: Not installed
2025-03-29 16:06:10,710:INFO:             autoviz: Not installed
2025-03-29 16:06:10,710:INFO:           fairlearn: Not installed
2025-03-29 16:06:10,710:INFO:          deepchecks: Not installed
2025-03-29 16:06:10,710:INFO:             xgboost: Not installed
2025-03-29 16:06:10,710:INFO:            catboost: Not installed
2025-03-29 16:06:10,710:INFO:              kmodes: Not installed
2025-03-29 16:06:10,710:INFO:             mlxtend: Not installed
2025-03-29 16:06:10,710:INFO:       statsforecast: Not installed
2025-03-29 16:06:10,710:INFO:        tune_sklearn: Not installed
2025-03-29 16:06:10,710:INFO:                 ray: Not installed
2025-03-29 16:06:10,710:INFO:            hyperopt: Not installed
2025-03-29 16:06:10,710:INFO:              optuna: Not installed
2025-03-29 16:06:10,710:INFO:               skopt: Not installed
2025-03-29 16:06:10,710:INFO:              mlflow: 2.21.2
2025-03-29 16:06:10,710:INFO:              gradio: Not installed
2025-03-29 16:06:10,710:INFO:             fastapi: 0.115.12
2025-03-29 16:06:10,710:INFO:             uvicorn: 0.34.0
2025-03-29 16:06:10,710:INFO:              m2cgen: Not installed
2025-03-29 16:06:10,710:INFO:           evidently: Not installed
2025-03-29 16:06:10,710:INFO:               fugue: Not installed
2025-03-29 16:06:10,710:INFO:           streamlit: 1.43.2
2025-03-29 16:06:10,710:INFO:             prophet: Not installed
2025-03-29 16:06:10,710:INFO:None
2025-03-29 16:06:10,710:INFO:Set up data.
2025-03-29 16:06:10,717:INFO:Set up folding strategy.
2025-03-29 16:06:10,717:INFO:Set up train/test split.
2025-03-29 16:06:10,722:INFO:Set up index.
2025-03-29 16:06:10,722:INFO:Assigning column types.
2025-03-29 16:06:10,727:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 16:06:10,727:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,730:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,733:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,799:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:10,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:10,800:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,803:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,806:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,844:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,871:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:10,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:10,872:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 16:06:10,874:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,877:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,943:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:10,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:10,946:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,949:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:06:10,988:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,017:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 16:06:11,022:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,099:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,174:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,175:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 16:06:11,219:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,319:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 16:06:11,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,427:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:06:11,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,452:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 16:06:11,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:11,589:INFO:Preparing preprocessing pipeline...
2025-03-29 16:06:11,589:INFO:Set up simple imputation.
2025-03-29 16:06:11,593:INFO:Set up encoding of ordinal features.
2025-03-29 16:06:11,594:INFO:Set up encoding of categorical features.
2025-03-29 16:06:11,594:INFO:Set up feature normalization.
2025-03-29 16:06:11,595:INFO:Set up column name cleaning.
2025-03-29 16:06:11,696:INFO:Finished creating preprocessing pipeline.
2025-03-29 16:06:11,710:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_i...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-03-29 16:06:11,710:INFO:Creating final display dataframe.
2025-03-29 16:06:11,933:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 18)
5   Transformed train set shape       (33742, 18)
6    Transformed test set shape       (14462, 18)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              26d2
2025-03-29 16:06:12,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:12,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:12,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:12,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:06:12,071:INFO:setup() successfully completed in 1.37s...............
2025-03-29 16:06:14,864:INFO:Initializing get_config()
2025-03-29 16:06:14,865:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, variable=X_train)
2025-03-29 16:06:14,865:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-03-29 16:06:14,865:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-03-29 16:06:14,872:INFO:Variable:  returned as        holiday        temp  rain_1h  snow_1h  clouds_all weather_main  \
5068         0  271.880005      0.0      0.0          90         Mist   
8455         0  290.549988      0.0      0.0          90       Clouds   
34864        0  284.339996      0.0      0.0           1        Clear   
1526         0  264.839996      0.0      0.0          40       Clouds   
6499         0  286.989990      0.0      0.0          90      Drizzle   
...        ...         ...      ...      ...         ...          ...   
7763         0  305.880005      0.0      0.0           0        Clear   
15377        0  298.799988      0.0      0.0          44       Clouds   
17730        0  282.170013      0.0      0.0           1         Mist   
28030        0  280.420013      0.0      0.0           1        Clear   
15725        0  290.320007      0.0      0.0           1        Clear   

       Rush Hour  
5068           0  
8455           0  
34864          0  
1526           0  
6499           0  
...          ...  
7763           0  
15377          0  
17730          0  
28030          0  
15725          0  

[33742 rows x 7 columns]
2025-03-29 16:06:14,872:INFO:get_config() successfully completed......................................
2025-03-29 16:06:15,748:INFO:Initializing compare_models()
2025-03-29 16:06:15,748:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-29 16:06:15,748:INFO:Checking exceptions
2025-03-29 16:06:15,753:INFO:Preparing display monitor
2025-03-29 16:06:15,771:INFO:Initializing Linear Regression
2025-03-29 16:06:15,771:INFO:Total runtime is 0.0 minutes
2025-03-29 16:06:15,773:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:15,773:INFO:Initializing create_model()
2025-03-29 16:06:15,774:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:15,774:INFO:Checking exceptions
2025-03-29 16:06:15,774:INFO:Importing libraries
2025-03-29 16:06:15,774:INFO:Copying training dataset
2025-03-29 16:06:15,782:INFO:Defining folds
2025-03-29 16:06:15,782:INFO:Declaring metric variables
2025-03-29 16:06:15,785:INFO:Importing untrained model
2025-03-29 16:06:15,787:INFO:Linear Regression Imported successfully
2025-03-29 16:06:15,792:INFO:Starting cross validation
2025-03-29 16:06:15,793:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:16,037:INFO:Calculating mean and std
2025-03-29 16:06:16,037:INFO:Creating metrics dataframe
2025-03-29 16:06:16,038:INFO:Uploading results into container
2025-03-29 16:06:16,038:INFO:Uploading model into container now
2025-03-29 16:06:16,039:INFO:_master_model_container: 1
2025-03-29 16:06:16,039:INFO:_display_container: 2
2025-03-29 16:06:16,039:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-03-29 16:06:16,039:INFO:create_model() successfully completed......................................
2025-03-29 16:06:16,203:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:16,203:INFO:Creating metrics dataframe
2025-03-29 16:06:16,207:INFO:Initializing Lasso Regression
2025-03-29 16:06:16,207:INFO:Total runtime is 0.007266771793365478 minutes
2025-03-29 16:06:16,209:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:16,209:INFO:Initializing create_model()
2025-03-29 16:06:16,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:16,209:INFO:Checking exceptions
2025-03-29 16:06:16,209:INFO:Importing libraries
2025-03-29 16:06:16,209:INFO:Copying training dataset
2025-03-29 16:06:16,217:INFO:Defining folds
2025-03-29 16:06:16,217:INFO:Declaring metric variables
2025-03-29 16:06:16,219:INFO:Importing untrained model
2025-03-29 16:06:16,221:INFO:Lasso Regression Imported successfully
2025-03-29 16:06:16,224:INFO:Starting cross validation
2025-03-29 16:06:16,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:16,455:INFO:Calculating mean and std
2025-03-29 16:06:16,455:INFO:Creating metrics dataframe
2025-03-29 16:06:16,456:INFO:Uploading results into container
2025-03-29 16:06:16,457:INFO:Uploading model into container now
2025-03-29 16:06:16,457:INFO:_master_model_container: 2
2025-03-29 16:06:16,457:INFO:_display_container: 2
2025-03-29 16:06:16,457:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-03-29 16:06:16,457:INFO:create_model() successfully completed......................................
2025-03-29 16:06:16,615:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:16,615:INFO:Creating metrics dataframe
2025-03-29 16:06:16,619:INFO:Initializing Ridge Regression
2025-03-29 16:06:16,619:INFO:Total runtime is 0.014133715629577636 minutes
2025-03-29 16:06:16,621:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:16,621:INFO:Initializing create_model()
2025-03-29 16:06:16,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:16,621:INFO:Checking exceptions
2025-03-29 16:06:16,621:INFO:Importing libraries
2025-03-29 16:06:16,621:INFO:Copying training dataset
2025-03-29 16:06:16,628:INFO:Defining folds
2025-03-29 16:06:16,628:INFO:Declaring metric variables
2025-03-29 16:06:16,630:INFO:Importing untrained model
2025-03-29 16:06:16,632:INFO:Ridge Regression Imported successfully
2025-03-29 16:06:16,635:INFO:Starting cross validation
2025-03-29 16:06:16,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:16,843:INFO:Calculating mean and std
2025-03-29 16:06:16,845:INFO:Creating metrics dataframe
2025-03-29 16:06:16,847:INFO:Uploading results into container
2025-03-29 16:06:16,847:INFO:Uploading model into container now
2025-03-29 16:06:16,847:INFO:_master_model_container: 3
2025-03-29 16:06:16,847:INFO:_display_container: 2
2025-03-29 16:06:16,847:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-03-29 16:06:16,848:INFO:create_model() successfully completed......................................
2025-03-29 16:06:17,002:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:17,002:INFO:Creating metrics dataframe
2025-03-29 16:06:17,006:INFO:Initializing Elastic Net
2025-03-29 16:06:17,006:INFO:Total runtime is 0.02058389186859131 minutes
2025-03-29 16:06:17,008:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:17,008:INFO:Initializing create_model()
2025-03-29 16:06:17,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:17,008:INFO:Checking exceptions
2025-03-29 16:06:17,008:INFO:Importing libraries
2025-03-29 16:06:17,008:INFO:Copying training dataset
2025-03-29 16:06:17,016:INFO:Defining folds
2025-03-29 16:06:17,016:INFO:Declaring metric variables
2025-03-29 16:06:17,019:INFO:Importing untrained model
2025-03-29 16:06:17,021:INFO:Elastic Net Imported successfully
2025-03-29 16:06:17,024:INFO:Starting cross validation
2025-03-29 16:06:17,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:17,231:INFO:Calculating mean and std
2025-03-29 16:06:17,232:INFO:Creating metrics dataframe
2025-03-29 16:06:17,233:INFO:Uploading results into container
2025-03-29 16:06:17,233:INFO:Uploading model into container now
2025-03-29 16:06:17,234:INFO:_master_model_container: 4
2025-03-29 16:06:17,234:INFO:_display_container: 2
2025-03-29 16:06:17,234:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-03-29 16:06:17,234:INFO:create_model() successfully completed......................................
2025-03-29 16:06:17,391:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:17,391:INFO:Creating metrics dataframe
2025-03-29 16:06:17,396:INFO:Initializing Least Angle Regression
2025-03-29 16:06:17,396:INFO:Total runtime is 0.02708388169606527 minutes
2025-03-29 16:06:17,397:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:17,398:INFO:Initializing create_model()
2025-03-29 16:06:17,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:17,398:INFO:Checking exceptions
2025-03-29 16:06:17,398:INFO:Importing libraries
2025-03-29 16:06:17,398:INFO:Copying training dataset
2025-03-29 16:06:17,405:INFO:Defining folds
2025-03-29 16:06:17,405:INFO:Declaring metric variables
2025-03-29 16:06:17,407:INFO:Importing untrained model
2025-03-29 16:06:17,409:INFO:Least Angle Regression Imported successfully
2025-03-29 16:06:17,413:INFO:Starting cross validation
2025-03-29 16:06:17,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:17,617:INFO:Calculating mean and std
2025-03-29 16:06:17,618:INFO:Creating metrics dataframe
2025-03-29 16:06:17,619:INFO:Uploading results into container
2025-03-29 16:06:17,619:INFO:Uploading model into container now
2025-03-29 16:06:17,619:INFO:_master_model_container: 5
2025-03-29 16:06:17,620:INFO:_display_container: 2
2025-03-29 16:06:17,620:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-03-29 16:06:17,620:INFO:create_model() successfully completed......................................
2025-03-29 16:06:17,774:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:17,774:INFO:Creating metrics dataframe
2025-03-29 16:06:17,779:INFO:Initializing Lasso Least Angle Regression
2025-03-29 16:06:17,779:INFO:Total runtime is 0.03346365690231323 minutes
2025-03-29 16:06:17,781:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:17,781:INFO:Initializing create_model()
2025-03-29 16:06:17,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:17,781:INFO:Checking exceptions
2025-03-29 16:06:17,781:INFO:Importing libraries
2025-03-29 16:06:17,781:INFO:Copying training dataset
2025-03-29 16:06:17,789:INFO:Defining folds
2025-03-29 16:06:17,789:INFO:Declaring metric variables
2025-03-29 16:06:17,791:INFO:Importing untrained model
2025-03-29 16:06:17,793:INFO:Lasso Least Angle Regression Imported successfully
2025-03-29 16:06:17,797:INFO:Starting cross validation
2025-03-29 16:06:17,798:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:18,009:INFO:Calculating mean and std
2025-03-29 16:06:18,010:INFO:Creating metrics dataframe
2025-03-29 16:06:18,011:INFO:Uploading results into container
2025-03-29 16:06:18,011:INFO:Uploading model into container now
2025-03-29 16:06:18,012:INFO:_master_model_container: 6
2025-03-29 16:06:18,012:INFO:_display_container: 2
2025-03-29 16:06:18,012:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-03-29 16:06:18,012:INFO:create_model() successfully completed......................................
2025-03-29 16:06:18,165:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:18,165:INFO:Creating metrics dataframe
2025-03-29 16:06:18,170:INFO:Initializing Orthogonal Matching Pursuit
2025-03-29 16:06:18,170:INFO:Total runtime is 0.03997642199198405 minutes
2025-03-29 16:06:18,172:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:18,172:INFO:Initializing create_model()
2025-03-29 16:06:18,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:18,173:INFO:Checking exceptions
2025-03-29 16:06:18,173:INFO:Importing libraries
2025-03-29 16:06:18,173:INFO:Copying training dataset
2025-03-29 16:06:18,180:INFO:Defining folds
2025-03-29 16:06:18,180:INFO:Declaring metric variables
2025-03-29 16:06:18,182:INFO:Importing untrained model
2025-03-29 16:06:18,184:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-29 16:06:18,189:INFO:Starting cross validation
2025-03-29 16:06:18,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:18,393:INFO:Calculating mean and std
2025-03-29 16:06:18,394:INFO:Creating metrics dataframe
2025-03-29 16:06:18,395:INFO:Uploading results into container
2025-03-29 16:06:18,395:INFO:Uploading model into container now
2025-03-29 16:06:18,395:INFO:_master_model_container: 7
2025-03-29 16:06:18,395:INFO:_display_container: 2
2025-03-29 16:06:18,396:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-03-29 16:06:18,396:INFO:create_model() successfully completed......................................
2025-03-29 16:06:18,552:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:18,552:INFO:Creating metrics dataframe
2025-03-29 16:06:18,556:INFO:Initializing Bayesian Ridge
2025-03-29 16:06:18,556:INFO:Total runtime is 0.04642228285471598 minutes
2025-03-29 16:06:18,558:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:18,558:INFO:Initializing create_model()
2025-03-29 16:06:18,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:18,558:INFO:Checking exceptions
2025-03-29 16:06:18,558:INFO:Importing libraries
2025-03-29 16:06:18,558:INFO:Copying training dataset
2025-03-29 16:06:18,566:INFO:Defining folds
2025-03-29 16:06:18,566:INFO:Declaring metric variables
2025-03-29 16:06:18,568:INFO:Importing untrained model
2025-03-29 16:06:18,570:INFO:Bayesian Ridge Imported successfully
2025-03-29 16:06:18,574:INFO:Starting cross validation
2025-03-29 16:06:18,575:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:18,811:INFO:Calculating mean and std
2025-03-29 16:06:18,812:INFO:Creating metrics dataframe
2025-03-29 16:06:18,813:INFO:Uploading results into container
2025-03-29 16:06:18,813:INFO:Uploading model into container now
2025-03-29 16:06:18,814:INFO:_master_model_container: 8
2025-03-29 16:06:18,814:INFO:_display_container: 2
2025-03-29 16:06:18,814:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-03-29 16:06:18,814:INFO:create_model() successfully completed......................................
2025-03-29 16:06:18,975:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:18,975:INFO:Creating metrics dataframe
2025-03-29 16:06:18,980:INFO:Initializing Passive Aggressive Regressor
2025-03-29 16:06:18,980:INFO:Total runtime is 0.053489152590433756 minutes
2025-03-29 16:06:18,982:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:18,982:INFO:Initializing create_model()
2025-03-29 16:06:18,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:18,982:INFO:Checking exceptions
2025-03-29 16:06:18,982:INFO:Importing libraries
2025-03-29 16:06:18,982:INFO:Copying training dataset
2025-03-29 16:06:18,990:INFO:Defining folds
2025-03-29 16:06:18,990:INFO:Declaring metric variables
2025-03-29 16:06:18,992:INFO:Importing untrained model
2025-03-29 16:06:18,994:INFO:Passive Aggressive Regressor Imported successfully
2025-03-29 16:06:18,998:INFO:Starting cross validation
2025-03-29 16:06:18,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:19,279:INFO:Calculating mean and std
2025-03-29 16:06:19,280:INFO:Creating metrics dataframe
2025-03-29 16:06:19,281:INFO:Uploading results into container
2025-03-29 16:06:19,281:INFO:Uploading model into container now
2025-03-29 16:06:19,282:INFO:_master_model_container: 9
2025-03-29 16:06:19,282:INFO:_display_container: 2
2025-03-29 16:06:19,282:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:06:19,282:INFO:create_model() successfully completed......................................
2025-03-29 16:06:19,443:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:19,443:INFO:Creating metrics dataframe
2025-03-29 16:06:19,449:INFO:Initializing Huber Regressor
2025-03-29 16:06:19,449:INFO:Total runtime is 0.06129333972930908 minutes
2025-03-29 16:06:19,451:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:19,451:INFO:Initializing create_model()
2025-03-29 16:06:19,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:19,451:INFO:Checking exceptions
2025-03-29 16:06:19,451:INFO:Importing libraries
2025-03-29 16:06:19,451:INFO:Copying training dataset
2025-03-29 16:06:19,459:INFO:Defining folds
2025-03-29 16:06:19,459:INFO:Declaring metric variables
2025-03-29 16:06:19,461:INFO:Importing untrained model
2025-03-29 16:06:19,463:INFO:Huber Regressor Imported successfully
2025-03-29 16:06:19,468:INFO:Starting cross validation
2025-03-29 16:06:19,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:19,819:INFO:Calculating mean and std
2025-03-29 16:06:19,820:INFO:Creating metrics dataframe
2025-03-29 16:06:19,821:INFO:Uploading results into container
2025-03-29 16:06:19,821:INFO:Uploading model into container now
2025-03-29 16:06:19,821:INFO:_master_model_container: 10
2025-03-29 16:06:19,821:INFO:_display_container: 2
2025-03-29 16:06:19,822:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-03-29 16:06:19,822:INFO:create_model() successfully completed......................................
2025-03-29 16:06:19,982:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:19,982:INFO:Creating metrics dataframe
2025-03-29 16:06:19,988:INFO:Initializing K Neighbors Regressor
2025-03-29 16:06:19,988:INFO:Total runtime is 0.07028456528981526 minutes
2025-03-29 16:06:19,990:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:19,990:INFO:Initializing create_model()
2025-03-29 16:06:19,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:19,990:INFO:Checking exceptions
2025-03-29 16:06:19,990:INFO:Importing libraries
2025-03-29 16:06:19,990:INFO:Copying training dataset
2025-03-29 16:06:19,998:INFO:Defining folds
2025-03-29 16:06:19,998:INFO:Declaring metric variables
2025-03-29 16:06:20,000:INFO:Importing untrained model
2025-03-29 16:06:20,003:INFO:K Neighbors Regressor Imported successfully
2025-03-29 16:06:20,007:INFO:Starting cross validation
2025-03-29 16:06:20,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:20,675:INFO:Calculating mean and std
2025-03-29 16:06:20,676:INFO:Creating metrics dataframe
2025-03-29 16:06:20,677:INFO:Uploading results into container
2025-03-29 16:06:20,678:INFO:Uploading model into container now
2025-03-29 16:06:20,678:INFO:_master_model_container: 11
2025-03-29 16:06:20,678:INFO:_display_container: 2
2025-03-29 16:06:20,678:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-03-29 16:06:20,679:INFO:create_model() successfully completed......................................
2025-03-29 16:06:20,843:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:20,843:INFO:Creating metrics dataframe
2025-03-29 16:06:20,849:INFO:Initializing Decision Tree Regressor
2025-03-29 16:06:20,849:INFO:Total runtime is 0.08463641007741292 minutes
2025-03-29 16:06:20,851:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:20,851:INFO:Initializing create_model()
2025-03-29 16:06:20,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:20,851:INFO:Checking exceptions
2025-03-29 16:06:20,851:INFO:Importing libraries
2025-03-29 16:06:20,851:INFO:Copying training dataset
2025-03-29 16:06:20,861:INFO:Defining folds
2025-03-29 16:06:20,862:INFO:Declaring metric variables
2025-03-29 16:06:20,864:INFO:Importing untrained model
2025-03-29 16:06:20,866:INFO:Decision Tree Regressor Imported successfully
2025-03-29 16:06:20,870:INFO:Starting cross validation
2025-03-29 16:06:20,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:21,170:INFO:Calculating mean and std
2025-03-29 16:06:21,171:INFO:Creating metrics dataframe
2025-03-29 16:06:21,172:INFO:Uploading results into container
2025-03-29 16:06:21,173:INFO:Uploading model into container now
2025-03-29 16:06:21,173:INFO:_master_model_container: 12
2025-03-29 16:06:21,173:INFO:_display_container: 2
2025-03-29 16:06:21,173:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-03-29 16:06:21,174:INFO:create_model() successfully completed......................................
2025-03-29 16:06:21,347:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:21,347:INFO:Creating metrics dataframe
2025-03-29 16:06:21,352:INFO:Initializing Random Forest Regressor
2025-03-29 16:06:21,352:INFO:Total runtime is 0.09301976760228474 minutes
2025-03-29 16:06:21,354:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:21,354:INFO:Initializing create_model()
2025-03-29 16:06:21,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:21,354:INFO:Checking exceptions
2025-03-29 16:06:21,354:INFO:Importing libraries
2025-03-29 16:06:21,354:INFO:Copying training dataset
2025-03-29 16:06:21,361:INFO:Defining folds
2025-03-29 16:06:21,362:INFO:Declaring metric variables
2025-03-29 16:06:21,364:INFO:Importing untrained model
2025-03-29 16:06:21,366:INFO:Random Forest Regressor Imported successfully
2025-03-29 16:06:21,369:INFO:Starting cross validation
2025-03-29 16:06:21,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:27,085:INFO:Calculating mean and std
2025-03-29 16:06:27,086:INFO:Creating metrics dataframe
2025-03-29 16:06:27,087:INFO:Uploading results into container
2025-03-29 16:06:27,088:INFO:Uploading model into container now
2025-03-29 16:06:27,088:INFO:_master_model_container: 13
2025-03-29 16:06:27,088:INFO:_display_container: 2
2025-03-29 16:06:27,088:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-03-29 16:06:27,089:INFO:create_model() successfully completed......................................
2025-03-29 16:06:27,281:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:27,281:INFO:Creating metrics dataframe
2025-03-29 16:06:27,288:INFO:Initializing Extra Trees Regressor
2025-03-29 16:06:27,288:INFO:Total runtime is 0.19194399515787758 minutes
2025-03-29 16:06:27,290:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:27,291:INFO:Initializing create_model()
2025-03-29 16:06:27,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:27,291:INFO:Checking exceptions
2025-03-29 16:06:27,291:INFO:Importing libraries
2025-03-29 16:06:27,291:INFO:Copying training dataset
2025-03-29 16:06:27,298:INFO:Defining folds
2025-03-29 16:06:27,299:INFO:Declaring metric variables
2025-03-29 16:06:27,301:INFO:Importing untrained model
2025-03-29 16:06:27,304:INFO:Extra Trees Regressor Imported successfully
2025-03-29 16:06:27,308:INFO:Starting cross validation
2025-03-29 16:06:27,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:30,676:INFO:Calculating mean and std
2025-03-29 16:06:30,678:INFO:Creating metrics dataframe
2025-03-29 16:06:30,680:INFO:Uploading results into container
2025-03-29 16:06:30,680:INFO:Uploading model into container now
2025-03-29 16:06:30,681:INFO:_master_model_container: 14
2025-03-29 16:06:30,681:INFO:_display_container: 2
2025-03-29 16:06:30,681:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-03-29 16:06:30,682:INFO:create_model() successfully completed......................................
2025-03-29 16:06:30,891:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:30,891:INFO:Creating metrics dataframe
2025-03-29 16:06:30,900:INFO:Initializing AdaBoost Regressor
2025-03-29 16:06:30,900:INFO:Total runtime is 0.2521437923113505 minutes
2025-03-29 16:06:30,903:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:30,904:INFO:Initializing create_model()
2025-03-29 16:06:30,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:30,904:INFO:Checking exceptions
2025-03-29 16:06:30,904:INFO:Importing libraries
2025-03-29 16:06:30,904:INFO:Copying training dataset
2025-03-29 16:06:30,914:INFO:Defining folds
2025-03-29 16:06:30,914:INFO:Declaring metric variables
2025-03-29 16:06:30,917:INFO:Importing untrained model
2025-03-29 16:06:30,920:INFO:AdaBoost Regressor Imported successfully
2025-03-29 16:06:30,926:INFO:Starting cross validation
2025-03-29 16:06:30,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:31,558:INFO:Calculating mean and std
2025-03-29 16:06:31,559:INFO:Creating metrics dataframe
2025-03-29 16:06:31,560:INFO:Uploading results into container
2025-03-29 16:06:31,560:INFO:Uploading model into container now
2025-03-29 16:06:31,560:INFO:_master_model_container: 15
2025-03-29 16:06:31,561:INFO:_display_container: 2
2025-03-29 16:06:31,561:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-03-29 16:06:31,561:INFO:create_model() successfully completed......................................
2025-03-29 16:06:31,729:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:31,730:INFO:Creating metrics dataframe
2025-03-29 16:06:31,736:INFO:Initializing Gradient Boosting Regressor
2025-03-29 16:06:31,736:INFO:Total runtime is 0.26607906023661293 minutes
2025-03-29 16:06:31,739:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:31,739:INFO:Initializing create_model()
2025-03-29 16:06:31,739:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:31,739:INFO:Checking exceptions
2025-03-29 16:06:31,739:INFO:Importing libraries
2025-03-29 16:06:31,739:INFO:Copying training dataset
2025-03-29 16:06:31,747:INFO:Defining folds
2025-03-29 16:06:31,747:INFO:Declaring metric variables
2025-03-29 16:06:31,750:INFO:Importing untrained model
2025-03-29 16:06:31,752:INFO:Gradient Boosting Regressor Imported successfully
2025-03-29 16:06:31,757:INFO:Starting cross validation
2025-03-29 16:06:31,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:33,379:INFO:Calculating mean and std
2025-03-29 16:06:33,380:INFO:Creating metrics dataframe
2025-03-29 16:06:33,381:INFO:Uploading results into container
2025-03-29 16:06:33,381:INFO:Uploading model into container now
2025-03-29 16:06:33,382:INFO:_master_model_container: 16
2025-03-29 16:06:33,382:INFO:_display_container: 2
2025-03-29 16:06:33,382:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-29 16:06:33,382:INFO:create_model() successfully completed......................................
2025-03-29 16:06:33,538:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:33,538:INFO:Creating metrics dataframe
2025-03-29 16:06:33,544:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 16:06:33,544:INFO:Total runtime is 0.2962167660395304 minutes
2025-03-29 16:06:33,546:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:33,546:INFO:Initializing create_model()
2025-03-29 16:06:33,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:33,547:INFO:Checking exceptions
2025-03-29 16:06:33,547:INFO:Importing libraries
2025-03-29 16:06:33,547:INFO:Copying training dataset
2025-03-29 16:06:33,555:INFO:Defining folds
2025-03-29 16:06:33,555:INFO:Declaring metric variables
2025-03-29 16:06:33,558:INFO:Importing untrained model
2025-03-29 16:06:33,560:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:06:33,564:INFO:Starting cross validation
2025-03-29 16:06:33,566:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:34,358:INFO:Calculating mean and std
2025-03-29 16:06:34,359:INFO:Creating metrics dataframe
2025-03-29 16:06:34,360:INFO:Uploading results into container
2025-03-29 16:06:34,361:INFO:Uploading model into container now
2025-03-29 16:06:34,361:INFO:_master_model_container: 17
2025-03-29 16:06:34,361:INFO:_display_container: 2
2025-03-29 16:06:34,362:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:06:34,362:INFO:create_model() successfully completed......................................
2025-03-29 16:06:34,548:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:34,548:INFO:Creating metrics dataframe
2025-03-29 16:06:34,555:INFO:Initializing Dummy Regressor
2025-03-29 16:06:34,555:INFO:Total runtime is 0.31306677659352616 minutes
2025-03-29 16:06:34,557:INFO:SubProcess create_model() called ==================================
2025-03-29 16:06:34,557:INFO:Initializing create_model()
2025-03-29 16:06:34,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F61A680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:34,557:INFO:Checking exceptions
2025-03-29 16:06:34,557:INFO:Importing libraries
2025-03-29 16:06:34,557:INFO:Copying training dataset
2025-03-29 16:06:34,565:INFO:Defining folds
2025-03-29 16:06:34,565:INFO:Declaring metric variables
2025-03-29 16:06:34,568:INFO:Importing untrained model
2025-03-29 16:06:34,570:INFO:Dummy Regressor Imported successfully
2025-03-29 16:06:34,575:INFO:Starting cross validation
2025-03-29 16:06:34,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:06:34,780:INFO:Calculating mean and std
2025-03-29 16:06:34,781:INFO:Creating metrics dataframe
2025-03-29 16:06:34,782:INFO:Uploading results into container
2025-03-29 16:06:34,782:INFO:Uploading model into container now
2025-03-29 16:06:34,783:INFO:_master_model_container: 18
2025-03-29 16:06:34,783:INFO:_display_container: 2
2025-03-29 16:06:34,783:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-03-29 16:06:34,783:INFO:create_model() successfully completed......................................
2025-03-29 16:06:34,939:INFO:SubProcess create_model() end ==================================
2025-03-29 16:06:34,939:INFO:Creating metrics dataframe
2025-03-29 16:06:34,946:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-29 16:06:34,954:INFO:Initializing create_model()
2025-03-29 16:06:34,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9206AE800>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:06:34,954:INFO:Checking exceptions
2025-03-29 16:06:34,955:INFO:Importing libraries
2025-03-29 16:06:34,955:INFO:Copying training dataset
2025-03-29 16:06:34,962:INFO:Defining folds
2025-03-29 16:06:34,962:INFO:Declaring metric variables
2025-03-29 16:06:34,962:INFO:Importing untrained model
2025-03-29 16:06:34,962:INFO:Declaring custom model
2025-03-29 16:06:34,963:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:06:34,964:INFO:Cross validation set to False
2025-03-29 16:06:34,964:INFO:Fitting Model
2025-03-29 16:06:35,057:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:06:35,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.
2025-03-29 16:06:35,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:06:35,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:06:35,059:INFO:[LightGBM] [Info] Total Bins 575
2025-03-29 16:06:35,059:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 16:06:35,059:INFO:[LightGBM] [Info] Start training from score 3248.074833
2025-03-29 16:06:35,118:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:06:35,118:INFO:create_model() successfully completed......................................
2025-03-29 16:06:35,322:INFO:_master_model_container: 18
2025-03-29 16:06:35,322:INFO:_display_container: 2
2025-03-29 16:06:35,323:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:06:35,323:INFO:compare_models() successfully completed......................................
2025-03-29 16:06:50,682:INFO:PyCaret RegressionExperiment
2025-03-29 16:06:50,682:INFO:Logging name: reg-default-name
2025-03-29 16:06:50,682:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 16:06:50,683:INFO:version 3.3.2
2025-03-29 16:06:50,683:INFO:Initializing setup()
2025-03-29 16:06:50,683:INFO:self.USI: 92a2
2025-03-29 16:06:50,683:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 16:06:50,683:INFO:Checking environment
2025-03-29 16:06:50,684:INFO:python_version: 3.10.16
2025-03-29 16:06:50,684:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:06:50,684:INFO:machine: AMD64
2025-03-29 16:06:50,684:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:06:50,689:INFO:Memory: svmem(total=33411727360, available=16965894144, percent=49.2, used=16445833216, free=16965894144)
2025-03-29 16:06:50,689:INFO:Physical Core: 6
2025-03-29 16:06:50,689:INFO:Logical Core: 12
2025-03-29 16:06:50,689:INFO:Checking libraries
2025-03-29 16:06:50,689:INFO:System:
2025-03-29 16:06:50,689:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:06:50,689:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:06:50,689:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:06:50,689:INFO:PyCaret required dependencies:
2025-03-29 16:06:50,689:INFO:                 pip: 25.0.1
2025-03-29 16:06:50,689:INFO:          setuptools: 75.8.2
2025-03-29 16:06:50,689:INFO:             pycaret: 3.3.2
2025-03-29 16:06:50,689:INFO:             IPython: 8.34.0
2025-03-29 16:06:50,689:INFO:          ipywidgets: 8.1.5
2025-03-29 16:06:50,689:INFO:                tqdm: 4.67.1
2025-03-29 16:06:50,689:INFO:               numpy: 1.26.4
2025-03-29 16:06:50,689:INFO:              pandas: 2.1.4
2025-03-29 16:06:50,689:INFO:              jinja2: 3.1.6
2025-03-29 16:06:50,689:INFO:               scipy: 1.11.4
2025-03-29 16:06:50,689:INFO:              joblib: 1.3.2
2025-03-29 16:06:50,690:INFO:             sklearn: 1.4.2
2025-03-29 16:06:50,690:INFO:                pyod: 2.0.2
2025-03-29 16:06:50,690:INFO:            imblearn: 0.13.0
2025-03-29 16:06:50,690:INFO:   category_encoders: 2.7.0
2025-03-29 16:06:50,690:INFO:            lightgbm: 4.6.0
2025-03-29 16:06:50,690:INFO:               numba: 0.61.0
2025-03-29 16:06:50,690:INFO:            requests: 2.32.3
2025-03-29 16:06:50,690:INFO:          matplotlib: 3.10.1
2025-03-29 16:06:50,690:INFO:          scikitplot: 0.3.7
2025-03-29 16:06:50,690:INFO:         yellowbrick: 1.5
2025-03-29 16:06:50,690:INFO:              plotly: 6.0.1
2025-03-29 16:06:50,690:INFO:    plotly-resampler: Not installed
2025-03-29 16:06:50,690:INFO:             kaleido: 0.2.1
2025-03-29 16:06:50,690:INFO:           schemdraw: 0.15
2025-03-29 16:06:50,690:INFO:         statsmodels: 0.14.4
2025-03-29 16:06:50,690:INFO:              sktime: 0.26.0
2025-03-29 16:06:50,690:INFO:               tbats: 1.1.3
2025-03-29 16:06:50,690:INFO:            pmdarima: 2.0.4
2025-03-29 16:06:50,690:INFO:              psutil: 7.0.0
2025-03-29 16:06:50,690:INFO:          markupsafe: 3.0.2
2025-03-29 16:06:50,690:INFO:             pickle5: Not installed
2025-03-29 16:06:50,690:INFO:         cloudpickle: 3.1.1
2025-03-29 16:06:50,690:INFO:         deprecation: 2.1.0
2025-03-29 16:06:50,690:INFO:              xxhash: 3.5.0
2025-03-29 16:06:50,690:INFO:           wurlitzer: 3.1.1
2025-03-29 16:06:50,690:INFO:PyCaret optional dependencies:
2025-03-29 16:06:50,690:INFO:                shap: Not installed
2025-03-29 16:06:50,690:INFO:           interpret: Not installed
2025-03-29 16:06:50,690:INFO:                umap: 0.5.7
2025-03-29 16:06:50,690:INFO:     ydata_profiling: Not installed
2025-03-29 16:06:50,690:INFO:  explainerdashboard: Not installed
2025-03-29 16:06:50,690:INFO:             autoviz: Not installed
2025-03-29 16:06:50,690:INFO:           fairlearn: Not installed
2025-03-29 16:06:50,690:INFO:          deepchecks: Not installed
2025-03-29 16:06:50,690:INFO:             xgboost: Not installed
2025-03-29 16:06:50,690:INFO:            catboost: Not installed
2025-03-29 16:06:50,690:INFO:              kmodes: Not installed
2025-03-29 16:06:50,690:INFO:             mlxtend: Not installed
2025-03-29 16:06:50,690:INFO:       statsforecast: Not installed
2025-03-29 16:06:50,690:INFO:        tune_sklearn: Not installed
2025-03-29 16:06:50,690:INFO:                 ray: Not installed
2025-03-29 16:06:50,690:INFO:            hyperopt: Not installed
2025-03-29 16:06:50,690:INFO:              optuna: Not installed
2025-03-29 16:06:50,690:INFO:               skopt: Not installed
2025-03-29 16:06:50,690:INFO:              mlflow: 2.21.2
2025-03-29 16:06:50,690:INFO:              gradio: Not installed
2025-03-29 16:06:50,690:INFO:             fastapi: 0.115.12
2025-03-29 16:06:50,690:INFO:             uvicorn: 0.34.0
2025-03-29 16:06:50,691:INFO:              m2cgen: Not installed
2025-03-29 16:06:50,691:INFO:           evidently: Not installed
2025-03-29 16:06:50,691:INFO:               fugue: Not installed
2025-03-29 16:06:50,691:INFO:           streamlit: 1.43.2
2025-03-29 16:06:50,691:INFO:             prophet: Not installed
2025-03-29 16:06:50,691:INFO:None
2025-03-29 16:06:50,691:INFO:Set up data.
2025-03-29 16:06:50,698:INFO:Set up folding strategy.
2025-03-29 16:08:51,144:INFO:PyCaret RegressionExperiment
2025-03-29 16:08:51,144:INFO:Logging name: reg-default-name
2025-03-29 16:08:51,144:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 16:08:51,144:INFO:version 3.3.2
2025-03-29 16:08:51,145:INFO:Initializing setup()
2025-03-29 16:08:51,145:INFO:self.USI: 3a31
2025-03-29 16:08:51,145:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 16:08:51,145:INFO:Checking environment
2025-03-29 16:08:51,145:INFO:python_version: 3.10.16
2025-03-29 16:08:51,145:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:08:51,145:INFO:machine: AMD64
2025-03-29 16:08:51,145:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:08:51,149:INFO:Memory: svmem(total=33411727360, available=16844419072, percent=49.6, used=16567308288, free=16844419072)
2025-03-29 16:08:51,149:INFO:Physical Core: 6
2025-03-29 16:08:51,149:INFO:Logical Core: 12
2025-03-29 16:08:51,149:INFO:Checking libraries
2025-03-29 16:08:51,149:INFO:System:
2025-03-29 16:08:51,149:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:08:51,149:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:08:51,149:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:08:51,149:INFO:PyCaret required dependencies:
2025-03-29 16:08:51,150:INFO:                 pip: 25.0.1
2025-03-29 16:08:51,150:INFO:          setuptools: 75.8.2
2025-03-29 16:08:51,150:INFO:             pycaret: 3.3.2
2025-03-29 16:08:51,150:INFO:             IPython: 8.34.0
2025-03-29 16:08:51,150:INFO:          ipywidgets: 8.1.5
2025-03-29 16:08:51,150:INFO:                tqdm: 4.67.1
2025-03-29 16:08:51,150:INFO:               numpy: 1.26.4
2025-03-29 16:08:51,150:INFO:              pandas: 2.1.4
2025-03-29 16:08:51,150:INFO:              jinja2: 3.1.6
2025-03-29 16:08:51,150:INFO:               scipy: 1.11.4
2025-03-29 16:08:51,150:INFO:              joblib: 1.3.2
2025-03-29 16:08:51,151:INFO:             sklearn: 1.4.2
2025-03-29 16:08:51,151:INFO:                pyod: 2.0.2
2025-03-29 16:08:51,151:INFO:            imblearn: 0.13.0
2025-03-29 16:08:51,151:INFO:   category_encoders: 2.7.0
2025-03-29 16:08:51,151:INFO:            lightgbm: 4.6.0
2025-03-29 16:08:51,151:INFO:               numba: 0.61.0
2025-03-29 16:08:51,151:INFO:            requests: 2.32.3
2025-03-29 16:08:51,151:INFO:          matplotlib: 3.10.1
2025-03-29 16:08:51,151:INFO:          scikitplot: 0.3.7
2025-03-29 16:08:51,151:INFO:         yellowbrick: 1.5
2025-03-29 16:08:51,151:INFO:              plotly: 6.0.1
2025-03-29 16:08:51,151:INFO:    plotly-resampler: Not installed
2025-03-29 16:08:51,152:INFO:             kaleido: 0.2.1
2025-03-29 16:08:51,152:INFO:           schemdraw: 0.15
2025-03-29 16:08:51,152:INFO:         statsmodels: 0.14.4
2025-03-29 16:08:51,152:INFO:              sktime: 0.26.0
2025-03-29 16:08:51,152:INFO:               tbats: 1.1.3
2025-03-29 16:08:51,152:INFO:            pmdarima: 2.0.4
2025-03-29 16:08:51,152:INFO:              psutil: 7.0.0
2025-03-29 16:08:51,152:INFO:          markupsafe: 3.0.2
2025-03-29 16:08:51,152:INFO:             pickle5: Not installed
2025-03-29 16:08:51,152:INFO:         cloudpickle: 3.1.1
2025-03-29 16:08:51,152:INFO:         deprecation: 2.1.0
2025-03-29 16:08:51,152:INFO:              xxhash: 3.5.0
2025-03-29 16:08:51,153:INFO:           wurlitzer: 3.1.1
2025-03-29 16:08:51,153:INFO:PyCaret optional dependencies:
2025-03-29 16:08:51,153:INFO:                shap: Not installed
2025-03-29 16:08:51,153:INFO:           interpret: Not installed
2025-03-29 16:08:51,153:INFO:                umap: 0.5.7
2025-03-29 16:08:51,153:INFO:     ydata_profiling: Not installed
2025-03-29 16:08:51,153:INFO:  explainerdashboard: Not installed
2025-03-29 16:08:51,153:INFO:             autoviz: Not installed
2025-03-29 16:08:51,153:INFO:           fairlearn: Not installed
2025-03-29 16:08:51,153:INFO:          deepchecks: Not installed
2025-03-29 16:08:51,153:INFO:             xgboost: Not installed
2025-03-29 16:08:51,153:INFO:            catboost: Not installed
2025-03-29 16:08:51,153:INFO:              kmodes: Not installed
2025-03-29 16:08:51,153:INFO:             mlxtend: Not installed
2025-03-29 16:08:51,153:INFO:       statsforecast: Not installed
2025-03-29 16:08:51,153:INFO:        tune_sklearn: Not installed
2025-03-29 16:08:51,153:INFO:                 ray: Not installed
2025-03-29 16:08:51,153:INFO:            hyperopt: Not installed
2025-03-29 16:08:51,153:INFO:              optuna: Not installed
2025-03-29 16:08:51,153:INFO:               skopt: Not installed
2025-03-29 16:08:51,153:INFO:              mlflow: 2.21.2
2025-03-29 16:08:51,153:INFO:              gradio: Not installed
2025-03-29 16:08:51,153:INFO:             fastapi: 0.115.12
2025-03-29 16:08:51,153:INFO:             uvicorn: 0.34.0
2025-03-29 16:08:51,153:INFO:              m2cgen: Not installed
2025-03-29 16:08:51,153:INFO:           evidently: Not installed
2025-03-29 16:08:51,153:INFO:               fugue: Not installed
2025-03-29 16:08:51,153:INFO:           streamlit: 1.43.2
2025-03-29 16:08:51,153:INFO:             prophet: Not installed
2025-03-29 16:08:51,153:INFO:None
2025-03-29 16:08:51,153:INFO:Set up data.
2025-03-29 16:08:51,162:INFO:Set up folding strategy.
2025-03-29 16:10:27,168:INFO:PyCaret RegressionExperiment
2025-03-29 16:10:27,169:INFO:Logging name: reg-default-name
2025-03-29 16:10:27,169:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 16:10:27,169:INFO:version 3.3.2
2025-03-29 16:10:27,169:INFO:Initializing setup()
2025-03-29 16:10:27,169:INFO:self.USI: 0cb3
2025-03-29 16:10:27,170:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 16:10:27,170:INFO:Checking environment
2025-03-29 16:10:27,170:INFO:python_version: 3.10.16
2025-03-29 16:10:27,170:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:10:27,171:INFO:machine: AMD64
2025-03-29 16:10:27,171:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:10:27,175:INFO:Memory: svmem(total=33411727360, available=16830631936, percent=49.6, used=16581095424, free=16830631936)
2025-03-29 16:10:27,175:INFO:Physical Core: 6
2025-03-29 16:10:27,175:INFO:Logical Core: 12
2025-03-29 16:10:27,176:INFO:Checking libraries
2025-03-29 16:10:27,176:INFO:System:
2025-03-29 16:10:27,176:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:10:27,176:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:10:27,176:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:10:27,176:INFO:PyCaret required dependencies:
2025-03-29 16:10:27,176:INFO:                 pip: 25.0.1
2025-03-29 16:10:27,176:INFO:          setuptools: 75.8.2
2025-03-29 16:10:27,176:INFO:             pycaret: 3.3.2
2025-03-29 16:10:27,177:INFO:             IPython: 8.34.0
2025-03-29 16:10:27,177:INFO:          ipywidgets: 8.1.5
2025-03-29 16:10:27,177:INFO:                tqdm: 4.67.1
2025-03-29 16:10:27,177:INFO:               numpy: 1.26.4
2025-03-29 16:10:27,177:INFO:              pandas: 2.1.4
2025-03-29 16:10:27,177:INFO:              jinja2: 3.1.6
2025-03-29 16:10:27,177:INFO:               scipy: 1.11.4
2025-03-29 16:10:27,177:INFO:              joblib: 1.3.2
2025-03-29 16:10:27,177:INFO:             sklearn: 1.4.2
2025-03-29 16:10:27,177:INFO:                pyod: 2.0.2
2025-03-29 16:10:27,177:INFO:            imblearn: 0.13.0
2025-03-29 16:10:27,177:INFO:   category_encoders: 2.7.0
2025-03-29 16:10:27,177:INFO:            lightgbm: 4.6.0
2025-03-29 16:10:27,177:INFO:               numba: 0.61.0
2025-03-29 16:10:27,177:INFO:            requests: 2.32.3
2025-03-29 16:10:27,177:INFO:          matplotlib: 3.10.1
2025-03-29 16:10:27,177:INFO:          scikitplot: 0.3.7
2025-03-29 16:10:27,177:INFO:         yellowbrick: 1.5
2025-03-29 16:10:27,177:INFO:              plotly: 6.0.1
2025-03-29 16:10:27,177:INFO:    plotly-resampler: Not installed
2025-03-29 16:10:27,177:INFO:             kaleido: 0.2.1
2025-03-29 16:10:27,177:INFO:           schemdraw: 0.15
2025-03-29 16:10:27,177:INFO:         statsmodels: 0.14.4
2025-03-29 16:10:27,178:INFO:              sktime: 0.26.0
2025-03-29 16:10:27,178:INFO:               tbats: 1.1.3
2025-03-29 16:10:27,178:INFO:            pmdarima: 2.0.4
2025-03-29 16:10:27,178:INFO:              psutil: 7.0.0
2025-03-29 16:10:27,178:INFO:          markupsafe: 3.0.2
2025-03-29 16:10:27,178:INFO:             pickle5: Not installed
2025-03-29 16:10:27,178:INFO:         cloudpickle: 3.1.1
2025-03-29 16:10:27,178:INFO:         deprecation: 2.1.0
2025-03-29 16:10:27,178:INFO:              xxhash: 3.5.0
2025-03-29 16:10:27,178:INFO:           wurlitzer: 3.1.1
2025-03-29 16:10:27,178:INFO:PyCaret optional dependencies:
2025-03-29 16:10:27,178:INFO:                shap: Not installed
2025-03-29 16:10:27,178:INFO:           interpret: Not installed
2025-03-29 16:10:27,178:INFO:                umap: 0.5.7
2025-03-29 16:10:27,178:INFO:     ydata_profiling: Not installed
2025-03-29 16:10:27,178:INFO:  explainerdashboard: Not installed
2025-03-29 16:10:27,178:INFO:             autoviz: Not installed
2025-03-29 16:10:27,178:INFO:           fairlearn: Not installed
2025-03-29 16:10:27,178:INFO:          deepchecks: Not installed
2025-03-29 16:10:27,178:INFO:             xgboost: Not installed
2025-03-29 16:10:27,178:INFO:            catboost: Not installed
2025-03-29 16:10:27,178:INFO:              kmodes: Not installed
2025-03-29 16:10:27,178:INFO:             mlxtend: Not installed
2025-03-29 16:10:27,178:INFO:       statsforecast: Not installed
2025-03-29 16:10:27,178:INFO:        tune_sklearn: Not installed
2025-03-29 16:10:27,178:INFO:                 ray: Not installed
2025-03-29 16:10:27,178:INFO:            hyperopt: Not installed
2025-03-29 16:10:27,178:INFO:              optuna: Not installed
2025-03-29 16:10:27,178:INFO:               skopt: Not installed
2025-03-29 16:10:27,178:INFO:              mlflow: 2.21.2
2025-03-29 16:10:27,178:INFO:              gradio: Not installed
2025-03-29 16:10:27,178:INFO:             fastapi: 0.115.12
2025-03-29 16:10:27,178:INFO:             uvicorn: 0.34.0
2025-03-29 16:10:27,178:INFO:              m2cgen: Not installed
2025-03-29 16:10:27,178:INFO:           evidently: Not installed
2025-03-29 16:10:27,178:INFO:               fugue: Not installed
2025-03-29 16:10:27,178:INFO:           streamlit: 1.43.2
2025-03-29 16:10:27,178:INFO:             prophet: Not installed
2025-03-29 16:10:27,178:INFO:None
2025-03-29 16:10:27,178:INFO:Set up data.
2025-03-29 16:10:27,186:INFO:Set up folding strategy.
2025-03-29 16:10:27,186:INFO:Set up train/test split.
2025-03-29 16:10:27,191:INFO:Set up index.
2025-03-29 16:10:27,191:INFO:Assigning column types.
2025-03-29 16:10:27,197:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 16:10:27,197:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,200:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,202:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,262:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,263:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,265:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,268:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,304:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,329:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 16:10:27,332:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,334:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,369:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,398:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,400:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,467:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,467:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 16:10:27,472:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,531:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,537:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,576:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,607:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 16:10:27,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,675:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,742:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,743:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 16:10:27,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:10:27,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,874:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 16:10:27,940:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:27,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:28,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:28,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:10:28,010:INFO:Preparing preprocessing pipeline...
2025-03-29 16:10:28,010:INFO:Set up simple imputation.
2025-03-29 16:10:28,013:INFO:Set up encoding of categorical features.
2025-03-29 16:10:28,013:INFO:Set up feature normalization.
2025-03-29 16:10:28,014:INFO:Set up column name cleaning.
2025-03-29 16:11:02,182:INFO:PyCaret RegressionExperiment
2025-03-29 16:11:02,182:INFO:Logging name: reg-default-name
2025-03-29 16:11:02,182:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 16:11:02,182:INFO:version 3.3.2
2025-03-29 16:11:02,183:INFO:Initializing setup()
2025-03-29 16:11:02,183:INFO:self.USI: 92a5
2025-03-29 16:11:02,183:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 16:11:02,183:INFO:Checking environment
2025-03-29 16:11:02,184:INFO:python_version: 3.10.16
2025-03-29 16:11:02,184:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:11:02,184:INFO:machine: AMD64
2025-03-29 16:11:02,184:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:11:02,188:INFO:Memory: svmem(total=33411727360, available=16700317696, percent=50.0, used=16711409664, free=16700317696)
2025-03-29 16:11:02,188:INFO:Physical Core: 6
2025-03-29 16:11:02,188:INFO:Logical Core: 12
2025-03-29 16:11:02,188:INFO:Checking libraries
2025-03-29 16:11:02,188:INFO:System:
2025-03-29 16:11:02,188:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:11:02,188:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:11:02,189:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:11:02,189:INFO:PyCaret required dependencies:
2025-03-29 16:11:02,189:INFO:                 pip: 25.0.1
2025-03-29 16:11:02,189:INFO:          setuptools: 75.8.2
2025-03-29 16:11:02,189:INFO:             pycaret: 3.3.2
2025-03-29 16:11:02,189:INFO:             IPython: 8.34.0
2025-03-29 16:11:02,189:INFO:          ipywidgets: 8.1.5
2025-03-29 16:11:02,189:INFO:                tqdm: 4.67.1
2025-03-29 16:11:02,190:INFO:               numpy: 1.26.4
2025-03-29 16:11:02,190:INFO:              pandas: 2.1.4
2025-03-29 16:11:02,190:INFO:              jinja2: 3.1.6
2025-03-29 16:11:02,190:INFO:               scipy: 1.11.4
2025-03-29 16:11:02,190:INFO:              joblib: 1.3.2
2025-03-29 16:11:02,190:INFO:             sklearn: 1.4.2
2025-03-29 16:11:02,190:INFO:                pyod: 2.0.2
2025-03-29 16:11:02,190:INFO:            imblearn: 0.13.0
2025-03-29 16:11:02,190:INFO:   category_encoders: 2.7.0
2025-03-29 16:11:02,190:INFO:            lightgbm: 4.6.0
2025-03-29 16:11:02,190:INFO:               numba: 0.61.0
2025-03-29 16:11:02,191:INFO:            requests: 2.32.3
2025-03-29 16:11:02,191:INFO:          matplotlib: 3.10.1
2025-03-29 16:11:02,191:INFO:          scikitplot: 0.3.7
2025-03-29 16:11:02,191:INFO:         yellowbrick: 1.5
2025-03-29 16:11:02,191:INFO:              plotly: 6.0.1
2025-03-29 16:11:02,191:INFO:    plotly-resampler: Not installed
2025-03-29 16:11:02,191:INFO:             kaleido: 0.2.1
2025-03-29 16:11:02,191:INFO:           schemdraw: 0.15
2025-03-29 16:11:02,191:INFO:         statsmodels: 0.14.4
2025-03-29 16:11:02,191:INFO:              sktime: 0.26.0
2025-03-29 16:11:02,191:INFO:               tbats: 1.1.3
2025-03-29 16:11:02,191:INFO:            pmdarima: 2.0.4
2025-03-29 16:11:02,191:INFO:              psutil: 7.0.0
2025-03-29 16:11:02,191:INFO:          markupsafe: 3.0.2
2025-03-29 16:11:02,191:INFO:             pickle5: Not installed
2025-03-29 16:11:02,191:INFO:         cloudpickle: 3.1.1
2025-03-29 16:11:02,191:INFO:         deprecation: 2.1.0
2025-03-29 16:11:02,191:INFO:              xxhash: 3.5.0
2025-03-29 16:11:02,191:INFO:           wurlitzer: 3.1.1
2025-03-29 16:11:02,191:INFO:PyCaret optional dependencies:
2025-03-29 16:11:02,191:INFO:                shap: Not installed
2025-03-29 16:11:02,191:INFO:           interpret: Not installed
2025-03-29 16:11:02,191:INFO:                umap: 0.5.7
2025-03-29 16:11:02,191:INFO:     ydata_profiling: Not installed
2025-03-29 16:11:02,191:INFO:  explainerdashboard: Not installed
2025-03-29 16:11:02,191:INFO:             autoviz: Not installed
2025-03-29 16:11:02,191:INFO:           fairlearn: Not installed
2025-03-29 16:11:02,191:INFO:          deepchecks: Not installed
2025-03-29 16:11:02,191:INFO:             xgboost: Not installed
2025-03-29 16:11:02,191:INFO:            catboost: Not installed
2025-03-29 16:11:02,191:INFO:              kmodes: Not installed
2025-03-29 16:11:02,191:INFO:             mlxtend: Not installed
2025-03-29 16:11:02,191:INFO:       statsforecast: Not installed
2025-03-29 16:11:02,191:INFO:        tune_sklearn: Not installed
2025-03-29 16:11:02,191:INFO:                 ray: Not installed
2025-03-29 16:11:02,191:INFO:            hyperopt: Not installed
2025-03-29 16:11:02,191:INFO:              optuna: Not installed
2025-03-29 16:11:02,191:INFO:               skopt: Not installed
2025-03-29 16:11:02,191:INFO:              mlflow: 2.21.2
2025-03-29 16:11:02,192:INFO:              gradio: Not installed
2025-03-29 16:11:02,192:INFO:             fastapi: 0.115.12
2025-03-29 16:11:02,192:INFO:             uvicorn: 0.34.0
2025-03-29 16:11:02,192:INFO:              m2cgen: Not installed
2025-03-29 16:11:02,192:INFO:           evidently: Not installed
2025-03-29 16:11:02,192:INFO:               fugue: Not installed
2025-03-29 16:11:02,192:INFO:           streamlit: 1.43.2
2025-03-29 16:11:02,192:INFO:             prophet: Not installed
2025-03-29 16:11:02,192:INFO:None
2025-03-29 16:11:02,192:INFO:Set up data.
2025-03-29 16:11:02,201:INFO:Set up folding strategy.
2025-03-29 16:11:02,201:INFO:Set up train/test split.
2025-03-29 16:11:02,206:INFO:Set up index.
2025-03-29 16:11:02,206:INFO:Assigning column types.
2025-03-29 16:15:58,456:INFO:PyCaret RegressionExperiment
2025-03-29 16:15:58,457:INFO:Logging name: reg-default-name
2025-03-29 16:15:58,457:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 16:15:58,457:INFO:version 3.3.2
2025-03-29 16:15:58,457:INFO:Initializing setup()
2025-03-29 16:15:58,457:INFO:self.USI: 884b
2025-03-29 16:15:58,458:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 16:15:58,458:INFO:Checking environment
2025-03-29 16:15:58,458:INFO:python_version: 3.10.16
2025-03-29 16:15:58,458:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:15:58,458:INFO:machine: AMD64
2025-03-29 16:15:58,458:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:15:58,462:INFO:Memory: svmem(total=33411727360, available=17324785664, percent=48.1, used=16086941696, free=17324785664)
2025-03-29 16:15:58,462:INFO:Physical Core: 6
2025-03-29 16:15:58,462:INFO:Logical Core: 12
2025-03-29 16:15:58,463:INFO:Checking libraries
2025-03-29 16:15:58,463:INFO:System:
2025-03-29 16:15:58,463:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:15:58,463:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:15:58,463:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:15:58,463:INFO:PyCaret required dependencies:
2025-03-29 16:15:58,463:INFO:                 pip: 25.0.1
2025-03-29 16:15:58,463:INFO:          setuptools: 75.8.2
2025-03-29 16:15:58,463:INFO:             pycaret: 3.3.2
2025-03-29 16:15:58,463:INFO:             IPython: 8.34.0
2025-03-29 16:15:58,463:INFO:          ipywidgets: 8.1.5
2025-03-29 16:15:58,463:INFO:                tqdm: 4.67.1
2025-03-29 16:15:58,463:INFO:               numpy: 1.26.4
2025-03-29 16:15:58,463:INFO:              pandas: 2.1.4
2025-03-29 16:15:58,463:INFO:              jinja2: 3.1.6
2025-03-29 16:15:58,463:INFO:               scipy: 1.11.4
2025-03-29 16:15:58,463:INFO:              joblib: 1.3.2
2025-03-29 16:15:58,463:INFO:             sklearn: 1.4.2
2025-03-29 16:15:58,463:INFO:                pyod: 2.0.2
2025-03-29 16:15:58,463:INFO:            imblearn: 0.13.0
2025-03-29 16:15:58,463:INFO:   category_encoders: 2.7.0
2025-03-29 16:15:58,463:INFO:            lightgbm: 4.6.0
2025-03-29 16:15:58,463:INFO:               numba: 0.61.0
2025-03-29 16:15:58,463:INFO:            requests: 2.32.3
2025-03-29 16:15:58,463:INFO:          matplotlib: 3.10.1
2025-03-29 16:15:58,463:INFO:          scikitplot: 0.3.7
2025-03-29 16:15:58,463:INFO:         yellowbrick: 1.5
2025-03-29 16:15:58,463:INFO:              plotly: 6.0.1
2025-03-29 16:15:58,463:INFO:    plotly-resampler: Not installed
2025-03-29 16:15:58,463:INFO:             kaleido: 0.2.1
2025-03-29 16:15:58,463:INFO:           schemdraw: 0.15
2025-03-29 16:15:58,463:INFO:         statsmodels: 0.14.4
2025-03-29 16:15:58,463:INFO:              sktime: 0.26.0
2025-03-29 16:15:58,463:INFO:               tbats: 1.1.3
2025-03-29 16:15:58,463:INFO:            pmdarima: 2.0.4
2025-03-29 16:15:58,463:INFO:              psutil: 7.0.0
2025-03-29 16:15:58,463:INFO:          markupsafe: 3.0.2
2025-03-29 16:15:58,463:INFO:             pickle5: Not installed
2025-03-29 16:15:58,463:INFO:         cloudpickle: 3.1.1
2025-03-29 16:15:58,463:INFO:         deprecation: 2.1.0
2025-03-29 16:15:58,463:INFO:              xxhash: 3.5.0
2025-03-29 16:15:58,463:INFO:           wurlitzer: 3.1.1
2025-03-29 16:15:58,463:INFO:PyCaret optional dependencies:
2025-03-29 16:15:58,463:INFO:                shap: Not installed
2025-03-29 16:15:58,463:INFO:           interpret: Not installed
2025-03-29 16:15:58,464:INFO:                umap: 0.5.7
2025-03-29 16:15:58,464:INFO:     ydata_profiling: Not installed
2025-03-29 16:15:58,464:INFO:  explainerdashboard: Not installed
2025-03-29 16:15:58,464:INFO:             autoviz: Not installed
2025-03-29 16:15:58,464:INFO:           fairlearn: Not installed
2025-03-29 16:15:58,464:INFO:          deepchecks: Not installed
2025-03-29 16:15:58,464:INFO:             xgboost: Not installed
2025-03-29 16:15:58,464:INFO:            catboost: Not installed
2025-03-29 16:15:58,464:INFO:              kmodes: Not installed
2025-03-29 16:15:58,464:INFO:             mlxtend: Not installed
2025-03-29 16:15:58,464:INFO:       statsforecast: Not installed
2025-03-29 16:15:58,464:INFO:        tune_sklearn: Not installed
2025-03-29 16:15:58,464:INFO:                 ray: Not installed
2025-03-29 16:15:58,464:INFO:            hyperopt: Not installed
2025-03-29 16:15:58,464:INFO:              optuna: Not installed
2025-03-29 16:15:58,464:INFO:               skopt: Not installed
2025-03-29 16:15:58,464:INFO:              mlflow: 2.21.2
2025-03-29 16:15:58,464:INFO:              gradio: Not installed
2025-03-29 16:15:58,464:INFO:             fastapi: 0.115.12
2025-03-29 16:15:58,464:INFO:             uvicorn: 0.34.0
2025-03-29 16:15:58,464:INFO:              m2cgen: Not installed
2025-03-29 16:15:58,464:INFO:           evidently: Not installed
2025-03-29 16:15:58,464:INFO:               fugue: Not installed
2025-03-29 16:15:58,464:INFO:           streamlit: 1.43.2
2025-03-29 16:15:58,464:INFO:             prophet: Not installed
2025-03-29 16:15:58,464:INFO:None
2025-03-29 16:15:58,464:INFO:Set up data.
2025-03-29 16:15:58,471:INFO:Set up folding strategy.
2025-03-29 16:15:58,472:INFO:Set up train/test split.
2025-03-29 16:15:58,476:INFO:Set up index.
2025-03-29 16:15:58,477:INFO:Assigning column types.
2025-03-29 16:15:58,481:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 16:15:58,481:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,484:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,486:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,553:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,556:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,559:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,623:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 16:15:58,626:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,628:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,667:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,699:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,702:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,741:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,769:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 16:15:58,775:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,813:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,839:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,845:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,910:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,910:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 16:15:58,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:15:58,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:58,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:15:59,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:15:59,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,049:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 16:15:59,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:15:59,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:15:59,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,179:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 16:15:59,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,313:INFO:Preparing preprocessing pipeline...
2025-03-29 16:15:59,313:INFO:Set up simple imputation.
2025-03-29 16:15:59,316:INFO:Set up encoding of categorical features.
2025-03-29 16:15:59,316:INFO:Set up feature normalization.
2025-03-29 16:15:59,317:INFO:Set up column name cleaning.
2025-03-29 16:15:59,427:INFO:Finished creating preprocessing pipeline.
2025-03-29 16:15:59,431:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_i...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-03-29 16:15:59,431:INFO:Creating final display dataframe.
2025-03-29 16:15:59,660:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              884b
2025-03-29 16:15:59,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:15:59,796:INFO:setup() successfully completed in 1.34s...............
2025-03-29 16:16:14,468:INFO:Initializing get_config()
2025-03-29 16:16:14,469:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, variable=X_train)
2025-03-29 16:16:14,470:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-03-29 16:16:14,470:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-03-29 16:16:14,475:INFO:Variable:  returned as       holiday        temp  rain_1h  snow_1h  clouds_all weather_main  \
5068      NaN  271.880005      0.0      0.0          90         Mist   
8455      NaN  290.549988      0.0      0.0          90       Clouds   
34864     NaN  284.339996      0.0      0.0           1        Clear   
1526      NaN  264.839996      0.0      0.0          40       Clouds   
6499      NaN  286.989990      0.0      0.0          90      Drizzle   
...       ...         ...      ...      ...         ...          ...   
7763      NaN  305.880005      0.0      0.0           0        Clear   
15377     NaN  298.799988      0.0      0.0          44       Clouds   
17730     NaN  282.170013      0.0      0.0           1         Mist   
28030     NaN  280.420013      0.0      0.0           1        Clear   
15725     NaN  290.320007      0.0      0.0           1        Clear   

       Rush Hour  
5068           0  
8455           0  
34864          0  
1526           0  
6499           0  
...          ...  
7763           0  
15377          0  
17730          0  
28030          0  
15725          0  

[33742 rows x 7 columns]
2025-03-29 16:16:14,476:INFO:get_config() successfully completed......................................
2025-03-29 16:16:15,962:INFO:Initializing compare_models()
2025-03-29 16:16:15,962:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-29 16:16:15,962:INFO:Checking exceptions
2025-03-29 16:16:15,965:INFO:Preparing display monitor
2025-03-29 16:16:15,978:INFO:Initializing Linear Regression
2025-03-29 16:16:15,978:INFO:Total runtime is 0.0 minutes
2025-03-29 16:16:15,980:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:15,981:INFO:Initializing create_model()
2025-03-29 16:16:15,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:15,981:INFO:Checking exceptions
2025-03-29 16:16:15,981:INFO:Importing libraries
2025-03-29 16:16:15,981:INFO:Copying training dataset
2025-03-29 16:16:15,988:INFO:Defining folds
2025-03-29 16:16:15,988:INFO:Declaring metric variables
2025-03-29 16:16:15,989:INFO:Importing untrained model
2025-03-29 16:16:15,992:INFO:Linear Regression Imported successfully
2025-03-29 16:16:15,998:INFO:Starting cross validation
2025-03-29 16:16:15,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:18,322:INFO:Calculating mean and std
2025-03-29 16:16:18,323:INFO:Creating metrics dataframe
2025-03-29 16:16:18,325:INFO:Uploading results into container
2025-03-29 16:16:18,325:INFO:Uploading model into container now
2025-03-29 16:16:18,325:INFO:_master_model_container: 1
2025-03-29 16:16:18,325:INFO:_display_container: 2
2025-03-29 16:16:18,326:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-03-29 16:16:18,326:INFO:create_model() successfully completed......................................
2025-03-29 16:16:18,507:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:18,508:INFO:Creating metrics dataframe
2025-03-29 16:16:18,511:INFO:Initializing Lasso Regression
2025-03-29 16:16:18,511:INFO:Total runtime is 0.04222784837086995 minutes
2025-03-29 16:16:18,513:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:18,514:INFO:Initializing create_model()
2025-03-29 16:16:18,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:18,514:INFO:Checking exceptions
2025-03-29 16:16:18,514:INFO:Importing libraries
2025-03-29 16:16:18,514:INFO:Copying training dataset
2025-03-29 16:16:18,521:INFO:Defining folds
2025-03-29 16:16:18,521:INFO:Declaring metric variables
2025-03-29 16:16:18,523:INFO:Importing untrained model
2025-03-29 16:16:18,525:INFO:Lasso Regression Imported successfully
2025-03-29 16:16:18,528:INFO:Starting cross validation
2025-03-29 16:16:18,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:20,315:INFO:Calculating mean and std
2025-03-29 16:16:20,316:INFO:Creating metrics dataframe
2025-03-29 16:16:20,318:INFO:Uploading results into container
2025-03-29 16:16:20,318:INFO:Uploading model into container now
2025-03-29 16:16:20,318:INFO:_master_model_container: 2
2025-03-29 16:16:20,318:INFO:_display_container: 2
2025-03-29 16:16:20,319:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-03-29 16:16:20,319:INFO:create_model() successfully completed......................................
2025-03-29 16:16:20,472:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:20,473:INFO:Creating metrics dataframe
2025-03-29 16:16:20,477:INFO:Initializing Ridge Regression
2025-03-29 16:16:20,477:INFO:Total runtime is 0.0749945084253947 minutes
2025-03-29 16:16:20,479:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:20,479:INFO:Initializing create_model()
2025-03-29 16:16:20,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:20,479:INFO:Checking exceptions
2025-03-29 16:16:20,479:INFO:Importing libraries
2025-03-29 16:16:20,479:INFO:Copying training dataset
2025-03-29 16:16:20,486:INFO:Defining folds
2025-03-29 16:16:20,486:INFO:Declaring metric variables
2025-03-29 16:16:20,488:INFO:Importing untrained model
2025-03-29 16:16:20,491:INFO:Ridge Regression Imported successfully
2025-03-29 16:16:20,494:INFO:Starting cross validation
2025-03-29 16:16:20,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:20,762:INFO:Calculating mean and std
2025-03-29 16:16:20,763:INFO:Creating metrics dataframe
2025-03-29 16:16:20,764:INFO:Uploading results into container
2025-03-29 16:16:20,764:INFO:Uploading model into container now
2025-03-29 16:16:20,764:INFO:_master_model_container: 3
2025-03-29 16:16:20,765:INFO:_display_container: 2
2025-03-29 16:16:20,765:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-03-29 16:16:20,765:INFO:create_model() successfully completed......................................
2025-03-29 16:16:20,924:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:20,924:INFO:Creating metrics dataframe
2025-03-29 16:16:20,928:INFO:Initializing Elastic Net
2025-03-29 16:16:20,929:INFO:Total runtime is 0.08251631657282511 minutes
2025-03-29 16:16:20,931:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:20,931:INFO:Initializing create_model()
2025-03-29 16:16:20,931:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:20,931:INFO:Checking exceptions
2025-03-29 16:16:20,931:INFO:Importing libraries
2025-03-29 16:16:20,931:INFO:Copying training dataset
2025-03-29 16:16:20,938:INFO:Defining folds
2025-03-29 16:16:20,938:INFO:Declaring metric variables
2025-03-29 16:16:20,940:INFO:Importing untrained model
2025-03-29 16:16:20,943:INFO:Elastic Net Imported successfully
2025-03-29 16:16:20,946:INFO:Starting cross validation
2025-03-29 16:16:20,948:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:21,219:INFO:Calculating mean and std
2025-03-29 16:16:21,220:INFO:Creating metrics dataframe
2025-03-29 16:16:21,221:INFO:Uploading results into container
2025-03-29 16:16:21,221:INFO:Uploading model into container now
2025-03-29 16:16:21,221:INFO:_master_model_container: 4
2025-03-29 16:16:21,221:INFO:_display_container: 2
2025-03-29 16:16:21,222:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-03-29 16:16:21,222:INFO:create_model() successfully completed......................................
2025-03-29 16:16:21,379:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:21,379:INFO:Creating metrics dataframe
2025-03-29 16:16:21,384:INFO:Initializing Least Angle Regression
2025-03-29 16:16:21,384:INFO:Total runtime is 0.09009929100672404 minutes
2025-03-29 16:16:21,386:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:21,386:INFO:Initializing create_model()
2025-03-29 16:16:21,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:21,386:INFO:Checking exceptions
2025-03-29 16:16:21,386:INFO:Importing libraries
2025-03-29 16:16:21,386:INFO:Copying training dataset
2025-03-29 16:16:21,393:INFO:Defining folds
2025-03-29 16:16:21,394:INFO:Declaring metric variables
2025-03-29 16:16:21,396:INFO:Importing untrained model
2025-03-29 16:16:21,398:INFO:Least Angle Regression Imported successfully
2025-03-29 16:16:21,401:INFO:Starting cross validation
2025-03-29 16:16:21,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:21,668:INFO:Calculating mean and std
2025-03-29 16:16:21,669:INFO:Creating metrics dataframe
2025-03-29 16:16:21,670:INFO:Uploading results into container
2025-03-29 16:16:21,670:INFO:Uploading model into container now
2025-03-29 16:16:21,670:INFO:_master_model_container: 5
2025-03-29 16:16:21,671:INFO:_display_container: 2
2025-03-29 16:16:21,671:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-03-29 16:16:21,671:INFO:create_model() successfully completed......................................
2025-03-29 16:16:21,826:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:21,826:INFO:Creating metrics dataframe
2025-03-29 16:16:21,830:INFO:Initializing Lasso Least Angle Regression
2025-03-29 16:16:21,831:INFO:Total runtime is 0.09753273328145344 minutes
2025-03-29 16:16:21,832:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:21,833:INFO:Initializing create_model()
2025-03-29 16:16:21,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:21,833:INFO:Checking exceptions
2025-03-29 16:16:21,833:INFO:Importing libraries
2025-03-29 16:16:21,833:INFO:Copying training dataset
2025-03-29 16:16:21,839:INFO:Defining folds
2025-03-29 16:16:21,840:INFO:Declaring metric variables
2025-03-29 16:16:21,842:INFO:Importing untrained model
2025-03-29 16:16:21,846:INFO:Lasso Least Angle Regression Imported successfully
2025-03-29 16:16:21,850:INFO:Starting cross validation
2025-03-29 16:16:21,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:22,113:INFO:Calculating mean and std
2025-03-29 16:16:22,114:INFO:Creating metrics dataframe
2025-03-29 16:16:22,116:INFO:Uploading results into container
2025-03-29 16:16:22,116:INFO:Uploading model into container now
2025-03-29 16:16:22,117:INFO:_master_model_container: 6
2025-03-29 16:16:22,117:INFO:_display_container: 2
2025-03-29 16:16:22,117:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-03-29 16:16:22,117:INFO:create_model() successfully completed......................................
2025-03-29 16:16:22,270:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:22,270:INFO:Creating metrics dataframe
2025-03-29 16:16:22,274:INFO:Initializing Orthogonal Matching Pursuit
2025-03-29 16:16:22,274:INFO:Total runtime is 0.10493271350860595 minutes
2025-03-29 16:16:22,276:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:22,277:INFO:Initializing create_model()
2025-03-29 16:16:22,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:22,277:INFO:Checking exceptions
2025-03-29 16:16:22,277:INFO:Importing libraries
2025-03-29 16:16:22,277:INFO:Copying training dataset
2025-03-29 16:16:22,284:INFO:Defining folds
2025-03-29 16:16:22,284:INFO:Declaring metric variables
2025-03-29 16:16:22,286:INFO:Importing untrained model
2025-03-29 16:16:22,288:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-29 16:16:22,291:INFO:Starting cross validation
2025-03-29 16:16:22,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:22,542:INFO:Calculating mean and std
2025-03-29 16:16:22,543:INFO:Creating metrics dataframe
2025-03-29 16:16:22,545:INFO:Uploading results into container
2025-03-29 16:16:22,545:INFO:Uploading model into container now
2025-03-29 16:16:22,546:INFO:_master_model_container: 7
2025-03-29 16:16:22,546:INFO:_display_container: 2
2025-03-29 16:16:22,546:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-03-29 16:16:22,546:INFO:create_model() successfully completed......................................
2025-03-29 16:16:22,708:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:22,708:INFO:Creating metrics dataframe
2025-03-29 16:16:22,713:INFO:Initializing Bayesian Ridge
2025-03-29 16:16:22,713:INFO:Total runtime is 0.11225927273432412 minutes
2025-03-29 16:16:22,715:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:22,715:INFO:Initializing create_model()
2025-03-29 16:16:22,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:22,716:INFO:Checking exceptions
2025-03-29 16:16:22,716:INFO:Importing libraries
2025-03-29 16:16:22,716:INFO:Copying training dataset
2025-03-29 16:16:22,723:INFO:Defining folds
2025-03-29 16:16:22,723:INFO:Declaring metric variables
2025-03-29 16:16:22,725:INFO:Importing untrained model
2025-03-29 16:16:22,727:INFO:Bayesian Ridge Imported successfully
2025-03-29 16:16:22,731:INFO:Starting cross validation
2025-03-29 16:16:22,732:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:23,026:INFO:Calculating mean and std
2025-03-29 16:16:23,027:INFO:Creating metrics dataframe
2025-03-29 16:16:23,028:INFO:Uploading results into container
2025-03-29 16:16:23,028:INFO:Uploading model into container now
2025-03-29 16:16:23,028:INFO:_master_model_container: 8
2025-03-29 16:16:23,028:INFO:_display_container: 2
2025-03-29 16:16:23,029:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-03-29 16:16:23,029:INFO:create_model() successfully completed......................................
2025-03-29 16:16:23,185:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:23,185:INFO:Creating metrics dataframe
2025-03-29 16:16:23,191:INFO:Initializing Passive Aggressive Regressor
2025-03-29 16:16:23,191:INFO:Total runtime is 0.12021960814793903 minutes
2025-03-29 16:16:23,193:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:23,193:INFO:Initializing create_model()
2025-03-29 16:16:23,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:23,193:INFO:Checking exceptions
2025-03-29 16:16:23,193:INFO:Importing libraries
2025-03-29 16:16:23,194:INFO:Copying training dataset
2025-03-29 16:16:23,201:INFO:Defining folds
2025-03-29 16:16:23,201:INFO:Declaring metric variables
2025-03-29 16:16:23,203:INFO:Importing untrained model
2025-03-29 16:16:23,205:INFO:Passive Aggressive Regressor Imported successfully
2025-03-29 16:16:23,209:INFO:Starting cross validation
2025-03-29 16:16:23,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:23,524:INFO:Calculating mean and std
2025-03-29 16:16:23,525:INFO:Creating metrics dataframe
2025-03-29 16:16:23,526:INFO:Uploading results into container
2025-03-29 16:16:23,526:INFO:Uploading model into container now
2025-03-29 16:16:23,527:INFO:_master_model_container: 9
2025-03-29 16:16:23,527:INFO:_display_container: 2
2025-03-29 16:16:23,527:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:16:23,527:INFO:create_model() successfully completed......................................
2025-03-29 16:16:23,682:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:23,682:INFO:Creating metrics dataframe
2025-03-29 16:16:23,688:INFO:Initializing Huber Regressor
2025-03-29 16:16:23,688:INFO:Total runtime is 0.12850294510523477 minutes
2025-03-29 16:16:23,690:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:23,690:INFO:Initializing create_model()
2025-03-29 16:16:23,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:23,690:INFO:Checking exceptions
2025-03-29 16:16:23,690:INFO:Importing libraries
2025-03-29 16:16:23,690:INFO:Copying training dataset
2025-03-29 16:16:23,697:INFO:Defining folds
2025-03-29 16:16:23,697:INFO:Declaring metric variables
2025-03-29 16:16:23,699:INFO:Importing untrained model
2025-03-29 16:16:23,701:INFO:Huber Regressor Imported successfully
2025-03-29 16:16:23,705:INFO:Starting cross validation
2025-03-29 16:16:23,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:24,185:INFO:Calculating mean and std
2025-03-29 16:16:24,186:INFO:Creating metrics dataframe
2025-03-29 16:16:24,187:INFO:Uploading results into container
2025-03-29 16:16:24,187:INFO:Uploading model into container now
2025-03-29 16:16:24,188:INFO:_master_model_container: 10
2025-03-29 16:16:24,188:INFO:_display_container: 2
2025-03-29 16:16:24,188:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-03-29 16:16:24,188:INFO:create_model() successfully completed......................................
2025-03-29 16:16:24,345:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:24,345:INFO:Creating metrics dataframe
2025-03-29 16:16:24,351:INFO:Initializing K Neighbors Regressor
2025-03-29 16:16:24,351:INFO:Total runtime is 0.13955351511637368 minutes
2025-03-29 16:16:24,353:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:24,353:INFO:Initializing create_model()
2025-03-29 16:16:24,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:24,353:INFO:Checking exceptions
2025-03-29 16:16:24,353:INFO:Importing libraries
2025-03-29 16:16:24,353:INFO:Copying training dataset
2025-03-29 16:16:24,361:INFO:Defining folds
2025-03-29 16:16:24,361:INFO:Declaring metric variables
2025-03-29 16:16:24,363:INFO:Importing untrained model
2025-03-29 16:16:24,365:INFO:K Neighbors Regressor Imported successfully
2025-03-29 16:16:24,369:INFO:Starting cross validation
2025-03-29 16:16:24,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:25,191:INFO:Calculating mean and std
2025-03-29 16:16:25,192:INFO:Creating metrics dataframe
2025-03-29 16:16:25,193:INFO:Uploading results into container
2025-03-29 16:16:25,194:INFO:Uploading model into container now
2025-03-29 16:16:25,194:INFO:_master_model_container: 11
2025-03-29 16:16:25,194:INFO:_display_container: 2
2025-03-29 16:16:25,194:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-03-29 16:16:25,195:INFO:create_model() successfully completed......................................
2025-03-29 16:16:25,355:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:25,355:INFO:Creating metrics dataframe
2025-03-29 16:16:25,361:INFO:Initializing Decision Tree Regressor
2025-03-29 16:16:25,361:INFO:Total runtime is 0.15639699697494505 minutes
2025-03-29 16:16:25,363:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:25,363:INFO:Initializing create_model()
2025-03-29 16:16:25,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:25,364:INFO:Checking exceptions
2025-03-29 16:16:25,364:INFO:Importing libraries
2025-03-29 16:16:25,364:INFO:Copying training dataset
2025-03-29 16:16:25,370:INFO:Defining folds
2025-03-29 16:16:25,370:INFO:Declaring metric variables
2025-03-29 16:16:25,372:INFO:Importing untrained model
2025-03-29 16:16:25,375:INFO:Decision Tree Regressor Imported successfully
2025-03-29 16:16:25,379:INFO:Starting cross validation
2025-03-29 16:16:25,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:25,734:INFO:Calculating mean and std
2025-03-29 16:16:25,735:INFO:Creating metrics dataframe
2025-03-29 16:16:25,736:INFO:Uploading results into container
2025-03-29 16:16:25,736:INFO:Uploading model into container now
2025-03-29 16:16:25,737:INFO:_master_model_container: 12
2025-03-29 16:16:25,737:INFO:_display_container: 2
2025-03-29 16:16:25,737:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-03-29 16:16:25,737:INFO:create_model() successfully completed......................................
2025-03-29 16:16:25,897:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:25,898:INFO:Creating metrics dataframe
2025-03-29 16:16:25,903:INFO:Initializing Random Forest Regressor
2025-03-29 16:16:25,904:INFO:Total runtime is 0.1654311696688334 minutes
2025-03-29 16:16:25,906:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:25,906:INFO:Initializing create_model()
2025-03-29 16:16:25,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:25,906:INFO:Checking exceptions
2025-03-29 16:16:25,906:INFO:Importing libraries
2025-03-29 16:16:25,906:INFO:Copying training dataset
2025-03-29 16:16:25,913:INFO:Defining folds
2025-03-29 16:16:25,913:INFO:Declaring metric variables
2025-03-29 16:16:25,916:INFO:Importing untrained model
2025-03-29 16:16:25,918:INFO:Random Forest Regressor Imported successfully
2025-03-29 16:16:25,922:INFO:Starting cross validation
2025-03-29 16:16:25,924:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:32,020:INFO:Calculating mean and std
2025-03-29 16:16:32,021:INFO:Creating metrics dataframe
2025-03-29 16:16:32,022:INFO:Uploading results into container
2025-03-29 16:16:32,023:INFO:Uploading model into container now
2025-03-29 16:16:32,023:INFO:_master_model_container: 13
2025-03-29 16:16:32,023:INFO:_display_container: 2
2025-03-29 16:16:32,024:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-03-29 16:16:32,024:INFO:create_model() successfully completed......................................
2025-03-29 16:16:32,219:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:32,219:INFO:Creating metrics dataframe
2025-03-29 16:16:32,225:INFO:Initializing Extra Trees Regressor
2025-03-29 16:16:32,225:INFO:Total runtime is 0.27078417539596555 minutes
2025-03-29 16:16:32,227:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:32,228:INFO:Initializing create_model()
2025-03-29 16:16:32,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:32,228:INFO:Checking exceptions
2025-03-29 16:16:32,228:INFO:Importing libraries
2025-03-29 16:16:32,228:INFO:Copying training dataset
2025-03-29 16:16:32,235:INFO:Defining folds
2025-03-29 16:16:32,235:INFO:Declaring metric variables
2025-03-29 16:16:32,237:INFO:Importing untrained model
2025-03-29 16:16:32,240:INFO:Extra Trees Regressor Imported successfully
2025-03-29 16:16:32,244:INFO:Starting cross validation
2025-03-29 16:16:32,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:36,172:INFO:Calculating mean and std
2025-03-29 16:16:36,173:INFO:Creating metrics dataframe
2025-03-29 16:16:36,174:INFO:Uploading results into container
2025-03-29 16:16:36,175:INFO:Uploading model into container now
2025-03-29 16:16:36,175:INFO:_master_model_container: 14
2025-03-29 16:16:36,175:INFO:_display_container: 2
2025-03-29 16:16:36,175:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-03-29 16:16:36,175:INFO:create_model() successfully completed......................................
2025-03-29 16:16:36,368:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:36,368:INFO:Creating metrics dataframe
2025-03-29 16:16:36,374:INFO:Initializing AdaBoost Regressor
2025-03-29 16:16:36,374:INFO:Total runtime is 0.33993273973464966 minutes
2025-03-29 16:16:36,377:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:36,377:INFO:Initializing create_model()
2025-03-29 16:16:36,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:36,377:INFO:Checking exceptions
2025-03-29 16:16:36,377:INFO:Importing libraries
2025-03-29 16:16:36,378:INFO:Copying training dataset
2025-03-29 16:16:36,385:INFO:Defining folds
2025-03-29 16:16:36,385:INFO:Declaring metric variables
2025-03-29 16:16:36,387:INFO:Importing untrained model
2025-03-29 16:16:36,389:INFO:AdaBoost Regressor Imported successfully
2025-03-29 16:16:36,393:INFO:Starting cross validation
2025-03-29 16:16:36,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:37,290:INFO:Calculating mean and std
2025-03-29 16:16:37,291:INFO:Creating metrics dataframe
2025-03-29 16:16:37,292:INFO:Uploading results into container
2025-03-29 16:16:37,292:INFO:Uploading model into container now
2025-03-29 16:16:37,293:INFO:_master_model_container: 15
2025-03-29 16:16:37,293:INFO:_display_container: 2
2025-03-29 16:16:37,293:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-03-29 16:16:37,293:INFO:create_model() successfully completed......................................
2025-03-29 16:16:37,458:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:37,459:INFO:Creating metrics dataframe
2025-03-29 16:16:37,465:INFO:Initializing Gradient Boosting Regressor
2025-03-29 16:16:37,465:INFO:Total runtime is 0.35812771717707315 minutes
2025-03-29 16:16:37,467:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:37,467:INFO:Initializing create_model()
2025-03-29 16:16:37,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:37,468:INFO:Checking exceptions
2025-03-29 16:16:37,468:INFO:Importing libraries
2025-03-29 16:16:37,468:INFO:Copying training dataset
2025-03-29 16:16:37,475:INFO:Defining folds
2025-03-29 16:16:37,475:INFO:Declaring metric variables
2025-03-29 16:16:37,477:INFO:Importing untrained model
2025-03-29 16:16:37,480:INFO:Gradient Boosting Regressor Imported successfully
2025-03-29 16:16:37,483:INFO:Starting cross validation
2025-03-29 16:16:37,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:39,581:INFO:Calculating mean and std
2025-03-29 16:16:39,582:INFO:Creating metrics dataframe
2025-03-29 16:16:39,583:INFO:Uploading results into container
2025-03-29 16:16:39,584:INFO:Uploading model into container now
2025-03-29 16:16:39,584:INFO:_master_model_container: 16
2025-03-29 16:16:39,584:INFO:_display_container: 2
2025-03-29 16:16:39,584:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-29 16:16:39,585:INFO:create_model() successfully completed......................................
2025-03-29 16:16:39,746:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:39,746:INFO:Creating metrics dataframe
2025-03-29 16:16:39,753:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 16:16:39,753:INFO:Total runtime is 0.39625834226608275 minutes
2025-03-29 16:16:39,755:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:39,755:INFO:Initializing create_model()
2025-03-29 16:16:39,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:39,755:INFO:Checking exceptions
2025-03-29 16:16:39,755:INFO:Importing libraries
2025-03-29 16:16:39,755:INFO:Copying training dataset
2025-03-29 16:16:39,762:INFO:Defining folds
2025-03-29 16:16:39,763:INFO:Declaring metric variables
2025-03-29 16:16:39,765:INFO:Importing untrained model
2025-03-29 16:16:39,767:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:16:39,770:INFO:Starting cross validation
2025-03-29 16:16:39,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:40,801:INFO:Calculating mean and std
2025-03-29 16:16:40,802:INFO:Creating metrics dataframe
2025-03-29 16:16:40,803:INFO:Uploading results into container
2025-03-29 16:16:40,804:INFO:Uploading model into container now
2025-03-29 16:16:40,804:INFO:_master_model_container: 17
2025-03-29 16:16:40,804:INFO:_display_container: 2
2025-03-29 16:16:40,805:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:16:40,805:INFO:create_model() successfully completed......................................
2025-03-29 16:16:40,992:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:40,992:INFO:Creating metrics dataframe
2025-03-29 16:16:40,999:INFO:Initializing Dummy Regressor
2025-03-29 16:16:40,999:INFO:Total runtime is 0.4170250376065572 minutes
2025-03-29 16:16:41,001:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:41,001:INFO:Initializing create_model()
2025-03-29 16:16:41,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E9208F6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:41,001:INFO:Checking exceptions
2025-03-29 16:16:41,001:INFO:Importing libraries
2025-03-29 16:16:41,001:INFO:Copying training dataset
2025-03-29 16:16:41,009:INFO:Defining folds
2025-03-29 16:16:41,009:INFO:Declaring metric variables
2025-03-29 16:16:41,012:INFO:Importing untrained model
2025-03-29 16:16:41,014:INFO:Dummy Regressor Imported successfully
2025-03-29 16:16:41,017:INFO:Starting cross validation
2025-03-29 16:16:41,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:41,265:INFO:Calculating mean and std
2025-03-29 16:16:41,266:INFO:Creating metrics dataframe
2025-03-29 16:16:41,268:INFO:Uploading results into container
2025-03-29 16:16:41,268:INFO:Uploading model into container now
2025-03-29 16:16:41,269:INFO:_master_model_container: 18
2025-03-29 16:16:41,269:INFO:_display_container: 2
2025-03-29 16:16:41,269:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-03-29 16:16:41,269:INFO:create_model() successfully completed......................................
2025-03-29 16:16:41,443:INFO:SubProcess create_model() end ==================================
2025-03-29 16:16:41,443:INFO:Creating metrics dataframe
2025-03-29 16:16:41,450:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-29 16:16:41,456:INFO:Initializing create_model()
2025-03-29 16:16:41,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:16:41,456:INFO:Checking exceptions
2025-03-29 16:16:41,457:INFO:Importing libraries
2025-03-29 16:16:41,457:INFO:Copying training dataset
2025-03-29 16:16:41,464:INFO:Defining folds
2025-03-29 16:16:41,464:INFO:Declaring metric variables
2025-03-29 16:16:41,464:INFO:Importing untrained model
2025-03-29 16:16:41,464:INFO:Declaring custom model
2025-03-29 16:16:41,465:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:16:41,466:INFO:Cross validation set to False
2025-03-29 16:16:41,466:INFO:Fitting Model
2025-03-29 16:16:41,562:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:16:41,564:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000858 seconds.
2025-03-29 16:16:41,564:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:16:41,564:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:16:41,564:INFO:[LightGBM] [Info] Total Bins 575
2025-03-29 16:16:41,564:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 16:16:41,565:INFO:[LightGBM] [Info] Start training from score 3248.074833
2025-03-29 16:16:41,633:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:16:41,633:INFO:create_model() successfully completed......................................
2025-03-29 16:16:41,837:INFO:_master_model_container: 18
2025-03-29 16:16:41,837:INFO:_display_container: 2
2025-03-29 16:16:41,838:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:16:41,838:INFO:compare_models() successfully completed......................................
2025-03-29 16:16:41,854:INFO:Initializing evaluate_model()
2025-03-29 16:16:41,854:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-29 16:16:41,864:INFO:Initializing plot_model()
2025-03-29 16:16:41,864:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, system=True)
2025-03-29 16:16:41,864:INFO:Checking exceptions
2025-03-29 16:16:41,868:INFO:Preloading libraries
2025-03-29 16:16:41,884:INFO:Copying training dataset
2025-03-29 16:16:41,884:INFO:Plot type: pipeline
2025-03-29 16:16:41,985:INFO:Visual Rendered Successfully
2025-03-29 16:16:42,150:INFO:plot_model() successfully completed......................................
2025-03-29 16:16:42,168:INFO:Initializing tune_model()
2025-03-29 16:16:42,168:INFO:tune_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>)
2025-03-29 16:16:42,168:INFO:Checking exceptions
2025-03-29 16:16:42,180:INFO:Copying training dataset
2025-03-29 16:16:42,185:INFO:Checking base model
2025-03-29 16:16:42,185:INFO:Base model : Light Gradient Boosting Machine
2025-03-29 16:16:42,188:INFO:Declaring metric variables
2025-03-29 16:16:42,191:INFO:Defining Hyperparameters
2025-03-29 16:16:42,368:INFO:Tuning with n_jobs=-1
2025-03-29 16:16:42,368:INFO:Initializing RandomizedSearchCV
2025-03-29 16:16:58,796:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-03-29 16:16:58,797:INFO:Hyperparameter search completed
2025-03-29 16:16:58,797:INFO:SubProcess create_model() called ==================================
2025-03-29 16:16:58,798:INFO:Initializing create_model()
2025-03-29 16:16:58,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E926C42EF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-03-29 16:16:58,798:INFO:Checking exceptions
2025-03-29 16:16:58,798:INFO:Importing libraries
2025-03-29 16:16:58,798:INFO:Copying training dataset
2025-03-29 16:16:58,807:INFO:Defining folds
2025-03-29 16:16:58,807:INFO:Declaring metric variables
2025-03-29 16:16:58,810:INFO:Importing untrained model
2025-03-29 16:16:58,810:INFO:Declaring custom model
2025-03-29 16:16:58,813:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:16:58,817:INFO:Starting cross validation
2025-03-29 16:16:58,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:16:59,643:INFO:Calculating mean and std
2025-03-29 16:16:59,643:INFO:Creating metrics dataframe
2025-03-29 16:16:59,647:INFO:Finalizing model
2025-03-29 16:16:59,758:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-03-29 16:16:59,758:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-03-29 16:16:59,758:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-03-29 16:16:59,776:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:16:59,777:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-03-29 16:16:59,777:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-03-29 16:16:59,777:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-03-29 16:16:59,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000801 seconds.
2025-03-29 16:16:59,779:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:16:59,779:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:16:59,779:INFO:[LightGBM] [Info] Total Bins 578
2025-03-29 16:16:59,779:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 16
2025-03-29 16:16:59,780:INFO:[LightGBM] [Info] Start training from score 3248.074833
2025-03-29 16:16:59,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:16:59,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:16:59,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:16:59,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:16:59,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:16:59,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:16:59,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:16:59,842:INFO:Uploading results into container
2025-03-29 16:16:59,842:INFO:Uploading model into container now
2025-03-29 16:16:59,843:INFO:_master_model_container: 19
2025-03-29 16:16:59,843:INFO:_display_container: 3
2025-03-29 16:16:59,844:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
              importance_type='split', learning_rate=0.4, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
              random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:16:59,844:INFO:create_model() successfully completed......................................
2025-03-29 16:17:00,032:INFO:SubProcess create_model() end ==================================
2025-03-29 16:17:00,032:INFO:choose_better activated
2025-03-29 16:17:00,035:INFO:SubProcess create_model() called ==================================
2025-03-29 16:17:00,035:INFO:Initializing create_model()
2025-03-29 16:17:00,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E920388970>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:17:00,035:INFO:Checking exceptions
2025-03-29 16:17:00,037:INFO:Importing libraries
2025-03-29 16:17:00,037:INFO:Copying training dataset
2025-03-29 16:17:00,043:INFO:Defining folds
2025-03-29 16:17:00,043:INFO:Declaring metric variables
2025-03-29 16:17:00,043:INFO:Importing untrained model
2025-03-29 16:17:00,043:INFO:Declaring custom model
2025-03-29 16:17:00,044:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:17:00,044:INFO:Starting cross validation
2025-03-29 16:17:00,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:17:00,989:INFO:Calculating mean and std
2025-03-29 16:17:00,989:INFO:Creating metrics dataframe
2025-03-29 16:17:00,991:INFO:Finalizing model
2025-03-29 16:17:01,113:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:17:01,115:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.
2025-03-29 16:17:01,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:17:01,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:17:01,115:INFO:[LightGBM] [Info] Total Bins 575
2025-03-29 16:17:01,115:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 16:17:01,115:INFO:[LightGBM] [Info] Start training from score 3248.074833
2025-03-29 16:17:01,165:INFO:Uploading results into container
2025-03-29 16:17:01,165:INFO:Uploading model into container now
2025-03-29 16:17:01,166:INFO:_master_model_container: 20
2025-03-29 16:17:01,166:INFO:_display_container: 4
2025-03-29 16:17:01,166:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:17:01,166:INFO:create_model() successfully completed......................................
2025-03-29 16:17:01,346:INFO:SubProcess create_model() end ==================================
2025-03-29 16:17:01,347:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.2201
2025-03-29 16:17:01,347:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
              importance_type='split', learning_rate=0.4, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
              random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.2148
2025-03-29 16:17:01,348:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-03-29 16:17:01,348:INFO:choose_better completed
2025-03-29 16:17:01,348:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-29 16:17:01,355:INFO:_master_model_container: 20
2025-03-29 16:17:01,355:INFO:_display_container: 3
2025-03-29 16:17:01,356:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:17:01,356:INFO:tune_model() successfully completed......................................
2025-03-29 16:17:01,544:INFO:Initializing save_model()
2025-03-29 16:17:01,544:INFO:save_model(model=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), model_name=traffic_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_i...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-29 16:17:01,544:INFO:Adding model into prep_pipe
2025-03-29 16:17:01,552:INFO:traffic_model.pkl saved in current working directory
2025-03-29 16:17:01,559:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,...
                 LGBMRegressor(boosting_type='gbdt', class_weight=None,
                               colsample_bytree=1.0, importance_type='split',
                               learning_rate=0.1, max_depth=-1,
                               min_child_samples=20, min_child_weight=0.001,
                               min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                               num_leaves=31, objective=None, random_state=123,
                               reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                               subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-03-29 16:17:01,559:INFO:save_model() successfully completed......................................
2025-03-29 16:24:50,442:INFO:PyCaret ClassificationExperiment
2025-03-29 16:24:50,443:INFO:Logging name: clf-default-name
2025-03-29 16:24:50,443:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-29 16:24:50,444:INFO:version 3.3.2
2025-03-29 16:24:50,444:INFO:Initializing setup()
2025-03-29 16:24:50,444:INFO:self.USI: 99bb
2025-03-29 16:24:50,444:INFO:self._variable_keys: {'pipeline', '_available_plots', 'fold_groups_param', 'data', 'target_param', 'log_plots_param', 'exp_id', 'fold_generator', 'y', 'gpu_param', 'X', 'n_jobs_param', 'y_test', 'idx', 'memory', 'logging_param', 'seed', 'y_train', 'html_param', 'USI', 'X_train', '_ml_usecase', 'fold_shuffle_param', 'is_multiclass', 'exp_name_log', 'fix_imbalance', 'gpu_n_jobs_param', 'X_test'}
2025-03-29 16:24:50,445:INFO:Checking environment
2025-03-29 16:24:50,445:INFO:python_version: 3.10.16
2025-03-29 16:24:50,445:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:24:50,445:INFO:machine: AMD64
2025-03-29 16:24:50,445:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:24:50,451:INFO:Memory: svmem(total=33411727360, available=18805915648, percent=43.7, used=14605811712, free=18805915648)
2025-03-29 16:24:50,451:INFO:Physical Core: 6
2025-03-29 16:24:50,451:INFO:Logical Core: 12
2025-03-29 16:24:50,451:INFO:Checking libraries
2025-03-29 16:24:50,451:INFO:System:
2025-03-29 16:24:50,451:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:24:50,451:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:24:50,452:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:24:50,452:INFO:PyCaret required dependencies:
2025-03-29 16:24:50,452:INFO:                 pip: 25.0.1
2025-03-29 16:24:50,452:INFO:          setuptools: 75.8.2
2025-03-29 16:24:50,452:INFO:             pycaret: 3.3.2
2025-03-29 16:24:50,452:INFO:             IPython: 8.34.0
2025-03-29 16:24:50,452:INFO:          ipywidgets: 8.1.5
2025-03-29 16:24:50,453:INFO:                tqdm: 4.67.1
2025-03-29 16:24:50,453:INFO:               numpy: 1.26.4
2025-03-29 16:24:50,453:INFO:              pandas: 2.1.4
2025-03-29 16:24:50,453:INFO:              jinja2: 3.1.6
2025-03-29 16:24:50,453:INFO:               scipy: 1.11.4
2025-03-29 16:24:50,453:INFO:              joblib: 1.3.2
2025-03-29 16:24:50,453:INFO:             sklearn: 1.4.2
2025-03-29 16:24:50,453:INFO:                pyod: 2.0.2
2025-03-29 16:24:50,453:INFO:            imblearn: 0.13.0
2025-03-29 16:24:50,453:INFO:   category_encoders: 2.7.0
2025-03-29 16:24:50,453:INFO:            lightgbm: 4.6.0
2025-03-29 16:24:50,454:INFO:               numba: 0.61.0
2025-03-29 16:24:50,454:INFO:            requests: 2.32.3
2025-03-29 16:24:50,454:INFO:          matplotlib: 3.10.1
2025-03-29 16:24:50,454:INFO:          scikitplot: 0.3.7
2025-03-29 16:24:50,454:INFO:         yellowbrick: 1.5
2025-03-29 16:24:50,454:INFO:              plotly: 6.0.1
2025-03-29 16:24:50,454:INFO:    plotly-resampler: Not installed
2025-03-29 16:24:50,454:INFO:             kaleido: 0.2.1
2025-03-29 16:24:50,454:INFO:           schemdraw: 0.15
2025-03-29 16:24:50,454:INFO:         statsmodels: 0.14.4
2025-03-29 16:24:50,454:INFO:              sktime: 0.26.0
2025-03-29 16:24:50,454:INFO:               tbats: 1.1.3
2025-03-29 16:24:50,454:INFO:            pmdarima: 2.0.4
2025-03-29 16:24:50,454:INFO:              psutil: 7.0.0
2025-03-29 16:24:50,454:INFO:          markupsafe: 3.0.2
2025-03-29 16:24:50,454:INFO:             pickle5: Not installed
2025-03-29 16:24:50,454:INFO:         cloudpickle: 3.1.1
2025-03-29 16:24:50,454:INFO:         deprecation: 2.1.0
2025-03-29 16:24:50,454:INFO:              xxhash: 3.5.0
2025-03-29 16:24:50,454:INFO:           wurlitzer: 3.1.1
2025-03-29 16:24:50,454:INFO:PyCaret optional dependencies:
2025-03-29 16:24:50,454:INFO:                shap: Not installed
2025-03-29 16:24:50,454:INFO:           interpret: Not installed
2025-03-29 16:24:50,454:INFO:                umap: 0.5.7
2025-03-29 16:24:50,454:INFO:     ydata_profiling: Not installed
2025-03-29 16:24:50,454:INFO:  explainerdashboard: Not installed
2025-03-29 16:24:50,455:INFO:             autoviz: Not installed
2025-03-29 16:24:50,455:INFO:           fairlearn: Not installed
2025-03-29 16:24:50,455:INFO:          deepchecks: Not installed
2025-03-29 16:24:50,455:INFO:             xgboost: Not installed
2025-03-29 16:24:50,455:INFO:            catboost: Not installed
2025-03-29 16:24:50,455:INFO:              kmodes: Not installed
2025-03-29 16:24:50,455:INFO:             mlxtend: Not installed
2025-03-29 16:24:50,455:INFO:       statsforecast: Not installed
2025-03-29 16:24:50,455:INFO:        tune_sklearn: Not installed
2025-03-29 16:24:50,455:INFO:                 ray: Not installed
2025-03-29 16:24:50,455:INFO:            hyperopt: Not installed
2025-03-29 16:24:50,455:INFO:              optuna: Not installed
2025-03-29 16:24:50,455:INFO:               skopt: Not installed
2025-03-29 16:24:50,455:INFO:              mlflow: 2.21.2
2025-03-29 16:24:50,455:INFO:              gradio: Not installed
2025-03-29 16:24:50,455:INFO:             fastapi: 0.115.12
2025-03-29 16:24:50,455:INFO:             uvicorn: 0.34.0
2025-03-29 16:24:50,455:INFO:              m2cgen: Not installed
2025-03-29 16:24:50,455:INFO:           evidently: Not installed
2025-03-29 16:24:50,455:INFO:               fugue: Not installed
2025-03-29 16:24:50,455:INFO:           streamlit: 1.43.2
2025-03-29 16:24:50,455:INFO:             prophet: Not installed
2025-03-29 16:24:50,455:INFO:None
2025-03-29 16:24:50,455:INFO:Set up data.
2025-03-29 16:24:50,481:INFO:Set up folding strategy.
2025-03-29 16:24:50,481:INFO:Set up train/test split.
2025-03-29 16:24:50,492:INFO:Set up index.
2025-03-29 16:24:50,493:INFO:Assigning column types.
2025-03-29 16:24:50,495:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 16:24:50,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:24:50,524:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-29 16:24:50,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,574:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:24:50,575:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-29 16:24:50,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,592:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 16:24:50,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-29 16:24:50,635:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,662:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-29 16:24:50,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,679:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-29 16:24:50,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:50,765:INFO:Preparing preprocessing pipeline...
2025-03-29 16:24:50,766:INFO:Set up simple imputation.
2025-03-29 16:24:50,768:INFO:Set up encoding of ordinal features.
2025-03-29 16:24:50,769:INFO:Set up encoding of categorical features.
2025-03-29 16:24:50,834:INFO:Finished creating preprocessing pipeline.
2025-03-29 16:24:50,847:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['loan_amount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=No...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': lender     0
partner    1
NaN       -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['country', 'sector'],
                                    transformer=OneHotEncoder(cols=['country',
                                                                    'sector'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-03-29 16:24:50,847:INFO:Creating final display dataframe.
2025-03-29 16:24:51,000:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            status
2                   Target type            Binary
3           Original data shape         (6818, 7)
4        Transformed data shape        (6818, 22)
5   Transformed train set shape        (4772, 22)
6    Transformed test set shape        (2046, 22)
7               Ignore features                 1
8              Numeric features                 1
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              99bb
2025-03-29 16:24:51,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:51,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:51,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:51,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:24:51,095:INFO:setup() successfully completed in 0.65s...............
2025-03-29 16:24:55,390:INFO:Initializing compare_models()
2025-03-29 16:24:55,392:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-29 16:24:55,392:INFO:Checking exceptions
2025-03-29 16:24:55,395:INFO:Preparing display monitor
2025-03-29 16:24:55,414:INFO:Initializing Logistic Regression
2025-03-29 16:24:55,414:INFO:Total runtime is 0.0 minutes
2025-03-29 16:24:55,417:INFO:SubProcess create_model() called ==================================
2025-03-29 16:24:55,418:INFO:Initializing create_model()
2025-03-29 16:24:55,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:24:55,418:INFO:Checking exceptions
2025-03-29 16:24:55,418:INFO:Importing libraries
2025-03-29 16:24:55,418:INFO:Copying training dataset
2025-03-29 16:24:55,422:INFO:Defining folds
2025-03-29 16:24:55,422:INFO:Declaring metric variables
2025-03-29 16:24:55,425:INFO:Importing untrained model
2025-03-29 16:24:55,428:INFO:Logistic Regression Imported successfully
2025-03-29 16:24:55,433:INFO:Starting cross validation
2025-03-29 16:24:55,434:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:24:58,422:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-29 16:24:58,443:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-29 16:24:58,452:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-29 16:24:58,453:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-29 16:24:58,456:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-29 16:24:58,464:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-29 16:24:58,469:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-29 16:24:58,469:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-29 16:24:58,471:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-29 16:24:58,473:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-29 16:24:58,519:INFO:Calculating mean and std
2025-03-29 16:24:58,520:INFO:Creating metrics dataframe
2025-03-29 16:24:58,523:INFO:Uploading results into container
2025-03-29 16:24:58,523:INFO:Uploading model into container now
2025-03-29 16:24:58,524:INFO:_master_model_container: 1
2025-03-29 16:24:58,524:INFO:_display_container: 2
2025-03-29 16:24:58,524:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-29 16:24:58,524:INFO:create_model() successfully completed......................................
2025-03-29 16:24:58,690:INFO:SubProcess create_model() end ==================================
2025-03-29 16:24:58,690:INFO:Creating metrics dataframe
2025-03-29 16:24:58,694:INFO:Initializing K Neighbors Classifier
2025-03-29 16:24:58,694:INFO:Total runtime is 0.05465550422668457 minutes
2025-03-29 16:24:58,696:INFO:SubProcess create_model() called ==================================
2025-03-29 16:24:58,696:INFO:Initializing create_model()
2025-03-29 16:24:58,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:24:58,697:INFO:Checking exceptions
2025-03-29 16:24:58,697:INFO:Importing libraries
2025-03-29 16:24:58,697:INFO:Copying training dataset
2025-03-29 16:24:58,699:INFO:Defining folds
2025-03-29 16:24:58,700:INFO:Declaring metric variables
2025-03-29 16:24:58,702:INFO:Importing untrained model
2025-03-29 16:24:58,704:INFO:K Neighbors Classifier Imported successfully
2025-03-29 16:24:58,708:INFO:Starting cross validation
2025-03-29 16:24:58,709:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:00,517:INFO:Calculating mean and std
2025-03-29 16:25:00,518:INFO:Creating metrics dataframe
2025-03-29 16:25:00,519:INFO:Uploading results into container
2025-03-29 16:25:00,520:INFO:Uploading model into container now
2025-03-29 16:25:00,520:INFO:_master_model_container: 2
2025-03-29 16:25:00,520:INFO:_display_container: 2
2025-03-29 16:25:00,521:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-29 16:25:00,521:INFO:create_model() successfully completed......................................
2025-03-29 16:25:00,651:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:00,651:INFO:Creating metrics dataframe
2025-03-29 16:25:00,656:INFO:Initializing Naive Bayes
2025-03-29 16:25:00,656:INFO:Total runtime is 0.08735551834106445 minutes
2025-03-29 16:25:00,658:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:00,658:INFO:Initializing create_model()
2025-03-29 16:25:00,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:00,658:INFO:Checking exceptions
2025-03-29 16:25:00,658:INFO:Importing libraries
2025-03-29 16:25:00,658:INFO:Copying training dataset
2025-03-29 16:25:00,661:INFO:Defining folds
2025-03-29 16:25:00,661:INFO:Declaring metric variables
2025-03-29 16:25:00,664:INFO:Importing untrained model
2025-03-29 16:25:00,666:INFO:Naive Bayes Imported successfully
2025-03-29 16:25:00,670:INFO:Starting cross validation
2025-03-29 16:25:00,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:00,781:INFO:Calculating mean and std
2025-03-29 16:25:00,782:INFO:Creating metrics dataframe
2025-03-29 16:25:00,783:INFO:Uploading results into container
2025-03-29 16:25:00,783:INFO:Uploading model into container now
2025-03-29 16:25:00,784:INFO:_master_model_container: 3
2025-03-29 16:25:00,784:INFO:_display_container: 2
2025-03-29 16:25:00,784:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-29 16:25:00,784:INFO:create_model() successfully completed......................................
2025-03-29 16:25:00,903:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:00,903:INFO:Creating metrics dataframe
2025-03-29 16:25:00,907:INFO:Initializing Decision Tree Classifier
2025-03-29 16:25:00,907:INFO:Total runtime is 0.09153897762298584 minutes
2025-03-29 16:25:00,909:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:00,910:INFO:Initializing create_model()
2025-03-29 16:25:00,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:00,910:INFO:Checking exceptions
2025-03-29 16:25:00,910:INFO:Importing libraries
2025-03-29 16:25:00,910:INFO:Copying training dataset
2025-03-29 16:25:00,912:INFO:Defining folds
2025-03-29 16:25:00,913:INFO:Declaring metric variables
2025-03-29 16:25:00,915:INFO:Importing untrained model
2025-03-29 16:25:00,917:INFO:Decision Tree Classifier Imported successfully
2025-03-29 16:25:00,921:INFO:Starting cross validation
2025-03-29 16:25:00,922:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:01,042:INFO:Calculating mean and std
2025-03-29 16:25:01,043:INFO:Creating metrics dataframe
2025-03-29 16:25:01,044:INFO:Uploading results into container
2025-03-29 16:25:01,045:INFO:Uploading model into container now
2025-03-29 16:25:01,045:INFO:_master_model_container: 4
2025-03-29 16:25:01,045:INFO:_display_container: 2
2025-03-29 16:25:01,045:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-03-29 16:25:01,046:INFO:create_model() successfully completed......................................
2025-03-29 16:25:01,164:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:01,164:INFO:Creating metrics dataframe
2025-03-29 16:25:01,169:INFO:Initializing SVM - Linear Kernel
2025-03-29 16:25:01,169:INFO:Total runtime is 0.09590568939844767 minutes
2025-03-29 16:25:01,171:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:01,171:INFO:Initializing create_model()
2025-03-29 16:25:01,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:01,171:INFO:Checking exceptions
2025-03-29 16:25:01,171:INFO:Importing libraries
2025-03-29 16:25:01,172:INFO:Copying training dataset
2025-03-29 16:25:01,174:INFO:Defining folds
2025-03-29 16:25:01,174:INFO:Declaring metric variables
2025-03-29 16:25:01,176:INFO:Importing untrained model
2025-03-29 16:25:01,178:INFO:SVM - Linear Kernel Imported successfully
2025-03-29 16:25:01,182:INFO:Starting cross validation
2025-03-29 16:25:01,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:01,320:INFO:Calculating mean and std
2025-03-29 16:25:01,321:INFO:Creating metrics dataframe
2025-03-29 16:25:01,322:INFO:Uploading results into container
2025-03-29 16:25:01,322:INFO:Uploading model into container now
2025-03-29 16:25:01,323:INFO:_master_model_container: 5
2025-03-29 16:25:01,323:INFO:_display_container: 2
2025-03-29 16:25:01,323:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-29 16:25:01,323:INFO:create_model() successfully completed......................................
2025-03-29 16:25:01,445:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:01,445:INFO:Creating metrics dataframe
2025-03-29 16:25:01,450:INFO:Initializing Ridge Classifier
2025-03-29 16:25:01,450:INFO:Total runtime is 0.10059249401092529 minutes
2025-03-29 16:25:01,452:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:01,453:INFO:Initializing create_model()
2025-03-29 16:25:01,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:01,453:INFO:Checking exceptions
2025-03-29 16:25:01,453:INFO:Importing libraries
2025-03-29 16:25:01,453:INFO:Copying training dataset
2025-03-29 16:25:01,455:INFO:Defining folds
2025-03-29 16:25:01,455:INFO:Declaring metric variables
2025-03-29 16:25:01,457:INFO:Importing untrained model
2025-03-29 16:25:01,459:INFO:Ridge Classifier Imported successfully
2025-03-29 16:25:01,463:INFO:Starting cross validation
2025-03-29 16:25:01,465:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:01,585:INFO:Calculating mean and std
2025-03-29 16:25:01,586:INFO:Creating metrics dataframe
2025-03-29 16:25:01,587:INFO:Uploading results into container
2025-03-29 16:25:01,587:INFO:Uploading model into container now
2025-03-29 16:25:01,588:INFO:_master_model_container: 6
2025-03-29 16:25:01,588:INFO:_display_container: 2
2025-03-29 16:25:01,588:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-03-29 16:25:01,588:INFO:create_model() successfully completed......................................
2025-03-29 16:25:01,709:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:01,709:INFO:Creating metrics dataframe
2025-03-29 16:25:01,714:INFO:Initializing Random Forest Classifier
2025-03-29 16:25:01,714:INFO:Total runtime is 0.10499249299367269 minutes
2025-03-29 16:25:01,716:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:01,716:INFO:Initializing create_model()
2025-03-29 16:25:01,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:01,716:INFO:Checking exceptions
2025-03-29 16:25:01,716:INFO:Importing libraries
2025-03-29 16:25:01,716:INFO:Copying training dataset
2025-03-29 16:25:01,719:INFO:Defining folds
2025-03-29 16:25:01,719:INFO:Declaring metric variables
2025-03-29 16:25:01,721:INFO:Importing untrained model
2025-03-29 16:25:01,723:INFO:Random Forest Classifier Imported successfully
2025-03-29 16:25:01,727:INFO:Starting cross validation
2025-03-29 16:25:01,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:02,141:INFO:Calculating mean and std
2025-03-29 16:25:02,142:INFO:Creating metrics dataframe
2025-03-29 16:25:02,143:INFO:Uploading results into container
2025-03-29 16:25:02,143:INFO:Uploading model into container now
2025-03-29 16:25:02,144:INFO:_master_model_container: 7
2025-03-29 16:25:02,144:INFO:_display_container: 2
2025-03-29 16:25:02,144:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-29 16:25:02,144:INFO:create_model() successfully completed......................................
2025-03-29 16:25:02,260:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:02,260:INFO:Creating metrics dataframe
2025-03-29 16:25:02,265:INFO:Initializing Quadratic Discriminant Analysis
2025-03-29 16:25:02,265:INFO:Total runtime is 0.11417185465494792 minutes
2025-03-29 16:25:02,267:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:02,267:INFO:Initializing create_model()
2025-03-29 16:25:02,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:02,267:INFO:Checking exceptions
2025-03-29 16:25:02,267:INFO:Importing libraries
2025-03-29 16:25:02,267:INFO:Copying training dataset
2025-03-29 16:25:02,270:INFO:Defining folds
2025-03-29 16:25:02,270:INFO:Declaring metric variables
2025-03-29 16:25:02,273:INFO:Importing untrained model
2025-03-29 16:25:02,275:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-29 16:25:02,279:INFO:Starting cross validation
2025-03-29 16:25:02,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:02,342:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 16:25:02,344:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 16:25:02,346:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 16:25:02,348:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 16:25:02,351:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 16:25:02,351:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 16:25:02,353:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 16:25:02,353:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 16:25:02,356:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 16:25:02,360:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-29 16:25:02,366:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,366:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,367:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,367:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,367:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,368:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,368:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,368:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,368:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,368:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,368:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,368:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,369:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,369:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,370:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,370:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,370:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,370:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,371:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-03-29 16:25:02,372:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,372:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,372:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,373:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-03-29 16:25:02,373:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-03-29 16:25:02,373:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,373:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,374:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,374:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,374:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,374:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,374:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,374:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,374:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,375:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,376:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,376:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,376:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,376:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,376:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,376:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,376:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,376:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,376:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,377:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,377:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,378:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-03-29 16:25:02,378:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,378:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,378:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,378:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,378:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,378:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,379:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,379:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-03-29 16:25:02,379:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,379:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,380:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,380:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,380:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-03-29 16:25:02,380:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,382:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-03-29 16:25:02,383:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-03-29 16:25:02,383:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-03-29 16:25:02,384:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,384:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,384:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,386:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,386:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-03-29 16:25:02,386:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-03-29 16:25:02,388:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-03-29 16:25:02,408:INFO:Calculating mean and std
2025-03-29 16:25:02,409:INFO:Creating metrics dataframe
2025-03-29 16:25:02,410:INFO:Uploading results into container
2025-03-29 16:25:02,410:INFO:Uploading model into container now
2025-03-29 16:25:02,410:INFO:_master_model_container: 8
2025-03-29 16:25:02,411:INFO:_display_container: 2
2025-03-29 16:25:02,411:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-29 16:25:02,411:INFO:create_model() successfully completed......................................
2025-03-29 16:25:02,529:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:02,529:INFO:Creating metrics dataframe
2025-03-29 16:25:02,534:INFO:Initializing Ada Boost Classifier
2025-03-29 16:25:02,534:INFO:Total runtime is 0.11866196791330974 minutes
2025-03-29 16:25:02,536:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:02,536:INFO:Initializing create_model()
2025-03-29 16:25:02,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:02,537:INFO:Checking exceptions
2025-03-29 16:25:02,537:INFO:Importing libraries
2025-03-29 16:25:02,537:INFO:Copying training dataset
2025-03-29 16:25:02,539:INFO:Defining folds
2025-03-29 16:25:02,539:INFO:Declaring metric variables
2025-03-29 16:25:02,541:INFO:Importing untrained model
2025-03-29 16:25:02,543:INFO:Ada Boost Classifier Imported successfully
2025-03-29 16:25:02,547:INFO:Starting cross validation
2025-03-29 16:25:02,549:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:02,614:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 16:25:02,615:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 16:25:02,617:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 16:25:02,619:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 16:25:02,619:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 16:25:02,620:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 16:25:02,620:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 16:25:02,621:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 16:25:02,624:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 16:25:02,626:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-29 16:25:02,790:INFO:Calculating mean and std
2025-03-29 16:25:02,791:INFO:Creating metrics dataframe
2025-03-29 16:25:02,792:INFO:Uploading results into container
2025-03-29 16:25:02,792:INFO:Uploading model into container now
2025-03-29 16:25:02,793:INFO:_master_model_container: 9
2025-03-29 16:25:02,793:INFO:_display_container: 2
2025-03-29 16:25:02,793:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-03-29 16:25:02,793:INFO:create_model() successfully completed......................................
2025-03-29 16:25:02,910:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:02,910:INFO:Creating metrics dataframe
2025-03-29 16:25:02,916:INFO:Initializing Gradient Boosting Classifier
2025-03-29 16:25:02,916:INFO:Total runtime is 0.12502877314885458 minutes
2025-03-29 16:25:02,918:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:02,918:INFO:Initializing create_model()
2025-03-29 16:25:02,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:02,918:INFO:Checking exceptions
2025-03-29 16:25:02,918:INFO:Importing libraries
2025-03-29 16:25:02,918:INFO:Copying training dataset
2025-03-29 16:25:02,921:INFO:Defining folds
2025-03-29 16:25:02,921:INFO:Declaring metric variables
2025-03-29 16:25:02,923:INFO:Importing untrained model
2025-03-29 16:25:02,925:INFO:Gradient Boosting Classifier Imported successfully
2025-03-29 16:25:02,929:INFO:Starting cross validation
2025-03-29 16:25:02,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:03,268:INFO:Calculating mean and std
2025-03-29 16:25:03,269:INFO:Creating metrics dataframe
2025-03-29 16:25:03,270:INFO:Uploading results into container
2025-03-29 16:25:03,270:INFO:Uploading model into container now
2025-03-29 16:25:03,270:INFO:_master_model_container: 10
2025-03-29 16:25:03,271:INFO:_display_container: 2
2025-03-29 16:25:03,271:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:25:03,271:INFO:create_model() successfully completed......................................
2025-03-29 16:25:03,390:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:03,390:INFO:Creating metrics dataframe
2025-03-29 16:25:03,396:INFO:Initializing Linear Discriminant Analysis
2025-03-29 16:25:03,396:INFO:Total runtime is 0.13302958408991497 minutes
2025-03-29 16:25:03,398:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:03,398:INFO:Initializing create_model()
2025-03-29 16:25:03,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:03,399:INFO:Checking exceptions
2025-03-29 16:25:03,399:INFO:Importing libraries
2025-03-29 16:25:03,399:INFO:Copying training dataset
2025-03-29 16:25:03,401:INFO:Defining folds
2025-03-29 16:25:03,402:INFO:Declaring metric variables
2025-03-29 16:25:03,404:INFO:Importing untrained model
2025-03-29 16:25:03,406:INFO:Linear Discriminant Analysis Imported successfully
2025-03-29 16:25:03,409:INFO:Starting cross validation
2025-03-29 16:25:03,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:03,518:INFO:Calculating mean and std
2025-03-29 16:25:03,519:INFO:Creating metrics dataframe
2025-03-29 16:25:03,520:INFO:Uploading results into container
2025-03-29 16:25:03,520:INFO:Uploading model into container now
2025-03-29 16:25:03,521:INFO:_master_model_container: 11
2025-03-29 16:25:03,521:INFO:_display_container: 2
2025-03-29 16:25:03,521:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-29 16:25:03,521:INFO:create_model() successfully completed......................................
2025-03-29 16:25:03,639:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:03,639:INFO:Creating metrics dataframe
2025-03-29 16:25:03,645:INFO:Initializing Extra Trees Classifier
2025-03-29 16:25:03,645:INFO:Total runtime is 0.13717962106068932 minutes
2025-03-29 16:25:03,648:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:03,648:INFO:Initializing create_model()
2025-03-29 16:25:03,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:03,648:INFO:Checking exceptions
2025-03-29 16:25:03,648:INFO:Importing libraries
2025-03-29 16:25:03,648:INFO:Copying training dataset
2025-03-29 16:25:03,651:INFO:Defining folds
2025-03-29 16:25:03,651:INFO:Declaring metric variables
2025-03-29 16:25:03,653:INFO:Importing untrained model
2025-03-29 16:25:03,655:INFO:Extra Trees Classifier Imported successfully
2025-03-29 16:25:03,659:INFO:Starting cross validation
2025-03-29 16:25:03,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:04,047:INFO:Calculating mean and std
2025-03-29 16:25:04,048:INFO:Creating metrics dataframe
2025-03-29 16:25:04,049:INFO:Uploading results into container
2025-03-29 16:25:04,049:INFO:Uploading model into container now
2025-03-29 16:25:04,050:INFO:_master_model_container: 12
2025-03-29 16:25:04,050:INFO:_display_container: 2
2025-03-29 16:25:04,050:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-03-29 16:25:04,050:INFO:create_model() successfully completed......................................
2025-03-29 16:25:04,168:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:04,168:INFO:Creating metrics dataframe
2025-03-29 16:25:04,174:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 16:25:04,174:INFO:Total runtime is 0.14598822593688968 minutes
2025-03-29 16:25:04,176:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:04,176:INFO:Initializing create_model()
2025-03-29 16:25:04,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:04,176:INFO:Checking exceptions
2025-03-29 16:25:04,176:INFO:Importing libraries
2025-03-29 16:25:04,176:INFO:Copying training dataset
2025-03-29 16:25:04,179:INFO:Defining folds
2025-03-29 16:25:04,179:INFO:Declaring metric variables
2025-03-29 16:25:04,181:INFO:Importing untrained model
2025-03-29 16:25:04,183:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:25:04,187:INFO:Starting cross validation
2025-03-29 16:25:04,189:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:04,753:INFO:Calculating mean and std
2025-03-29 16:25:04,754:INFO:Creating metrics dataframe
2025-03-29 16:25:04,755:INFO:Uploading results into container
2025-03-29 16:25:04,756:INFO:Uploading model into container now
2025-03-29 16:25:04,756:INFO:_master_model_container: 13
2025-03-29 16:25:04,756:INFO:_display_container: 2
2025-03-29 16:25:04,757:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:25:04,757:INFO:create_model() successfully completed......................................
2025-03-29 16:25:04,895:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:04,895:INFO:Creating metrics dataframe
2025-03-29 16:25:04,901:INFO:Initializing Dummy Classifier
2025-03-29 16:25:04,902:INFO:Total runtime is 0.15812157392501833 minutes
2025-03-29 16:25:04,903:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:04,904:INFO:Initializing create_model()
2025-03-29 16:25:04,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002422F8397B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:04,904:INFO:Checking exceptions
2025-03-29 16:25:04,904:INFO:Importing libraries
2025-03-29 16:25:04,904:INFO:Copying training dataset
2025-03-29 16:25:04,906:INFO:Defining folds
2025-03-29 16:25:04,906:INFO:Declaring metric variables
2025-03-29 16:25:04,908:INFO:Importing untrained model
2025-03-29 16:25:04,911:INFO:Dummy Classifier Imported successfully
2025-03-29 16:25:04,915:INFO:Starting cross validation
2025-03-29 16:25:04,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:05,000:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 16:25:05,001:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 16:25:05,003:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 16:25:05,003:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 16:25:05,004:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 16:25:05,004:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 16:25:05,004:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 16:25:05,008:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 16:25:05,008:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 16:25:05,009:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-29 16:25:05,019:INFO:Calculating mean and std
2025-03-29 16:25:05,020:INFO:Creating metrics dataframe
2025-03-29 16:25:05,021:INFO:Uploading results into container
2025-03-29 16:25:05,021:INFO:Uploading model into container now
2025-03-29 16:25:05,022:INFO:_master_model_container: 14
2025-03-29 16:25:05,022:INFO:_display_container: 2
2025-03-29 16:25:05,022:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-03-29 16:25:05,022:INFO:create_model() successfully completed......................................
2025-03-29 16:25:05,139:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:05,139:INFO:Creating metrics dataframe
2025-03-29 16:25:05,145:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-29 16:25:05,150:INFO:Initializing create_model()
2025-03-29 16:25:05,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:05,151:INFO:Checking exceptions
2025-03-29 16:25:05,152:INFO:Importing libraries
2025-03-29 16:25:05,152:INFO:Copying training dataset
2025-03-29 16:25:05,154:INFO:Defining folds
2025-03-29 16:25:05,154:INFO:Declaring metric variables
2025-03-29 16:25:05,154:INFO:Importing untrained model
2025-03-29 16:25:05,154:INFO:Declaring custom model
2025-03-29 16:25:05,154:INFO:Gradient Boosting Classifier Imported successfully
2025-03-29 16:25:05,155:INFO:Cross validation set to False
2025-03-29 16:25:05,155:INFO:Fitting Model
2025-03-29 16:25:05,369:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:25:05,369:INFO:create_model() successfully completed......................................
2025-03-29 16:25:05,504:INFO:_master_model_container: 14
2025-03-29 16:25:05,504:INFO:_display_container: 2
2025-03-29 16:25:05,504:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:25:05,504:INFO:compare_models() successfully completed......................................
2025-03-29 16:25:05,517:INFO:Initializing tune_model()
2025-03-29 16:25:05,517:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>)
2025-03-29 16:25:05,517:INFO:Checking exceptions
2025-03-29 16:25:05,527:INFO:Copying training dataset
2025-03-29 16:25:05,529:INFO:Checking base model
2025-03-29 16:25:05,530:INFO:Base model : Gradient Boosting Classifier
2025-03-29 16:25:05,532:INFO:Declaring metric variables
2025-03-29 16:25:05,534:INFO:Defining Hyperparameters
2025-03-29 16:25:05,666:INFO:Tuning with n_jobs=-1
2025-03-29 16:25:05,667:INFO:Initializing RandomizedSearchCV
2025-03-29 16:25:10,470:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2025-03-29 16:25:10,470:INFO:Hyperparameter search completed
2025-03-29 16:25:10,471:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:10,471:INFO:Initializing create_model()
2025-03-29 16:25:10,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002423EBDE9E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2025-03-29 16:25:10,471:INFO:Checking exceptions
2025-03-29 16:25:10,471:INFO:Importing libraries
2025-03-29 16:25:10,471:INFO:Copying training dataset
2025-03-29 16:25:10,474:INFO:Defining folds
2025-03-29 16:25:10,474:INFO:Declaring metric variables
2025-03-29 16:25:10,476:INFO:Importing untrained model
2025-03-29 16:25:10,476:INFO:Declaring custom model
2025-03-29 16:25:10,478:INFO:Gradient Boosting Classifier Imported successfully
2025-03-29 16:25:10,482:INFO:Starting cross validation
2025-03-29 16:25:10,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:10,766:INFO:Calculating mean and std
2025-03-29 16:25:10,767:INFO:Creating metrics dataframe
2025-03-29 16:25:10,770:INFO:Finalizing model
2025-03-29 16:25:10,945:INFO:Uploading results into container
2025-03-29 16:25:10,945:INFO:Uploading model into container now
2025-03-29 16:25:10,946:INFO:_master_model_container: 15
2025-03-29 16:25:10,946:INFO:_display_container: 3
2025-03-29 16:25:10,946:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:25:10,946:INFO:create_model() successfully completed......................................
2025-03-29 16:25:11,069:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:11,069:INFO:choose_better activated
2025-03-29 16:25:11,071:INFO:SubProcess create_model() called ==================================
2025-03-29 16:25:11,072:INFO:Initializing create_model()
2025-03-29 16:25:11,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:11,072:INFO:Checking exceptions
2025-03-29 16:25:11,073:INFO:Importing libraries
2025-03-29 16:25:11,073:INFO:Copying training dataset
2025-03-29 16:25:11,075:INFO:Defining folds
2025-03-29 16:25:11,075:INFO:Declaring metric variables
2025-03-29 16:25:11,075:INFO:Importing untrained model
2025-03-29 16:25:11,075:INFO:Declaring custom model
2025-03-29 16:25:11,076:INFO:Gradient Boosting Classifier Imported successfully
2025-03-29 16:25:11,076:INFO:Starting cross validation
2025-03-29 16:25:11,077:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:25:11,412:INFO:Calculating mean and std
2025-03-29 16:25:11,413:INFO:Creating metrics dataframe
2025-03-29 16:25:11,415:INFO:Finalizing model
2025-03-29 16:25:11,633:INFO:Uploading results into container
2025-03-29 16:25:11,633:INFO:Uploading model into container now
2025-03-29 16:25:11,633:INFO:_master_model_container: 16
2025-03-29 16:25:11,633:INFO:_display_container: 4
2025-03-29 16:25:11,634:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:25:11,634:INFO:create_model() successfully completed......................................
2025-03-29 16:25:11,755:INFO:SubProcess create_model() end ==================================
2025-03-29 16:25:11,756:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8959
2025-03-29 16:25:11,756:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8935
2025-03-29 16:25:11,756:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-03-29 16:25:11,756:INFO:choose_better completed
2025-03-29 16:25:11,757:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-29 16:25:11,763:INFO:_master_model_container: 16
2025-03-29 16:25:11,763:INFO:_display_container: 3
2025-03-29 16:25:11,763:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:25:11,763:INFO:tune_model() successfully completed......................................
2025-03-29 16:25:26,875:INFO:Initializing finalize_model()
2025-03-29 16:25:26,875:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-29 16:25:26,876:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:25:26,878:INFO:Initializing create_model()
2025-03-29 16:25:26,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002422F9B5870>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:25:26,878:INFO:Checking exceptions
2025-03-29 16:25:26,879:INFO:Importing libraries
2025-03-29 16:25:26,879:INFO:Copying training dataset
2025-03-29 16:25:26,879:INFO:Defining folds
2025-03-29 16:25:26,879:INFO:Declaring metric variables
2025-03-29 16:25:26,880:INFO:Importing untrained model
2025-03-29 16:25:26,880:INFO:Declaring custom model
2025-03-29 16:25:26,880:INFO:Gradient Boosting Classifier Imported successfully
2025-03-29 16:25:26,881:INFO:Cross validation set to False
2025-03-29 16:25:26,881:INFO:Fitting Model
2025-03-29 16:25:27,199:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['loan_amount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['country', 'gender', 'nonpayme...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-03-29 16:25:27,199:INFO:create_model() successfully completed......................................
2025-03-29 16:25:27,323:INFO:_master_model_container: 16
2025-03-29 16:25:27,323:INFO:_display_container: 3
2025-03-29 16:25:27,337:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['loan_amount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['country', 'gender', 'nonpayme...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-03-29 16:25:27,337:INFO:finalize_model() successfully completed......................................
2025-03-29 16:51:19,654:INFO:PyCaret RegressionExperiment
2025-03-29 16:51:19,655:INFO:Logging name: reg-default-name
2025-03-29 16:51:19,655:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 16:51:19,655:INFO:version 3.3.2
2025-03-29 16:51:19,655:INFO:Initializing setup()
2025-03-29 16:51:19,655:INFO:self.USI: 5359
2025-03-29 16:51:19,656:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 16:51:19,656:INFO:Checking environment
2025-03-29 16:51:19,656:INFO:python_version: 3.10.16
2025-03-29 16:51:19,656:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:51:19,656:INFO:machine: AMD64
2025-03-29 16:51:19,656:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:51:19,660:INFO:Memory: svmem(total=33411727360, available=17997905920, percent=46.1, used=15413821440, free=17997905920)
2025-03-29 16:51:19,660:INFO:Physical Core: 6
2025-03-29 16:51:19,661:INFO:Logical Core: 12
2025-03-29 16:51:19,661:INFO:Checking libraries
2025-03-29 16:51:19,661:INFO:System:
2025-03-29 16:51:19,661:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:51:19,661:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:51:19,661:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:51:19,661:INFO:PyCaret required dependencies:
2025-03-29 16:51:19,662:INFO:                 pip: 25.0.1
2025-03-29 16:51:19,662:INFO:          setuptools: 75.8.2
2025-03-29 16:51:19,662:INFO:             pycaret: 3.3.2
2025-03-29 16:51:19,662:INFO:             IPython: 8.34.0
2025-03-29 16:51:19,662:INFO:          ipywidgets: 8.1.5
2025-03-29 16:51:19,662:INFO:                tqdm: 4.67.1
2025-03-29 16:51:19,662:INFO:               numpy: 1.26.4
2025-03-29 16:51:19,663:INFO:              pandas: 2.1.4
2025-03-29 16:51:19,663:INFO:              jinja2: 3.1.6
2025-03-29 16:51:19,663:INFO:               scipy: 1.11.4
2025-03-29 16:51:19,663:INFO:              joblib: 1.3.2
2025-03-29 16:51:19,663:INFO:             sklearn: 1.4.2
2025-03-29 16:51:19,663:INFO:                pyod: 2.0.2
2025-03-29 16:51:19,663:INFO:            imblearn: 0.13.0
2025-03-29 16:51:19,663:INFO:   category_encoders: 2.7.0
2025-03-29 16:51:19,664:INFO:            lightgbm: 4.6.0
2025-03-29 16:51:19,664:INFO:               numba: 0.61.0
2025-03-29 16:51:19,664:INFO:            requests: 2.32.3
2025-03-29 16:51:19,664:INFO:          matplotlib: 3.10.1
2025-03-29 16:51:19,664:INFO:          scikitplot: 0.3.7
2025-03-29 16:51:19,664:INFO:         yellowbrick: 1.5
2025-03-29 16:51:19,664:INFO:              plotly: 6.0.1
2025-03-29 16:51:19,664:INFO:    plotly-resampler: Not installed
2025-03-29 16:51:19,664:INFO:             kaleido: 0.2.1
2025-03-29 16:51:19,664:INFO:           schemdraw: 0.15
2025-03-29 16:51:19,664:INFO:         statsmodels: 0.14.4
2025-03-29 16:51:19,665:INFO:              sktime: 0.26.0
2025-03-29 16:51:19,665:INFO:               tbats: 1.1.3
2025-03-29 16:51:19,665:INFO:            pmdarima: 2.0.4
2025-03-29 16:51:19,665:INFO:              psutil: 7.0.0
2025-03-29 16:51:19,665:INFO:          markupsafe: 3.0.2
2025-03-29 16:51:19,665:INFO:             pickle5: Not installed
2025-03-29 16:51:19,665:INFO:         cloudpickle: 3.1.1
2025-03-29 16:51:19,665:INFO:         deprecation: 2.1.0
2025-03-29 16:51:19,665:INFO:              xxhash: 3.5.0
2025-03-29 16:51:19,665:INFO:           wurlitzer: 3.1.1
2025-03-29 16:51:19,665:INFO:PyCaret optional dependencies:
2025-03-29 16:51:19,665:INFO:                shap: Not installed
2025-03-29 16:51:19,665:INFO:           interpret: Not installed
2025-03-29 16:51:19,665:INFO:                umap: 0.5.7
2025-03-29 16:51:19,665:INFO:     ydata_profiling: Not installed
2025-03-29 16:51:19,666:INFO:  explainerdashboard: Not installed
2025-03-29 16:51:19,666:INFO:             autoviz: Not installed
2025-03-29 16:51:19,666:INFO:           fairlearn: Not installed
2025-03-29 16:51:19,666:INFO:          deepchecks: Not installed
2025-03-29 16:51:19,666:INFO:             xgboost: Not installed
2025-03-29 16:51:19,666:INFO:            catboost: Not installed
2025-03-29 16:51:19,666:INFO:              kmodes: Not installed
2025-03-29 16:51:19,666:INFO:             mlxtend: Not installed
2025-03-29 16:51:19,666:INFO:       statsforecast: Not installed
2025-03-29 16:51:19,666:INFO:        tune_sklearn: Not installed
2025-03-29 16:51:19,666:INFO:                 ray: Not installed
2025-03-29 16:51:19,666:INFO:            hyperopt: Not installed
2025-03-29 16:51:19,666:INFO:              optuna: Not installed
2025-03-29 16:51:19,666:INFO:               skopt: Not installed
2025-03-29 16:51:19,666:INFO:              mlflow: 2.21.2
2025-03-29 16:51:19,666:INFO:              gradio: Not installed
2025-03-29 16:51:19,666:INFO:             fastapi: 0.115.12
2025-03-29 16:51:19,666:INFO:             uvicorn: 0.34.0
2025-03-29 16:51:19,666:INFO:              m2cgen: Not installed
2025-03-29 16:51:19,666:INFO:           evidently: Not installed
2025-03-29 16:51:19,666:INFO:               fugue: Not installed
2025-03-29 16:51:19,666:INFO:           streamlit: 1.43.2
2025-03-29 16:51:19,666:INFO:             prophet: Not installed
2025-03-29 16:51:19,666:INFO:None
2025-03-29 16:51:19,666:INFO:Set up data.
2025-03-29 16:51:19,673:INFO:Set up folding strategy.
2025-03-29 16:51:19,674:INFO:Set up train/test split.
2025-03-29 16:51:19,679:INFO:Set up index.
2025-03-29 16:51:19,679:INFO:Assigning column types.
2025-03-29 16:51:19,683:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 16:51:19,683:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,689:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,728:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:19,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:19,758:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,760:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,763:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,801:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,829:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:19,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:19,830:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 16:51:19,833:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,835:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,873:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:19,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:19,903:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,906:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:51:19,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:19,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:19,973:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 16:51:19,979:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,045:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,051:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,131:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,131:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 16:51:20,173:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,203:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,203:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,251:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,278:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,279:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 16:51:20,320:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,349:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,392:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:51:20,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,417:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 16:51:20,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,550:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,551:INFO:Preparing preprocessing pipeline...
2025-03-29 16:51:20,551:INFO:Set up simple imputation.
2025-03-29 16:51:20,555:INFO:Set up encoding of categorical features.
2025-03-29 16:51:20,556:INFO:Set up column name cleaning.
2025-03-29 16:51:20,661:INFO:Finished creating preprocessing pipeline.
2025-03-29 16:51:20,666:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_i...
                                    include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-03-29 16:51:20,667:INFO:Creating final display dataframe.
2025-03-29 16:51:20,877:INFO:Setup _display_container:                     Description             Value
0                    Session id              8428
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              5359
2025-03-29 16:51:20,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:20,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:21,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:21,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:51:21,012:INFO:setup() successfully completed in 1.36s...............
2025-03-29 16:53:14,889:INFO:Initializing compare_models()
2025-03-29 16:53:14,890:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-29 16:53:14,890:INFO:Checking exceptions
2025-03-29 16:53:14,894:INFO:Preparing display monitor
2025-03-29 16:53:14,908:INFO:Initializing Linear Regression
2025-03-29 16:53:14,908:INFO:Total runtime is 0.0 minutes
2025-03-29 16:53:14,910:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:14,910:INFO:Initializing create_model()
2025-03-29 16:53:14,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:14,910:INFO:Checking exceptions
2025-03-29 16:53:14,910:INFO:Importing libraries
2025-03-29 16:53:14,910:INFO:Copying training dataset
2025-03-29 16:53:14,919:INFO:Defining folds
2025-03-29 16:53:14,919:INFO:Declaring metric variables
2025-03-29 16:53:14,921:INFO:Importing untrained model
2025-03-29 16:53:14,923:INFO:Linear Regression Imported successfully
2025-03-29 16:53:14,926:INFO:Starting cross validation
2025-03-29 16:53:14,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:17,884:INFO:Calculating mean and std
2025-03-29 16:53:17,886:INFO:Creating metrics dataframe
2025-03-29 16:53:17,887:INFO:Uploading results into container
2025-03-29 16:53:17,888:INFO:Uploading model into container now
2025-03-29 16:53:17,888:INFO:_master_model_container: 1
2025-03-29 16:53:17,888:INFO:_display_container: 2
2025-03-29 16:53:17,888:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-03-29 16:53:17,888:INFO:create_model() successfully completed......................................
2025-03-29 16:53:18,066:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:18,066:INFO:Creating metrics dataframe
2025-03-29 16:53:18,070:INFO:Initializing Lasso Regression
2025-03-29 16:53:18,070:INFO:Total runtime is 0.05269668896993001 minutes
2025-03-29 16:53:18,072:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:18,072:INFO:Initializing create_model()
2025-03-29 16:53:18,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:18,072:INFO:Checking exceptions
2025-03-29 16:53:18,072:INFO:Importing libraries
2025-03-29 16:53:18,072:INFO:Copying training dataset
2025-03-29 16:53:18,079:INFO:Defining folds
2025-03-29 16:53:18,079:INFO:Declaring metric variables
2025-03-29 16:53:18,082:INFO:Importing untrained model
2025-03-29 16:53:18,084:INFO:Lasso Regression Imported successfully
2025-03-29 16:53:18,088:INFO:Starting cross validation
2025-03-29 16:53:18,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:19,807:INFO:Calculating mean and std
2025-03-29 16:53:19,808:INFO:Creating metrics dataframe
2025-03-29 16:53:19,809:INFO:Uploading results into container
2025-03-29 16:53:19,810:INFO:Uploading model into container now
2025-03-29 16:53:19,810:INFO:_master_model_container: 2
2025-03-29 16:53:19,810:INFO:_display_container: 2
2025-03-29 16:53:19,811:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=8428, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-03-29 16:53:19,811:INFO:create_model() successfully completed......................................
2025-03-29 16:53:19,976:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:19,976:INFO:Creating metrics dataframe
2025-03-29 16:53:19,981:INFO:Initializing Ridge Regression
2025-03-29 16:53:19,981:INFO:Total runtime is 0.08454763491948444 minutes
2025-03-29 16:53:19,983:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:19,983:INFO:Initializing create_model()
2025-03-29 16:53:19,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:19,983:INFO:Checking exceptions
2025-03-29 16:53:19,983:INFO:Importing libraries
2025-03-29 16:53:19,983:INFO:Copying training dataset
2025-03-29 16:53:19,990:INFO:Defining folds
2025-03-29 16:53:19,990:INFO:Declaring metric variables
2025-03-29 16:53:19,992:INFO:Importing untrained model
2025-03-29 16:53:19,995:INFO:Ridge Regression Imported successfully
2025-03-29 16:53:19,999:INFO:Starting cross validation
2025-03-29 16:53:20,000:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:20,214:INFO:Calculating mean and std
2025-03-29 16:53:20,215:INFO:Creating metrics dataframe
2025-03-29 16:53:20,216:INFO:Uploading results into container
2025-03-29 16:53:20,216:INFO:Uploading model into container now
2025-03-29 16:53:20,217:INFO:_master_model_container: 3
2025-03-29 16:53:20,217:INFO:_display_container: 2
2025-03-29 16:53:20,217:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=8428, solver='auto', tol=0.0001)
2025-03-29 16:53:20,217:INFO:create_model() successfully completed......................................
2025-03-29 16:53:20,379:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:20,379:INFO:Creating metrics dataframe
2025-03-29 16:53:20,383:INFO:Initializing Elastic Net
2025-03-29 16:53:20,384:INFO:Total runtime is 0.09126176039377847 minutes
2025-03-29 16:53:20,385:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:20,386:INFO:Initializing create_model()
2025-03-29 16:53:20,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:20,386:INFO:Checking exceptions
2025-03-29 16:53:20,386:INFO:Importing libraries
2025-03-29 16:53:20,386:INFO:Copying training dataset
2025-03-29 16:53:20,393:INFO:Defining folds
2025-03-29 16:53:20,393:INFO:Declaring metric variables
2025-03-29 16:53:20,395:INFO:Importing untrained model
2025-03-29 16:53:20,397:INFO:Elastic Net Imported successfully
2025-03-29 16:53:20,401:INFO:Starting cross validation
2025-03-29 16:53:20,402:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:20,634:INFO:Calculating mean and std
2025-03-29 16:53:20,635:INFO:Creating metrics dataframe
2025-03-29 16:53:20,636:INFO:Uploading results into container
2025-03-29 16:53:20,636:INFO:Uploading model into container now
2025-03-29 16:53:20,636:INFO:_master_model_container: 4
2025-03-29 16:53:20,637:INFO:_display_container: 2
2025-03-29 16:53:20,637:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=8428,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-03-29 16:53:20,637:INFO:create_model() successfully completed......................................
2025-03-29 16:53:20,805:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:20,805:INFO:Creating metrics dataframe
2025-03-29 16:53:20,810:INFO:Initializing Least Angle Regression
2025-03-29 16:53:20,810:INFO:Total runtime is 0.09836602210998534 minutes
2025-03-29 16:53:20,813:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:20,813:INFO:Initializing create_model()
2025-03-29 16:53:20,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:20,813:INFO:Checking exceptions
2025-03-29 16:53:20,813:INFO:Importing libraries
2025-03-29 16:53:20,813:INFO:Copying training dataset
2025-03-29 16:53:20,820:INFO:Defining folds
2025-03-29 16:53:20,820:INFO:Declaring metric variables
2025-03-29 16:53:20,822:INFO:Importing untrained model
2025-03-29 16:53:20,824:INFO:Least Angle Regression Imported successfully
2025-03-29 16:53:20,830:INFO:Starting cross validation
2025-03-29 16:53:20,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:21,034:INFO:Calculating mean and std
2025-03-29 16:53:21,035:INFO:Creating metrics dataframe
2025-03-29 16:53:21,037:INFO:Uploading results into container
2025-03-29 16:53:21,037:INFO:Uploading model into container now
2025-03-29 16:53:21,038:INFO:_master_model_container: 5
2025-03-29 16:53:21,038:INFO:_display_container: 2
2025-03-29 16:53:21,038:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=8428,
     verbose=False)
2025-03-29 16:53:21,038:INFO:create_model() successfully completed......................................
2025-03-29 16:53:21,208:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:21,208:INFO:Creating metrics dataframe
2025-03-29 16:53:21,212:INFO:Initializing Lasso Least Angle Regression
2025-03-29 16:53:21,213:INFO:Total runtime is 0.10509045124053953 minutes
2025-03-29 16:53:21,215:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:21,215:INFO:Initializing create_model()
2025-03-29 16:53:21,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:21,215:INFO:Checking exceptions
2025-03-29 16:53:21,215:INFO:Importing libraries
2025-03-29 16:53:21,215:INFO:Copying training dataset
2025-03-29 16:53:21,222:INFO:Defining folds
2025-03-29 16:53:21,223:INFO:Declaring metric variables
2025-03-29 16:53:21,226:INFO:Importing untrained model
2025-03-29 16:53:21,228:INFO:Lasso Least Angle Regression Imported successfully
2025-03-29 16:53:21,232:INFO:Starting cross validation
2025-03-29 16:53:21,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:21,448:INFO:Calculating mean and std
2025-03-29 16:53:21,449:INFO:Creating metrics dataframe
2025-03-29 16:53:21,450:INFO:Uploading results into container
2025-03-29 16:53:21,451:INFO:Uploading model into container now
2025-03-29 16:53:21,451:INFO:_master_model_container: 6
2025-03-29 16:53:21,451:INFO:_display_container: 2
2025-03-29 16:53:21,451:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=8428, verbose=False)
2025-03-29 16:53:21,451:INFO:create_model() successfully completed......................................
2025-03-29 16:53:21,613:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:21,613:INFO:Creating metrics dataframe
2025-03-29 16:53:21,617:INFO:Initializing Orthogonal Matching Pursuit
2025-03-29 16:53:21,617:INFO:Total runtime is 0.11181333859761554 minutes
2025-03-29 16:53:21,619:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:21,620:INFO:Initializing create_model()
2025-03-29 16:53:21,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:21,620:INFO:Checking exceptions
2025-03-29 16:53:21,620:INFO:Importing libraries
2025-03-29 16:53:21,620:INFO:Copying training dataset
2025-03-29 16:53:21,628:INFO:Defining folds
2025-03-29 16:53:21,628:INFO:Declaring metric variables
2025-03-29 16:53:21,630:INFO:Importing untrained model
2025-03-29 16:53:21,632:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-29 16:53:21,636:INFO:Starting cross validation
2025-03-29 16:53:21,638:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:21,849:INFO:Calculating mean and std
2025-03-29 16:53:21,850:INFO:Creating metrics dataframe
2025-03-29 16:53:21,852:INFO:Uploading results into container
2025-03-29 16:53:21,853:INFO:Uploading model into container now
2025-03-29 16:53:21,853:INFO:_master_model_container: 7
2025-03-29 16:53:21,853:INFO:_display_container: 2
2025-03-29 16:53:21,854:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-03-29 16:53:21,854:INFO:create_model() successfully completed......................................
2025-03-29 16:53:22,025:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:22,025:INFO:Creating metrics dataframe
2025-03-29 16:53:22,030:INFO:Initializing Bayesian Ridge
2025-03-29 16:53:22,030:INFO:Total runtime is 0.11870507399241127 minutes
2025-03-29 16:53:22,032:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:22,032:INFO:Initializing create_model()
2025-03-29 16:53:22,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:22,032:INFO:Checking exceptions
2025-03-29 16:53:22,032:INFO:Importing libraries
2025-03-29 16:53:22,032:INFO:Copying training dataset
2025-03-29 16:53:22,039:INFO:Defining folds
2025-03-29 16:53:22,039:INFO:Declaring metric variables
2025-03-29 16:53:22,042:INFO:Importing untrained model
2025-03-29 16:53:22,044:INFO:Bayesian Ridge Imported successfully
2025-03-29 16:53:22,048:INFO:Starting cross validation
2025-03-29 16:53:22,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:22,300:INFO:Calculating mean and std
2025-03-29 16:53:22,301:INFO:Creating metrics dataframe
2025-03-29 16:53:22,302:INFO:Uploading results into container
2025-03-29 16:53:22,302:INFO:Uploading model into container now
2025-03-29 16:53:22,303:INFO:_master_model_container: 8
2025-03-29 16:53:22,303:INFO:_display_container: 2
2025-03-29 16:53:22,303:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-03-29 16:53:22,303:INFO:create_model() successfully completed......................................
2025-03-29 16:53:22,464:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:22,464:INFO:Creating metrics dataframe
2025-03-29 16:53:22,469:INFO:Initializing Passive Aggressive Regressor
2025-03-29 16:53:22,469:INFO:Total runtime is 0.12602459589640297 minutes
2025-03-29 16:53:22,471:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:22,471:INFO:Initializing create_model()
2025-03-29 16:53:22,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:22,471:INFO:Checking exceptions
2025-03-29 16:53:22,471:INFO:Importing libraries
2025-03-29 16:53:22,471:INFO:Copying training dataset
2025-03-29 16:53:22,479:INFO:Defining folds
2025-03-29 16:53:22,479:INFO:Declaring metric variables
2025-03-29 16:53:22,481:INFO:Importing untrained model
2025-03-29 16:53:22,484:INFO:Passive Aggressive Regressor Imported successfully
2025-03-29 16:53:22,488:INFO:Starting cross validation
2025-03-29 16:53:22,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:22,872:INFO:Calculating mean and std
2025-03-29 16:53:22,873:INFO:Creating metrics dataframe
2025-03-29 16:53:22,874:INFO:Uploading results into container
2025-03-29 16:53:22,874:INFO:Uploading model into container now
2025-03-29 16:53:22,875:INFO:_master_model_container: 9
2025-03-29 16:53:22,875:INFO:_display_container: 2
2025-03-29 16:53:22,875:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=8428, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:53:22,875:INFO:create_model() successfully completed......................................
2025-03-29 16:53:23,037:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:23,037:INFO:Creating metrics dataframe
2025-03-29 16:53:23,042:INFO:Initializing Huber Regressor
2025-03-29 16:53:23,042:INFO:Total runtime is 0.13556530078252155 minutes
2025-03-29 16:53:23,044:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:23,045:INFO:Initializing create_model()
2025-03-29 16:53:23,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:23,045:INFO:Checking exceptions
2025-03-29 16:53:23,045:INFO:Importing libraries
2025-03-29 16:53:23,045:INFO:Copying training dataset
2025-03-29 16:53:23,052:INFO:Defining folds
2025-03-29 16:53:23,052:INFO:Declaring metric variables
2025-03-29 16:53:23,054:INFO:Importing untrained model
2025-03-29 16:53:23,057:INFO:Huber Regressor Imported successfully
2025-03-29 16:53:23,060:INFO:Starting cross validation
2025-03-29 16:53:23,062:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:24,474:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:53:24,490:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:53:24,502:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:53:24,511:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:53:24,527:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:53:24,545:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:53:24,546:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:53:24,564:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:53:24,631:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:53:24,650:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:53:24,670:INFO:Calculating mean and std
2025-03-29 16:53:24,671:INFO:Creating metrics dataframe
2025-03-29 16:53:24,672:INFO:Uploading results into container
2025-03-29 16:53:24,672:INFO:Uploading model into container now
2025-03-29 16:53:24,672:INFO:_master_model_container: 10
2025-03-29 16:53:24,673:INFO:_display_container: 2
2025-03-29 16:53:24,673:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-03-29 16:53:24,673:INFO:create_model() successfully completed......................................
2025-03-29 16:53:24,836:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:24,836:INFO:Creating metrics dataframe
2025-03-29 16:53:24,842:INFO:Initializing K Neighbors Regressor
2025-03-29 16:53:24,842:INFO:Total runtime is 0.1655766447385152 minutes
2025-03-29 16:53:24,844:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:24,844:INFO:Initializing create_model()
2025-03-29 16:53:24,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:24,845:INFO:Checking exceptions
2025-03-29 16:53:24,845:INFO:Importing libraries
2025-03-29 16:53:24,845:INFO:Copying training dataset
2025-03-29 16:53:24,852:INFO:Defining folds
2025-03-29 16:53:24,852:INFO:Declaring metric variables
2025-03-29 16:53:24,854:INFO:Importing untrained model
2025-03-29 16:53:24,857:INFO:K Neighbors Regressor Imported successfully
2025-03-29 16:53:24,860:INFO:Starting cross validation
2025-03-29 16:53:24,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:25,662:INFO:Calculating mean and std
2025-03-29 16:53:25,663:INFO:Creating metrics dataframe
2025-03-29 16:53:25,664:INFO:Uploading results into container
2025-03-29 16:53:25,664:INFO:Uploading model into container now
2025-03-29 16:53:25,665:INFO:_master_model_container: 11
2025-03-29 16:53:25,665:INFO:_display_container: 2
2025-03-29 16:53:25,665:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-03-29 16:53:25,665:INFO:create_model() successfully completed......................................
2025-03-29 16:53:25,834:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:25,834:INFO:Creating metrics dataframe
2025-03-29 16:53:25,840:INFO:Initializing Decision Tree Regressor
2025-03-29 16:53:25,840:INFO:Total runtime is 0.18220960696538285 minutes
2025-03-29 16:53:25,842:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:25,843:INFO:Initializing create_model()
2025-03-29 16:53:25,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:25,843:INFO:Checking exceptions
2025-03-29 16:53:25,843:INFO:Importing libraries
2025-03-29 16:53:25,843:INFO:Copying training dataset
2025-03-29 16:53:25,852:INFO:Defining folds
2025-03-29 16:53:25,852:INFO:Declaring metric variables
2025-03-29 16:53:25,854:INFO:Importing untrained model
2025-03-29 16:53:25,857:INFO:Decision Tree Regressor Imported successfully
2025-03-29 16:53:25,860:INFO:Starting cross validation
2025-03-29 16:53:25,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:26,160:INFO:Calculating mean and std
2025-03-29 16:53:26,161:INFO:Creating metrics dataframe
2025-03-29 16:53:26,163:INFO:Uploading results into container
2025-03-29 16:53:26,163:INFO:Uploading model into container now
2025-03-29 16:53:26,163:INFO:_master_model_container: 12
2025-03-29 16:53:26,163:INFO:_display_container: 2
2025-03-29 16:53:26,164:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=8428, splitter='best')
2025-03-29 16:53:26,164:INFO:create_model() successfully completed......................................
2025-03-29 16:53:26,328:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:26,328:INFO:Creating metrics dataframe
2025-03-29 16:53:26,335:INFO:Initializing Random Forest Regressor
2025-03-29 16:53:26,335:INFO:Total runtime is 0.1904472708702087 minutes
2025-03-29 16:53:26,338:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:26,338:INFO:Initializing create_model()
2025-03-29 16:53:26,338:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:26,338:INFO:Checking exceptions
2025-03-29 16:53:26,338:INFO:Importing libraries
2025-03-29 16:53:26,338:INFO:Copying training dataset
2025-03-29 16:53:26,346:INFO:Defining folds
2025-03-29 16:53:26,346:INFO:Declaring metric variables
2025-03-29 16:53:26,348:INFO:Importing untrained model
2025-03-29 16:53:26,350:INFO:Random Forest Regressor Imported successfully
2025-03-29 16:53:26,355:INFO:Starting cross validation
2025-03-29 16:53:26,356:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:32,595:INFO:Calculating mean and std
2025-03-29 16:53:32,597:INFO:Creating metrics dataframe
2025-03-29 16:53:32,598:INFO:Uploading results into container
2025-03-29 16:53:32,599:INFO:Uploading model into container now
2025-03-29 16:53:32,599:INFO:_master_model_container: 13
2025-03-29 16:53:32,600:INFO:_display_container: 2
2025-03-29 16:53:32,600:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=8428, verbose=0, warm_start=False)
2025-03-29 16:53:32,600:INFO:create_model() successfully completed......................................
2025-03-29 16:53:32,781:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:32,781:INFO:Creating metrics dataframe
2025-03-29 16:53:32,786:INFO:Initializing Extra Trees Regressor
2025-03-29 16:53:32,786:INFO:Total runtime is 0.2979767084121704 minutes
2025-03-29 16:53:32,790:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:32,790:INFO:Initializing create_model()
2025-03-29 16:53:32,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:32,790:INFO:Checking exceptions
2025-03-29 16:53:32,790:INFO:Importing libraries
2025-03-29 16:53:32,790:INFO:Copying training dataset
2025-03-29 16:53:32,797:INFO:Defining folds
2025-03-29 16:53:32,797:INFO:Declaring metric variables
2025-03-29 16:53:32,800:INFO:Importing untrained model
2025-03-29 16:53:32,803:INFO:Extra Trees Regressor Imported successfully
2025-03-29 16:53:32,807:INFO:Starting cross validation
2025-03-29 16:53:32,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:36,870:INFO:Calculating mean and std
2025-03-29 16:53:36,871:INFO:Creating metrics dataframe
2025-03-29 16:53:36,872:INFO:Uploading results into container
2025-03-29 16:53:36,873:INFO:Uploading model into container now
2025-03-29 16:53:36,873:INFO:_master_model_container: 14
2025-03-29 16:53:36,873:INFO:_display_container: 2
2025-03-29 16:53:36,873:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=8428, verbose=0, warm_start=False)
2025-03-29 16:53:36,873:INFO:create_model() successfully completed......................................
2025-03-29 16:53:37,098:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:37,098:INFO:Creating metrics dataframe
2025-03-29 16:53:37,104:INFO:Initializing AdaBoost Regressor
2025-03-29 16:53:37,104:INFO:Total runtime is 0.36993817090988157 minutes
2025-03-29 16:53:37,106:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:37,107:INFO:Initializing create_model()
2025-03-29 16:53:37,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:37,107:INFO:Checking exceptions
2025-03-29 16:53:37,107:INFO:Importing libraries
2025-03-29 16:53:37,107:INFO:Copying training dataset
2025-03-29 16:53:37,115:INFO:Defining folds
2025-03-29 16:53:37,115:INFO:Declaring metric variables
2025-03-29 16:53:37,118:INFO:Importing untrained model
2025-03-29 16:53:37,120:INFO:AdaBoost Regressor Imported successfully
2025-03-29 16:53:37,125:INFO:Starting cross validation
2025-03-29 16:53:37,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:38,084:INFO:Calculating mean and std
2025-03-29 16:53:38,085:INFO:Creating metrics dataframe
2025-03-29 16:53:38,086:INFO:Uploading results into container
2025-03-29 16:53:38,086:INFO:Uploading model into container now
2025-03-29 16:53:38,086:INFO:_master_model_container: 15
2025-03-29 16:53:38,087:INFO:_display_container: 2
2025-03-29 16:53:38,087:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=8428)
2025-03-29 16:53:38,087:INFO:create_model() successfully completed......................................
2025-03-29 16:53:38,255:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:38,255:INFO:Creating metrics dataframe
2025-03-29 16:53:38,261:INFO:Initializing Gradient Boosting Regressor
2025-03-29 16:53:38,261:INFO:Total runtime is 0.38922566175460815 minutes
2025-03-29 16:53:38,264:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:38,264:INFO:Initializing create_model()
2025-03-29 16:53:38,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:38,265:INFO:Checking exceptions
2025-03-29 16:53:38,265:INFO:Importing libraries
2025-03-29 16:53:38,265:INFO:Copying training dataset
2025-03-29 16:53:38,273:INFO:Defining folds
2025-03-29 16:53:38,273:INFO:Declaring metric variables
2025-03-29 16:53:38,276:INFO:Importing untrained model
2025-03-29 16:53:38,279:INFO:Gradient Boosting Regressor Imported successfully
2025-03-29 16:53:38,283:INFO:Starting cross validation
2025-03-29 16:53:38,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:40,261:INFO:Calculating mean and std
2025-03-29 16:53:40,262:INFO:Creating metrics dataframe
2025-03-29 16:53:40,263:INFO:Uploading results into container
2025-03-29 16:53:40,264:INFO:Uploading model into container now
2025-03-29 16:53:40,264:INFO:_master_model_container: 16
2025-03-29 16:53:40,264:INFO:_display_container: 2
2025-03-29 16:53:40,264:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=8428, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-29 16:53:40,265:INFO:create_model() successfully completed......................................
2025-03-29 16:53:40,435:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:40,435:INFO:Creating metrics dataframe
2025-03-29 16:53:40,441:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 16:53:40,441:INFO:Total runtime is 0.4255601167678833 minutes
2025-03-29 16:53:40,443:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:40,444:INFO:Initializing create_model()
2025-03-29 16:53:40,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:40,444:INFO:Checking exceptions
2025-03-29 16:53:40,444:INFO:Importing libraries
2025-03-29 16:53:40,444:INFO:Copying training dataset
2025-03-29 16:53:40,453:INFO:Defining folds
2025-03-29 16:53:40,453:INFO:Declaring metric variables
2025-03-29 16:53:40,456:INFO:Importing untrained model
2025-03-29 16:53:40,459:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:53:40,464:INFO:Starting cross validation
2025-03-29 16:53:40,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:41,321:INFO:Calculating mean and std
2025-03-29 16:53:41,322:INFO:Creating metrics dataframe
2025-03-29 16:53:41,323:INFO:Uploading results into container
2025-03-29 16:53:41,324:INFO:Uploading model into container now
2025-03-29 16:53:41,324:INFO:_master_model_container: 17
2025-03-29 16:53:41,324:INFO:_display_container: 2
2025-03-29 16:53:41,325:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:53:41,325:INFO:create_model() successfully completed......................................
2025-03-29 16:53:41,524:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:41,525:INFO:Creating metrics dataframe
2025-03-29 16:53:41,532:INFO:Initializing Dummy Regressor
2025-03-29 16:53:41,532:INFO:Total runtime is 0.44374282360076905 minutes
2025-03-29 16:53:41,535:INFO:SubProcess create_model() called ==================================
2025-03-29 16:53:41,535:INFO:Initializing create_model()
2025-03-29 16:53:41,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E920E59DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:41,535:INFO:Checking exceptions
2025-03-29 16:53:41,535:INFO:Importing libraries
2025-03-29 16:53:41,535:INFO:Copying training dataset
2025-03-29 16:53:41,542:INFO:Defining folds
2025-03-29 16:53:41,542:INFO:Declaring metric variables
2025-03-29 16:53:41,545:INFO:Importing untrained model
2025-03-29 16:53:41,550:INFO:Dummy Regressor Imported successfully
2025-03-29 16:53:41,555:INFO:Starting cross validation
2025-03-29 16:53:41,556:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:53:41,771:INFO:Calculating mean and std
2025-03-29 16:53:41,772:INFO:Creating metrics dataframe
2025-03-29 16:53:41,773:INFO:Uploading results into container
2025-03-29 16:53:41,774:INFO:Uploading model into container now
2025-03-29 16:53:41,774:INFO:_master_model_container: 18
2025-03-29 16:53:41,774:INFO:_display_container: 2
2025-03-29 16:53:41,774:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-03-29 16:53:41,774:INFO:create_model() successfully completed......................................
2025-03-29 16:53:41,942:INFO:SubProcess create_model() end ==================================
2025-03-29 16:53:41,942:INFO:Creating metrics dataframe
2025-03-29 16:53:41,950:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-29 16:53:41,955:INFO:Initializing create_model()
2025-03-29 16:53:41,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:53:41,956:INFO:Checking exceptions
2025-03-29 16:53:41,956:INFO:Importing libraries
2025-03-29 16:53:41,956:INFO:Copying training dataset
2025-03-29 16:53:41,965:INFO:Defining folds
2025-03-29 16:53:41,965:INFO:Declaring metric variables
2025-03-29 16:53:41,965:INFO:Importing untrained model
2025-03-29 16:53:41,965:INFO:Declaring custom model
2025-03-29 16:53:41,966:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:53:41,966:INFO:Cross validation set to False
2025-03-29 16:53:41,966:INFO:Fitting Model
2025-03-29 16:53:42,057:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:53:42,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.
2025-03-29 16:53:42,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:53:42,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:53:42,059:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 16:53:42,059:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 16:53:42,059:INFO:[LightGBM] [Info] Start training from score 3260.364827
2025-03-29 16:53:42,105:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:53:42,105:INFO:create_model() successfully completed......................................
2025-03-29 16:53:42,310:INFO:_master_model_container: 18
2025-03-29 16:53:42,310:INFO:_display_container: 2
2025-03-29 16:53:42,310:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:53:42,310:INFO:compare_models() successfully completed......................................
2025-03-29 16:54:52,728:INFO:Initializing evaluate_model()
2025-03-29 16:54:52,728:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-29 16:54:52,738:INFO:Initializing plot_model()
2025-03-29 16:54:52,738:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, system=True)
2025-03-29 16:54:52,738:INFO:Checking exceptions
2025-03-29 16:54:52,740:INFO:Preloading libraries
2025-03-29 16:54:52,743:INFO:Copying training dataset
2025-03-29 16:54:52,743:INFO:Plot type: pipeline
2025-03-29 16:54:52,825:INFO:Visual Rendered Successfully
2025-03-29 16:54:52,996:INFO:plot_model() successfully completed......................................
2025-03-29 16:54:56,498:INFO:Initializing plot_model()
2025-03-29 16:54:56,498:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, system=True)
2025-03-29 16:54:56,498:INFO:Checking exceptions
2025-03-29 16:54:56,501:INFO:Preloading libraries
2025-03-29 16:54:56,504:INFO:Copying training dataset
2025-03-29 16:54:56,504:INFO:Plot type: residuals
2025-03-29 16:54:56,751:INFO:Fitting Model
2025-03-29 16:54:56,801:INFO:Scoring test/hold-out set
2025-03-29 16:54:57,222:INFO:Visual Rendered Successfully
2025-03-29 16:54:57,383:INFO:plot_model() successfully completed......................................
2025-03-29 16:55:40,063:INFO:Initializing tune_model()
2025-03-29 16:55:40,063:INFO:tune_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>)
2025-03-29 16:55:40,063:INFO:Checking exceptions
2025-03-29 16:55:40,078:INFO:Copying training dataset
2025-03-29 16:55:40,083:INFO:Checking base model
2025-03-29 16:55:40,083:INFO:Base model : Light Gradient Boosting Machine
2025-03-29 16:55:40,085:INFO:Declaring metric variables
2025-03-29 16:55:40,088:INFO:Defining Hyperparameters
2025-03-29 16:55:40,275:INFO:Tuning with n_jobs=-1
2025-03-29 16:55:40,275:INFO:Initializing RandomizedSearchCV
2025-03-29 16:56:01,386:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.15, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 56, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.9}
2025-03-29 16:56:01,386:INFO:Hyperparameter search completed
2025-03-29 16:56:01,386:INFO:SubProcess create_model() called ==================================
2025-03-29 16:56:01,388:INFO:Initializing create_model()
2025-03-29 16:56:01,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F5AADA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.15, 'num_leaves': 50, 'n_estimators': 90, 'min_split_gain': 0.2, 'min_child_samples': 56, 'learning_rate': 0.05, 'feature_fraction': 0.7, 'bagging_freq': 1, 'bagging_fraction': 0.9})
2025-03-29 16:56:01,388:INFO:Checking exceptions
2025-03-29 16:56:01,388:INFO:Importing libraries
2025-03-29 16:56:01,388:INFO:Copying training dataset
2025-03-29 16:56:01,398:INFO:Defining folds
2025-03-29 16:56:01,398:INFO:Declaring metric variables
2025-03-29 16:56:01,399:INFO:Importing untrained model
2025-03-29 16:56:01,400:INFO:Declaring custom model
2025-03-29 16:56:01,403:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:56:01,408:INFO:Starting cross validation
2025-03-29 16:56:01,410:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:56:02,499:INFO:Calculating mean and std
2025-03-29 16:56:02,500:INFO:Creating metrics dataframe
2025-03-29 16:56:02,504:INFO:Finalizing model
2025-03-29 16:56:02,597:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-03-29 16:56:02,597:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-03-29 16:56:02,597:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-03-29 16:56:02,607:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:56:02,607:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-03-29 16:56:02,607:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-03-29 16:56:02,607:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-03-29 16:56:02,609:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.
2025-03-29 16:56:02,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:56:02,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:56:02,609:INFO:[LightGBM] [Info] Total Bins 549
2025-03-29 16:56:02,610:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 13
2025-03-29 16:56:02,610:INFO:[LightGBM] [Info] Start training from score 3260.364827
2025-03-29 16:56:02,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:56:02,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:56:02,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:56:02,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:56:02,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:56:02,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:56:02,721:INFO:Uploading results into container
2025-03-29 16:56:02,721:INFO:Uploading model into container now
2025-03-29 16:56:02,722:INFO:_master_model_container: 19
2025-03-29 16:56:02,722:INFO:_display_container: 3
2025-03-29 16:56:02,722:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
              importance_type='split', learning_rate=0.05, max_depth=-1,
              min_child_samples=56, min_child_weight=0.001, min_split_gain=0.2,
              n_estimators=90, n_jobs=-1, num_leaves=50, objective=None,
              random_state=8428, reg_alpha=0.15, reg_lambda=0.1, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:56:02,723:INFO:create_model() successfully completed......................................
2025-03-29 16:56:02,931:INFO:SubProcess create_model() end ==================================
2025-03-29 16:56:02,932:INFO:choose_better activated
2025-03-29 16:56:02,935:INFO:SubProcess create_model() called ==================================
2025-03-29 16:56:02,935:INFO:Initializing create_model()
2025-03-29 16:56:02,935:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E92270D270>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:56:02,936:INFO:Checking exceptions
2025-03-29 16:56:02,937:INFO:Importing libraries
2025-03-29 16:56:02,937:INFO:Copying training dataset
2025-03-29 16:56:02,943:INFO:Defining folds
2025-03-29 16:56:02,943:INFO:Declaring metric variables
2025-03-29 16:56:02,943:INFO:Importing untrained model
2025-03-29 16:56:02,943:INFO:Declaring custom model
2025-03-29 16:56:02,945:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:56:02,945:INFO:Starting cross validation
2025-03-29 16:56:02,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:56:03,729:INFO:Calculating mean and std
2025-03-29 16:56:03,729:INFO:Creating metrics dataframe
2025-03-29 16:56:03,730:INFO:Finalizing model
2025-03-29 16:56:03,829:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:56:03,830:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-03-29 16:56:03,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:56:03,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:56:03,830:INFO:[LightGBM] [Info] Total Bins 559
2025-03-29 16:56:03,830:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 16:56:03,831:INFO:[LightGBM] [Info] Start training from score 3260.364827
2025-03-29 16:56:03,877:INFO:Uploading results into container
2025-03-29 16:56:03,877:INFO:Uploading model into container now
2025-03-29 16:56:03,877:INFO:_master_model_container: 20
2025-03-29 16:56:03,877:INFO:_display_container: 4
2025-03-29 16:56:03,878:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:56:03,878:INFO:create_model() successfully completed......................................
2025-03-29 16:56:04,089:INFO:SubProcess create_model() end ==================================
2025-03-29 16:56:04,090:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.2212
2025-03-29 16:56:04,091:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
              importance_type='split', learning_rate=0.05, max_depth=-1,
              min_child_samples=56, min_child_weight=0.001, min_split_gain=0.2,
              n_estimators=90, n_jobs=-1, num_leaves=50, objective=None,
              random_state=8428, reg_alpha=0.15, reg_lambda=0.1, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.2152
2025-03-29 16:56:04,091:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-03-29 16:56:04,091:INFO:choose_better completed
2025-03-29 16:56:04,091:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-29 16:56:04,097:INFO:_master_model_container: 20
2025-03-29 16:56:04,097:INFO:_display_container: 3
2025-03-29 16:56:04,097:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:56:04,097:INFO:tune_model() successfully completed......................................
2025-03-29 16:56:15,949:INFO:Initializing save_model()
2025-03-29 16:56:15,949:INFO:save_model(model=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8428, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), model_name=traffic_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_i...
                                    include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-29 16:56:15,949:INFO:Adding model into prep_pipe
2025-03-29 16:56:15,958:INFO:traffic_model.pkl saved in current working directory
2025-03-29 16:56:15,964:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,...
                 LGBMRegressor(boosting_type='gbdt', class_weight=None,
                               colsample_bytree=1.0, importance_type='split',
                               learning_rate=0.1, max_depth=-1,
                               min_child_samples=20, min_child_weight=0.001,
                               min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                               num_leaves=31, objective=None, random_state=8428,
                               reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                               subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-03-29 16:56:15,964:INFO:save_model() successfully completed......................................
2025-03-29 16:57:42,338:INFO:PyCaret RegressionExperiment
2025-03-29 16:57:42,338:INFO:Logging name: reg-default-name
2025-03-29 16:57:42,338:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-29 16:57:42,338:INFO:version 3.3.2
2025-03-29 16:57:42,338:INFO:Initializing setup()
2025-03-29 16:57:42,338:INFO:self.USI: ba2e
2025-03-29 16:57:42,338:INFO:self._variable_keys: {'y_train', 'X_test', 'target_param', 'data', 'gpu_param', 'transform_target_param', 'html_param', 'pipeline', 'n_jobs_param', 'y', 'fold_groups_param', 'exp_id', 'seed', 'y_test', 'fold_generator', 'X', 'X_train', 'memory', '_ml_usecase', 'exp_name_log', 'idx', 'logging_param', 'fold_shuffle_param', 'USI', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param'}
2025-03-29 16:57:42,338:INFO:Checking environment
2025-03-29 16:57:42,338:INFO:python_version: 3.10.16
2025-03-29 16:57:42,338:INFO:python_build: ('main', 'Dec  5 2024 14:07:43')
2025-03-29 16:57:42,338:INFO:machine: AMD64
2025-03-29 16:57:42,338:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-29 16:57:42,343:INFO:Memory: svmem(total=33411727360, available=16889151488, percent=49.5, used=16522575872, free=16889151488)
2025-03-29 16:57:42,343:INFO:Physical Core: 6
2025-03-29 16:57:42,343:INFO:Logical Core: 12
2025-03-29 16:57:42,343:INFO:Checking libraries
2025-03-29 16:57:42,343:INFO:System:
2025-03-29 16:57:42,344:INFO:    python: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:07:43) [MSC v.1942 64 bit (AMD64)]
2025-03-29 16:57:42,344:INFO:executable: c:\Users\vladk\anaconda3\envs\pycaret\python.exe
2025-03-29 16:57:42,344:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-29 16:57:42,344:INFO:PyCaret required dependencies:
2025-03-29 16:57:42,344:INFO:                 pip: 25.0.1
2025-03-29 16:57:42,344:INFO:          setuptools: 75.8.2
2025-03-29 16:57:42,344:INFO:             pycaret: 3.3.2
2025-03-29 16:57:42,344:INFO:             IPython: 8.34.0
2025-03-29 16:57:42,344:INFO:          ipywidgets: 8.1.5
2025-03-29 16:57:42,344:INFO:                tqdm: 4.67.1
2025-03-29 16:57:42,344:INFO:               numpy: 1.26.4
2025-03-29 16:57:42,344:INFO:              pandas: 2.1.4
2025-03-29 16:57:42,344:INFO:              jinja2: 3.1.6
2025-03-29 16:57:42,344:INFO:               scipy: 1.11.4
2025-03-29 16:57:42,344:INFO:              joblib: 1.3.2
2025-03-29 16:57:42,344:INFO:             sklearn: 1.4.2
2025-03-29 16:57:42,344:INFO:                pyod: 2.0.2
2025-03-29 16:57:42,344:INFO:            imblearn: 0.13.0
2025-03-29 16:57:42,344:INFO:   category_encoders: 2.7.0
2025-03-29 16:57:42,345:INFO:            lightgbm: 4.6.0
2025-03-29 16:57:42,345:INFO:               numba: 0.61.0
2025-03-29 16:57:42,345:INFO:            requests: 2.32.3
2025-03-29 16:57:42,345:INFO:          matplotlib: 3.10.1
2025-03-29 16:57:42,345:INFO:          scikitplot: 0.3.7
2025-03-29 16:57:42,345:INFO:         yellowbrick: 1.5
2025-03-29 16:57:42,345:INFO:              plotly: 6.0.1
2025-03-29 16:57:42,345:INFO:    plotly-resampler: Not installed
2025-03-29 16:57:42,345:INFO:             kaleido: 0.2.1
2025-03-29 16:57:42,345:INFO:           schemdraw: 0.15
2025-03-29 16:57:42,345:INFO:         statsmodels: 0.14.4
2025-03-29 16:57:42,345:INFO:              sktime: 0.26.0
2025-03-29 16:57:42,345:INFO:               tbats: 1.1.3
2025-03-29 16:57:42,345:INFO:            pmdarima: 2.0.4
2025-03-29 16:57:42,345:INFO:              psutil: 7.0.0
2025-03-29 16:57:42,345:INFO:          markupsafe: 3.0.2
2025-03-29 16:57:42,345:INFO:             pickle5: Not installed
2025-03-29 16:57:42,345:INFO:         cloudpickle: 3.1.1
2025-03-29 16:57:42,345:INFO:         deprecation: 2.1.0
2025-03-29 16:57:42,345:INFO:              xxhash: 3.5.0
2025-03-29 16:57:42,345:INFO:           wurlitzer: 3.1.1
2025-03-29 16:57:42,345:INFO:PyCaret optional dependencies:
2025-03-29 16:57:42,345:INFO:                shap: Not installed
2025-03-29 16:57:42,345:INFO:           interpret: Not installed
2025-03-29 16:57:42,345:INFO:                umap: 0.5.7
2025-03-29 16:57:42,345:INFO:     ydata_profiling: Not installed
2025-03-29 16:57:42,345:INFO:  explainerdashboard: Not installed
2025-03-29 16:57:42,345:INFO:             autoviz: Not installed
2025-03-29 16:57:42,345:INFO:           fairlearn: Not installed
2025-03-29 16:57:42,345:INFO:          deepchecks: Not installed
2025-03-29 16:57:42,345:INFO:             xgboost: Not installed
2025-03-29 16:57:42,345:INFO:            catboost: Not installed
2025-03-29 16:57:42,345:INFO:              kmodes: Not installed
2025-03-29 16:57:42,345:INFO:             mlxtend: Not installed
2025-03-29 16:57:42,345:INFO:       statsforecast: Not installed
2025-03-29 16:57:42,345:INFO:        tune_sklearn: Not installed
2025-03-29 16:57:42,345:INFO:                 ray: Not installed
2025-03-29 16:57:42,345:INFO:            hyperopt: Not installed
2025-03-29 16:57:42,345:INFO:              optuna: Not installed
2025-03-29 16:57:42,345:INFO:               skopt: Not installed
2025-03-29 16:57:42,345:INFO:              mlflow: 2.21.2
2025-03-29 16:57:42,345:INFO:              gradio: Not installed
2025-03-29 16:57:42,345:INFO:             fastapi: 0.115.12
2025-03-29 16:57:42,345:INFO:             uvicorn: 0.34.0
2025-03-29 16:57:42,345:INFO:              m2cgen: Not installed
2025-03-29 16:57:42,345:INFO:           evidently: Not installed
2025-03-29 16:57:42,346:INFO:               fugue: Not installed
2025-03-29 16:57:42,346:INFO:           streamlit: 1.43.2
2025-03-29 16:57:42,346:INFO:             prophet: Not installed
2025-03-29 16:57:42,346:INFO:None
2025-03-29 16:57:42,346:INFO:Set up data.
2025-03-29 16:57:42,353:INFO:Set up folding strategy.
2025-03-29 16:57:42,353:INFO:Set up train/test split.
2025-03-29 16:57:42,358:INFO:Set up index.
2025-03-29 16:57:42,359:INFO:Assigning column types.
2025-03-29 16:57:42,363:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-29 16:57:42,363:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,366:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,368:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,432:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,433:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,436:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,439:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,503:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,504:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-29 16:57:42,506:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,511:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,562:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,589:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,593:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,596:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,659:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,660:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-29 16:57:42,666:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,735:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,742:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,781:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,808:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,808:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-29 16:57:42,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-29 16:57:42,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:42,948:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-29 16:57:42,989:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:57:43,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,059:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-29 16:57:43,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,084:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-29 16:57:43,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,218:INFO:Preparing preprocessing pipeline...
2025-03-29 16:57:43,218:INFO:Set up simple imputation.
2025-03-29 16:57:43,223:INFO:Set up encoding of categorical features.
2025-03-29 16:57:43,224:INFO:Set up column name cleaning.
2025-03-29 16:57:43,317:INFO:Finished creating preprocessing pipeline.
2025-03-29 16:57:43,320:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_i...
                                    include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-03-29 16:57:43,320:INFO:Creating final display dataframe.
2025-03-29 16:57:43,545:INFO:Setup _display_container:                     Description             Value
0                    Session id               453
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 28)
5   Transformed train set shape       (33742, 28)
6    Transformed test set shape       (14462, 28)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             99.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              ba2e
2025-03-29 16:57:43,615:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-29 16:57:43,697:INFO:setup() successfully completed in 1.36s...............
2025-03-29 16:57:43,715:INFO:Initializing compare_models()
2025-03-29 16:57:43,715:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-29 16:57:43,715:INFO:Checking exceptions
2025-03-29 16:57:43,719:INFO:Preparing display monitor
2025-03-29 16:57:43,731:INFO:Initializing Linear Regression
2025-03-29 16:57:43,731:INFO:Total runtime is 0.0 minutes
2025-03-29 16:57:43,733:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:43,733:INFO:Initializing create_model()
2025-03-29 16:57:43,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:43,734:INFO:Checking exceptions
2025-03-29 16:57:43,734:INFO:Importing libraries
2025-03-29 16:57:43,734:INFO:Copying training dataset
2025-03-29 16:57:43,740:INFO:Defining folds
2025-03-29 16:57:43,740:INFO:Declaring metric variables
2025-03-29 16:57:43,742:INFO:Importing untrained model
2025-03-29 16:57:43,745:INFO:Linear Regression Imported successfully
2025-03-29 16:57:43,748:INFO:Starting cross validation
2025-03-29 16:57:43,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:43,973:INFO:Calculating mean and std
2025-03-29 16:57:43,974:INFO:Creating metrics dataframe
2025-03-29 16:57:43,975:INFO:Uploading results into container
2025-03-29 16:57:43,976:INFO:Uploading model into container now
2025-03-29 16:57:43,976:INFO:_master_model_container: 1
2025-03-29 16:57:43,976:INFO:_display_container: 2
2025-03-29 16:57:43,976:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-03-29 16:57:43,976:INFO:create_model() successfully completed......................................
2025-03-29 16:57:44,169:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:44,169:INFO:Creating metrics dataframe
2025-03-29 16:57:44,173:INFO:Initializing Lasso Regression
2025-03-29 16:57:44,173:INFO:Total runtime is 0.007370285193125407 minutes
2025-03-29 16:57:44,175:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:44,176:INFO:Initializing create_model()
2025-03-29 16:57:44,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:44,176:INFO:Checking exceptions
2025-03-29 16:57:44,176:INFO:Importing libraries
2025-03-29 16:57:44,176:INFO:Copying training dataset
2025-03-29 16:57:44,182:INFO:Defining folds
2025-03-29 16:57:44,182:INFO:Declaring metric variables
2025-03-29 16:57:44,184:INFO:Importing untrained model
2025-03-29 16:57:44,186:INFO:Lasso Regression Imported successfully
2025-03-29 16:57:44,189:INFO:Starting cross validation
2025-03-29 16:57:44,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:44,435:INFO:Calculating mean and std
2025-03-29 16:57:44,436:INFO:Creating metrics dataframe
2025-03-29 16:57:44,437:INFO:Uploading results into container
2025-03-29 16:57:44,437:INFO:Uploading model into container now
2025-03-29 16:57:44,437:INFO:_master_model_container: 2
2025-03-29 16:57:44,437:INFO:_display_container: 2
2025-03-29 16:57:44,437:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=453, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-03-29 16:57:44,437:INFO:create_model() successfully completed......................................
2025-03-29 16:57:44,610:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:44,610:INFO:Creating metrics dataframe
2025-03-29 16:57:44,614:INFO:Initializing Ridge Regression
2025-03-29 16:57:44,614:INFO:Total runtime is 0.014715433120727539 minutes
2025-03-29 16:57:44,616:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:44,616:INFO:Initializing create_model()
2025-03-29 16:57:44,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:44,616:INFO:Checking exceptions
2025-03-29 16:57:44,616:INFO:Importing libraries
2025-03-29 16:57:44,616:INFO:Copying training dataset
2025-03-29 16:57:44,622:INFO:Defining folds
2025-03-29 16:57:44,622:INFO:Declaring metric variables
2025-03-29 16:57:44,624:INFO:Importing untrained model
2025-03-29 16:57:44,625:INFO:Ridge Regression Imported successfully
2025-03-29 16:57:44,629:INFO:Starting cross validation
2025-03-29 16:57:44,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:44,852:INFO:Calculating mean and std
2025-03-29 16:57:44,853:INFO:Creating metrics dataframe
2025-03-29 16:57:44,854:INFO:Uploading results into container
2025-03-29 16:57:44,854:INFO:Uploading model into container now
2025-03-29 16:57:44,855:INFO:_master_model_container: 3
2025-03-29 16:57:44,855:INFO:_display_container: 2
2025-03-29 16:57:44,855:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=453, solver='auto', tol=0.0001)
2025-03-29 16:57:44,855:INFO:create_model() successfully completed......................................
2025-03-29 16:57:45,022:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:45,022:INFO:Creating metrics dataframe
2025-03-29 16:57:45,027:INFO:Initializing Elastic Net
2025-03-29 16:57:45,027:INFO:Total runtime is 0.02159650723139445 minutes
2025-03-29 16:57:45,029:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:45,029:INFO:Initializing create_model()
2025-03-29 16:57:45,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:45,029:INFO:Checking exceptions
2025-03-29 16:57:45,030:INFO:Importing libraries
2025-03-29 16:57:45,030:INFO:Copying training dataset
2025-03-29 16:57:45,037:INFO:Defining folds
2025-03-29 16:57:45,037:INFO:Declaring metric variables
2025-03-29 16:57:45,040:INFO:Importing untrained model
2025-03-29 16:57:45,042:INFO:Elastic Net Imported successfully
2025-03-29 16:57:45,045:INFO:Starting cross validation
2025-03-29 16:57:45,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:45,306:INFO:Calculating mean and std
2025-03-29 16:57:45,307:INFO:Creating metrics dataframe
2025-03-29 16:57:45,308:INFO:Uploading results into container
2025-03-29 16:57:45,308:INFO:Uploading model into container now
2025-03-29 16:57:45,309:INFO:_master_model_container: 4
2025-03-29 16:57:45,309:INFO:_display_container: 2
2025-03-29 16:57:45,309:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=453,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-03-29 16:57:45,309:INFO:create_model() successfully completed......................................
2025-03-29 16:57:45,486:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:45,486:INFO:Creating metrics dataframe
2025-03-29 16:57:45,490:INFO:Initializing Least Angle Regression
2025-03-29 16:57:45,490:INFO:Total runtime is 0.029327150185902914 minutes
2025-03-29 16:57:45,492:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:45,492:INFO:Initializing create_model()
2025-03-29 16:57:45,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:45,493:INFO:Checking exceptions
2025-03-29 16:57:45,493:INFO:Importing libraries
2025-03-29 16:57:45,493:INFO:Copying training dataset
2025-03-29 16:57:45,500:INFO:Defining folds
2025-03-29 16:57:45,500:INFO:Declaring metric variables
2025-03-29 16:57:45,503:INFO:Importing untrained model
2025-03-29 16:57:45,504:INFO:Least Angle Regression Imported successfully
2025-03-29 16:57:45,508:INFO:Starting cross validation
2025-03-29 16:57:45,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:45,735:INFO:Calculating mean and std
2025-03-29 16:57:45,736:INFO:Creating metrics dataframe
2025-03-29 16:57:45,737:INFO:Uploading results into container
2025-03-29 16:57:45,738:INFO:Uploading model into container now
2025-03-29 16:57:45,738:INFO:_master_model_container: 5
2025-03-29 16:57:45,738:INFO:_display_container: 2
2025-03-29 16:57:45,738:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=453,
     verbose=False)
2025-03-29 16:57:45,738:INFO:create_model() successfully completed......................................
2025-03-29 16:57:45,908:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:45,908:INFO:Creating metrics dataframe
2025-03-29 16:57:45,914:INFO:Initializing Lasso Least Angle Regression
2025-03-29 16:57:45,915:INFO:Total runtime is 0.0364015539487203 minutes
2025-03-29 16:57:45,917:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:45,917:INFO:Initializing create_model()
2025-03-29 16:57:45,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:45,918:INFO:Checking exceptions
2025-03-29 16:57:45,918:INFO:Importing libraries
2025-03-29 16:57:45,918:INFO:Copying training dataset
2025-03-29 16:57:45,925:INFO:Defining folds
2025-03-29 16:57:45,925:INFO:Declaring metric variables
2025-03-29 16:57:45,927:INFO:Importing untrained model
2025-03-29 16:57:45,929:INFO:Lasso Least Angle Regression Imported successfully
2025-03-29 16:57:45,933:INFO:Starting cross validation
2025-03-29 16:57:45,934:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:46,155:INFO:Calculating mean and std
2025-03-29 16:57:46,156:INFO:Creating metrics dataframe
2025-03-29 16:57:46,157:INFO:Uploading results into container
2025-03-29 16:57:46,157:INFO:Uploading model into container now
2025-03-29 16:57:46,158:INFO:_master_model_container: 6
2025-03-29 16:57:46,158:INFO:_display_container: 2
2025-03-29 16:57:46,158:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=453, verbose=False)
2025-03-29 16:57:46,158:INFO:create_model() successfully completed......................................
2025-03-29 16:57:46,343:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:46,343:INFO:Creating metrics dataframe
2025-03-29 16:57:46,348:INFO:Initializing Orthogonal Matching Pursuit
2025-03-29 16:57:46,348:INFO:Total runtime is 0.043629082043965664 minutes
2025-03-29 16:57:46,350:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:46,350:INFO:Initializing create_model()
2025-03-29 16:57:46,350:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:46,350:INFO:Checking exceptions
2025-03-29 16:57:46,350:INFO:Importing libraries
2025-03-29 16:57:46,350:INFO:Copying training dataset
2025-03-29 16:57:46,358:INFO:Defining folds
2025-03-29 16:57:46,358:INFO:Declaring metric variables
2025-03-29 16:57:46,360:INFO:Importing untrained model
2025-03-29 16:57:46,362:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-29 16:57:46,365:INFO:Starting cross validation
2025-03-29 16:57:46,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:46,589:INFO:Calculating mean and std
2025-03-29 16:57:46,589:INFO:Creating metrics dataframe
2025-03-29 16:57:46,591:INFO:Uploading results into container
2025-03-29 16:57:46,592:INFO:Uploading model into container now
2025-03-29 16:57:46,592:INFO:_master_model_container: 7
2025-03-29 16:57:46,592:INFO:_display_container: 2
2025-03-29 16:57:46,592:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-03-29 16:57:46,592:INFO:create_model() successfully completed......................................
2025-03-29 16:57:46,767:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:46,767:INFO:Creating metrics dataframe
2025-03-29 16:57:46,772:INFO:Initializing Bayesian Ridge
2025-03-29 16:57:46,772:INFO:Total runtime is 0.050695379575093596 minutes
2025-03-29 16:57:46,774:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:46,774:INFO:Initializing create_model()
2025-03-29 16:57:46,774:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:46,774:INFO:Checking exceptions
2025-03-29 16:57:46,774:INFO:Importing libraries
2025-03-29 16:57:46,774:INFO:Copying training dataset
2025-03-29 16:57:46,781:INFO:Defining folds
2025-03-29 16:57:46,781:INFO:Declaring metric variables
2025-03-29 16:57:46,783:INFO:Importing untrained model
2025-03-29 16:57:46,785:INFO:Bayesian Ridge Imported successfully
2025-03-29 16:57:46,788:INFO:Starting cross validation
2025-03-29 16:57:46,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:47,035:INFO:Calculating mean and std
2025-03-29 16:57:47,036:INFO:Creating metrics dataframe
2025-03-29 16:57:47,038:INFO:Uploading results into container
2025-03-29 16:57:47,039:INFO:Uploading model into container now
2025-03-29 16:57:47,039:INFO:_master_model_container: 8
2025-03-29 16:57:47,039:INFO:_display_container: 2
2025-03-29 16:57:47,039:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-03-29 16:57:47,039:INFO:create_model() successfully completed......................................
2025-03-29 16:57:47,206:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:47,207:INFO:Creating metrics dataframe
2025-03-29 16:57:47,212:INFO:Initializing Passive Aggressive Regressor
2025-03-29 16:57:47,212:INFO:Total runtime is 0.05801895459493002 minutes
2025-03-29 16:57:47,214:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:47,214:INFO:Initializing create_model()
2025-03-29 16:57:47,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:47,214:INFO:Checking exceptions
2025-03-29 16:57:47,214:INFO:Importing libraries
2025-03-29 16:57:47,214:INFO:Copying training dataset
2025-03-29 16:57:47,222:INFO:Defining folds
2025-03-29 16:57:47,222:INFO:Declaring metric variables
2025-03-29 16:57:47,224:INFO:Importing untrained model
2025-03-29 16:57:47,226:INFO:Passive Aggressive Regressor Imported successfully
2025-03-29 16:57:47,229:INFO:Starting cross validation
2025-03-29 16:57:47,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:47,604:INFO:Calculating mean and std
2025-03-29 16:57:47,606:INFO:Creating metrics dataframe
2025-03-29 16:57:47,608:INFO:Uploading results into container
2025-03-29 16:57:47,608:INFO:Uploading model into container now
2025-03-29 16:57:47,609:INFO:_master_model_container: 9
2025-03-29 16:57:47,609:INFO:_display_container: 2
2025-03-29 16:57:47,609:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=453, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-29 16:57:47,609:INFO:create_model() successfully completed......................................
2025-03-29 16:57:47,777:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:47,777:INFO:Creating metrics dataframe
2025-03-29 16:57:47,782:INFO:Initializing Huber Regressor
2025-03-29 16:57:47,782:INFO:Total runtime is 0.06751683553059896 minutes
2025-03-29 16:57:47,784:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:47,784:INFO:Initializing create_model()
2025-03-29 16:57:47,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:47,784:INFO:Checking exceptions
2025-03-29 16:57:47,784:INFO:Importing libraries
2025-03-29 16:57:47,784:INFO:Copying training dataset
2025-03-29 16:57:47,791:INFO:Defining folds
2025-03-29 16:57:47,791:INFO:Declaring metric variables
2025-03-29 16:57:47,794:INFO:Importing untrained model
2025-03-29 16:57:47,795:INFO:Huber Regressor Imported successfully
2025-03-29 16:57:47,799:INFO:Starting cross validation
2025-03-29 16:57:47,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:49,190:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:57:49,294:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:57:49,336:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:57:49,414:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:57:49,424:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:57:49,453:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:57:49,486:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:57:49,512:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:57:49,656:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:57:49,669:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-29 16:57:49,702:INFO:Calculating mean and std
2025-03-29 16:57:49,703:INFO:Creating metrics dataframe
2025-03-29 16:57:49,705:INFO:Uploading results into container
2025-03-29 16:57:49,706:INFO:Uploading model into container now
2025-03-29 16:57:49,706:INFO:_master_model_container: 10
2025-03-29 16:57:49,706:INFO:_display_container: 2
2025-03-29 16:57:49,706:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-03-29 16:57:49,706:INFO:create_model() successfully completed......................................
2025-03-29 16:57:49,898:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:49,898:INFO:Creating metrics dataframe
2025-03-29 16:57:49,904:INFO:Initializing K Neighbors Regressor
2025-03-29 16:57:49,904:INFO:Total runtime is 0.10288324356079102 minutes
2025-03-29 16:57:49,906:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:49,907:INFO:Initializing create_model()
2025-03-29 16:57:49,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:49,907:INFO:Checking exceptions
2025-03-29 16:57:49,907:INFO:Importing libraries
2025-03-29 16:57:49,907:INFO:Copying training dataset
2025-03-29 16:57:49,913:INFO:Defining folds
2025-03-29 16:57:49,913:INFO:Declaring metric variables
2025-03-29 16:57:49,916:INFO:Importing untrained model
2025-03-29 16:57:49,918:INFO:K Neighbors Regressor Imported successfully
2025-03-29 16:57:49,923:INFO:Starting cross validation
2025-03-29 16:57:49,924:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:50,657:INFO:Calculating mean and std
2025-03-29 16:57:50,658:INFO:Creating metrics dataframe
2025-03-29 16:57:50,659:INFO:Uploading results into container
2025-03-29 16:57:50,660:INFO:Uploading model into container now
2025-03-29 16:57:50,660:INFO:_master_model_container: 11
2025-03-29 16:57:50,660:INFO:_display_container: 2
2025-03-29 16:57:50,660:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-03-29 16:57:50,661:INFO:create_model() successfully completed......................................
2025-03-29 16:57:50,820:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:50,820:INFO:Creating metrics dataframe
2025-03-29 16:57:50,826:INFO:Initializing Decision Tree Regressor
2025-03-29 16:57:50,826:INFO:Total runtime is 0.11824824412663779 minutes
2025-03-29 16:57:50,827:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:50,827:INFO:Initializing create_model()
2025-03-29 16:57:50,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:50,828:INFO:Checking exceptions
2025-03-29 16:57:50,828:INFO:Importing libraries
2025-03-29 16:57:50,828:INFO:Copying training dataset
2025-03-29 16:57:50,835:INFO:Defining folds
2025-03-29 16:57:50,835:INFO:Declaring metric variables
2025-03-29 16:57:50,837:INFO:Importing untrained model
2025-03-29 16:57:50,840:INFO:Decision Tree Regressor Imported successfully
2025-03-29 16:57:50,843:INFO:Starting cross validation
2025-03-29 16:57:50,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:51,138:INFO:Calculating mean and std
2025-03-29 16:57:51,138:INFO:Creating metrics dataframe
2025-03-29 16:57:51,140:INFO:Uploading results into container
2025-03-29 16:57:51,141:INFO:Uploading model into container now
2025-03-29 16:57:51,141:INFO:_master_model_container: 12
2025-03-29 16:57:51,141:INFO:_display_container: 2
2025-03-29 16:57:51,141:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=453, splitter='best')
2025-03-29 16:57:51,142:INFO:create_model() successfully completed......................................
2025-03-29 16:57:51,307:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:51,307:INFO:Creating metrics dataframe
2025-03-29 16:57:51,313:INFO:Initializing Random Forest Regressor
2025-03-29 16:57:51,313:INFO:Total runtime is 0.1263657808303833 minutes
2025-03-29 16:57:51,315:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:51,315:INFO:Initializing create_model()
2025-03-29 16:57:51,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:51,315:INFO:Checking exceptions
2025-03-29 16:57:51,315:INFO:Importing libraries
2025-03-29 16:57:51,315:INFO:Copying training dataset
2025-03-29 16:57:51,322:INFO:Defining folds
2025-03-29 16:57:51,322:INFO:Declaring metric variables
2025-03-29 16:57:51,323:INFO:Importing untrained model
2025-03-29 16:57:51,326:INFO:Random Forest Regressor Imported successfully
2025-03-29 16:57:51,329:INFO:Starting cross validation
2025-03-29 16:57:51,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:57:57,496:INFO:Calculating mean and std
2025-03-29 16:57:57,498:INFO:Creating metrics dataframe
2025-03-29 16:57:57,499:INFO:Uploading results into container
2025-03-29 16:57:57,500:INFO:Uploading model into container now
2025-03-29 16:57:57,500:INFO:_master_model_container: 13
2025-03-29 16:57:57,500:INFO:_display_container: 2
2025-03-29 16:57:57,501:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=453, verbose=0, warm_start=False)
2025-03-29 16:57:57,501:INFO:create_model() successfully completed......................................
2025-03-29 16:57:57,727:INFO:SubProcess create_model() end ==================================
2025-03-29 16:57:57,727:INFO:Creating metrics dataframe
2025-03-29 16:57:57,736:INFO:Initializing Extra Trees Regressor
2025-03-29 16:57:57,736:INFO:Total runtime is 0.23342901468276978 minutes
2025-03-29 16:57:57,740:INFO:SubProcess create_model() called ==================================
2025-03-29 16:57:57,740:INFO:Initializing create_model()
2025-03-29 16:57:57,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:57:57,741:INFO:Checking exceptions
2025-03-29 16:57:57,741:INFO:Importing libraries
2025-03-29 16:57:57,741:INFO:Copying training dataset
2025-03-29 16:57:57,750:INFO:Defining folds
2025-03-29 16:57:57,750:INFO:Declaring metric variables
2025-03-29 16:57:57,753:INFO:Importing untrained model
2025-03-29 16:57:57,756:INFO:Extra Trees Regressor Imported successfully
2025-03-29 16:57:57,761:INFO:Starting cross validation
2025-03-29 16:57:57,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:58:01,634:INFO:Calculating mean and std
2025-03-29 16:58:01,635:INFO:Creating metrics dataframe
2025-03-29 16:58:01,636:INFO:Uploading results into container
2025-03-29 16:58:01,637:INFO:Uploading model into container now
2025-03-29 16:58:01,637:INFO:_master_model_container: 14
2025-03-29 16:58:01,637:INFO:_display_container: 2
2025-03-29 16:58:01,638:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=453, verbose=0, warm_start=False)
2025-03-29 16:58:01,638:INFO:create_model() successfully completed......................................
2025-03-29 16:58:01,823:INFO:SubProcess create_model() end ==================================
2025-03-29 16:58:01,823:INFO:Creating metrics dataframe
2025-03-29 16:58:01,829:INFO:Initializing AdaBoost Regressor
2025-03-29 16:58:01,829:INFO:Total runtime is 0.30164507230122883 minutes
2025-03-29 16:58:01,831:INFO:SubProcess create_model() called ==================================
2025-03-29 16:58:01,831:INFO:Initializing create_model()
2025-03-29 16:58:01,831:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:58:01,831:INFO:Checking exceptions
2025-03-29 16:58:01,831:INFO:Importing libraries
2025-03-29 16:58:01,831:INFO:Copying training dataset
2025-03-29 16:58:01,839:INFO:Defining folds
2025-03-29 16:58:01,839:INFO:Declaring metric variables
2025-03-29 16:58:01,841:INFO:Importing untrained model
2025-03-29 16:58:01,843:INFO:AdaBoost Regressor Imported successfully
2025-03-29 16:58:01,846:INFO:Starting cross validation
2025-03-29 16:58:01,848:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:58:02,707:INFO:Calculating mean and std
2025-03-29 16:58:02,708:INFO:Creating metrics dataframe
2025-03-29 16:58:02,709:INFO:Uploading results into container
2025-03-29 16:58:02,709:INFO:Uploading model into container now
2025-03-29 16:58:02,709:INFO:_master_model_container: 15
2025-03-29 16:58:02,709:INFO:_display_container: 2
2025-03-29 16:58:02,709:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=453)
2025-03-29 16:58:02,709:INFO:create_model() successfully completed......................................
2025-03-29 16:58:02,869:INFO:SubProcess create_model() end ==================================
2025-03-29 16:58:02,869:INFO:Creating metrics dataframe
2025-03-29 16:58:02,876:INFO:Initializing Gradient Boosting Regressor
2025-03-29 16:58:02,876:INFO:Total runtime is 0.31908801396687825 minutes
2025-03-29 16:58:02,877:INFO:SubProcess create_model() called ==================================
2025-03-29 16:58:02,878:INFO:Initializing create_model()
2025-03-29 16:58:02,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:58:02,878:INFO:Checking exceptions
2025-03-29 16:58:02,878:INFO:Importing libraries
2025-03-29 16:58:02,878:INFO:Copying training dataset
2025-03-29 16:58:02,885:INFO:Defining folds
2025-03-29 16:58:02,885:INFO:Declaring metric variables
2025-03-29 16:58:02,887:INFO:Importing untrained model
2025-03-29 16:58:02,890:INFO:Gradient Boosting Regressor Imported successfully
2025-03-29 16:58:02,894:INFO:Starting cross validation
2025-03-29 16:58:02,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:58:04,826:INFO:Calculating mean and std
2025-03-29 16:58:04,827:INFO:Creating metrics dataframe
2025-03-29 16:58:04,828:INFO:Uploading results into container
2025-03-29 16:58:04,828:INFO:Uploading model into container now
2025-03-29 16:58:04,829:INFO:_master_model_container: 16
2025-03-29 16:58:04,829:INFO:_display_container: 2
2025-03-29 16:58:04,830:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=453, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-29 16:58:04,830:INFO:create_model() successfully completed......................................
2025-03-29 16:58:04,997:INFO:SubProcess create_model() end ==================================
2025-03-29 16:58:04,997:INFO:Creating metrics dataframe
2025-03-29 16:58:05,003:INFO:Initializing Light Gradient Boosting Machine
2025-03-29 16:58:05,003:INFO:Total runtime is 0.35453532536824545 minutes
2025-03-29 16:58:05,005:INFO:SubProcess create_model() called ==================================
2025-03-29 16:58:05,005:INFO:Initializing create_model()
2025-03-29 16:58:05,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:58:05,006:INFO:Checking exceptions
2025-03-29 16:58:05,006:INFO:Importing libraries
2025-03-29 16:58:05,006:INFO:Copying training dataset
2025-03-29 16:58:05,012:INFO:Defining folds
2025-03-29 16:58:05,013:INFO:Declaring metric variables
2025-03-29 16:58:05,015:INFO:Importing untrained model
2025-03-29 16:58:05,017:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:58:05,021:INFO:Starting cross validation
2025-03-29 16:58:05,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:58:05,833:INFO:Calculating mean and std
2025-03-29 16:58:05,834:INFO:Creating metrics dataframe
2025-03-29 16:58:05,836:INFO:Uploading results into container
2025-03-29 16:58:05,836:INFO:Uploading model into container now
2025-03-29 16:58:05,836:INFO:_master_model_container: 17
2025-03-29 16:58:05,836:INFO:_display_container: 2
2025-03-29 16:58:05,836:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:58:05,836:INFO:create_model() successfully completed......................................
2025-03-29 16:58:06,031:INFO:SubProcess create_model() end ==================================
2025-03-29 16:58:06,031:INFO:Creating metrics dataframe
2025-03-29 16:58:06,037:INFO:Initializing Dummy Regressor
2025-03-29 16:58:06,037:INFO:Total runtime is 0.3717652877171834 minutes
2025-03-29 16:58:06,039:INFO:SubProcess create_model() called ==================================
2025-03-29 16:58:06,040:INFO:Initializing create_model()
2025-03-29 16:58:06,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F556530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:58:06,040:INFO:Checking exceptions
2025-03-29 16:58:06,040:INFO:Importing libraries
2025-03-29 16:58:06,040:INFO:Copying training dataset
2025-03-29 16:58:06,047:INFO:Defining folds
2025-03-29 16:58:06,048:INFO:Declaring metric variables
2025-03-29 16:58:06,049:INFO:Importing untrained model
2025-03-29 16:58:06,050:INFO:Dummy Regressor Imported successfully
2025-03-29 16:58:06,055:INFO:Starting cross validation
2025-03-29 16:58:06,057:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:58:06,268:INFO:Calculating mean and std
2025-03-29 16:58:06,269:INFO:Creating metrics dataframe
2025-03-29 16:58:06,271:INFO:Uploading results into container
2025-03-29 16:58:06,272:INFO:Uploading model into container now
2025-03-29 16:58:06,272:INFO:_master_model_container: 18
2025-03-29 16:58:06,273:INFO:_display_container: 2
2025-03-29 16:58:06,273:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-03-29 16:58:06,273:INFO:create_model() successfully completed......................................
2025-03-29 16:58:06,441:INFO:SubProcess create_model() end ==================================
2025-03-29 16:58:06,441:INFO:Creating metrics dataframe
2025-03-29 16:58:06,448:WARNING:c:\Users\vladk\anaconda3\envs\pycaret\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-29 16:58:06,453:INFO:Initializing create_model()
2025-03-29 16:58:06,453:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:58:06,453:INFO:Checking exceptions
2025-03-29 16:58:06,454:INFO:Importing libraries
2025-03-29 16:58:06,454:INFO:Copying training dataset
2025-03-29 16:58:06,462:INFO:Defining folds
2025-03-29 16:58:06,462:INFO:Declaring metric variables
2025-03-29 16:58:06,462:INFO:Importing untrained model
2025-03-29 16:58:06,462:INFO:Declaring custom model
2025-03-29 16:58:06,463:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:58:06,464:INFO:Cross validation set to False
2025-03-29 16:58:06,464:INFO:Fitting Model
2025-03-29 16:58:06,536:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:58:06,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-29 16:58:06,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:58:06,537:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:58:06,537:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 16:58:06,538:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 16:58:06,538:INFO:[LightGBM] [Info] Start training from score 3252.273902
2025-03-29 16:58:06,586:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:58:06,586:INFO:create_model() successfully completed......................................
2025-03-29 16:58:06,790:INFO:_master_model_container: 18
2025-03-29 16:58:06,790:INFO:_display_container: 2
2025-03-29 16:58:06,791:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:58:06,791:INFO:compare_models() successfully completed......................................
2025-03-29 16:58:06,803:INFO:Initializing evaluate_model()
2025-03-29 16:58:06,803:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-29 16:58:06,812:INFO:Initializing plot_model()
2025-03-29 16:58:06,813:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, system=True)
2025-03-29 16:58:06,813:INFO:Checking exceptions
2025-03-29 16:58:06,815:INFO:Preloading libraries
2025-03-29 16:58:06,818:INFO:Copying training dataset
2025-03-29 16:58:06,818:INFO:Plot type: pipeline
2025-03-29 16:58:06,898:INFO:Visual Rendered Successfully
2025-03-29 16:58:07,066:INFO:plot_model() successfully completed......................................
2025-03-29 16:58:07,082:INFO:Initializing tune_model()
2025-03-29 16:58:07,082:INFO:tune_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>)
2025-03-29 16:58:07,082:INFO:Checking exceptions
2025-03-29 16:58:07,095:INFO:Copying training dataset
2025-03-29 16:58:07,101:INFO:Checking base model
2025-03-29 16:58:07,101:INFO:Base model : Light Gradient Boosting Machine
2025-03-29 16:58:07,103:INFO:Declaring metric variables
2025-03-29 16:58:07,105:INFO:Defining Hyperparameters
2025-03-29 16:58:07,274:INFO:Tuning with n_jobs=-1
2025-03-29 16:58:07,274:INFO:Initializing RandomizedSearchCV
2025-03-29 16:58:22,965:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 20, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_split_gain': 0, 'actual_estimator__min_child_samples': 36, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.8}
2025-03-29 16:58:22,966:INFO:Hyperparameter search completed
2025-03-29 16:58:22,966:INFO:SubProcess create_model() called ==================================
2025-03-29 16:58:22,966:INFO:Initializing create_model()
2025-03-29 16:58:22,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E91F6465C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 0.005, 'num_leaves': 20, 'n_estimators': 280, 'min_split_gain': 0, 'min_child_samples': 36, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.8})
2025-03-29 16:58:22,966:INFO:Checking exceptions
2025-03-29 16:58:22,966:INFO:Importing libraries
2025-03-29 16:58:22,968:INFO:Copying training dataset
2025-03-29 16:58:22,976:INFO:Defining folds
2025-03-29 16:58:22,976:INFO:Declaring metric variables
2025-03-29 16:58:22,980:INFO:Importing untrained model
2025-03-29 16:58:22,980:INFO:Declaring custom model
2025-03-29 16:58:22,983:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:58:22,987:INFO:Starting cross validation
2025-03-29 16:58:22,988:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:58:24,560:INFO:Calculating mean and std
2025-03-29 16:58:24,561:INFO:Creating metrics dataframe
2025-03-29 16:58:24,565:INFO:Finalizing model
2025-03-29 16:58:24,657:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-03-29 16:58:24,657:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-03-29 16:58:24,657:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-03-29 16:58:24,669:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:58:24,669:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-03-29 16:58:24,669:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-03-29 16:58:24,669:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-03-29 16:58:24,670:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.
2025-03-29 16:58:24,670:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:58:24,670:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:58:24,670:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 16:58:24,670:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 16:58:24,671:INFO:[LightGBM] [Info] Start training from score 3252.273902
2025-03-29 16:58:24,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-29 16:58:24,819:INFO:Uploading results into container
2025-03-29 16:58:24,819:INFO:Uploading model into container now
2025-03-29 16:58:24,821:INFO:_master_model_container: 19
2025-03-29 16:58:24,821:INFO:_display_container: 3
2025-03-29 16:58:24,821:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
              importance_type='split', learning_rate=0.05, max_depth=-1,
              min_child_samples=36, min_child_weight=0.001, min_split_gain=0,
              n_estimators=280, n_jobs=-1, num_leaves=20, objective=None,
              random_state=453, reg_alpha=0.005, reg_lambda=0.4, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:58:24,822:INFO:create_model() successfully completed......................................
2025-03-29 16:58:25,018:INFO:SubProcess create_model() end ==================================
2025-03-29 16:58:25,018:INFO:choose_better activated
2025-03-29 16:58:25,021:INFO:SubProcess create_model() called ==================================
2025-03-29 16:58:25,022:INFO:Initializing create_model()
2025-03-29 16:58:25,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002E9203A06A0>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-29 16:58:25,022:INFO:Checking exceptions
2025-03-29 16:58:25,023:INFO:Importing libraries
2025-03-29 16:58:25,023:INFO:Copying training dataset
2025-03-29 16:58:25,030:INFO:Defining folds
2025-03-29 16:58:25,030:INFO:Declaring metric variables
2025-03-29 16:58:25,030:INFO:Importing untrained model
2025-03-29 16:58:25,030:INFO:Declaring custom model
2025-03-29 16:58:25,031:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-29 16:58:25,031:INFO:Starting cross validation
2025-03-29 16:58:25,032:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-29 16:58:25,910:INFO:Calculating mean and std
2025-03-29 16:58:25,910:INFO:Creating metrics dataframe
2025-03-29 16:58:25,912:INFO:Finalizing model
2025-03-29 16:58:26,009:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-29 16:58:26,010:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-03-29 16:58:26,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-29 16:58:26,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-29 16:58:26,011:INFO:[LightGBM] [Info] Total Bins 560
2025-03-29 16:58:26,011:INFO:[LightGBM] [Info] Number of data points in the train set: 33742, number of used features: 15
2025-03-29 16:58:26,011:INFO:[LightGBM] [Info] Start training from score 3252.273902
2025-03-29 16:58:26,075:INFO:Uploading results into container
2025-03-29 16:58:26,076:INFO:Uploading model into container now
2025-03-29 16:58:26,076:INFO:_master_model_container: 20
2025-03-29 16:58:26,076:INFO:_display_container: 4
2025-03-29 16:58:26,077:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:58:26,077:INFO:create_model() successfully completed......................................
2025-03-29 16:58:26,272:INFO:SubProcess create_model() end ==================================
2025-03-29 16:58:26,272:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.2175
2025-03-29 16:58:26,273:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
              importance_type='split', learning_rate=0.05, max_depth=-1,
              min_child_samples=36, min_child_weight=0.001, min_split_gain=0,
              n_estimators=280, n_jobs=-1, num_leaves=20, objective=None,
              random_state=453, reg_alpha=0.005, reg_lambda=0.4, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.2164
2025-03-29 16:58:26,274:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-03-29 16:58:26,274:INFO:choose_better completed
2025-03-29 16:58:26,274:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-29 16:58:26,280:INFO:_master_model_container: 20
2025-03-29 16:58:26,280:INFO:_display_container: 3
2025-03-29 16:58:26,280:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-03-29 16:58:26,280:INFO:tune_model() successfully completed......................................
2025-03-29 16:58:26,467:INFO:Initializing save_model()
2025-03-29 16:58:26,467:INFO:save_model(model=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=453, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), model_name=traffic_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\vladk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_i...
                                    include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-29 16:58:26,468:INFO:Adding model into prep_pipe
2025-03-29 16:58:26,476:INFO:traffic_model.pkl saved in current working directory
2025-03-29 16:58:26,482:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,...
                 LGBMRegressor(boosting_type='gbdt', class_weight=None,
                               colsample_bytree=1.0, importance_type='split',
                               learning_rate=0.1, max_depth=-1,
                               min_child_samples=20, min_child_weight=0.001,
                               min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                               num_leaves=31, objective=None, random_state=453,
                               reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                               subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-03-29 16:58:26,483:INFO:save_model() successfully completed......................................
2025-03-29 17:01:34,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 17:01:34,537:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 17:01:34,537:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 17:01:34,537:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 17:01:36,524:INFO:Initializing load_model()
2025-03-29 17:01:36,525:INFO:load_model(model_name=traffic_classification_model, platform=None, authentication=None, verbose=True)
2025-03-29 17:02:56,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 17:02:56,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 17:02:56,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 17:02:56,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-29 17:02:58,880:INFO:Initializing load_model()
2025-03-29 17:02:58,880:INFO:load_model(model_name=traffic_model, platform=None, authentication=None, verbose=True)
2025-03-29 17:02:58,942:INFO:Initializing predict_model()
2025-03-29 17:02:58,942:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000174D5DCC430>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=453))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000174D60FA200>)
2025-03-29 17:02:58,944:INFO:Checking exceptions
2025-03-29 17:02:58,944:INFO:Preloading libraries
2025-03-29 17:02:58,944:INFO:Set up data.
2025-03-29 17:02:58,955:INFO:Set up index.
